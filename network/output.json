[{"layer_params": [31, 48, 34], "learning_rate": 0.0003725633921667208, "batch_size": 475, "loss": 0.007303595175035298}, {"layer_params": [44, 60, 58, 54, 51], "learning_rate": 0.0074311709795061185, "batch_size": 354, "loss": 0.001101273968233727}, {"layer_params": [54, 46, 61], "learning_rate": 0.00855631440385206, "batch_size": 462, "loss": 0.0007906805776292459}, {"layer_params": [57, 31, 48, 19], "learning_rate": 0.0014026488272391917, "batch_size": 384, "loss": 0.0020922199042979627}, {"layer_params": [57, 46], "learning_rate": 0.006641612675683654, "batch_size": 356, "loss": 0.001278438774170354}, {"layer_params": [35, 43], "learning_rate": 0.005480157356185176, "batch_size": 29, "loss": 0.003663338037440553}, {"layer_params": [39, 36, 50, 37, 58], "learning_rate": 0.004180039952512889, "batch_size": 314, "loss": 0.0010697441903175786}, {"layer_params": [47, 16, 44, 62, 47], "learning_rate": 0.008542761573141556, "batch_size": 508, "loss": 0.002355797920608893}, {"layer_params": [52, 37, 35, 47, 63], "learning_rate": 0.007503910072743161, "batch_size": 394, "loss": 0.002068652481539175}, {"layer_params": [61, 17, 32, 25], "learning_rate": 0.007166485025895001, "batch_size": 74, "loss": 0.0027242799126543107}, {"layer_params": [50, 36, 40], "learning_rate": 0.00962089266498597, "batch_size": 82, "loss": 0.0025834598555229604}, {"layer_params": [54, 61], "learning_rate": 0.006344571781346023, "batch_size": 357, "loss": 0.0011980783508624881}, {"layer_params": [58, 58, 46], "learning_rate": 0.0033371220251460663, "batch_size": 152, "loss": 0.0017622395884245635}, {"layer_params": [55, 31, 62, 36, 55], "learning_rate": 0.0019215576346979896, "batch_size": 494, "loss": 0.0018249640800058842}, {"layer_params": [47, 33, 48, 59], "learning_rate": 0.006428827364857461, "batch_size": 165, "loss": 0.0021500139590352775}, {"layer_params": [61, 42, 31, 16, 54], "learning_rate": 0.0055529993731295735, "batch_size": 348, "loss": 0.001619926504790783}, {"layer_params": [17, 48, 58], "learning_rate": 0.003899198774859602, "batch_size": 500, "loss": 0.0019412732042837888}, {"layer_params": [38, 50, 45, 20, 31], "learning_rate": 0.00949174766638012, "batch_size": 188, "loss": 0.0022351369995158164}, {"layer_params": [58, 40, 58, 44, 26], "learning_rate": 0.005868143308435923, "batch_size": 52, "loss": 0.002740035630995408}, {"layer_params": [43, 26, 43, 49], "learning_rate": 0.0039041599370950785, "batch_size": 69, "loss": 0.003674085424281657}, {"layer_params": [19, 17, 25, 27, 41], "learning_rate": 0.001873439603857253, "batch_size": 230, "loss": 0.005557211986742913}, {"layer_params": [59, 59], "learning_rate": 0.0023863113216615025, "batch_size": 313, "loss": 0.001950532189803198}, {"layer_params": [20, 28, 59, 29, 34], "learning_rate": 0.008767202812102215, "batch_size": 148, "loss": 0.002461611806647852}, {"layer_params": [49, 29, 20, 22, 56], "learning_rate": 0.008216365209788825, "batch_size": 31, "loss": 0.00552977530984208}, {"layer_params": [59, 55, 31, 41], "learning_rate": 0.007585655907382147, "batch_size": 290, "loss": 0.0010193080233875662}, {"layer_params": [25, 32, 62, 48, 21], "learning_rate": 0.0015007755664374948, "batch_size": 350, "loss": 0.0023034607130102813}, {"layer_params": [21, 18, 39], "learning_rate": 0.008762666619713, "batch_size": 512, "loss": 0.0029824047232978046}, {"layer_params": [61, 19, 64, 32, 22], "learning_rate": 0.007504760003784715, "batch_size": 491, "loss": 0.0009888508747098968}, {"layer_params": [22, 18], "learning_rate": 0.00937954978539501, "batch_size": 464, "loss": 0.0020404842658899723}, {"layer_params": [30, 46], "learning_rate": 0.004928069067199647, "batch_size": 101, "loss": 0.004133929663803429}, {"layer_params": [21, 64], "learning_rate": 0.009500579386570803, "batch_size": 304, "loss": 0.0023026900249533354}, {"layer_params": [24, 40, 32, 16], "learning_rate": 0.005206229923318905, "batch_size": 109, "loss": 0.004149725988972932}, {"layer_params": [17, 30, 17, 16, 25], "learning_rate": 0.0005704605895983151, "batch_size": 256, "loss": 0.006266695582307875}, {"layer_params": [42, 23, 37], "learning_rate": 0.008371889485073723, "batch_size": 138, "loss": 0.0029932845057919623}, {"layer_params": [58, 30], "learning_rate": 0.0014661257837247108, "batch_size": 178, "loss": 0.0024960148776881396}, {"layer_params": [43, 18, 64, 64], "learning_rate": 0.005618520960929293, "batch_size": 99, "loss": 0.003889015035238117}, {"layer_params": [42, 16, 31], "learning_rate": 0.00520371039120306, "batch_size": 240, "loss": 0.002590365360956639}, {"layer_params": [47, 54], "learning_rate": 0.0034611332020558156, "batch_size": 327, "loss": 0.0024518912448547783}, {"layer_params": [28, 30, 52, 22, 56], "learning_rate": 0.007219024044771493, "batch_size": 158, "loss": 0.0022748105786740778}, {"layer_params": [27, 26], "learning_rate": 0.005959560634208839, "batch_size": 385, "loss": 0.0025898926262743773}, {"layer_params": [31, 62, 28, 38], "learning_rate": 0.009516206322545788, "batch_size": 500, "loss": 0.001637418691534549}, {"layer_params": [22, 51, 33, 61, 31], "learning_rate": 0.005977562380261152, "batch_size": 443, "loss": 0.0014135747868567706}, {"layer_params": [56, 33], "learning_rate": 0.0018480319980226118, "batch_size": 96, "loss": 0.0030307134403847157}, {"layer_params": [59, 27, 47], "learning_rate": 0.002345862602118524, "batch_size": 466, "loss": 0.0013841791870072484}, {"layer_params": [34, 64, 19, 56], "learning_rate": 0.008665297750148586, "batch_size": 79, "loss": 0.003097961647436023}, {"layer_params": [33, 58], "learning_rate": 0.008673221429235515, "batch_size": 512, "loss": 0.0016251818765886127}, {"layer_params": [23, 55, 19, 48, 30], "learning_rate": 0.008925445069606753, "batch_size": 301, "loss": 0.0017282472224906086}, {"layer_params": [18, 51, 41], "learning_rate": 0.0020249228964206675, "batch_size": 375, "loss": 0.0030862952838651837}, {"layer_params": [54, 29, 50, 57, 51], "learning_rate": 0.007435428636094626, "batch_size": 112, "loss": 0.0023177098343148826}, {"layer_params": [28, 16, 38, 22, 52], "learning_rate": 0.009173145042352508, "batch_size": 148, "loss": 0.0035925550502724944}, {"layer_params": [20, 42, 36, 23, 30], "learning_rate": 0.0012040008343699182, "batch_size": 305, "loss": 0.004193398721981794}, {"layer_params": [34, 53, 18, 47], "learning_rate": 0.009113788577826815, "batch_size": 128, "loss": 0.0035943416552618145}, {"layer_params": [34, 19], "learning_rate": 0.009458097640010942, "batch_size": 328, "loss": 0.003309284106362611}, {"layer_params": [40, 28, 22, 43], "learning_rate": 0.006999864290785692, "batch_size": 78, "loss": 0.003970294429454953}, {"layer_params": [28, 37], "learning_rate": 0.007257944102141816, "batch_size": 305, "loss": 0.002453470182372257}, {"layer_params": [40, 21], "learning_rate": 0.0014983516892807538, "batch_size": 143, "loss": 0.004400184366386384}, {"layer_params": [39, 21, 20, 56, 45], "learning_rate": 0.001231335215145088, "batch_size": 209, "loss": 0.003716540508903563}, {"layer_params": [27, 49, 51, 33], "learning_rate": 0.003297904054068228, "batch_size": 23, "loss": 0.007397323744371533}, {"layer_params": [17, 36, 37, 42], "learning_rate": 0.0034165821630987663, "batch_size": 357, "loss": 0.002023044130764902}, {"layer_params": [44, 48], "learning_rate": 0.005480624986435366, "batch_size": 120, "loss": 0.0019264761568047106}, {"layer_params": [57, 18, 26, 62, 34], "learning_rate": 0.007281825169161305, "batch_size": 436, "loss": 0.0008889965782873332}, {"layer_params": [47, 62, 35, 32, 50], "learning_rate": 0.004883715823251664, "batch_size": 233, "loss": 0.0014259569207206368}, {"layer_params": [55, 59], "learning_rate": 0.007762267111038594, "batch_size": 83, "loss": 0.002239367273868993}, {"layer_params": [19, 20, 32, 62, 45], "learning_rate": 0.008855172353023629, "batch_size": 232, "loss": 0.004131731418892741}, {"layer_params": [31, 29, 61, 56], "learning_rate": 0.008705725517864542, "batch_size": 437, "loss": 0.0019412179628852755}, {"layer_params": [33, 62, 57], "learning_rate": 0.002410330770040666, "batch_size": 218, "loss": 0.001503366983961314}, {"layer_params": [61, 18], "learning_rate": 0.003978056563513553, "batch_size": 109, "loss": 0.004847197192721069}, {"layer_params": [31, 29, 16], "learning_rate": 0.0005973147737618261, "batch_size": 56, "loss": 0.008155587632209062}, {"layer_params": [63, 42, 25, 47, 43], "learning_rate": 0.003754289712089301, "batch_size": 172, "loss": 0.0020964795420877636}, {"layer_params": [58, 42, 23, 32], "learning_rate": 0.0031719299054754255, "batch_size": 277, "loss": 0.001519788351142779}, {"layer_params": [31, 42], "learning_rate": 0.003546524623844629, "batch_size": 355, "loss": 0.002266038915840909}, {"layer_params": [28, 36], "learning_rate": 0.00838221086852086, "batch_size": 237, "loss": 0.004378849393688143}, {"layer_params": [32, 39, 55], "learning_rate": 0.0008016187004722745, "batch_size": 78, "loss": 0.006556505430489778}, {"layer_params": [61, 41, 54, 33, 57], "learning_rate": 0.008830001923750693, "batch_size": 402, "loss": 0.0017623814835678786}, {"layer_params": [53, 23, 28], "learning_rate": 0.0021892277794465544, "batch_size": 251, "loss": 0.0044556206907145676}, {"layer_params": [57, 42, 34, 33, 52], "learning_rate": 0.0028730801979356788, "batch_size": 447, "loss": 0.0015373525174800307}, {"layer_params": [55, 38, 40, 51], "learning_rate": 0.009662653310857435, "batch_size": 461, "loss": 0.002091837846674025}, {"layer_params": [62, 54, 38], "learning_rate": 0.006701764821405076, "batch_size": 98, "loss": 0.001938502889825031}, {"layer_params": [52, 39, 59], "learning_rate": 0.009131897438280294, "batch_size": 227, "loss": 0.0011299434409011155}, {"layer_params": [59, 55], "learning_rate": 0.0062537757192746525, "batch_size": 289, "loss": 0.0012787628814112395}, {"layer_params": [58, 54, 35], "learning_rate": 0.0009204152086310908, "batch_size": 439, "loss": 0.0019623748632147907}, {"layer_params": [29, 20, 40, 22, 55], "learning_rate": 0.0013699060060112331, "batch_size": 325, "loss": 0.003977500761393458}, {"layer_params": [54, 41], "learning_rate": 0.001072565456518762, "batch_size": 309, "loss": 0.003320292406715453}, {"layer_params": [57, 26, 22], "learning_rate": 0.005769291374304847, "batch_size": 419, "loss": 0.0030382898659445344}, {"layer_params": [28, 35, 19, 57, 22], "learning_rate": 0.009278045621572346, "batch_size": 158, "loss": 0.0026819031592458485}, {"layer_params": [18, 62, 51, 36, 63], "learning_rate": 0.0011508179884148417, "batch_size": 187, "loss": 0.004715397022664547}, {"layer_params": [54, 44, 19, 48, 58], "learning_rate": 0.0010635527654264375, "batch_size": 197, "loss": 0.002804402807960287}, {"layer_params": [41, 24], "learning_rate": 0.009734638342529004, "batch_size": 25, "loss": 0.008158892788924278}, {"layer_params": [21, 39, 23], "learning_rate": 0.003645769207398987, "batch_size": 351, "loss": 0.003484910735860467}, {"layer_params": [50, 53, 64, 26], "learning_rate": 0.003672841937189066, "batch_size": 241, "loss": 0.0013375964394072072}, {"layer_params": [24, 20, 29], "learning_rate": 0.006226344288833726, "batch_size": 498, "loss": 0.0028160056890919804}, {"layer_params": [57, 36], "learning_rate": 0.007479241196888107, "batch_size": 309, "loss": 0.0024266752845142035}, {"layer_params": [50, 37, 48], "learning_rate": 0.0028581901037916034, "batch_size": 436, "loss": 0.001214533515740186}, {"layer_params": [55, 28, 23, 59, 52], "learning_rate": 0.0004856221772395904, "batch_size": 180, "loss": 0.0036131211183965204}, {"layer_params": [19, 27, 40, 16], "learning_rate": 0.007994742197996113, "batch_size": 385, "loss": 0.0022836212429683655}, {"layer_params": [62, 25, 28, 59], "learning_rate": 0.002217224119661956, "batch_size": 166, "loss": 0.0030192669807001947}, {"layer_params": [30, 22, 34, 55, 46], "learning_rate": 0.0030355858877265064, "batch_size": 17, "loss": 0.008454071823507547}, {"layer_params": [33, 64, 52], "learning_rate": 0.0010795286341624545, "batch_size": 352, "loss": 0.0027187465876340865}, {"layer_params": [34, 61, 27, 55, 64], "learning_rate": 0.008169095044333956, "batch_size": 344, "loss": 0.001386184450238943}, {"layer_params": [49, 24, 40, 56, 19], "learning_rate": 0.005022245148630248, "batch_size": 325, "loss": 0.0018068123457487672}, {"layer_params": [23, 27, 20], "learning_rate": 0.00046568507933628475, "batch_size": 471, "loss": 0.006551644252613187}, {"layer_params": [42, 21, 64], "learning_rate": 0.009977335628978424, "batch_size": 81, "loss": 0.0037448986864183098}, {"layer_params": [24, 32, 56, 17], "learning_rate": 0.008268896601814103, "batch_size": 197, "loss": 0.0034030010947026313}, {"layer_params": [41, 56], "learning_rate": 0.0004177199087086911, "batch_size": 473, "loss": 0.007513791671954095}, {"layer_params": [36, 34, 43], "learning_rate": 0.0067764353991117575, "batch_size": 77, "loss": 0.003875664258375764}, {"layer_params": [40, 25, 48, 32, 22], "learning_rate": 0.0031327758020388537, "batch_size": 212, "loss": 0.004095507927704602}, {"layer_params": [23, 19, 35, 43], "learning_rate": 0.005604588715342608, "batch_size": 379, "loss": 0.001882086576661095}, {"layer_params": [58, 57, 17, 37], "learning_rate": 0.0008127129813868761, "batch_size": 445, "loss": 0.0024662411771714686}, {"layer_params": [63, 30], "learning_rate": 0.005522574607471877, "batch_size": 51, "loss": 0.004809775506146252}, {"layer_params": [59, 61, 38, 36, 39], "learning_rate": 0.0016802953492004232, "batch_size": 510, "loss": 0.0011752718721982091}, {"layer_params": [51, 58, 33], "learning_rate": 0.00653365717108801, "batch_size": 208, "loss": 0.0014659624744672328}, {"layer_params": [62, 49, 51], "learning_rate": 0.008745005019250157, "batch_size": 217, "loss": 0.0011511414748383686}, {"layer_params": [59, 60, 27], "learning_rate": 0.0038713984341713146, "batch_size": 186, "loss": 0.0013410685484996066}, {"layer_params": [54, 19, 37, 31], "learning_rate": 7.80196948071322e-05, "batch_size": 509, "loss": 0.014259486887603999}, {"layer_params": [24, 24], "learning_rate": 0.0025105509069899643, "batch_size": 379, "loss": 0.004911325285211206}, {"layer_params": [58, 19], "learning_rate": 0.008329292809439795, "batch_size": 218, "loss": 0.002459185515763238}, {"layer_params": [59, 30], "learning_rate": 0.0010142738037074545, "batch_size": 174, "loss": 0.003977990155108273}, {"layer_params": [53, 40, 39], "learning_rate": 0.0029346928388156884, "batch_size": 215, "loss": 0.0018750780646223575}, {"layer_params": [24, 35, 28, 40, 50], "learning_rate": 0.0010131330094324683, "batch_size": 398, "loss": 0.004501973171718418}, {"layer_params": [59, 62, 52, 31, 20], "learning_rate": 0.008851687054215152, "batch_size": 304, "loss": 0.0021030569833237677}, {"layer_params": [45, 63], "learning_rate": 0.008815794451277606, "batch_size": 209, "loss": 0.0017205052345525473}, {"layer_params": [33, 30, 56, 18, 57], "learning_rate": 0.00582621362951402, "batch_size": 306, "loss": 0.0013513028412126004}, {"layer_params": [37, 63], "learning_rate": 0.006384571357665241, "batch_size": 170, "loss": 0.002249966817907989}, {"layer_params": [29, 28, 19, 38, 17], "learning_rate": 0.0025432417365934116, "batch_size": 316, "loss": 0.003625102024525404}, {"layer_params": [36, 48, 30, 48, 60], "learning_rate": 0.0023540111296410085, "batch_size": 300, "loss": 0.0016981180489528925}, {"layer_params": [44, 20], "learning_rate": 0.0015124358772158693, "batch_size": 41, "loss": 0.007451566380914301}, {"layer_params": [39, 39, 49, 20], "learning_rate": 0.0041556777145723275, "batch_size": 398, "loss": 0.0016659502079710365}, {"layer_params": [24, 35, 38], "learning_rate": 0.00011262365197353425, "batch_size": 129, "loss": 0.031164876371622085}, {"layer_params": [59, 58, 17, 22], "learning_rate": 0.0007231137547135216, "batch_size": 39, "loss": 0.006369463605806231}, {"layer_params": [23, 50], "learning_rate": 0.008608575611963534, "batch_size": 223, "loss": 0.00465228697983548}, {"layer_params": [40, 32, 61, 35, 60], "learning_rate": 0.00949272205394252, "batch_size": 446, "loss": 0.0017733660887461157}, {"layer_params": [46, 46], "learning_rate": 0.004805022080207347, "batch_size": 340, "loss": 0.002052307053236291}, {"layer_params": [60, 23, 30, 34, 52], "learning_rate": 0.0012676010123345402, "batch_size": 424, "loss": 0.0027200935967266558}, {"layer_params": [36, 30], "learning_rate": 0.007078934854236579, "batch_size": 150, "loss": 0.004208278665319085}, {"layer_params": [26, 17, 56], "learning_rate": 0.006096393680479977, "batch_size": 259, "loss": 0.003042663743253797}, {"layer_params": [25, 21, 32], "learning_rate": 0.00182721200490646, "batch_size": 412, "loss": 0.0027644168306142094}, {"layer_params": [60, 61], "learning_rate": 0.00681134156753728, "batch_size": 220, "loss": 0.001162000370095484}, {"layer_params": [16, 19], "learning_rate": 0.008985335620394441, "batch_size": 39, "loss": 0.00852198054548353}, {"layer_params": [21, 32, 35], "learning_rate": 0.003299526645390791, "batch_size": 225, "loss": 0.00393241192214191}, {"layer_params": [20, 56, 64, 61, 29], "learning_rate": 0.0073503501527552246, "batch_size": 141, "loss": 0.0034051429806277156}, {"layer_params": [42, 45, 17, 35, 26], "learning_rate": 0.004321234076354584, "batch_size": 130, "loss": 0.0023037050117272885}, {"layer_params": [28, 22, 48, 25, 57], "learning_rate": 0.0014755798801256703, "batch_size": 117, "loss": 0.006193614490330219}, {"layer_params": [19, 60, 34], "learning_rate": 0.00435574649069728, "batch_size": 270, "loss": 0.0022568802384193985}, {"layer_params": [50, 24, 40], "learning_rate": 0.0035962511639982824, "batch_size": 238, "loss": 0.002494904880877584}, {"layer_params": [31, 46], "learning_rate": 0.007624161298540904, "batch_size": 168, "loss": 0.0022360889601986855}, {"layer_params": [17, 32, 64], "learning_rate": 0.0024879193123531003, "batch_size": 80, "loss": 0.004511565605644137}, {"layer_params": [19, 64, 59], "learning_rate": 0.007209697650499662, "batch_size": 333, "loss": 0.0021142098400741814}, {"layer_params": [58, 46, 31], "learning_rate": 0.003468676271575365, "batch_size": 287, "loss": 0.0016318512067664416}, {"layer_params": [45, 50, 24], "learning_rate": 0.0074822834625797, "batch_size": 32, "loss": 0.00598497869214043}, {"layer_params": [17, 31, 61, 41, 21], "learning_rate": 0.003439030627682966, "batch_size": 186, "loss": 0.002858940858859569}, {"layer_params": [42, 33, 25], "learning_rate": 0.006654290637297114, "batch_size": 277, "loss": 0.001354588280664757}, {"layer_params": [47, 56], "learning_rate": 0.008113572199570198, "batch_size": 510, "loss": 0.0015687969257123769}, {"layer_params": [22, 30], "learning_rate": 0.004386039306042567, "batch_size": 285, "loss": 0.0032975464104674757}, {"layer_params": [21, 24, 61, 19, 54], "learning_rate": 0.006320294538461152, "batch_size": 161, "loss": 0.0024501234176568685}, {"layer_params": [53, 16, 37, 30, 29], "learning_rate": 0.00434987615456461, "batch_size": 450, "loss": 0.0028934907633811234}, {"layer_params": [60, 56, 64, 47], "learning_rate": 0.00942724422722353, "batch_size": 30, "loss": 0.004954952497500926}, {"layer_params": [16, 24, 60], "learning_rate": 0.008689775426005153, "batch_size": 249, "loss": 0.0023107457370497284}, {"layer_params": [57, 32, 61, 54], "learning_rate": 0.009705600670342249, "batch_size": 476, "loss": 0.0008947186713339761}, {"layer_params": [49, 30, 59, 21, 27], "learning_rate": 0.0027579321109619686, "batch_size": 63, "loss": 0.004771331646479666}, {"layer_params": [60, 23, 61, 45, 63], "learning_rate": 0.0037833569823215256, "batch_size": 200, "loss": 0.0033195168315432967}, {"layer_params": [48, 46, 50, 40], "learning_rate": 0.009076459743088044, "batch_size": 484, "loss": 0.0014057838229928166}, {"layer_params": [37, 53], "learning_rate": 0.006430089664916546, "batch_size": 133, "loss": 0.0019503333908505738}, {"layer_params": [53, 52, 45, 26], "learning_rate": 0.006783744563323453, "batch_size": 213, "loss": 0.0013215567654697225}, {"layer_params": [34, 46], "learning_rate": 0.0028780711056843257, "batch_size": 226, "loss": 0.0034260444762185217}, {"layer_params": [36, 22, 18], "learning_rate": 0.002666059466438436, "batch_size": 233, "loss": 0.0026937574543990195}, {"layer_params": [33, 31, 16], "learning_rate": 0.00837328118711669, "batch_size": 309, "loss": 0.002941851606592536}, {"layer_params": [55, 26, 24], "learning_rate": 0.0012712655157463785, "batch_size": 491, "loss": 0.00309820698807016}, {"layer_params": [31, 28], "learning_rate": 0.002419224477925825, "batch_size": 305, "loss": 0.002202020643744618}, {"layer_params": [19, 20, 41, 50], "learning_rate": 0.00784120817321308, "batch_size": 31, "loss": 0.00823893084190786}, {"layer_params": [49, 44, 27, 47, 20], "learning_rate": 0.0026927624661168986, "batch_size": 428, "loss": 0.0015012509014923126}, {"layer_params": [48, 36, 19], "learning_rate": 0.009423321337144375, "batch_size": 129, "loss": 0.0013640272634802386}, {"layer_params": [41, 40], "learning_rate": 0.00989492487455525, "batch_size": 353, "loss": 0.001913871142314747}, {"layer_params": [41, 24], "learning_rate": 0.007811500528446782, "batch_size": 505, "loss": 0.002265199355315417}, {"layer_params": [46, 37, 22, 54, 20], "learning_rate": 0.006780361967303081, "batch_size": 150, "loss": 0.0016936532652471214}, {"layer_params": [21, 51], "learning_rate": 0.0028081818928363516, "batch_size": 220, "loss": 0.004326407455373556}, {"layer_params": [21, 61, 60], "learning_rate": 0.002220054787137699, "batch_size": 159, "loss": 0.0025528645748272537}, {"layer_params": [47, 61, 23], "learning_rate": 0.0012295325950567153, "batch_size": 70, "loss": 0.005106071280315518}, {"layer_params": [40, 36, 36], "learning_rate": 0.0009318356347580728, "batch_size": 400, "loss": 0.003329237650614232}, {"layer_params": [46, 36], "learning_rate": 0.0016800749604576615, "batch_size": 476, "loss": 0.0033766192104667425}, {"layer_params": [34, 53], "learning_rate": 0.006727956426011078, "batch_size": 327, "loss": 0.0038228886388242244}, {"layer_params": [20, 32, 40, 17, 54], "learning_rate": 0.00674333507154841, "batch_size": 333, "loss": 0.0034316519275307657}, {"layer_params": [61, 35, 60], "learning_rate": 0.008472738335492015, "batch_size": 205, "loss": 0.0015522891958244145}, {"layer_params": [29, 44, 28, 52, 39], "learning_rate": 0.0029610838453907316, "batch_size": 389, "loss": 0.001989752878434956}, {"layer_params": [33, 22, 17, 46], "learning_rate": 0.004129106055499401, "batch_size": 67, "loss": 0.002892387700267136}, {"layer_params": [34, 41, 24, 44, 17], "learning_rate": 0.002459418988462638, "batch_size": 406, "loss": 0.0014810994814615697}, {"layer_params": [32, 36], "learning_rate": 0.005825496405630645, "batch_size": 453, "loss": 0.002738831168971956}, {"layer_params": [64, 37, 27], "learning_rate": 0.0035641639630972425, "batch_size": 107, "loss": 0.003017754778265953}, {"layer_params": [44, 25, 26, 54, 53], "learning_rate": 0.005560625969627615, "batch_size": 468, "loss": 0.0020925225911196323}, {"layer_params": [32, 32], "learning_rate": 0.0008081667552242787, "batch_size": 66, "loss": 0.008264772975817323}, {"layer_params": [32, 51, 63, 60], "learning_rate": 0.007289770415894218, "batch_size": 496, "loss": 0.0011608447140315547}, {"layer_params": [45, 36], "learning_rate": 0.00234865194773689, "batch_size": 168, "loss": 0.003706487789750099}, {"layer_params": [27, 62, 35], "learning_rate": 0.004454004434777517, "batch_size": 286, "loss": 0.0022156909864861516}, {"layer_params": [26, 16, 51, 46, 45], "learning_rate": 0.000646946410279236, "batch_size": 211, "loss": 0.006311123082414269}, {"layer_params": [60, 28, 18], "learning_rate": 0.006815665111083941, "batch_size": 380, "loss": 0.0014381087198853493}, {"layer_params": [51, 45, 44, 43, 41], "learning_rate": 0.005546708467832561, "batch_size": 189, "loss": 0.0012386793742189183}, {"layer_params": [53, 25, 59], "learning_rate": 0.0027498105267000717, "batch_size": 228, "loss": 0.0018474401684943588}, {"layer_params": [33, 58, 54, 30], "learning_rate": 0.0011782964460249575, "batch_size": 224, "loss": 0.0033557528303936124}, {"layer_params": [26, 38, 23], "learning_rate": 0.007331287394105755, "batch_size": 366, "loss": 0.0024187462916597726}, {"layer_params": [30, 34], "learning_rate": 0.00784563957603907, "batch_size": 202, "loss": 0.0020143338420893996}, {"layer_params": [42, 30], "learning_rate": 0.009056836939216955, "batch_size": 29, "loss": 0.005947447936050594}, {"layer_params": [23, 50, 18], "learning_rate": 0.007850564293660314, "batch_size": 402, "loss": 0.002646524719893932}, {"layer_params": [31, 48, 43, 59], "learning_rate": 0.000595329803070184, "batch_size": 320, "loss": 0.005935228080488741}, {"layer_params": [42, 36, 20, 26], "learning_rate": 1.731418351985273e-05, "batch_size": 27, "loss": 0.13916629195213318}, {"layer_params": [44, 52, 49, 34, 22], "learning_rate": 0.008056392948222618, "batch_size": 239, "loss": 0.0015284483367577195}, {"layer_params": [64, 29, 43, 32], "learning_rate": 0.006078633965602191, "batch_size": 462, "loss": 0.00165382873499766}, {"layer_params": [31, 30], "learning_rate": 0.0033130540844828397, "batch_size": 188, "loss": 0.0038968220376409592}, {"layer_params": [55, 61, 19, 41, 54], "learning_rate": 0.00806073372530582, "batch_size": 409, "loss": 0.0007968761533265934}, {"layer_params": [32, 20, 55, 44, 44], "learning_rate": 0.003795529570050107, "batch_size": 206, "loss": 0.0023038612480740994}, {"layer_params": [49, 35, 45], "learning_rate": 0.0055651328158957914, "batch_size": 502, "loss": 0.0012057059037033468}, {"layer_params": [22, 35, 42], "learning_rate": 0.009205623448805184, "batch_size": 424, "loss": 0.00149727295152843}, {"layer_params": [19, 32, 57, 27, 49], "learning_rate": 0.0037400918596281695, "batch_size": 257, "loss": 0.0026997383031994106}, {"layer_params": [38, 49, 22, 19], "learning_rate": 0.0084739856791845, "batch_size": 388, "loss": 0.0020019864931236954}, {"layer_params": [64, 34, 38, 22, 24], "learning_rate": 0.00011347434028183512, "batch_size": 303, "loss": 0.02246677864342928}, {"layer_params": [53, 62], "learning_rate": 0.00911237392684139, "batch_size": 444, "loss": 0.0011257534829201177}, {"layer_params": [51, 24, 60, 16, 18], "learning_rate": 0.0020176161935333958, "batch_size": 216, "loss": 0.002389212816487998}, {"layer_params": [34, 16, 28, 24], "learning_rate": 0.0022639103202094397, "batch_size": 284, "loss": 0.003232536178547889}, {"layer_params": [31, 23, 61, 48], "learning_rate": 0.0014739026466802627, "batch_size": 410, "loss": 0.0032928532571531834}, {"layer_params": [16, 47, 28], "learning_rate": 0.005754109005554688, "batch_size": 64, "loss": 0.005557551861274987}, {"layer_params": [17, 16, 40, 41], "learning_rate": 0.009511698545688268, "batch_size": 154, "loss": 0.00416159207932651}, {"layer_params": [29, 33, 63, 48, 61], "learning_rate": 0.00624722051223756, "batch_size": 48, "loss": 0.00602270542876795}, {"layer_params": [33, 45, 61], "learning_rate": 0.009487024960034287, "batch_size": 423, "loss": 0.001526646031998098}, {"layer_params": [49, 34, 35, 46, 46], "learning_rate": 0.001933208064882925, "batch_size": 255, "loss": 0.0020152243040502072}, {"layer_params": [30, 35, 38], "learning_rate": 0.007274043033097004, "batch_size": 480, "loss": 0.0016147774423006921}, {"layer_params": [22, 31, 52], "learning_rate": 0.005759243091299027, "batch_size": 490, "loss": 0.0012088709755335002}, {"layer_params": [32, 63, 45], "learning_rate": 0.007987548574051427, "batch_size": 82, "loss": 0.0030769641930237413}, {"layer_params": [47, 48], "learning_rate": 0.009516687842248094, "batch_size": 416, "loss": 0.001649694840889424}, {"layer_params": [23, 47, 41, 16, 46], "learning_rate": 0.007444950986903835, "batch_size": 40, "loss": 0.005518560477066785}, {"layer_params": [24, 37, 17], "learning_rate": 0.007220770831205689, "batch_size": 418, "loss": 0.002641326538287103}, {"layer_params": [56, 36, 58, 48], "learning_rate": 0.00534250038084161, "batch_size": 140, "loss": 0.0015314630535431207}, {"layer_params": [31, 36, 32, 37, 46], "learning_rate": 0.00911298386999284, "batch_size": 55, "loss": 0.003995058205910027}, {"layer_params": [38, 40, 46, 61], "learning_rate": 0.0028258090167025893, "batch_size": 186, "loss": 0.0025947771733626722}, {"layer_params": [27, 49], "learning_rate": 0.005327939122074618, "batch_size": 181, "loss": 0.0021961678622756152}, {"layer_params": [62, 41], "learning_rate": 0.0007157459909956139, "batch_size": 338, "loss": 0.003918002187274397}, {"layer_params": [39, 64, 40, 53, 49], "learning_rate": 0.004846802603321379, "batch_size": 153, "loss": 0.002197086806409061}, {"layer_params": [38, 54, 56, 19], "learning_rate": 0.0028869072527715387, "batch_size": 349, "loss": 0.0020967595325782893}, {"layer_params": [38, 48, 42, 40, 29], "learning_rate": 0.00797425355389289, "batch_size": 362, "loss": 0.0014742938720155507}, {"layer_params": [40, 35], "learning_rate": 0.007411669911472221, "batch_size": 169, "loss": 0.0026515993650536984}, {"layer_params": [58, 44], "learning_rate": 0.00022282290706178312, "batch_size": 467, "loss": 0.006920560663565993}, {"layer_params": [48, 28, 48], "learning_rate": 0.006749719570968991, "batch_size": 366, "loss": 0.001724956788821146}, {"layer_params": [28, 49, 42], "learning_rate": 0.009654705270496217, "batch_size": 21, "loss": 0.007870500478893518}, {"layer_params": [57, 63, 53], "learning_rate": 0.008543886003905921, "batch_size": 261, "loss": 0.0016634043317753822}, {"layer_params": [37, 47], "learning_rate": 0.0007288087617527064, "batch_size": 501, "loss": 0.005553883095271886}, {"layer_params": [32, 29, 47, 34, 35], "learning_rate": 0.004334127462724518, "batch_size": 190, "loss": 0.0032892654137685897}, {"layer_params": [29, 45, 32, 64, 43], "learning_rate": 0.007054523130779293, "batch_size": 173, "loss": 0.0034754151455126704}, {"layer_params": [59, 51, 62, 31, 35], "learning_rate": 0.005464551001510692, "batch_size": 486, "loss": 0.0008801809744909406}, {"layer_params": [63, 35, 52, 29, 22], "learning_rate": 0.00473459566698676, "batch_size": 232, "loss": 0.00132904120197054}, {"layer_params": [40, 60, 59], "learning_rate": 0.006913082471333853, "batch_size": 78, "loss": 0.0023653271293733267}, {"layer_params": [59, 17], "learning_rate": 0.0002760486800728088, "batch_size": 78, "loss": 0.01567557585425675}, {"layer_params": [34, 61, 63, 45], "learning_rate": 0.00992438194070902, "batch_size": 163, "loss": 0.001620242859935388}, {"layer_params": [48, 33], "learning_rate": 0.004267332985516574, "batch_size": 226, "loss": 0.002659354782663286}, {"layer_params": [24, 61, 20, 57, 47], "learning_rate": 0.009317487566323737, "batch_size": 16, "loss": 0.009442234931048005}, {"layer_params": [55, 31, 64, 37], "learning_rate": 0.006114844449916546, "batch_size": 145, "loss": 0.0017012057115789502}, {"layer_params": [62, 38, 56, 50], "learning_rate": 0.009968333827797536, "batch_size": 32, "loss": 0.006270719955209642}, {"layer_params": [18, 22, 47, 38], "learning_rate": 0.0075007478179324825, "batch_size": 25, "loss": 0.008249837006442249}, {"layer_params": [43, 36], "learning_rate": 0.004799509456212101, "batch_size": 291, "loss": 0.0023322528519202023}, {"layer_params": [59, 17], "learning_rate": 0.005502819506753052, "batch_size": 194, "loss": 0.004054065039381385}, {"layer_params": [36, 41, 27, 38], "learning_rate": 0.0014908631130603456, "batch_size": 384, "loss": 0.00310246123932302}, {"layer_params": [27, 57], "learning_rate": 0.00785069709518104, "batch_size": 166, "loss": 0.0021182277286425234}, {"layer_params": [43, 30], "learning_rate": 0.005884612143911801, "batch_size": 262, "loss": 0.0022207878960762172}, {"layer_params": [45, 46, 26, 18], "learning_rate": 0.009341947926211527, "batch_size": 305, "loss": 0.0009456401213537902}, {"layer_params": [24, 19], "learning_rate": 0.0007032386755582224, "batch_size": 493, "loss": 0.007433722941204906}, {"layer_params": [38, 32, 34, 63, 32], "learning_rate": 0.006223993154007177, "batch_size": 392, "loss": 0.0022638256556820123}, {"layer_params": [30, 50, 17, 29, 31], "learning_rate": 0.00535200179454967, "batch_size": 450, "loss": 0.0010267137171467767}, {"layer_params": [19, 23], "learning_rate": 0.0029486012076018852, "batch_size": 146, "loss": 0.005426771333441138}, {"layer_params": [45, 55], "learning_rate": 0.006003127941187452, "batch_size": 470, "loss": 0.0018708629708271475}, {"layer_params": [63, 50], "learning_rate": 0.009269989873642182, "batch_size": 230, "loss": 0.0015561824891483411}, {"layer_params": [63, 31, 45], "learning_rate": 0.002100542785398106, "batch_size": 253, "loss": 0.002474788292311132}, {"layer_params": [28, 27, 42, 40], "learning_rate": 0.002066551078118721, "batch_size": 150, "loss": 0.004479951977264136}, {"layer_params": [47, 25, 56, 40, 47], "learning_rate": 0.002341713056423142, "batch_size": 480, "loss": 0.0017445173487067223}, {"layer_params": [19, 22, 39, 36, 16], "learning_rate": 0.007730736271615492, "batch_size": 197, "loss": 0.004809886119328439}, {"layer_params": [51, 45, 56, 58, 61], "learning_rate": 0.00894194320463132, "batch_size": 62, "loss": 0.0028000939486082644}, {"layer_params": [16, 34, 57, 31, 46], "learning_rate": 0.009747208017883585, "batch_size": 109, "loss": 0.003916937110479921}, {"layer_params": [19, 50, 43, 29, 46], "learning_rate": 0.004118619700667509, "batch_size": 309, "loss": 0.0026819809735752643}, {"layer_params": [63, 46, 38, 51], "learning_rate": 0.005771388692842334, "batch_size": 80, "loss": 0.00211846933583729}, {"layer_params": [57, 34, 53, 34], "learning_rate": 0.00045176178224774706, "batch_size": 265, "loss": 0.005561247249133885}, {"layer_params": [53, 22, 22, 19, 27], "learning_rate": 0.009485763914345116, "batch_size": 43, "loss": 0.008611032380722463}, {"layer_params": [34, 64, 29, 32, 51], "learning_rate": 0.008547290679509722, "batch_size": 125, "loss": 0.002170347956707701}, {"layer_params": [56, 22], "learning_rate": 0.0018820706086368744, "batch_size": 132, "loss": 0.004619388617575168}, {"layer_params": [52, 38, 61, 56], "learning_rate": 0.0011894287869047555, "batch_size": 198, "loss": 0.0022489918512292205}, {"layer_params": [45, 27, 36, 27], "learning_rate": 0.0011637111990052311, "batch_size": 476, "loss": 0.0025350859644822778}, {"layer_params": [32, 44, 56], "learning_rate": 0.007164372163650847, "batch_size": 273, "loss": 0.0014837363082915544}, {"layer_params": [44, 42, 30], "learning_rate": 0.008938089683729795, "batch_size": 337, "loss": 0.001033450803370215}, {"layer_params": [47, 49, 51, 41, 58], "learning_rate": 0.008252635362394152, "batch_size": 479, "loss": 0.0012384736922103911}, {"layer_params": [34, 23], "learning_rate": 0.0032540241413810825, "batch_size": 403, "loss": 0.0033716431143693626}, {"layer_params": [59, 28, 42, 41, 53], "learning_rate": 0.0054778458625746075, "batch_size": 313, "loss": 0.0013323887751903385}, {"layer_params": [32, 42, 61, 38, 62], "learning_rate": 0.005446708778859824, "batch_size": 271, "loss": 0.0018189374613575638}, {"layer_params": [46, 36, 20, 21, 64], "learning_rate": 0.003954635976345428, "batch_size": 51, "loss": 0.003291621016105637}, {"layer_params": [52, 25, 40, 55], "learning_rate": 0.009491585662954207, "batch_size": 136, "loss": 0.0017608308256603776}, {"layer_params": [24, 59, 36], "learning_rate": 0.00594929425852042, "batch_size": 148, "loss": 0.0031186324078589676}, {"layer_params": [38, 40, 39, 39, 36], "learning_rate": 0.000599032597371892, "batch_size": 457, "loss": 0.005747609469108283}, {"layer_params": [19, 32, 43, 51], "learning_rate": 0.009651267634553389, "batch_size": 358, "loss": 0.0025007966300472618}, {"layer_params": [38, 24, 38, 48], "learning_rate": 0.001142005540480956, "batch_size": 380, "loss": 0.002947124890051782}, {"layer_params": [63, 47], "learning_rate": 0.004348123031666312, "batch_size": 489, "loss": 0.002085082654375583}, {"layer_params": [59, 22, 64, 59, 57], "learning_rate": 0.003662468823801167, "batch_size": 418, "loss": 0.0023619959154166283}, {"layer_params": [29, 28, 44, 17], "learning_rate": 0.006422073746537592, "batch_size": 316, "loss": 0.00221670342492871}, {"layer_params": [21, 20, 25], "learning_rate": 0.0005532164964671325, "batch_size": 430, "loss": 0.007271113633178175}, {"layer_params": [36, 30], "learning_rate": 0.0011405001104436467, "batch_size": 186, "loss": 0.0062526954570785165}, {"layer_params": [17, 34, 26], "learning_rate": 0.00542134434826061, "batch_size": 190, "loss": 0.003950295464601367}, {"layer_params": [19, 34, 39, 57], "learning_rate": 0.008928261726520486, "batch_size": 104, "loss": 0.004223814785946161}, {"layer_params": [29, 64, 27, 33, 55], "learning_rate": 0.005916646196534928, "batch_size": 148, "loss": 0.002336937377694994}, {"layer_params": [29, 51, 23, 57], "learning_rate": 0.007293225549799181, "batch_size": 107, "loss": 0.0022579862538259477}, {"layer_params": [28, 54, 59], "learning_rate": 0.0017981874589506842, "batch_size": 424, "loss": 0.0014805409812834113}, {"layer_params": [45, 19], "learning_rate": 0.009885520459923816, "batch_size": 262, "loss": 0.002300114075187594}, {"layer_params": [47, 44, 57, 53], "learning_rate": 0.0009734686485406423, "batch_size": 213, "loss": 0.0023857311345636843}, {"layer_params": [40, 24], "learning_rate": 0.008251396685287411, "batch_size": 153, "loss": 0.002569392151199281}, {"layer_params": [50, 57, 63, 61], "learning_rate": 0.007357073714330898, "batch_size": 474, "loss": 0.0008396630233619362}, {"layer_params": [47, 63, 34], "learning_rate": 0.0030661420772550066, "batch_size": 185, "loss": 0.0024174005701206626}, {"layer_params": [41, 46], "learning_rate": 0.009440660782373295, "batch_size": 268, "loss": 0.001978412667522207}, {"layer_params": [27, 54, 46, 25], "learning_rate": 0.0044783124659590594, "batch_size": 119, "loss": 0.0013326093571959063}, {"layer_params": [45, 57, 61, 57], "learning_rate": 0.0057390895804316335, "batch_size": 263, "loss": 0.0014325903885765}, {"layer_params": [47, 46, 20, 56, 47], "learning_rate": 0.005238956172187662, "batch_size": 317, "loss": 0.0012924020580248907}, {"layer_params": [51, 41], "learning_rate": 0.0038205135921027026, "batch_size": 328, "loss": 0.0017359384812880307}, {"layer_params": [53, 57, 40, 60], "learning_rate": 0.0022525079791895068, "batch_size": 84, "loss": 0.003020998506108299}, {"layer_params": [42, 41], "learning_rate": 0.0038135434338557686, "batch_size": 144, "loss": 0.00232869129977189}, {"layer_params": [26, 52, 34, 30, 28], "learning_rate": 0.0037489992962161153, "batch_size": 65, "loss": 0.005255264120642096}, {"layer_params": [17, 30, 60, 47], "learning_rate": 0.003177036646283418, "batch_size": 349, "loss": 0.003464019927196205}, {"layer_params": [60, 45, 34, 59], "learning_rate": 0.008562979642659846, "batch_size": 57, "loss": 0.0031045776710379868}, {"layer_params": [31, 17], "learning_rate": 0.0015988942442739516, "batch_size": 49, "loss": 0.007223131945356727}, {"layer_params": [40, 34, 21, 64, 30], "learning_rate": 0.008378856114686936, "batch_size": 372, "loss": 0.002152371893171221}, {"layer_params": [54, 38, 17], "learning_rate": 0.0014419225303841706, "batch_size": 133, "loss": 0.00336392458062619}, {"layer_params": [27, 19, 54, 52, 57], "learning_rate": 0.009969529270445022, "batch_size": 195, "loss": 0.0031050168653018774}, {"layer_params": [43, 21, 42, 28], "learning_rate": 0.0017138504250712348, "batch_size": 41, "loss": 0.005766522875055671}, {"layer_params": [54, 42, 64], "learning_rate": 0.004453288991477792, "batch_size": 400, "loss": 0.0009898306959075854}, {"layer_params": [30, 50], "learning_rate": 0.006494389837702734, "batch_size": 443, "loss": 0.0015774235024582596}, {"layer_params": [52, 48, 27, 60, 55], "learning_rate": 0.005446148672176786, "batch_size": 165, "loss": 0.001403007033513859}, {"layer_params": [48, 56, 32], "learning_rate": 0.008347648701660325, "batch_size": 343, "loss": 0.00151593575370498}, {"layer_params": [46, 32, 46, 48, 43], "learning_rate": 0.004610880032546151, "batch_size": 446, "loss": 0.0013975108123850078}, {"layer_params": [42, 60], "learning_rate": 0.005474769683611927, "batch_size": 359, "loss": 0.0018049624783452601}, {"layer_params": [23, 16], "learning_rate": 0.0013901787951895478, "batch_size": 233, "loss": 0.0063762044720351695}, {"layer_params": [31, 27, 64], "learning_rate": 0.009745394383250845, "batch_size": 182, "loss": 0.0018694523116573691}, {"layer_params": [48, 29, 59], "learning_rate": 0.006931701622856367, "batch_size": 79, "loss": 0.004421274873893708}, {"layer_params": [47, 55, 59, 18, 33], "learning_rate": 0.005987413812269449, "batch_size": 294, "loss": 0.0020095080847386273}, {"layer_params": [33, 24, 20, 50, 61], "learning_rate": 0.007927187318325193, "batch_size": 445, "loss": 0.0016364583536051215}, {"layer_params": [40, 24, 28], "learning_rate": 0.009342243334413441, "batch_size": 180, "loss": 0.003988592161331326}, {"layer_params": [39, 31, 63], "learning_rate": 0.004511847289033324, "batch_size": 23, "loss": 0.005264157461933792}, {"layer_params": [50, 32, 21, 24], "learning_rate": 0.007403455440083904, "batch_size": 83, "loss": 0.0030461217218544336}, {"layer_params": [29, 24, 22, 56, 62], "learning_rate": 0.002161178102765101, "batch_size": 494, "loss": 0.0025232247891835867}, {"layer_params": [38, 16, 52, 42], "learning_rate": 0.008742167983399692, "batch_size": 511, "loss": 0.0028273569117300214}, {"layer_params": [61, 55, 50, 41], "learning_rate": 0.005099486016545623, "batch_size": 178, "loss": 0.0014416610228363425}, {"layer_params": [24, 46], "learning_rate": 0.0038446261156176013, "batch_size": 479, "loss": 0.002047322178259492}, {"layer_params": [20, 25, 60, 61, 50], "learning_rate": 0.009193918323819118, "batch_size": 205, "loss": 0.002659223472001031}, {"layer_params": [49, 54, 45, 43], "learning_rate": 0.009336629892018663, "batch_size": 209, "loss": 0.00221289487904869}, {"layer_params": [58, 43, 22, 40], "learning_rate": 0.005081053394365482, "batch_size": 318, "loss": 0.0012801950855646283}, {"layer_params": [39, 64, 16], "learning_rate": 0.0047436548887949135, "batch_size": 417, "loss": 0.001522206737427041}, {"layer_params": [60, 64], "learning_rate": 0.009765948287705065, "batch_size": 162, "loss": 0.002714564527850598}, {"layer_params": [51, 17], "learning_rate": 0.0060259549641690875, "batch_size": 423, "loss": 0.0027502659638412295}, {"layer_params": [32, 54, 22, 18, 54], "learning_rate": 0.004715882775658101, "batch_size": 398, "loss": 0.001271357558434829}, {"layer_params": [60, 17, 47], "learning_rate": 0.00538366966995056, "batch_size": 136, "loss": 0.0024918486352544277}, {"layer_params": [39, 33, 57, 54, 61], "learning_rate": 0.003908560009442724, "batch_size": 29, "loss": 0.004714287086389959}, {"layer_params": [40, 23, 32, 45], "learning_rate": 0.002417252859179386, "batch_size": 118, "loss": 0.0033188032219186427}, {"layer_params": [28, 33], "learning_rate": 0.00311674871482638, "batch_size": 208, "loss": 0.0058277505077421665}, {"layer_params": [53, 35], "learning_rate": 0.004913262511353833, "batch_size": 341, "loss": 0.002089884552406147}, {"layer_params": [43, 35], "learning_rate": 0.0005079125483974076, "batch_size": 439, "loss": 0.005700990105979144}, {"layer_params": [35, 34, 34], "learning_rate": 0.008081073876189799, "batch_size": 180, "loss": 0.0027450146246701477}, {"layer_params": [22, 49, 48, 32, 47], "learning_rate": 0.009182744057831092, "batch_size": 430, "loss": 0.001212098462274298}, {"layer_params": [30, 27, 20, 59], "learning_rate": 0.005004105640836693, "batch_size": 88, "loss": 0.0028350929589942096}, {"layer_params": [45, 45], "learning_rate": 0.0035205703266587636, "batch_size": 355, "loss": 0.0019159246317576616}, {"layer_params": [45, 51], "learning_rate": 0.009881675771069834, "batch_size": 479, "loss": 0.0010635252424981445}, {"layer_params": [34, 23, 64, 23], "learning_rate": 0.0023159274534506682, "batch_size": 227, "loss": 0.0024269031756557523}, {"layer_params": [20, 37, 56, 38, 25], "learning_rate": 0.0076807292827118, "batch_size": 198, "loss": 0.0024501058459281922}, {"layer_params": [46, 28, 26, 58], "learning_rate": 0.003690572857946617, "batch_size": 231, "loss": 0.00271996283903718}, {"layer_params": [36, 48], "learning_rate": 0.0020384064675035493, "batch_size": 59, "loss": 0.00621743923984468}, {"layer_params": [36, 48, 26, 59], "learning_rate": 0.00697053633583193, "batch_size": 221, "loss": 0.0016382125054951757}, {"layer_params": [40, 29, 20], "learning_rate": 0.0012361464242754386, "batch_size": 52, "loss": 0.007578333141282201}, {"layer_params": [26, 40], "learning_rate": 0.0007408718179259138, "batch_size": 375, "loss": 0.006157488292083144}, {"layer_params": [60, 56], "learning_rate": 0.007317540520910768, "batch_size": 134, "loss": 0.001334593838546425}, {"layer_params": [64, 60], "learning_rate": 0.0045496557817950875, "batch_size": 435, "loss": 0.0009955620806431397}, {"layer_params": [21, 33], "learning_rate": 0.00018574381058489528, "batch_size": 207, "loss": 0.015286076702177525}, {"layer_params": [41, 47, 53], "learning_rate": 0.003176480029304519, "batch_size": 219, "loss": 0.0014474167989101262}, {"layer_params": [36, 44, 31], "learning_rate": 0.008000137698446772, "batch_size": 410, "loss": 0.0012222870619734748}, {"layer_params": [30, 18], "learning_rate": 0.0032601666633347414, "batch_size": 148, "loss": 0.004480640552937985}, {"layer_params": [16, 59, 36, 64, 36], "learning_rate": 0.004448722568547023, "batch_size": 20, "loss": 0.010862255345564335}, {"layer_params": [36, 19], "learning_rate": 0.0037075561065023797, "batch_size": 429, "loss": 0.0030745052406564357}, {"layer_params": [37, 35, 31], "learning_rate": 0.00459864658072213, "batch_size": 154, "loss": 0.0032831209735013547}, {"layer_params": [21, 58, 17, 41], "learning_rate": 0.0049715099917052126, "batch_size": 164, "loss": 0.003564891016576439}, {"layer_params": [39, 56, 36], "learning_rate": 0.0005261248115994885, "batch_size": 467, "loss": 0.0038648234540596604}, {"layer_params": [58, 62, 38, 49, 47], "learning_rate": 0.00955211024936721, "batch_size": 434, "loss": 0.0012941058608703314}, {"layer_params": [63, 41, 47], "learning_rate": 0.0075304698666854445, "batch_size": 355, "loss": 0.0012821998051367701}, {"layer_params": [45, 41, 29, 61, 40], "learning_rate": 0.0035289380974616803, "batch_size": 472, "loss": 0.001802389898803085}, {"layer_params": [39, 40], "learning_rate": 0.002423934718775146, "batch_size": 25, "loss": 0.006511227360460907}, {"layer_params": [25, 35], "learning_rate": 0.003926106171995128, "batch_size": 356, "loss": 0.0030652391887269915}, {"layer_params": [26, 59], "learning_rate": 0.009785743032232532, "batch_size": 83, "loss": 0.004210395119152963}, {"layer_params": [29, 32], "learning_rate": 0.0057305506574807956, "batch_size": 369, "loss": 0.0020376531290821733}, {"layer_params": [20, 36, 34, 46, 44], "learning_rate": 0.006907414196463783, "batch_size": 234, "loss": 0.002465202435851097}, {"layer_params": [63, 27, 26, 31], "learning_rate": 0.003907968936291423, "batch_size": 470, "loss": 0.0013643803459126502}, {"layer_params": [53, 33, 31, 60, 39], "learning_rate": 0.0018326386019103305, "batch_size": 59, "loss": 0.004716046769171953}, {"layer_params": [57, 55], "learning_rate": 0.007727300239871295, "batch_size": 131, "loss": 0.001805892721749842}, {"layer_params": [29, 27, 31, 48], "learning_rate": 0.0027053439850053514, "batch_size": 360, "loss": 0.002038792783860117}, {"layer_params": [19, 23, 22, 32], "learning_rate": 0.0005607434271514755, "batch_size": 146, "loss": 0.007968812901526689}, {"layer_params": [37, 20, 44, 60], "learning_rate": 0.00322368987085907, "batch_size": 448, "loss": 0.002184397327946499}, {"layer_params": [28, 44, 42, 28], "learning_rate": 0.009885344385500476, "batch_size": 481, "loss": 0.002420680217910558}, {"layer_params": [36, 56, 58], "learning_rate": 0.004914490647095714, "batch_size": 189, "loss": 0.0011933391523780302}, {"layer_params": [61, 49, 47], "learning_rate": 0.005930623882195017, "batch_size": 381, "loss": 0.0007596953283064067}, {"layer_params": [57, 30, 19, 52, 27], "learning_rate": 0.009950594352990847, "batch_size": 61, "loss": 0.004061564146541059}, {"layer_params": [52, 23, 57, 56, 31], "learning_rate": 0.006490952336654518, "batch_size": 271, "loss": 0.00196053804946132}, {"layer_params": [45, 51, 32, 54], "learning_rate": 0.008617024684061855, "batch_size": 263, "loss": 0.000975929000414908}, {"layer_params": [54, 34, 33, 30, 44], "learning_rate": 0.00950766939094654, "batch_size": 106, "loss": 0.0024657276156358422}, {"layer_params": [27, 57, 61, 55, 52], "learning_rate": 0.0044726684094206146, "batch_size": 442, "loss": 0.0012323417305015027}, {"layer_params": [33, 33], "learning_rate": 0.0037023786267109783, "batch_size": 424, "loss": 0.0023117648949846623}, {"layer_params": [39, 56, 43], "learning_rate": 0.00863135656995395, "batch_size": 56, "loss": 0.0023381646687630564}, {"layer_params": [63, 51, 29, 60], "learning_rate": 0.004366722179318614, "batch_size": 193, "loss": 0.0020803875708952546}, {"layer_params": [52, 53], "learning_rate": 0.007498274433829684, "batch_size": 488, "loss": 0.001447653224458918}, {"layer_params": [30, 40], "learning_rate": 0.009771942888804836, "batch_size": 488, "loss": 0.005037518546450883}, {"layer_params": [35, 31, 28, 49], "learning_rate": 0.003956429374557413, "batch_size": 377, "loss": 0.0013523702998645604}, {"layer_params": [17, 62, 24, 44], "learning_rate": 0.0005538736872740878, "batch_size": 374, "loss": 0.006718878145329654}, {"layer_params": [50, 32], "learning_rate": 0.009485728218064945, "batch_size": 398, "loss": 0.0017039838177151977}, {"layer_params": [60, 34], "learning_rate": 0.004379482622827744, "batch_size": 433, "loss": 0.0013467166759073734}, {"layer_params": [36, 56], "learning_rate": 0.0031488549600438105, "batch_size": 406, "loss": 0.002282124130288139}, {"layer_params": [18, 44], "learning_rate": 0.005177200149111369, "batch_size": 259, "loss": 0.003094833013601601}, {"layer_params": [49, 30, 21, 60], "learning_rate": 0.007347518991631882, "batch_size": 413, "loss": 0.00197020199499093}, {"layer_params": [19, 17, 19, 58], "learning_rate": 0.0060088645239798144, "batch_size": 359, "loss": 0.004193614644464105}, {"layer_params": [62, 48, 54, 62], "learning_rate": 0.0029075049586039306, "batch_size": 357, "loss": 0.0014089979080017655}, {"layer_params": [64, 35, 51, 45], "learning_rate": 0.009999747065880268, "batch_size": 19, "loss": 0.0063284452934749425}, {"layer_params": [44, 64], "learning_rate": 0.001776856915330264, "batch_size": 25, "loss": 0.006562685072422028}, {"layer_params": [38, 23, 27, 60], "learning_rate": 0.009695432833428774, "batch_size": 217, "loss": 0.0024000097438693045}, {"layer_params": [49, 34], "learning_rate": 0.0016393308972571226, "batch_size": 468, "loss": 0.0018153087410610169}, {"layer_params": [32, 46, 39, 63, 45], "learning_rate": 0.0076098883884427515, "batch_size": 151, "loss": 0.0025531875248998403}, {"layer_params": [40, 29], "learning_rate": 0.004444937532876355, "batch_size": 50, "loss": 0.004422945103142411}, {"layer_params": [36, 44, 47, 50, 48], "learning_rate": 0.0029032777488447238, "batch_size": 92, "loss": 0.003038049810566008}, {"layer_params": [30, 20], "learning_rate": 0.003121596910239236, "batch_size": 248, "loss": 0.004100705636665225}, {"layer_params": [41, 35, 52], "learning_rate": 0.009084195520398509, "batch_size": 431, "loss": 0.0019556763593573125}, {"layer_params": [35, 40, 48, 21], "learning_rate": 0.001449399178229205, "batch_size": 227, "loss": 0.004518672048579902}, {"layer_params": [63, 32, 43, 50], "learning_rate": 0.0019113644047644722, "batch_size": 96, "loss": 0.0025064776581712068}, {"layer_params": [41, 47, 38, 31], "learning_rate": 0.007471770027803746, "batch_size": 108, "loss": 0.002014269722858444}, {"layer_params": [49, 35, 24, 58], "learning_rate": 0.002439498077216762, "batch_size": 240, "loss": 0.0020071271364577115}, {"layer_params": [26, 41, 35, 61, 34], "learning_rate": 0.005123647760723074, "batch_size": 394, "loss": 0.001813782115932554}, {"layer_params": [21, 27, 44, 55, 20], "learning_rate": 0.001639249242159177, "batch_size": 72, "loss": 0.006554637236986309}, {"layer_params": [44, 40, 29, 34], "learning_rate": 0.00692252323755468, "batch_size": 42, "loss": 0.005017179450951517}, {"layer_params": [46, 33, 54, 39, 59], "learning_rate": 0.005255820185380075, "batch_size": 459, "loss": 0.0013092738203704358}, {"layer_params": [24, 34, 25, 27], "learning_rate": 0.0008388808505945786, "batch_size": 187, "loss": 0.006563895004801452}, {"layer_params": [63, 54, 47, 37], "learning_rate": 0.0019363730610401832, "batch_size": 208, "loss": 0.0019872702495194973}, {"layer_params": [54, 63, 24, 60], "learning_rate": 0.0008710289634212488, "batch_size": 461, "loss": 0.002122902557021007}, {"layer_params": [61, 39, 24, 57], "learning_rate": 0.002271443683317011, "batch_size": 301, "loss": 0.0017808641982264817}, {"layer_params": [31, 37, 62, 28], "learning_rate": 0.009429124884224444, "batch_size": 504, "loss": 0.0016034596099052578}, {"layer_params": [55, 57, 20, 54], "learning_rate": 0.0007699638260864991, "batch_size": 241, "loss": 0.0027807564195245506}, {"layer_params": [59, 61, 27], "learning_rate": 0.007496037326896731, "batch_size": 420, "loss": 0.0008540807431563735}, {"layer_params": [37, 27, 46], "learning_rate": 0.006866283410262427, "batch_size": 218, "loss": 0.002223969637416303}, {"layer_params": [60, 36, 64, 35], "learning_rate": 0.004938206696833609, "batch_size": 195, "loss": 0.0019107706460636108}, {"layer_params": [29, 55, 32], "learning_rate": 0.004417282222376976, "batch_size": 68, "loss": 0.004391575451008976}, {"layer_params": [60, 36, 45, 39, 46], "learning_rate": 0.0055038973788824165, "batch_size": 206, "loss": 0.0019154225825332104}, {"layer_params": [57, 32, 29, 51, 43], "learning_rate": 0.006507938807207076, "batch_size": 28, "loss": 0.006821976292412728}, {"layer_params": [47, 54, 22, 44, 59], "learning_rate": 0.001939174855673058, "batch_size": 110, "loss": 0.002419998582918197}, {"layer_params": [55, 42, 31], "learning_rate": 0.003977771222284483, "batch_size": 492, "loss": 0.00212008340167813}, {"layer_params": [60, 28, 16, 40], "learning_rate": 0.000576064044003746, "batch_size": 457, "loss": 0.004603289375081658}, {"layer_params": [60, 20, 57, 50, 52], "learning_rate": 0.004042351523553349, "batch_size": 61, "loss": 0.002920309405308217}, {"layer_params": [60, 36, 46, 56, 55], "learning_rate": 0.009420885903857824, "batch_size": 267, "loss": 0.0009129291464341805}, {"layer_params": [21, 19], "learning_rate": 0.005636982130350714, "batch_size": 50, "loss": 0.008077202537097037}, {"layer_params": [46, 38], "learning_rate": 0.005800529930317665, "batch_size": 21, "loss": 0.005646275766193867}, {"layer_params": [53, 57, 37, 20, 59], "learning_rate": 0.009765098406696168, "batch_size": 449, "loss": 0.0013361331494525074}, {"layer_params": [39, 62, 34, 58, 38], "learning_rate": 0.008377840412745622, "batch_size": 396, "loss": 0.0011928685830207542}, {"layer_params": [30, 28], "learning_rate": 0.003519069230683255, "batch_size": 393, "loss": 0.0027108255587518213}, {"layer_params": [44, 50, 19, 17, 62], "learning_rate": 0.009100685294826572, "batch_size": 393, "loss": 0.0008346491138217971}, {"layer_params": [49, 53, 48, 64], "learning_rate": 0.002067998675651006, "batch_size": 371, "loss": 0.0010201889206655323}, {"layer_params": [46, 24, 57], "learning_rate": 0.008399539639324747, "batch_size": 151, "loss": 0.002565901780035347}, {"layer_params": [29, 47, 63, 64], "learning_rate": 0.0031104286632118046, "batch_size": 96, "loss": 0.002610746076097712}, {"layer_params": [57, 52], "learning_rate": 0.008079961009022824, "batch_size": 346, "loss": 0.0010788621450774371}, {"layer_params": [62, 17, 16, 50], "learning_rate": 0.0010629596788617954, "batch_size": 195, "loss": 0.0029589956207200885}, {"layer_params": [40, 41], "learning_rate": 0.008912401137968236, "batch_size": 110, "loss": 0.0047633597301319245}, {"layer_params": [30, 18, 44, 61, 53], "learning_rate": 0.004623732655201914, "batch_size": 174, "loss": 0.003336476527620107}, {"layer_params": [53, 41], "learning_rate": 0.0010809321060251964, "batch_size": 482, "loss": 0.003296319975052029}, {"layer_params": [55, 57, 57, 63, 26], "learning_rate": 0.00659483023735885, "batch_size": 119, "loss": 0.001994926142506301}, {"layer_params": [64, 58], "learning_rate": 0.000696533201169384, "batch_size": 202, "loss": 0.005485581799875945}, {"layer_params": [19, 38, 29, 51], "learning_rate": 0.0003159550190901384, "batch_size": 257, "loss": 0.007977690943516792}, {"layer_params": [26, 55, 42, 42, 30], "learning_rate": 0.006409772544212195, "batch_size": 362, "loss": 0.0012390661676181481}, {"layer_params": [52, 21, 35], "learning_rate": 0.0021910566838750744, "batch_size": 379, "loss": 0.0032322062808088957}, {"layer_params": [16, 38, 61, 54], "learning_rate": 0.004518396400430743, "batch_size": 367, "loss": 0.002317921961657703}, {"layer_params": [26, 34, 60, 24, 21], "learning_rate": 0.005309474667900292, "batch_size": 351, "loss": 0.0018245517229661347}, {"layer_params": [30, 32], "learning_rate": 0.0033058184563752213, "batch_size": 249, "loss": 0.002832908742129803}, {"layer_params": [38, 38, 21, 48, 18], "learning_rate": 0.003132624143371707, "batch_size": 73, "loss": 0.00450390437617898}, {"layer_params": [35, 54, 48, 21, 31], "learning_rate": 0.007048733872454502, "batch_size": 41, "loss": 0.005215867313090712}, {"layer_params": [54, 27, 64, 23, 29], "learning_rate": 0.0026983223754336273, "batch_size": 188, "loss": 0.0022193603019695727}, {"layer_params": [32, 17], "learning_rate": 0.0037627547972439346, "batch_size": 480, "loss": 0.00476142670493573}, {"layer_params": [46, 21, 41, 16], "learning_rate": 0.005211262205966456, "batch_size": 459, "loss": 0.0012969890364911407}, {"layer_params": [58, 57], "learning_rate": 0.006017620589428812, "batch_size": 86, "loss": 0.0018829848233144731}, {"layer_params": [54, 57, 47], "learning_rate": 0.007755481831755146, "batch_size": 228, "loss": 0.0008407366345636547}, {"layer_params": [17, 37], "learning_rate": 0.007314750882891225, "batch_size": 61, "loss": 0.005377322458662093}, {"layer_params": [23, 17], "learning_rate": 0.007385992527231438, "batch_size": 106, "loss": 0.0032144814124330876}, {"layer_params": [21, 63, 28], "learning_rate": 0.007337337886667514, "batch_size": 151, "loss": 0.003049400714226067}, {"layer_params": [21, 37, 47], "learning_rate": 0.005280587831570534, "batch_size": 345, "loss": 0.002452974179759622}, {"layer_params": [37, 60], "learning_rate": 0.00495848772955328, "batch_size": 487, "loss": 0.001692832853877917}, {"layer_params": [40, 21], "learning_rate": 0.003396006338579428, "batch_size": 393, "loss": 0.0028320384700782596}, {"layer_params": [59, 23, 58], "learning_rate": 0.00825354496531656, "batch_size": 122, "loss": 0.0019854848459362985}, {"layer_params": [63, 51, 64], "learning_rate": 0.005244708373591351, "batch_size": 429, "loss": 0.000759906752500683}, {"layer_params": [36, 27], "learning_rate": 0.006768130466377218, "batch_size": 311, "loss": 0.002830876766238362}, {"layer_params": [57, 21], "learning_rate": 0.005305142637591982, "batch_size": 59, "loss": 0.0028484556288458406}, {"layer_params": [55, 58, 27, 53, 56], "learning_rate": 0.00014620469437380171, "batch_size": 487, "loss": 0.007476335256360472}, {"layer_params": [38, 29, 55, 35, 64], "learning_rate": 0.00648988115086138, "batch_size": 184, "loss": 0.0018498757656197995}, {"layer_params": [23, 26, 34, 55, 50], "learning_rate": 0.005264372719152234, "batch_size": 201, "loss": 0.004258888338226825}, {"layer_params": [47, 45, 44], "learning_rate": 0.004073603151649935, "batch_size": 47, "loss": 0.0029479862295556814}, {"layer_params": [27, 58], "learning_rate": 0.006310815403875458, "batch_size": 291, "loss": 0.002573291703592986}, {"layer_params": [36, 44, 21, 34, 44], "learning_rate": 0.0043904127733211794, "batch_size": 315, "loss": 0.0015716645319480448}, {"layer_params": [53, 56, 59, 51, 44], "learning_rate": 0.006529271391215971, "batch_size": 415, "loss": 0.001034561902633868}, {"layer_params": [21, 39, 44, 31], "learning_rate": 0.005010721116489932, "batch_size": 20, "loss": 0.007283147918060422}, {"layer_params": [59, 35, 46, 63, 57], "learning_rate": 0.004402238494620236, "batch_size": 297, "loss": 0.00165278808795847}, {"layer_params": [56, 18, 37, 24, 41], "learning_rate": 0.0016057775699042057, "batch_size": 148, "loss": 0.0029451574059203268}, {"layer_params": [30, 64, 56], "learning_rate": 0.005770129200314929, "batch_size": 257, "loss": 0.0010466686321888119}, {"layer_params": [47, 51, 31, 50], "learning_rate": 0.0044656898396758385, "batch_size": 130, "loss": 0.0022309584286995233}, {"layer_params": [26, 48], "learning_rate": 0.0006850118165631411, "batch_size": 336, "loss": 0.006689738724380731}, {"layer_params": [53, 19, 50, 16, 50], "learning_rate": 0.008420967654272004, "batch_size": 285, "loss": 0.0024590910354163496}, {"layer_params": [16, 41, 47, 54], "learning_rate": 0.007299664348067657, "batch_size": 211, "loss": 0.002495205223094672}, {"layer_params": [35, 31, 37, 61, 30], "learning_rate": 0.00975020667693308, "batch_size": 195, "loss": 0.002286871349206194}, {"layer_params": [54, 57, 58, 23], "learning_rate": 0.00970419333750819, "batch_size": 432, "loss": 0.000770490916329436}, {"layer_params": [38, 61, 20, 57], "learning_rate": 0.0011471342867785017, "batch_size": 102, "loss": 0.003569589448161423}, {"layer_params": [55, 64, 44], "learning_rate": 0.008383863266013881, "batch_size": 418, "loss": 0.0009148355922661722}, {"layer_params": [36, 30, 40], "learning_rate": 0.008664715566636621, "batch_size": 84, "loss": 0.0036237919190898536}, {"layer_params": [38, 61], "learning_rate": 0.0028872088994443337, "batch_size": 272, "loss": 0.0018280600814614444}, {"layer_params": [29, 34], "learning_rate": 0.009127633071606233, "batch_size": 283, "loss": 0.0031130333803594114}, {"layer_params": [52, 27, 24], "learning_rate": 0.0010815724525006355, "batch_size": 175, "loss": 0.004630466504022479}, {"layer_params": [51, 55, 55], "learning_rate": 0.0067859363721897775, "batch_size": 446, "loss": 0.000839376850053668}, {"layer_params": [28, 63, 51, 49, 49], "learning_rate": 0.006370864853858081, "batch_size": 52, "loss": 0.003963159341365099}, {"layer_params": [36, 61, 37, 46], "learning_rate": 0.007852482847490202, "batch_size": 195, "loss": 0.0014408465271117167}, {"layer_params": [63, 56, 62, 52], "learning_rate": 0.004356298575044358, "batch_size": 375, "loss": 0.0006570005480898545}, {"layer_params": [58, 49, 22], "learning_rate": 0.007252411169365919, "batch_size": 438, "loss": 0.0012952465622220188}, {"layer_params": [27, 47, 20, 41, 47], "learning_rate": 0.008995559120391768, "batch_size": 130, "loss": 0.0027936900930944832}, {"layer_params": [39, 54, 63, 31], "learning_rate": 0.003146280210692782, "batch_size": 128, "loss": 0.0019077224237844348}, {"layer_params": [62, 30, 35, 35], "learning_rate": 0.009662730020606409, "batch_size": 106, "loss": 0.0024753019970376045}, {"layer_params": [59, 52, 16, 25, 48], "learning_rate": 0.008651989088537048, "batch_size": 359, "loss": 0.0009141947230091318}, {"layer_params": [36, 54, 62, 20], "learning_rate": 0.0004053225798392667, "batch_size": 83, "loss": 0.007245533196255565}, {"layer_params": [48, 56, 54, 43], "learning_rate": 0.002867508122256114, "batch_size": 368, "loss": 0.0010549560852814465}, {"layer_params": [61, 33], "learning_rate": 0.004173821349174015, "batch_size": 334, "loss": 0.002340895297238603}, {"layer_params": [49, 25, 50, 62], "learning_rate": 0.007649085735380947, "batch_size": 314, "loss": 0.0016992672323249281}, {"layer_params": [22, 37, 32], "learning_rate": 0.005067086954692451, "batch_size": 280, "loss": 0.002345580228138715}, {"layer_params": [26, 57, 41], "learning_rate": 0.009863352061257701, "batch_size": 206, "loss": 0.002677348970901221}, {"layer_params": [24, 36], "learning_rate": 0.004425482579808708, "batch_size": 147, "loss": 0.0022634038468822837}, {"layer_params": [46, 36, 35, 19, 53], "learning_rate": 0.0037581733732539244, "batch_size": 119, "loss": 0.003692452881950885}, {"layer_params": [40, 44], "learning_rate": 0.007358291418557754, "batch_size": 336, "loss": 0.001989293748047203}, {"layer_params": [46, 37, 50, 55, 43], "learning_rate": 0.008222551326659886, "batch_size": 447, "loss": 0.0014276122418232261}, {"layer_params": [62, 19, 46, 53], "learning_rate": 0.0006038643399165231, "batch_size": 272, "loss": 0.0043526183580979705}, {"layer_params": [19, 51, 56, 55, 24], "learning_rate": 0.0008612586619504271, "batch_size": 127, "loss": 0.006140947402454913}, {"layer_params": [60, 18], "learning_rate": 0.0069028823432438335, "batch_size": 178, "loss": 0.003808698810171336}, {"layer_params": [52, 31, 22, 39], "learning_rate": 0.0017727804137622706, "batch_size": 135, "loss": 0.0029185742675326763}, {"layer_params": [23, 22, 16, 63, 56], "learning_rate": 0.006395444884996542, "batch_size": 134, "loss": 0.003956682614516467}, {"layer_params": [33, 44], "learning_rate": 0.002263077438351462, "batch_size": 325, "loss": 0.004255114735569805}, {"layer_params": [17, 24, 32, 50, 23], "learning_rate": 0.0040012696009714055, "batch_size": 184, "loss": 0.004070049882866442}, {"layer_params": [22, 54, 35, 24], "learning_rate": 0.005345834422638747, "batch_size": 377, "loss": 0.002301014745607972}, {"layer_params": [30, 51, 45, 18], "learning_rate": 0.0013113787366413221, "batch_size": 267, "loss": 0.002489931273739785}, {"layer_params": [61, 55, 51, 29], "learning_rate": 0.0057211761714697044, "batch_size": 70, "loss": 0.00227527956594713}, {"layer_params": [29, 28], "learning_rate": 0.0020680247939931498, "batch_size": 183, "loss": 0.0033172742114402354}, {"layer_params": [32, 17], "learning_rate": 0.006642409316479151, "batch_size": 366, "loss": 0.004123339639045298}, {"layer_params": [49, 21, 32, 28], "learning_rate": 0.007477031321453773, "batch_size": 57, "loss": 0.005328289514873177}, {"layer_params": [41, 40, 31], "learning_rate": 0.003487378286791577, "batch_size": 215, "loss": 0.00280748616787605}, {"layer_params": [46, 31, 58, 47, 34], "learning_rate": 0.0027081492311735803, "batch_size": 51, "loss": 0.004097995045594871}, {"layer_params": [44, 19], "learning_rate": 0.00547984164989817, "batch_size": 295, "loss": 0.004134288949426263}, {"layer_params": [25, 19, 32], "learning_rate": 0.005537425540666685, "batch_size": 467, "loss": 0.00179920649738051}, {"layer_params": [46, 29], "learning_rate": 0.007016238111271612, "batch_size": 447, "loss": 0.0010302299313480034}, {"layer_params": [57, 26, 17], "learning_rate": 0.0018442469809098585, "batch_size": 320, "loss": 0.0035368095175363125}, {"layer_params": [38, 61, 59, 37], "learning_rate": 0.001644932953073986, "batch_size": 194, "loss": 0.0023683818837162106}, {"layer_params": [31, 40, 58], "learning_rate": 0.007351509792928151, "batch_size": 319, "loss": 0.0017141057399567216}, {"layer_params": [39, 34], "learning_rate": 0.003337288633098475, "batch_size": 256, "loss": 0.0026028022239916026}, {"layer_params": [34, 34, 34, 52, 62], "learning_rate": 0.007855004571064804, "batch_size": 327, "loss": 0.0021578083245549352}, {"layer_params": [58, 48, 61, 54], "learning_rate": 0.0019525367284182339, "batch_size": 323, "loss": 0.001575579852797091}, {"layer_params": [44, 41, 36, 23], "learning_rate": 0.005143046468190426, "batch_size": 342, "loss": 0.0012494181242072955}, {"layer_params": [32, 51, 28, 32, 35], "learning_rate": 0.008862046621121448, "batch_size": 103, "loss": 0.001996871769661084}, {"layer_params": [22, 45], "learning_rate": 0.005413899584888348, "batch_size": 257, "loss": 0.003980936505831778}, {"layer_params": [22, 36, 20], "learning_rate": 0.009180652439528139, "batch_size": 217, "loss": 0.00228857452631928}, {"layer_params": [60, 59, 16], "learning_rate": 0.006270098114433726, "batch_size": 112, "loss": 0.0020090210426133128}, {"layer_params": [21, 47], "learning_rate": 0.009964896853903229, "batch_size": 312, "loss": 0.004318786012008786}, {"layer_params": [16, 59], "learning_rate": 0.009465671518468425, "batch_size": 343, "loss": 0.0032487971265800298}, {"layer_params": [35, 16, 20], "learning_rate": 0.0060305737211772525, "batch_size": 444, "loss": 0.00227670393534936}, {"layer_params": [53, 30, 57, 62, 51], "learning_rate": 0.009219434872593947, "batch_size": 508, "loss": 0.0007390719442628324}, {"layer_params": [57, 58, 23], "learning_rate": 0.0060561772739350025, "batch_size": 381, "loss": 0.0017249389074277133}, {"layer_params": [23, 58, 42, 54], "learning_rate": 0.0002548093151016926, "batch_size": 336, "loss": 0.007313497820869088}, {"layer_params": [64, 27, 64, 49], "learning_rate": 0.009955998403372218, "batch_size": 158, "loss": 0.0017252981348428876}, {"layer_params": [42, 20, 63, 40], "learning_rate": 0.007130593189745942, "batch_size": 332, "loss": 0.0016739683609921486}, {"layer_params": [37, 44], "learning_rate": 0.00820096342709538, "batch_size": 444, "loss": 0.001835462199524045}, {"layer_params": [60, 51, 34, 30], "learning_rate": 0.004226705899720673, "batch_size": 171, "loss": 0.001988787864102051}, {"layer_params": [33, 50, 41, 54], "learning_rate": 0.0011351541145942193, "batch_size": 274, "loss": 0.004266280906740576}, {"layer_params": [44, 41, 26, 30, 29], "learning_rate": 0.009791288229898274, "batch_size": 225, "loss": 0.0023752979072742164}, {"layer_params": [39, 47], "learning_rate": 0.003636068848385086, "batch_size": 193, "loss": 0.002123829375486821}, {"layer_params": [49, 18, 31], "learning_rate": 0.005402591715821428, "batch_size": 264, "loss": 0.004108747073914855}, {"layer_params": [56, 61], "learning_rate": 0.008191283971959349, "batch_size": 388, "loss": 0.0013242639054078609}, {"layer_params": [30, 56], "learning_rate": 0.008713322347972025, "batch_size": 436, "loss": 0.002129602493951097}, {"layer_params": [59, 39, 26, 47, 30], "learning_rate": 0.007172778400779156, "batch_size": 297, "loss": 0.0012023229489568621}, {"layer_params": [61, 53], "learning_rate": 0.008209337881398493, "batch_size": 144, "loss": 0.002079443468246609}, {"layer_params": [43, 40, 22], "learning_rate": 0.008554901022554129, "batch_size": 175, "loss": 0.0019676932017318903}, {"layer_params": [41, 29, 29, 30, 48], "learning_rate": 0.001589859397028556, "batch_size": 392, "loss": 0.003579356358386576}, {"layer_params": [38, 31, 64, 25, 55], "learning_rate": 0.00836761546330484, "batch_size": 53, "loss": 0.0055373481148853895}, {"layer_params": [30, 56], "learning_rate": 0.004841111143272332, "batch_size": 216, "loss": 0.0029748430638574064}, {"layer_params": [57, 16, 63, 25], "learning_rate": 0.002224393160525208, "batch_size": 121, "loss": 0.006251446506939829}, {"layer_params": [46, 50, 26], "learning_rate": 0.004312007426699564, "batch_size": 501, "loss": 0.0013562516984529794}, {"layer_params": [53, 42], "learning_rate": 0.005214918013864845, "batch_size": 157, "loss": 0.0036735716834664345}, {"layer_params": [43, 60, 22, 49], "learning_rate": 0.004971350235318249, "batch_size": 252, "loss": 0.0018984820123296232}, {"layer_params": [27, 53], "learning_rate": 0.0005653674938765927, "batch_size": 314, "loss": 0.00748077588621527}, {"layer_params": [18, 22, 56, 34], "learning_rate": 0.009161788213727245, "batch_size": 338, "loss": 0.0031498017930425702}, {"layer_params": [16, 41, 62], "learning_rate": 0.005965641489439404, "batch_size": 469, "loss": 0.0019309270370285957}, {"layer_params": [27, 55], "learning_rate": 0.00978070933910144, "batch_size": 129, "loss": 0.0031422215909697117}, {"layer_params": [53, 58, 57], "learning_rate": 0.009647155667058703, "batch_size": 36, "loss": 0.0036023441446013747}, {"layer_params": [52, 55, 20], "learning_rate": 0.007051749174901222, "batch_size": 294, "loss": 0.0020923580683302133}, {"layer_params": [53, 46, 45, 44], "learning_rate": 0.0036638343404864215, "batch_size": 180, "loss": 0.002082804017700255}, {"layer_params": [60, 48], "learning_rate": 0.005203234831936362, "batch_size": 84, "loss": 0.0018671601451933383}, {"layer_params": [62, 58, 56], "learning_rate": 0.0051503180984527, "batch_size": 88, "loss": 0.0021566660492680968}, {"layer_params": [30, 18, 51, 26], "learning_rate": 3.643105516300707e-05, "batch_size": 109, "loss": 0.04331110704690218}, {"layer_params": [57, 32, 23, 29], "learning_rate": 0.003583081604630817, "batch_size": 511, "loss": 0.0022718891070690004}, {"layer_params": [52, 35, 50, 38, 21], "learning_rate": 0.004331795564672911, "batch_size": 432, "loss": 0.0015536267345305531}, {"layer_params": [26, 54, 47], "learning_rate": 0.0003266734806067936, "batch_size": 245, "loss": 0.006631946288980544}, {"layer_params": [51, 63], "learning_rate": 0.005953394758938467, "batch_size": 310, "loss": 0.001185583874466829}, {"layer_params": [58, 31, 61, 41], "learning_rate": 0.007332654200870319, "batch_size": 145, "loss": 0.0019401848746929318}, {"layer_params": [32, 44], "learning_rate": 0.00504414973485907, "batch_size": 503, "loss": 0.0018305629550013692}, {"layer_params": [61, 21], "learning_rate": 0.009233535674449999, "batch_size": 271, "loss": 0.002112292308593169}, {"layer_params": [47, 56, 62, 59], "learning_rate": 0.009188634725842816, "batch_size": 493, "loss": 0.000829928518505767}, {"layer_params": [31, 61, 34, 18], "learning_rate": 0.0025223375077671906, "batch_size": 345, "loss": 0.0018394819681998341}, {"layer_params": [53, 47, 37, 42], "learning_rate": 0.009098071636930528, "batch_size": 364, "loss": 0.0010743052116595209}, {"layer_params": [58, 55, 29, 19, 23], "learning_rate": 0.008171566943324177, "batch_size": 478, "loss": 0.0012529018567875028}, {"layer_params": [20, 63, 48, 25], "learning_rate": 0.007980329506814422, "batch_size": 265, "loss": 0.002481199767207727}, {"layer_params": [22, 48, 40, 51], "learning_rate": 0.0010611997402837038, "batch_size": 359, "loss": 0.0027837783563882113}, {"layer_params": [36, 25, 42], "learning_rate": 0.008630385266439954, "batch_size": 336, "loss": 0.0031686606910079716}, {"layer_params": [51, 54], "learning_rate": 0.003663872019012951, "batch_size": 65, "loss": 0.003268394413171336}, {"layer_params": [25, 18, 63, 19, 42], "learning_rate": 0.003966631110649141, "batch_size": 127, "loss": 0.004346385858952999}, {"layer_params": [51, 26], "learning_rate": 0.00886874261637495, "batch_size": 215, "loss": 0.0022504622652195394}, {"layer_params": [30, 57, 19, 64, 21], "learning_rate": 0.004117457828052428, "batch_size": 107, "loss": 0.003944058709312231}, {"layer_params": [32, 42], "learning_rate": 0.007491302199413607, "batch_size": 460, "loss": 0.0014636751054786146}, {"layer_params": [63, 17, 22, 40, 44], "learning_rate": 0.0008188412346788247, "batch_size": 416, "loss": 0.003755357468035072}, {"layer_params": [38, 21, 23, 41], "learning_rate": 0.008624506015362686, "batch_size": 495, "loss": 0.0018550714373122901}, {"layer_params": [32, 38], "learning_rate": 0.008210816517209917, "batch_size": 408, "loss": 0.0022576545260380955}, {"layer_params": [46, 53, 28], "learning_rate": 0.0019349964580358098, "batch_size": 272, "loss": 0.0020700361020863055}, {"layer_params": [28, 61, 48, 32], "learning_rate": 0.009802777073026342, "batch_size": 363, "loss": 0.0014107698888983578}, {"layer_params": [42, 60, 62, 50, 44], "learning_rate": 0.007777009567298891, "batch_size": 32, "loss": 0.004901458115782588}, {"layer_params": [53, 30, 53, 49], "learning_rate": 0.0002456953972851428, "batch_size": 161, "loss": 0.0065919252345338466}, {"layer_params": [21, 32], "learning_rate": 0.00243602784205246, "batch_size": 398, "loss": 0.0052177246147766705}, {"layer_params": [51, 21, 24, 18], "learning_rate": 0.006628275133208518, "batch_size": 437, "loss": 0.0015528704202733934}, {"layer_params": [26, 52, 17, 55], "learning_rate": 0.009033276178145214, "batch_size": 48, "loss": 0.004934181140270084}, {"layer_params": [21, 42], "learning_rate": 0.009927189143949064, "batch_size": 444, "loss": 0.002494089589454234}, {"layer_params": [40, 22, 64, 49, 41], "learning_rate": 0.0031353656925655706, "batch_size": 273, "loss": 0.0021277755207847805}, {"layer_params": [28, 56, 38, 20, 59], "learning_rate": 0.008108007863518086, "batch_size": 136, "loss": 0.0023058705404400827}, {"layer_params": [44, 20], "learning_rate": 0.004301118887704911, "batch_size": 499, "loss": 0.00188986407360062}, {"layer_params": [30, 33, 32], "learning_rate": 0.005286995821190174, "batch_size": 441, "loss": 0.0017818835005164147}, {"layer_params": [48, 19, 30, 32, 32], "learning_rate": 3.635663852932337e-05, "batch_size": 400, "loss": 0.03741938726976514}, {"layer_params": [50, 29], "learning_rate": 0.009397823580388766, "batch_size": 433, "loss": 0.0031476584007032217}, {"layer_params": [30, 36, 26], "learning_rate": 0.00856628297521448, "batch_size": 396, "loss": 0.0026795372343622146}, {"layer_params": [53, 48, 53, 41, 40], "learning_rate": 0.007289747825176219, "batch_size": 406, "loss": 0.0008987831725971773}, {"layer_params": [49, 26, 64, 28], "learning_rate": 0.007695212399893016, "batch_size": 268, "loss": 0.0020156995207071303}, {"layer_params": [26, 32, 39], "learning_rate": 0.0049412454917895435, "batch_size": 134, "loss": 0.0022476599575020372}, {"layer_params": [36, 21], "learning_rate": 0.0016727417344257571, "batch_size": 447, "loss": 0.0031049996824003756}, {"layer_params": [22, 56, 41], "learning_rate": 0.00392834020141598, "batch_size": 384, "loss": 0.0013157959305681289}, {"layer_params": [24, 41, 22], "learning_rate": 0.0016996497910909776, "batch_size": 100, "loss": 0.005914314007386565}, {"layer_params": [56, 22], "learning_rate": 0.0029708545187369186, "batch_size": 350, "loss": 0.003798096748068929}, {"layer_params": [40, 29, 53], "learning_rate": 0.00415646483657488, "batch_size": 403, "loss": 0.0022327534575015307}, {"layer_params": [44, 33, 59], "learning_rate": 0.0021920864185998724, "batch_size": 217, "loss": 0.0022440843225922436}, {"layer_params": [17, 32, 50], "learning_rate": 0.004995382388520949, "batch_size": 83, "loss": 0.00431693305959925}, {"layer_params": [38, 54, 45], "learning_rate": 0.0020245467412459022, "batch_size": 25, "loss": 0.004117404647404328}, {"layer_params": [56, 63, 17, 57], "learning_rate": 0.008583637668521929, "batch_size": 510, "loss": 0.0007022009138017893}, {"layer_params": [37, 51], "learning_rate": 0.0013299824994012022, "batch_size": 413, "loss": 0.002782481259200722}, {"layer_params": [37, 29, 59, 25], "learning_rate": 0.005096093600161308, "batch_size": 393, "loss": 0.0015817832539323717}, {"layer_params": [44, 35, 28, 42, 43], "learning_rate": 0.0029994543320612335, "batch_size": 161, "loss": 0.002577411336824298}, {"layer_params": [56, 21, 60], "learning_rate": 0.005524046539606298, "batch_size": 291, "loss": 0.002708092815009877}, {"layer_params": [51, 59, 38, 42, 58], "learning_rate": 0.006903605054859538, "batch_size": 502, "loss": 0.0006714890082366765}, {"layer_params": [37, 42, 64], "learning_rate": 0.009500130562339053, "batch_size": 442, "loss": 0.0010851523041492327}, {"layer_params": [38, 32, 63, 24, 60], "learning_rate": 0.0027502892295853455, "batch_size": 360, "loss": 0.0013562743575312197}, {"layer_params": [19, 19, 23, 27], "learning_rate": 0.0038693220819483545, "batch_size": 467, "loss": 0.002932181456126273}, {"layer_params": [41, 50, 18, 28], "learning_rate": 0.003734846889781608, "batch_size": 182, "loss": 0.0021880410343874247}, {"layer_params": [58, 29, 17, 62, 25], "learning_rate": 0.0026218463979242987, "batch_size": 131, "loss": 0.0028035489970352503}, {"layer_params": [18, 44, 27, 29, 30], "learning_rate": 0.004496073469050375, "batch_size": 219, "loss": 0.0024273916601669043}, {"layer_params": [29, 35], "learning_rate": 0.0035470036353405063, "batch_size": 289, "loss": 0.0023279700090643018}, {"layer_params": [27, 61, 30, 26], "learning_rate": 0.0046745986595176005, "batch_size": 392, "loss": 0.0013734191912226378}, {"layer_params": [60, 31, 61, 40, 20], "learning_rate": 0.004376604329255406, "batch_size": 110, "loss": 0.0021762699366081506}, {"layer_params": [16, 29], "learning_rate": 0.004186092260851554, "batch_size": 16, "loss": 0.008263072164263576}, {"layer_params": [29, 42, 33, 32], "learning_rate": 0.002365722735292896, "batch_size": 266, "loss": 0.001889151046052575}, {"layer_params": [40, 60], "learning_rate": 0.005072568278099635, "batch_size": 153, "loss": 0.0016074647393543274}, {"layer_params": [42, 16, 47], "learning_rate": 0.004639690985455158, "batch_size": 313, "loss": 0.003790029606316239}, {"layer_params": [37, 52, 56], "learning_rate": 0.005615636142869803, "batch_size": 310, "loss": 0.0013445621391292662}, {"layer_params": [52, 20, 32, 60, 45], "learning_rate": 0.005615058282430875, "batch_size": 175, "loss": 0.002250487292185426}, {"layer_params": [28, 43], "learning_rate": 0.0006538306501604294, "batch_size": 241, "loss": 0.006174511639401316}, {"layer_params": [16, 57, 22], "learning_rate": 0.002711103004660244, "batch_size": 449, "loss": 0.0030319420341402294}, {"layer_params": [20, 61, 18], "learning_rate": 0.0023770548458284728, "batch_size": 114, "loss": 0.004119148149620742}, {"layer_params": [32, 22], "learning_rate": 0.00510180883929442, "batch_size": 103, "loss": 0.003630572829861194}, {"layer_params": [48, 47, 58, 36], "learning_rate": 0.005360813054772114, "batch_size": 136, "loss": 0.002053747664904222}, {"layer_params": [49, 59, 21, 51, 24], "learning_rate": 0.005947238759778429, "batch_size": 483, "loss": 0.0010089053731644525}, {"layer_params": [39, 64], "learning_rate": 0.0006697595084391818, "batch_size": 182, "loss": 0.005996746914461255}, {"layer_params": [61, 51, 60], "learning_rate": 0.0015773955580319435, "batch_size": 404, "loss": 0.0013758403284009546}, {"layer_params": [21, 32, 16, 50], "learning_rate": 0.0018088342295656918, "batch_size": 186, "loss": 0.0034683542838320138}, {"layer_params": [63, 23, 29], "learning_rate": 0.0034039095156485257, "batch_size": 99, "loss": 0.003715402614325285}, {"layer_params": [21, 35, 47], "learning_rate": 0.0021216502691986544, "batch_size": 184, "loss": 0.0036172421858645977}, {"layer_params": [41, 58], "learning_rate": 0.0034934193316154146, "batch_size": 471, "loss": 0.001179463369771838}, {"layer_params": [54, 29, 19], "learning_rate": 0.002758751773786769, "batch_size": 493, "loss": 0.0031534259277395905}, {"layer_params": [56, 22], "learning_rate": 0.004622610651513408, "batch_size": 104, "loss": 0.0052802046202123165}, {"layer_params": [37, 62, 43, 48, 40], "learning_rate": 0.009614469844941216, "batch_size": 220, "loss": 0.001764610167592764}, {"layer_params": [58, 48, 16, 20], "learning_rate": 0.007047265488745751, "batch_size": 332, "loss": 0.0022225077543407677}, {"layer_params": [42, 60, 31], "learning_rate": 0.0033058538726171995, "batch_size": 193, "loss": 0.002816820782609284}, {"layer_params": [44, 23], "learning_rate": 0.006653949368166269, "batch_size": 282, "loss": 0.0012216548551805318}, {"layer_params": [39, 17, 36, 62], "learning_rate": 0.00593458523680099, "batch_size": 459, "loss": 0.0019020758417900652}, {"layer_params": [36, 48, 56, 59], "learning_rate": 0.00651386709548873, "batch_size": 440, "loss": 0.0011737491795793175}, {"layer_params": [19, 28, 16, 33, 56], "learning_rate": 0.004191315976395564, "batch_size": 298, "loss": 0.003419657964259386}, {"layer_params": [24, 24, 25], "learning_rate": 0.006325602570267629, "batch_size": 86, "loss": 0.003542291515041143}, {"layer_params": [56, 43, 37, 55, 21], "learning_rate": 0.007371555322372306, "batch_size": 434, "loss": 0.0016251637518871576}, {"layer_params": [20, 22], "learning_rate": 0.00787135715643846, "batch_size": 19, "loss": 0.007156048117903993}, {"layer_params": [56, 23, 56, 51, 55], "learning_rate": 0.00506861767123323, "batch_size": 55, "loss": 0.003996819229796529}, {"layer_params": [17, 54, 34, 52], "learning_rate": 0.008602388104943069, "batch_size": 234, "loss": 0.002747146429028362}, {"layer_params": [23, 46, 51], "learning_rate": 0.002459109491024576, "batch_size": 55, "loss": 0.0037277392158284782}, {"layer_params": [53, 34], "learning_rate": 0.00644631503389911, "batch_size": 91, "loss": 0.0026386360602919014}, {"layer_params": [28, 36, 18, 49], "learning_rate": 0.006066594481984064, "batch_size": 196, "loss": 0.002404739666962996}, {"layer_params": [43, 35, 47, 55], "learning_rate": 0.002459454797813481, "batch_size": 511, "loss": 0.0016196948802098632}, {"layer_params": [39, 17, 24], "learning_rate": 0.008420285813653346, "batch_size": 406, "loss": 0.0020232289866544306}, {"layer_params": [44, 35, 41], "learning_rate": 0.009192332154070589, "batch_size": 59, "loss": 0.0037689146981574593}, {"layer_params": [45, 56, 37, 63, 34], "learning_rate": 0.0014790294737689334, "batch_size": 273, "loss": 0.002217767733382061}, {"layer_params": [64, 27, 50, 45, 32], "learning_rate": 0.004181906346445717, "batch_size": 477, "loss": 0.0008026623283512891}, {"layer_params": [51, 19, 20, 19], "learning_rate": 0.005752638464791527, "batch_size": 32, "loss": 0.005717775386292487}, {"layer_params": [54, 48, 59, 29, 25], "learning_rate": 0.007388213893275871, "batch_size": 223, "loss": 0.0009359431581106037}, {"layer_params": [17, 40], "learning_rate": 0.0011785426801532361, "batch_size": 19, "loss": 0.009126046545570716}, {"layer_params": [40, 17, 42, 61, 33], "learning_rate": 0.0040315094908417596, "batch_size": 338, "loss": 0.002422988344915211}, {"layer_params": [27, 38], "learning_rate": 0.0017643271286805352, "batch_size": 426, "loss": 0.004249916980043054}, {"layer_params": [42, 18, 42, 44, 64], "learning_rate": 0.0006675547885801405, "batch_size": 364, "loss": 0.005104134627617896}, {"layer_params": [51, 38, 38, 20], "learning_rate": 0.002451803978852459, "batch_size": 71, "loss": 0.004296884965151548}, {"layer_params": [37, 22, 56, 38], "learning_rate": 0.008251221908833137, "batch_size": 171, "loss": 0.0022580859367735684}, {"layer_params": [47, 64, 16], "learning_rate": 0.004010940098468738, "batch_size": 177, "loss": 0.0013421160832513123}, {"layer_params": [31, 33, 17, 51], "learning_rate": 0.004514887479467423, "batch_size": 316, "loss": 0.0019159564888104796}, {"layer_params": [53, 31, 43], "learning_rate": 0.0008870214305574289, "batch_size": 163, "loss": 0.003699714122340083}, {"layer_params": [40, 29, 43, 21], "learning_rate": 0.0026861900087002135, "batch_size": 512, "loss": 0.001522550005465746}, {"layer_params": [53, 48, 38], "learning_rate": 0.005666076530534655, "batch_size": 62, "loss": 0.002730603045783937}, {"layer_params": [33, 59, 38, 58, 60], "learning_rate": 0.0073414167629558425, "batch_size": 312, "loss": 0.0009148336679209024}, {"layer_params": [56, 34, 43, 44], "learning_rate": 0.008122522465900466, "batch_size": 263, "loss": 0.0015358047327026724}, {"layer_params": [30, 33, 32, 52, 24], "learning_rate": 0.008811142236322848, "batch_size": 390, "loss": 0.0018691495410166682}, {"layer_params": [56, 18], "learning_rate": 0.0069882734402580094, "batch_size": 226, "loss": 0.003918717722408474}, {"layer_params": [63, 24], "learning_rate": 0.004227788138932242, "batch_size": 469, "loss": 0.0018572948721703143}, {"layer_params": [18, 42, 57, 37, 42], "learning_rate": 0.005668870560641957, "batch_size": 212, "loss": 0.0024711268406827002}, {"layer_params": [46, 55, 25, 51], "learning_rate": 0.008035870372767734, "batch_size": 451, "loss": 0.001439032913185656}, {"layer_params": [31, 32, 22], "learning_rate": 0.009616555406579845, "batch_size": 415, "loss": 0.0030909391213208436}, {"layer_params": [36, 40, 56, 22, 64], "learning_rate": 0.0025498846049609404, "batch_size": 243, "loss": 0.0019573593931272626}, {"layer_params": [59, 41], "learning_rate": 0.00250529840740577, "batch_size": 115, "loss": 0.0029638923460152}, {"layer_params": [50, 29, 30], "learning_rate": 0.0003703293582108445, "batch_size": 466, "loss": 0.00608888054266572}, {"layer_params": [29, 30, 21, 23], "learning_rate": 0.007867258326959838, "batch_size": 464, "loss": 0.0019166222668718547}, {"layer_params": [19, 26, 33, 59], "learning_rate": 0.004113535537270815, "batch_size": 406, "loss": 0.0019110012101009489}, {"layer_params": [27, 29, 19, 52], "learning_rate": 0.00011211020870497941, "batch_size": 408, "loss": 0.012700245464220643}, {"layer_params": [45, 50, 41, 35], "learning_rate": 0.007153315390314709, "batch_size": 412, "loss": 0.0012353564385557548}, {"layer_params": [26, 36], "learning_rate": 0.002056371698227519, "batch_size": 115, "loss": 0.005960246920585633}, {"layer_params": [47, 23, 30], "learning_rate": 0.0069718515654204356, "batch_size": 106, "loss": 0.003668078142218292}, {"layer_params": [40, 63, 16, 37], "learning_rate": 0.001649546453964546, "batch_size": 427, "loss": 0.001960635451832786}, {"layer_params": [45, 50], "learning_rate": 0.009746760287885127, "batch_size": 493, "loss": 0.0013798652519471943}, {"layer_params": [60, 64], "learning_rate": 0.0012953561975582088, "batch_size": 505, "loss": 0.0022128490649629385}, {"layer_params": [16, 55], "learning_rate": 0.0069411355957275265, "batch_size": 165, "loss": 0.004093884155154228}, {"layer_params": [20, 60, 57], "learning_rate": 0.004179947311256508, "batch_size": 458, "loss": 0.00249080742476508}, {"layer_params": [28, 45, 57], "learning_rate": 0.001686799247955824, "batch_size": 352, "loss": 0.002077478303108364}, {"layer_params": [48, 32, 59, 33], "learning_rate": 0.0010072824750041584, "batch_size": 61, "loss": 0.0046439448976889255}, {"layer_params": [17, 48, 21, 51], "learning_rate": 0.009576187918796285, "batch_size": 425, "loss": 0.003487374568358064}, {"layer_params": [19, 18, 36, 23, 37], "learning_rate": 0.001340779517348504, "batch_size": 461, "loss": 0.003704349515028298}, {"layer_params": [48, 63, 26], "learning_rate": 0.0001877100580324848, "batch_size": 22, "loss": 0.021188833666965366}, {"layer_params": [50, 30, 27], "learning_rate": 0.0078747550141902, "batch_size": 26, "loss": 0.006963674502912909}, {"layer_params": [33, 43], "learning_rate": 0.0016046981731776997, "batch_size": 407, "loss": 0.003485546458978206}, {"layer_params": [24, 62], "learning_rate": 0.005383369606211205, "batch_size": 230, "loss": 0.0020189894177019595}, {"layer_params": [42, 24, 23, 46, 53], "learning_rate": 0.0019254767931133334, "batch_size": 449, "loss": 0.0024017773696687074}, {"layer_params": [55, 58, 22, 28], "learning_rate": 0.0035254630048795156, "batch_size": 359, "loss": 0.001230666832998395}, {"layer_params": [62, 52, 22, 58], "learning_rate": 0.006011296083991603, "batch_size": 367, "loss": 0.0011097209283616393}, {"layer_params": [42, 21], "learning_rate": 0.008318709712463108, "batch_size": 249, "loss": 0.0018242531351279467}, {"layer_params": [43, 22, 53], "learning_rate": 0.00099124965716492, "batch_size": 78, "loss": 0.006134352667722851}, {"layer_params": [39, 31, 33, 27, 54], "learning_rate": 0.004645045997042962, "batch_size": 494, "loss": 0.0022540154901798813}, {"layer_params": [24, 61], "learning_rate": 0.000630747242512752, "batch_size": 309, "loss": 0.007156100673601031}, {"layer_params": [63, 47, 58, 62, 54], "learning_rate": 0.0010643068092248019, "batch_size": 431, "loss": 0.002067540790885687}, {"layer_params": [30, 51, 26, 55, 25], "learning_rate": 0.0044162930023689505, "batch_size": 130, "loss": 0.0021567459183279426}, {"layer_params": [38, 23], "learning_rate": 0.0044975167661255, "batch_size": 51, "loss": 0.00587499825283885}, {"layer_params": [38, 43, 19, 33], "learning_rate": 0.003976243903939254, "batch_size": 50, "loss": 0.004917558351298795}, {"layer_params": [42, 53], "learning_rate": 0.0012549906121036506, "batch_size": 203, "loss": 0.0033057543216273187}, {"layer_params": [45, 35, 46, 17], "learning_rate": 0.0077836363058612044, "batch_size": 201, "loss": 0.0014470957114826888}, {"layer_params": [52, 42], "learning_rate": 0.0060895323390109425, "batch_size": 341, "loss": 0.0012528940849006176}, {"layer_params": [31, 32, 61], "learning_rate": 0.00010373341428995188, "batch_size": 348, "loss": 0.02463942613452673}, {"layer_params": [31, 63, 52, 35], "learning_rate": 0.003940748709850185, "batch_size": 351, "loss": 0.0012574032618431375}, {"layer_params": [61, 42, 20, 57, 24], "learning_rate": 0.0028212442242922294, "batch_size": 37, "loss": 0.002896384543273598}, {"layer_params": [20, 55, 25, 28, 38], "learning_rate": 0.002986661294867259, "batch_size": 166, "loss": 0.0028709675453137606}, {"layer_params": [63, 46], "learning_rate": 0.006427528047630299, "batch_size": 284, "loss": 0.0009884467348456384}, {"layer_params": [50, 62, 20, 39], "learning_rate": 0.008203077227165087, "batch_size": 429, "loss": 0.00138559166691266}, {"layer_params": [46, 32, 61, 45], "learning_rate": 0.008475746976425932, "batch_size": 432, "loss": 0.0017448477633297444}, {"layer_params": [16, 18, 36, 63, 28], "learning_rate": 0.0035951328732352354, "batch_size": 321, "loss": 0.004697224865667522}, {"layer_params": [47, 43, 57, 22, 47], "learning_rate": 0.0012260694926070842, "batch_size": 244, "loss": 0.002679315765853971}, {"layer_params": [54, 20, 34], "learning_rate": 0.0007990476379943381, "batch_size": 460, "loss": 0.002979488328564912}, {"layer_params": [63, 59, 41, 25, 52], "learning_rate": 0.0011182909514621943, "batch_size": 272, "loss": 0.002404525214806199}, {"layer_params": [39, 59, 34, 21], "learning_rate": 0.00802980072266212, "batch_size": 130, "loss": 0.0019326261500827969}, {"layer_params": [43, 36, 16, 24], "learning_rate": 0.009267948731365269, "batch_size": 24, "loss": 0.006749273894820362}, {"layer_params": [24, 43, 41], "learning_rate": 0.006087492501887662, "batch_size": 332, "loss": 0.002530005710432306}, {"layer_params": [63, 21, 62, 29, 21], "learning_rate": 0.0008613215982781917, "batch_size": 274, "loss": 0.003068461299408227}, {"layer_params": [61, 53], "learning_rate": 0.0032979149946535252, "batch_size": 285, "loss": 0.001967755266232416}, {"layer_params": [58, 16, 21, 38], "learning_rate": 0.009252812307571006, "batch_size": 172, "loss": 0.001934445600491017}, {"layer_params": [20, 61, 49], "learning_rate": 0.006838748990583525, "batch_size": 214, "loss": 0.0023545412335079165}, {"layer_params": [20, 49, 16, 47, 39], "learning_rate": 0.0027793912312897005, "batch_size": 249, "loss": 0.003333200274500996}, {"layer_params": [53, 53, 43], "learning_rate": 0.00885349482185553, "batch_size": 114, "loss": 0.002078738892450929}, {"layer_params": [59, 42, 55, 63], "learning_rate": 0.00615653264868674, "batch_size": 95, "loss": 0.002334860219852999}, {"layer_params": [42, 54], "learning_rate": 0.005666557589848716, "batch_size": 347, "loss": 0.0011500044248532503}, {"layer_params": [24, 22], "learning_rate": 0.007850010572736276, "batch_size": 408, "loss": 0.003496713717468083}, {"layer_params": [56, 51, 28, 52], "learning_rate": 0.0025509197294513847, "batch_size": 459, "loss": 0.001555254211416468}, {"layer_params": [40, 47, 57], "learning_rate": 0.003921311633190261, "batch_size": 46, "loss": 0.003360630605602637}, {"layer_params": [60, 61, 33], "learning_rate": 0.008856396496085352, "batch_size": 171, "loss": 0.0014182282390538604}, {"layer_params": [63, 49, 37, 63], "learning_rate": 0.00778132307402773, "batch_size": 491, "loss": 0.0009366476821014658}, {"layer_params": [61, 53, 34, 64], "learning_rate": 0.002294495447890082, "batch_size": 403, "loss": 0.0008882451121462509}, {"layer_params": [54, 44, 49], "learning_rate": 0.006673623332736222, "batch_size": 88, "loss": 0.0015420562092913314}, {"layer_params": [39, 25], "learning_rate": 0.0032732424603389124, "batch_size": 258, "loss": 0.004769526135642081}, {"layer_params": [45, 35, 36, 57, 40], "learning_rate": 0.0035675952184321086, "batch_size": 48, "loss": 0.004289451264776289}, {"layer_params": [64, 42, 21, 50], "learning_rate": 0.004606257320842186, "batch_size": 143, "loss": 0.0016938433842733503}, {"layer_params": [63, 30], "learning_rate": 0.004502802077432887, "batch_size": 479, "loss": 0.0026337821478955446}, {"layer_params": [60, 62, 34], "learning_rate": 0.004765668758012352, "batch_size": 411, "loss": 0.001238332277862355}, {"layer_params": [31, 42], "learning_rate": 0.007378169086627662, "batch_size": 404, "loss": 0.002726694152224809}, {"layer_params": [25, 51, 24], "learning_rate": 0.00992720255797063, "batch_size": 427, "loss": 0.0019086466054432094}, {"layer_params": [45, 64], "learning_rate": 0.003216219896063068, "batch_size": 474, "loss": 0.0020181144657544794}, {"layer_params": [21, 45, 35, 46, 26], "learning_rate": 0.00989927096168923, "batch_size": 268, "loss": 0.003507804910186678}, {"layer_params": [48, 25, 21], "learning_rate": 0.005007169938506718, "batch_size": 159, "loss": 0.0034263665904290972}, {"layer_params": [41, 43, 49], "learning_rate": 0.0024477059937529086, "batch_size": 224, "loss": 0.0019167025852948427}, {"layer_params": [62, 35], "learning_rate": 0.008804186864152286, "batch_size": 150, "loss": 0.003058363040909171}, {"layer_params": [30, 18], "learning_rate": 0.008276628933177592, "batch_size": 58, "loss": 0.002973611960187554}, {"layer_params": [63, 29], "learning_rate": 0.009800242418676787, "batch_size": 413, "loss": 0.0023910093493759634}, {"layer_params": [37, 38, 64], "learning_rate": 0.0008878374381489564, "batch_size": 430, "loss": 0.0031172462226822972}, {"layer_params": [29, 29, 38], "learning_rate": 0.006601088316177412, "batch_size": 132, "loss": 0.002728420553030446}, {"layer_params": [21, 37, 41], "learning_rate": 0.0019107266713510086, "batch_size": 165, "loss": 0.005508983740583062}, {"layer_params": [44, 55], "learning_rate": 0.0065910102915262845, "batch_size": 142, "loss": 0.002469255637843162}, {"layer_params": [30, 50], "learning_rate": 0.0015354289689690575, "batch_size": 503, "loss": 0.0019761235977057367}, {"layer_params": [30, 45, 34, 39, 61], "learning_rate": 0.0004566254254465861, "batch_size": 87, "loss": 0.00680788959376514}, {"layer_params": [19, 40], "learning_rate": 0.005927883772667297, "batch_size": 144, "loss": 0.00474856304936111}, {"layer_params": [36, 45, 25, 52, 19], "learning_rate": 0.007068855166616486, "batch_size": 28, "loss": 0.005458797251340002}, {"layer_params": [32, 37, 56, 49, 21], "learning_rate": 0.0009361632707212632, "batch_size": 61, "loss": 0.0064840489206835624}, {"layer_params": [42, 45], "learning_rate": 0.0038687656398625927, "batch_size": 252, "loss": 0.0021319273533299565}, {"layer_params": [54, 61], "learning_rate": 0.002830787457623784, "batch_size": 86, "loss": 0.003575650204438716}, {"layer_params": [19, 27], "learning_rate": 0.008859923386502122, "batch_size": 313, "loss": 0.003131554338615388}, {"layer_params": [17, 35, 22, 44, 20], "learning_rate": 0.0067259457367843615, "batch_size": 244, "loss": 0.002789949516300112}, {"layer_params": [26, 56, 50, 58, 38], "learning_rate": 0.00969747532178385, "batch_size": 70, "loss": 0.00319070280645974}, {"layer_params": [35, 26, 50, 46, 49], "learning_rate": 0.002395796095080572, "batch_size": 413, "loss": 0.002247183845611289}, {"layer_params": [55, 39, 32, 28], "learning_rate": 0.0010755036849515013, "batch_size": 108, "loss": 0.004832816440612077}, {"layer_params": [33, 41, 26], "learning_rate": 0.00786718161006108, "batch_size": 113, "loss": 0.002909063798142597}, {"layer_params": [35, 61, 51, 38, 31], "learning_rate": 0.00624204507698669, "batch_size": 302, "loss": 0.0011525753489695489}, {"layer_params": [28, 32, 31, 32, 33], "learning_rate": 0.0006087905354843015, "batch_size": 482, "loss": 0.005383525523357093}, {"layer_params": [25, 54, 41, 30], "learning_rate": 0.0018167807720466693, "batch_size": 82, "loss": 0.003459283048287034}, {"layer_params": [44, 18, 23, 38], "learning_rate": 0.005308519557849828, "batch_size": 298, "loss": 0.002722493594046682}, {"layer_params": [52, 36, 49, 43], "learning_rate": 0.006066228384551684, "batch_size": 148, "loss": 0.0013796012656530365}, {"layer_params": [48, 53], "learning_rate": 0.0012820224955040393, "batch_size": 117, "loss": 0.004145034162793309}, {"layer_params": [64, 31, 23], "learning_rate": 0.0021264261094051154, "batch_size": 341, "loss": 0.004403963065706193}, {"layer_params": [34, 23, 30], "learning_rate": 0.005950333083122017, "batch_size": 197, "loss": 0.003217806317843497}, {"layer_params": [59, 54], "learning_rate": 0.004612469166338016, "batch_size": 470, "loss": 0.0012983778247144073}, {"layer_params": [32, 34], "learning_rate": 0.006088388690776233, "batch_size": 167, "loss": 0.003209661019500345}, {"layer_params": [44, 40], "learning_rate": 0.0013634573539996484, "batch_size": 308, "loss": 0.003930605968926102}, {"layer_params": [42, 37, 23, 40], "learning_rate": 0.008674653789644106, "batch_size": 248, "loss": 0.002637297403998673}, {"layer_params": [20, 44], "learning_rate": 0.006420894068648588, "batch_size": 175, "loss": 0.003796274696942419}, {"layer_params": [40, 32], "learning_rate": 0.009353827768624099, "batch_size": 310, "loss": 0.00163418608950451}, {"layer_params": [19, 33, 23], "learning_rate": 0.00855257236050642, "batch_size": 109, "loss": 0.0051066504255868495}, {"layer_params": [57, 40], "learning_rate": 0.0006451688260632364, "batch_size": 284, "loss": 0.004731882556807249}, {"layer_params": [31, 26], "learning_rate": 0.009377146835414865, "batch_size": 383, "loss": 0.0037411688873544334}, {"layer_params": [39, 20], "learning_rate": 0.005344135862009069, "batch_size": 236, "loss": 0.0017285682167857885}, {"layer_params": [48, 21, 53, 56], "learning_rate": 0.002832491248433538, "batch_size": 18, "loss": 0.008062998559325933}, {"layer_params": [23, 41, 20, 24, 39], "learning_rate": 0.0015444925227692588, "batch_size": 37, "loss": 0.00668267032597214}, {"layer_params": [34, 36, 36, 46, 33], "learning_rate": 0.009151116298286513, "batch_size": 118, "loss": 0.0032011692598462103}, {"layer_params": [63, 16, 17, 33, 16], "learning_rate": 0.004707961984388784, "batch_size": 85, "loss": 0.002760995429707691}, {"layer_params": [63, 23, 36, 39, 53], "learning_rate": 0.0044547586454966774, "batch_size": 121, "loss": 0.0023134085058700293}, {"layer_params": [58, 35], "learning_rate": 0.0047010722644715485, "batch_size": 336, "loss": 0.001518934729974717}, {"layer_params": [17, 54, 60, 30], "learning_rate": 0.0009030704482273038, "batch_size": 288, "loss": 0.0050300964224152265}, {"layer_params": [28, 27, 17, 58], "learning_rate": 0.009773231371634702, "batch_size": 305, "loss": 0.0032069026911631226}, {"layer_params": [27, 28, 57], "learning_rate": 0.004513500367047692, "batch_size": 362, "loss": 0.0030069793807342648}, {"layer_params": [54, 20, 61, 25], "learning_rate": 0.005722418744567842, "batch_size": 57, "loss": 0.003760115762706846}, {"layer_params": [54, 46, 26, 60, 22], "learning_rate": 0.0009883725636768655, "batch_size": 196, "loss": 0.0058673638664186005}, {"layer_params": [55, 18, 45], "learning_rate": 0.00815385129401514, "batch_size": 266, "loss": 0.0021417681779712437}, {"layer_params": [17, 40], "learning_rate": 0.006498835880434529, "batch_size": 501, "loss": 0.004553761624265462}, {"layer_params": [29, 16, 21, 52], "learning_rate": 0.004997491153379496, "batch_size": 338, "loss": 0.0036899713939055803}, {"layer_params": [52, 63, 47, 18], "learning_rate": 0.0038114753291559962, "batch_size": 334, "loss": 0.0016041660716291518}, {"layer_params": [46, 26, 21, 45], "learning_rate": 0.0002436513473130176, "batch_size": 26, "loss": 0.029540153946727515}, {"layer_params": [58, 43, 17], "learning_rate": 0.004628484974704368, "batch_size": 492, "loss": 0.0013061895174905657}, {"layer_params": [61, 53], "learning_rate": 0.0003068484600989016, "batch_size": 116, "loss": 0.0073745534382760524}, {"layer_params": [46, 49, 33], "learning_rate": 0.0064124050163292074, "batch_size": 61, "loss": 0.0028820218285545707}, {"layer_params": [62, 30], "learning_rate": 0.003262466736354624, "batch_size": 121, "loss": 0.0022347075876314195}, {"layer_params": [23, 25, 33], "learning_rate": 0.008303096852890893, "batch_size": 31, "loss": 0.005827005617320537}, {"layer_params": [43, 38, 23, 38, 46], "learning_rate": 0.00965730561487519, "batch_size": 68, "loss": 0.003979219296015799}, {"layer_params": [41, 59, 55, 16, 26], "learning_rate": 0.008730703573204573, "batch_size": 313, "loss": 0.0015195845789276064}, {"layer_params": [55, 53], "learning_rate": 0.0036331112227194844, "batch_size": 503, "loss": 0.0017505434644408523}, {"layer_params": [62, 61, 49, 45, 51], "learning_rate": 0.0070867382464289965, "batch_size": 271, "loss": 0.0009506282850634307}, {"layer_params": [26, 64, 45], "learning_rate": 0.005480421466911854, "batch_size": 93, "loss": 0.004003234913107008}, {"layer_params": [64, 43, 54], "learning_rate": 0.0021981115918759523, "batch_size": 472, "loss": 0.001135219897259958}, {"layer_params": [47, 62, 64], "learning_rate": 0.006420767318915312, "batch_size": 471, "loss": 0.0006281798577401787}, {"layer_params": [32, 20, 37, 29, 23], "learning_rate": 0.003216463889928236, "batch_size": 497, "loss": 0.003217894008848816}, {"layer_params": [35, 29, 53], "learning_rate": 0.009127832565151083, "batch_size": 510, "loss": 0.0019174672325607389}, {"layer_params": [44, 45, 52], "learning_rate": 0.0007929513760434485, "batch_size": 99, "loss": 0.005076161774341017}, {"layer_params": [37, 54, 27, 19, 43], "learning_rate": 0.0034080652936746675, "batch_size": 309, "loss": 0.0020516386593226344}, {"layer_params": [47, 35, 45], "learning_rate": 0.006080517784728209, "batch_size": 24, "loss": 0.00564969788538292}, {"layer_params": [36, 30, 46, 27, 50], "learning_rate": 0.0027867804437847797, "batch_size": 181, "loss": 0.0029688845295459034}, {"layer_params": [58, 24], "learning_rate": 0.0013705508920901395, "batch_size": 151, "loss": 0.004493946714792401}, {"layer_params": [38, 58], "learning_rate": 0.00047340282340015084, "batch_size": 370, "loss": 0.005534370541572571}, {"layer_params": [18, 35, 45, 47, 25], "learning_rate": 0.006695712564272295, "batch_size": 167, "loss": 0.0022516463370993735}, {"layer_params": [20, 40, 24, 20], "learning_rate": 0.0063259588133797754, "batch_size": 334, "loss": 0.0026459146896377207}, {"layer_params": [36, 32], "learning_rate": 0.0018591635318686735, "batch_size": 182, "loss": 0.004190419742371887}, {"layer_params": [18, 51, 35, 41, 48], "learning_rate": 0.007096105264411484, "batch_size": 312, "loss": 0.0020408438832964747}, {"layer_params": [55, 27, 26], "learning_rate": 0.0037910763935852894, "batch_size": 56, "loss": 0.003229696718044579}, {"layer_params": [54, 30, 47, 26, 35], "learning_rate": 0.0026860073814301854, "batch_size": 479, "loss": 0.001696658730506897}, {"layer_params": [32, 35, 29, 48], "learning_rate": 0.004176644067456494, "batch_size": 24, "loss": 0.006465629425365478}, {"layer_params": [56, 24, 44, 24], "learning_rate": 0.006037564413446309, "batch_size": 250, "loss": 0.0017918687185738236}, {"layer_params": [16, 35, 28, 49], "learning_rate": 0.00493901218859687, "batch_size": 315, "loss": 0.0027524277730844914}, {"layer_params": [61, 42, 39, 40, 40], "learning_rate": 0.0069654022032514945, "batch_size": 499, "loss": 0.0007142004405613989}, {"layer_params": [34, 51, 44, 44], "learning_rate": 0.007639653022076891, "batch_size": 30, "loss": 0.004471173434285447}, {"layer_params": [16, 41, 53], "learning_rate": 0.0019068694096015194, "batch_size": 508, "loss": 0.0049380893260240555}, {"layer_params": [25, 40], "learning_rate": 0.009145352574590754, "batch_size": 242, "loss": 0.0033870814507827164}, {"layer_params": [60, 27, 63, 42], "learning_rate": 0.005868770059304517, "batch_size": 167, "loss": 0.0018267341889441012}, {"layer_params": [36, 58, 49, 51, 64], "learning_rate": 0.006433808331684117, "batch_size": 78, "loss": 0.002389209776883945}, {"layer_params": [18, 34, 46, 50, 17], "learning_rate": 0.0007938891619268345, "batch_size": 275, "loss": 0.005701773068867624}, {"layer_params": [17, 56, 31, 57], "learning_rate": 0.004880872128416449, "batch_size": 99, "loss": 0.005975046679377555}, {"layer_params": [56, 57, 63], "learning_rate": 0.004116476115048732, "batch_size": 344, "loss": 0.0010340965347131715}, {"layer_params": [40, 43, 43], "learning_rate": 0.007430414858852764, "batch_size": 456, "loss": 0.0017846182663924992}, {"layer_params": [55, 18, 48, 38, 30], "learning_rate": 0.0073878198932202065, "batch_size": 314, "loss": 0.0016131902940105646}, {"layer_params": [37, 47, 64, 18], "learning_rate": 0.0034444119341350793, "batch_size": 74, "loss": 0.002484532775124535}, {"layer_params": [19, 54, 52, 43, 54], "learning_rate": 0.005842149143498109, "batch_size": 230, "loss": 0.002184650078415871}, {"layer_params": [52, 21], "learning_rate": 0.009326160643627172, "batch_size": 511, "loss": 0.0018532412289641797}, {"layer_params": [56, 46], "learning_rate": 0.006176298446780243, "batch_size": 192, "loss": 0.002214862830005586}, {"layer_params": [44, 44, 26, 20, 55], "learning_rate": 0.00477672566692103, "batch_size": 329, "loss": 0.0015351642621681094}, {"layer_params": [21, 29, 27, 34, 33], "learning_rate": 0.006813469808554151, "batch_size": 252, "loss": 0.00442268983926624}, {"layer_params": [48, 55, 51], "learning_rate": 5.219261983959095e-05, "batch_size": 509, "loss": 0.02177850956097245}, {"layer_params": [48, 50], "learning_rate": 0.0024385544259836606, "batch_size": 136, "loss": 0.002893371388781816}, {"layer_params": [20, 28], "learning_rate": 0.006066646602468926, "batch_size": 68, "loss": 0.006517697176896035}, {"layer_params": [34, 63], "learning_rate": 0.004716780852672145, "batch_size": 416, "loss": 0.0014803121995646507}, {"layer_params": [21, 48, 19, 49, 58], "learning_rate": 0.009607405807156081, "batch_size": 166, "loss": 0.0028030607884284107}, {"layer_params": [59, 45, 52, 25], "learning_rate": 0.006802469288022887, "batch_size": 251, "loss": 0.0012291244551306591}, {"layer_params": [41, 40], "learning_rate": 0.008710836402474614, "batch_size": 138, "loss": 0.0040562570071779195}, {"layer_params": [64, 50], "learning_rate": 0.00691216027964987, "batch_size": 167, "loss": 0.0011514212342444807}, {"layer_params": [60, 16, 60], "learning_rate": 0.005053868953199392, "batch_size": 226, "loss": 0.002356550128897652}, {"layer_params": [42, 22, 29], "learning_rate": 0.00177037537651417, "batch_size": 504, "loss": 0.002744629089720547}, {"layer_params": [23, 61], "learning_rate": 0.007757583135072486, "batch_size": 458, "loss": 0.0025226481282152238}, {"layer_params": [49, 53, 25, 54, 64], "learning_rate": 0.003207292681919922, "batch_size": 390, "loss": 0.0015479174652136861}, {"layer_params": [63, 16, 36, 53], "learning_rate": 0.004087318568991949, "batch_size": 101, "loss": 0.0036775056784972547}, {"layer_params": [54, 50, 18, 39], "learning_rate": 0.003450127199304787, "batch_size": 294, "loss": 0.0023029026470612734}, {"layer_params": [42, 53], "learning_rate": 0.009097765479788142, "batch_size": 131, "loss": 0.001885232370113954}, {"layer_params": [25, 26], "learning_rate": 0.0009450309777052742, "batch_size": 263, "loss": 0.008133265222422779}, {"layer_params": [57, 28, 41, 60], "learning_rate": 0.002451988173993766, "batch_size": 355, "loss": 0.0021163126290775834}, {"layer_params": [21, 33, 33], "learning_rate": 0.008843495855753386, "batch_size": 141, "loss": 0.0036885590897873044}, {"layer_params": [35, 16, 32], "learning_rate": 0.007929358304765795, "batch_size": 102, "loss": 0.004000320911873132}, {"layer_params": [43, 64], "learning_rate": 0.009107117943344872, "batch_size": 129, "loss": 0.0017550290672807022}, {"layer_params": [24, 36, 62, 61, 51], "learning_rate": 0.0021785757373983146, "batch_size": 116, "loss": 0.0041353906248696145}, {"layer_params": [46, 21], "learning_rate": 0.00272179055139615, "batch_size": 426, "loss": 0.004379318442661315}, {"layer_params": [37, 20, 53], "learning_rate": 0.00793545160054577, "batch_size": 162, "loss": 0.0014026119100162759}, {"layer_params": [52, 22, 62, 19], "learning_rate": 0.007552884349596153, "batch_size": 479, "loss": 0.0021958696981891988}, {"layer_params": [17, 64], "learning_rate": 0.0006028398464268013, "batch_size": 373, "loss": 0.007683462002314627}, {"layer_params": [63, 55, 60, 23, 22], "learning_rate": 0.0018063641578421176, "batch_size": 312, "loss": 0.0012228196882642806}, {"layer_params": [41, 48, 23, 39], "learning_rate": 0.006719963962073329, "batch_size": 199, "loss": 0.0017067086894530803}, {"layer_params": [54, 20], "learning_rate": 0.0022536573114210405, "batch_size": 387, "loss": 0.0036824600188992917}, {"layer_params": [54, 62, 62], "learning_rate": 0.0028874806262399358, "batch_size": 111, "loss": 0.0016479398292722181}, {"layer_params": [36, 20], "learning_rate": 0.0037173535708646486, "batch_size": 470, "loss": 0.002687778235413134}, {"layer_params": [53, 35], "learning_rate": 0.0024088003701913598, "batch_size": 107, "loss": 0.002870214569848031}, {"layer_params": [25, 28, 48, 27], "learning_rate": 0.00450469583809951, "batch_size": 353, "loss": 0.003342315477784723}, {"layer_params": [37, 31], "learning_rate": 0.004715212749282761, "batch_size": 412, "loss": 0.002257844741689041}, {"layer_params": [39, 19], "learning_rate": 0.0027069263843491997, "batch_size": 112, "loss": 0.002714091120287776}, {"layer_params": [46, 60], "learning_rate": 0.0005522760693331833, "batch_size": 405, "loss": 0.004527219608426094}, {"layer_params": [62, 47], "learning_rate": 0.0048965311328700465, "batch_size": 352, "loss": 0.0013332728063687681}, {"layer_params": [32, 41, 22, 30, 21], "learning_rate": 0.008918678527025872, "batch_size": 155, "loss": 0.0025471783452667295}, {"layer_params": [27, 21], "learning_rate": 0.005013548924890443, "batch_size": 402, "loss": 0.004444795439485461}, {"layer_params": [62, 17], "learning_rate": 0.0026119446997450715, "batch_size": 233, "loss": 0.006402320773340762}, {"layer_params": [48, 52, 62], "learning_rate": 0.0009882483644374008, "batch_size": 465, "loss": 0.0024997782916761934}, {"layer_params": [50, 58], "learning_rate": 0.0033605313585110593, "batch_size": 168, "loss": 0.0020436342176981272}, {"layer_params": [29, 20, 42], "learning_rate": 0.0033323559626392977, "batch_size": 53, "loss": 0.006061739267315716}, {"layer_params": [49, 51], "learning_rate": 0.0024421002918966236, "batch_size": 492, "loss": 0.0019466991443186999}, {"layer_params": [29, 49], "learning_rate": 0.008844051412918934, "batch_size": 164, "loss": 0.0026189096446614713}, {"layer_params": [38, 31, 26, 34, 26], "learning_rate": 0.008166429770239491, "batch_size": 90, "loss": 0.0027786327502690254}, {"layer_params": [23, 51], "learning_rate": 0.0035503974714954953, "batch_size": 375, "loss": 0.0027845732169225813}, {"layer_params": [61, 54, 44, 28, 49], "learning_rate": 0.008239827193693733, "batch_size": 221, "loss": 0.0017525762598961591}, {"layer_params": [36, 40], "learning_rate": 0.00800539178283207, "batch_size": 69, "loss": 0.004458103771321475}, {"layer_params": [30, 16], "learning_rate": 0.007478615434431211, "batch_size": 344, "loss": 0.004348980716895312}, {"layer_params": [63, 44], "learning_rate": 0.0011021434823354213, "batch_size": 85, "loss": 0.004578277948312461}, {"layer_params": [18, 39, 59, 63, 17], "learning_rate": 0.002181074951037071, "batch_size": 371, "loss": 0.003512425892986357}, {"layer_params": [58, 34, 22], "learning_rate": 0.008124131548190036, "batch_size": 493, "loss": 0.0014646292012184857}, {"layer_params": [39, 32, 18, 31, 17], "learning_rate": 0.0031271738841516113, "batch_size": 153, "loss": 0.0028833268920425326}, {"layer_params": [52, 59, 20, 62], "learning_rate": 0.00884252603187805, "batch_size": 450, "loss": 0.001356174685060978}, {"layer_params": [24, 48, 48, 19, 46], "learning_rate": 0.004155818672690283, "batch_size": 327, "loss": 0.001405202493770048}, {"layer_params": [52, 30, 43, 40, 24], "learning_rate": 0.0010353259440260079, "batch_size": 172, "loss": 0.004955603687558323}, {"layer_params": [28, 17], "learning_rate": 0.0025032200496754426, "batch_size": 507, "loss": 0.004981571966782212}, {"layer_params": [28, 19, 53, 24, 42], "learning_rate": 0.007628483470309132, "batch_size": 506, "loss": 0.0025266021373681726}, {"layer_params": [20, 28, 19], "learning_rate": 0.006644953251260258, "batch_size": 44, "loss": 0.005955052464269101}, {"layer_params": [37, 27, 62, 20], "learning_rate": 0.009417359769637496, "batch_size": 356, "loss": 0.0019916087144520134}, {"layer_params": [24, 19, 52], "learning_rate": 0.009784004958676878, "batch_size": 347, "loss": 0.0029817623598501087}, {"layer_params": [61, 27, 22, 49, 22], "learning_rate": 0.009389907086794217, "batch_size": 140, "loss": 0.003242791302036494}, {"layer_params": [27, 31, 64], "learning_rate": 0.0035685400098642846, "batch_size": 170, "loss": 0.002771911531453952}, {"layer_params": [58, 62, 60], "learning_rate": 0.0050391001972430885, "batch_size": 161, "loss": 0.0019358272885438054}, {"layer_params": [51, 53, 34, 30, 54], "learning_rate": 0.0024365798433489713, "batch_size": 378, "loss": 0.0015834027843084186}, {"layer_params": [28, 37], "learning_rate": 0.006954102921917818, "batch_size": 355, "loss": 0.001996780928457156}, {"layer_params": [17, 25, 45], "learning_rate": 0.009848860292603874, "batch_size": 370, "loss": 0.0033504277165047826}, {"layer_params": [29, 60, 40, 50], "learning_rate": 0.007694068645686218, "batch_size": 82, "loss": 0.003258698612917215}, {"layer_params": [30, 48, 50, 44, 51], "learning_rate": 0.008714829365434915, "batch_size": 185, "loss": 0.0018995032296516001}, {"layer_params": [18, 36, 28, 41, 63], "learning_rate": 0.009790944852748985, "batch_size": 76, "loss": 0.007753664054907858}, {"layer_params": [56, 25, 24, 30], "learning_rate": 0.006361933958198916, "batch_size": 72, "loss": 0.0033435281820129604}, {"layer_params": [25, 54, 49, 39, 48], "learning_rate": 0.00682712925847791, "batch_size": 71, "loss": 0.004077698818873614}, {"layer_params": [50, 41, 26, 48, 32], "learning_rate": 0.00491298837943291, "batch_size": 39, "loss": 0.004484022904653102}, {"layer_params": [17, 60, 27, 62], "learning_rate": 0.007220435773623268, "batch_size": 390, "loss": 0.0029605095903389154}, {"layer_params": [20, 27], "learning_rate": 0.00746260551962702, "batch_size": 360, "loss": 0.004001462629530579}, {"layer_params": [54, 24, 49, 27, 43], "learning_rate": 0.0008794599116108255, "batch_size": 52, "loss": 0.0062788222450762985}, {"layer_params": [22, 43, 26], "learning_rate": 0.009932950397018109, "batch_size": 232, "loss": 0.001767106105107814}, {"layer_params": [37, 48], "learning_rate": 0.00029571694235822044, "batch_size": 282, "loss": 0.007892638123594224}, {"layer_params": [31, 36, 38, 36], "learning_rate": 0.0043316985920444605, "batch_size": 194, "loss": 0.002228409934323281}, {"layer_params": [58, 44, 60], "learning_rate": 0.002759320074282174, "batch_size": 172, "loss": 0.002220411404268816}, {"layer_params": [31, 45], "learning_rate": 0.0015688356664985293, "batch_size": 228, "loss": 0.004994435056578368}, {"layer_params": [39, 63, 49, 30], "learning_rate": 0.0058684007636297525, "batch_size": 280, "loss": 0.001726784367347136}, {"layer_params": [28, 38], "learning_rate": 0.007288164476434707, "batch_size": 74, "loss": 0.0039380676066502925}, {"layer_params": [26, 31, 26, 42], "learning_rate": 0.0035191428633508074, "batch_size": 481, "loss": 0.0020947917515877633}, {"layer_params": [19, 31, 59, 37, 25], "learning_rate": 0.0023626109718335596, "batch_size": 204, "loss": 0.0038318836060352622}, {"layer_params": [62, 62, 20, 46], "learning_rate": 0.004882891003469619, "batch_size": 355, "loss": 0.001312707024626434}, {"layer_params": [53, 46, 26, 48, 31], "learning_rate": 0.00939461689349233, "batch_size": 23, "loss": 0.006114687500521541}, {"layer_params": [42, 56, 49], "learning_rate": 0.006692123709221167, "batch_size": 111, "loss": 0.002113283983198926}, {"layer_params": [54, 17], "learning_rate": 0.006050628223287379, "batch_size": 323, "loss": 0.0031471255398355423}, {"layer_params": [41, 47, 30, 64], "learning_rate": 0.0065979903791295955, "batch_size": 84, "loss": 0.0028336936759296803}, {"layer_params": [35, 37, 48], "learning_rate": 0.005917832919104615, "batch_size": 22, "loss": 0.005280264806933701}, {"layer_params": [61, 59, 37], "learning_rate": 0.007744428533328311, "batch_size": 502, "loss": 0.0011322658561402931}, {"layer_params": [43, 49, 43, 59], "learning_rate": 0.00427198461381116, "batch_size": 194, "loss": 0.0021374301926698537}, {"layer_params": [36, 49, 32], "learning_rate": 0.0020292378528489704, "batch_size": 309, "loss": 0.0021149899868760256}, {"layer_params": [36, 32], "learning_rate": 0.0033857808434080753, "batch_size": 450, "loss": 0.001972712646238506}, {"layer_params": [59, 16, 44], "learning_rate": 0.006915559358652119, "batch_size": 412, "loss": 0.0031566467694938184}, {"layer_params": [28, 34], "learning_rate": 0.0025288879124174737, "batch_size": 100, "loss": 0.003225535615347326}, {"layer_params": [34, 46, 64, 17, 41], "learning_rate": 0.0038640437914342638, "batch_size": 178, "loss": 0.0022819420520681886}, {"layer_params": [60, 48, 25], "learning_rate": 0.0015879185127311824, "batch_size": 27, "loss": 0.005831204378046096}, {"layer_params": [20, 30], "learning_rate": 0.004553275108451691, "batch_size": 424, "loss": 0.004544128314591944}, {"layer_params": [54, 48], "learning_rate": 0.007171784131382503, "batch_size": 35, "loss": 0.0034006928955204784}, {"layer_params": [40, 54], "learning_rate": 0.006008882003417637, "batch_size": 170, "loss": 0.0020201434183400122}, {"layer_params": [49, 20, 59, 29, 47], "learning_rate": 0.0015592417440238012, "batch_size": 267, "loss": 0.002798794605769217}, {"layer_params": [19, 51], "learning_rate": 0.0017293433707849463, "batch_size": 461, "loss": 0.005364274447783828}, {"layer_params": [38, 51, 64], "learning_rate": 0.004388246478416089, "batch_size": 492, "loss": 0.00123307122499682}, {"layer_params": [53, 38, 34], "learning_rate": 0.002570375412401693, "batch_size": 136, "loss": 0.0034654029994271697}, {"layer_params": [16, 25, 57, 17], "learning_rate": 0.0037000399390045746, "batch_size": 34, "loss": 0.008322227920871228}, {"layer_params": [35, 57], "learning_rate": 0.007935197115456968, "batch_size": 277, "loss": 0.001560942518990487}, {"layer_params": [48, 61], "learning_rate": 0.004076833828902917, "batch_size": 429, "loss": 0.0015778458991553635}, {"layer_params": [36, 47, 37, 51, 43], "learning_rate": 1.4088375998761099e-05, "batch_size": 200, "loss": 0.03931654904037714}, {"layer_params": [34, 61], "learning_rate": 0.0085255874139535, "batch_size": 492, "loss": 0.0010839490161743015}, {"layer_params": [27, 45, 53, 55, 37], "learning_rate": 0.0020531992699604805, "batch_size": 316, "loss": 0.0018062001839280128}, {"layer_params": [47, 56, 57, 25, 43], "learning_rate": 0.009678779301764204, "batch_size": 403, "loss": 0.001667625739937648}, {"layer_params": [56, 33], "learning_rate": 0.007731353330545176, "batch_size": 348, "loss": 0.0018846189952455461}, {"layer_params": [61, 18, 45], "learning_rate": 0.005241032832031584, "batch_size": 294, "loss": 0.0030293547827750446}, {"layer_params": [20, 56, 32, 25, 56], "learning_rate": 0.00046549371103607934, "batch_size": 434, "loss": 0.006310672694817185}, {"layer_params": [36, 38, 42], "learning_rate": 0.009736011608165979, "batch_size": 491, "loss": 0.0021787964273244143}, {"layer_params": [64, 33, 55], "learning_rate": 0.0002701855770354608, "batch_size": 278, "loss": 0.006933591179549694}, {"layer_params": [59, 64, 40, 62, 36], "learning_rate": 0.0028146526085198573, "batch_size": 269, "loss": 0.0016907111997716128}, {"layer_params": [39, 32, 32, 56], "learning_rate": 0.002652669699142386, "batch_size": 341, "loss": 0.0022473073296714573}, {"layer_params": [44, 51, 50, 22, 20], "learning_rate": 0.001664984445134483, "batch_size": 437, "loss": 0.002167005680967122}, {"layer_params": [28, 23, 19], "learning_rate": 0.003512166229628404, "batch_size": 375, "loss": 0.003062472082674503}, {"layer_params": [62, 16, 46, 51, 62], "learning_rate": 0.0062353623251723625, "batch_size": 206, "loss": 0.0017613344744313508}, {"layer_params": [33, 33], "learning_rate": 0.0017180014433049297, "batch_size": 164, "loss": 0.00597157004289329}, {"layer_params": [18, 16], "learning_rate": 0.005666887388376642, "batch_size": 437, "loss": 0.005157996718771755}, {"layer_params": [35, 55, 54], "learning_rate": 0.0066469677740031655, "batch_size": 409, "loss": 0.0013740807119756936}, {"layer_params": [39, 27, 31], "learning_rate": 0.0012933366069386033, "batch_size": 309, "loss": 0.002459369539283216}, {"layer_params": [34, 54, 26, 23, 28], "learning_rate": 0.0024673827900343406, "batch_size": 424, "loss": 0.0012747060367837549}, {"layer_params": [35, 34, 36, 32], "learning_rate": 0.009700975737926295, "batch_size": 416, "loss": 0.0016418101266026496}, {"layer_params": [36, 32], "learning_rate": 0.002111615970640065, "batch_size": 80, "loss": 0.006290949003305286}, {"layer_params": [45, 34, 24], "learning_rate": 0.0065604283394286944, "batch_size": 350, "loss": 0.001714460855582729}, {"layer_params": [57, 45, 60], "learning_rate": 0.007140410742240023, "batch_size": 390, "loss": 0.0011232789617497475}, {"layer_params": [42, 49], "learning_rate": 0.0031205630706907703, "batch_size": 405, "loss": 0.0014571327506564557}, {"layer_params": [43, 42, 30, 37], "learning_rate": 0.003374171572342404, "batch_size": 421, "loss": 0.0019462984404526652}, {"layer_params": [50, 26, 21], "learning_rate": 0.0021783958402551242, "batch_size": 228, "loss": 0.0026427749847061934}, {"layer_params": [62, 61, 46], "learning_rate": 0.0010477710117576305, "batch_size": 318, "loss": 0.0018878151243552565}, {"layer_params": [51, 59, 44, 34, 34], "learning_rate": 0.0009402367895598641, "batch_size": 94, "loss": 0.0032204391853883864}, {"layer_params": [55, 41], "learning_rate": 0.006718015342189607, "batch_size": 307, "loss": 0.001091080904006958}, {"layer_params": [29, 37], "learning_rate": 0.003994936744072726, "batch_size": 432, "loss": 0.0024742561858147384}, {"layer_params": [56, 36, 27, 61], "learning_rate": 0.009852020556874579, "batch_size": 507, "loss": 0.0009269877918995917}, {"layer_params": [50, 58, 50, 57, 34], "learning_rate": 0.006782299972026268, "batch_size": 381, "loss": 0.0012154827435733751}, {"layer_params": [56, 25, 20, 39], "learning_rate": 0.0009102055846600529, "batch_size": 466, "loss": 0.0038809721893630924}, {"layer_params": [54, 33, 36], "learning_rate": 0.009174620106327481, "batch_size": 183, "loss": 0.0022450000105891377}, {"layer_params": [45, 25, 63, 20], "learning_rate": 0.004400722627281975, "batch_size": 245, "loss": 0.002093833794351667}, {"layer_params": [61, 52, 60, 24, 42], "learning_rate": 0.0039053129529625467, "batch_size": 393, "loss": 0.0010336895671207457}, {"layer_params": [51, 16, 32, 34], "learning_rate": 0.007726734275044726, "batch_size": 183, "loss": 0.003824458399321884}, {"layer_params": [60, 37, 32, 50], "learning_rate": 0.00991869530140158, "batch_size": 504, "loss": 0.0014342851843684912}, {"layer_params": [26, 23, 44], "learning_rate": 0.0073083707315625785, "batch_size": 79, "loss": 0.0032683775667101144}, {"layer_params": [46, 43, 28, 31], "learning_rate": 0.003111618799660117, "batch_size": 107, "loss": 0.0035666414722800256}, {"layer_params": [16, 31, 48, 32, 29], "learning_rate": 0.0008915871595869421, "batch_size": 397, "loss": 0.007372514759190381}, {"layer_params": [45, 23, 35], "learning_rate": 0.005120918062096835, "batch_size": 304, "loss": 0.0025211065739858896}, {"layer_params": [54, 17, 58], "learning_rate": 0.003433483361697729, "batch_size": 457, "loss": 0.002165900822728872}, {"layer_params": [60, 25, 64, 46, 50], "learning_rate": 0.0012849251823251616, "batch_size": 319, "loss": 0.004338114438578487}, {"layer_params": [31, 54, 46, 24], "learning_rate": 0.002638516251915501, "batch_size": 479, "loss": 0.0012885584332980216}, {"layer_params": [38, 39, 50], "learning_rate": 0.007020362490803395, "batch_size": 155, "loss": 0.0021751793846488}, {"layer_params": [21, 62, 57, 55, 36], "learning_rate": 0.0009582524767056223, "batch_size": 474, "loss": 0.003241359875537455}, {"layer_params": [50, 48, 20], "learning_rate": 0.0023454601640816677, "batch_size": 96, "loss": 0.003566351761110127}, {"layer_params": [28, 21, 61, 16], "learning_rate": 0.004364048910644756, "batch_size": 341, "loss": 0.00237975285272114}, {"layer_params": [17, 25, 63], "learning_rate": 0.007258516961286127, "batch_size": 326, "loss": 0.003499564554076642}, {"layer_params": [17, 35, 46, 25], "learning_rate": 0.008344675307496285, "batch_size": 56, "loss": 0.006874368647113442}, {"layer_params": [43, 32, 44, 45, 22], "learning_rate": 0.002807813054544654, "batch_size": 493, "loss": 0.0030742611712776123}, {"layer_params": [37, 35, 30], "learning_rate": 0.004747732512594644, "batch_size": 106, "loss": 0.003050289435777813}, {"layer_params": [35, 24, 55, 60, 50], "learning_rate": 0.0028758455915314537, "batch_size": 161, "loss": 0.003089973528403789}, {"layer_params": [60, 45, 36], "learning_rate": 0.0091174380336314, "batch_size": 42, "loss": 0.003847972600487992}, {"layer_params": [28, 24, 48, 49], "learning_rate": 0.003195342802056059, "batch_size": 246, "loss": 0.002769729965366423}, {"layer_params": [59, 33, 27], "learning_rate": 0.004338792405441573, "batch_size": 210, "loss": 0.0028716100403107705}, {"layer_params": [45, 36, 48, 52], "learning_rate": 0.0003724139418379336, "batch_size": 99, "loss": 0.0070121850119903685}, {"layer_params": [60, 36, 56, 39, 42], "learning_rate": 0.00922614469226542, "batch_size": 382, "loss": 0.0007150023576105014}, {"layer_params": [19, 54], "learning_rate": 0.005765261520797289, "batch_size": 303, "loss": 0.0030647955858148636}, {"layer_params": [25, 22, 51, 43], "learning_rate": 0.0021017990862838083, "batch_size": 441, "loss": 0.0030492556211538613}, {"layer_params": [42, 61, 41, 64, 23], "learning_rate": 0.003962637619831415, "batch_size": 249, "loss": 0.0016281638154760003}, {"layer_params": [35, 36, 38, 60, 25], "learning_rate": 0.000591648562672465, "batch_size": 391, "loss": 0.005102489958517253}, {"layer_params": [47, 52, 62, 21], "learning_rate": 0.006602755434645334, "batch_size": 449, "loss": 0.0011375371960457414}, {"layer_params": [17, 22, 16, 43, 50], "learning_rate": 0.007620317535113266, "batch_size": 227, "loss": 0.0035975840920582413}, {"layer_params": [61, 46, 37, 23, 34], "learning_rate": 0.005754060957102035, "batch_size": 455, "loss": 0.0006578014936530962}, {"layer_params": [33, 26], "learning_rate": 0.007203252162757024, "batch_size": 373, "loss": 0.0027162182331085206}, {"layer_params": [47, 56, 32, 64], "learning_rate": 0.0046875945756043895, "batch_size": 140, "loss": 0.0019963950384408236}, {"layer_params": [25, 43, 37], "learning_rate": 0.0016754538829326204, "batch_size": 156, "loss": 0.0044005088857375085}, {"layer_params": [54, 26, 37, 61], "learning_rate": 0.0015886369564149599, "batch_size": 451, "loss": 0.0021052800549659877}, {"layer_params": [53, 20, 56, 32, 46], "learning_rate": 0.002094400782816137, "batch_size": 324, "loss": 0.0031607525306753814}, {"layer_params": [26, 63, 22, 38, 38], "learning_rate": 0.0014657819433946063, "batch_size": 95, "loss": 0.004806294462177903}, {"layer_params": [30, 47, 62, 17, 32], "learning_rate": 0.0025677976928598916, "batch_size": 45, "loss": 0.006848200981039554}, {"layer_params": [21, 33, 55], "learning_rate": 0.0027982480005496234, "batch_size": 91, "loss": 0.005411245154682547}, {"layer_params": [54, 26, 24], "learning_rate": 0.0015200472351738997, "batch_size": 216, "loss": 0.003418957300018519}, {"layer_params": [55, 52], "learning_rate": 0.006298061788491572, "batch_size": 310, "loss": 0.0011523586645489558}, {"layer_params": [29, 62, 55], "learning_rate": 0.0038572923447896075, "batch_size": 244, "loss": 0.0013802077365107834}, {"layer_params": [47, 55], "learning_rate": 0.00623927023401451, "batch_size": 208, "loss": 0.0012491524504730479}, {"layer_params": [31, 24], "learning_rate": 0.004618659749286224, "batch_size": 63, "loss": 0.005450739210937172}, {"layer_params": [40, 20, 21, 46, 46], "learning_rate": 0.0053527836885040765, "batch_size": 349, "loss": 0.0015402109979186208}, {"layer_params": [59, 21], "learning_rate": 0.007888481948466093, "batch_size": 135, "loss": 0.0018807391612790526}, {"layer_params": [37, 26], "learning_rate": 0.008974257930642581, "batch_size": 477, "loss": 0.0031175388442352416}, {"layer_params": [47, 17, 41, 37], "learning_rate": 0.004016149763295058, "batch_size": 92, "loss": 0.0038372671860270203}, {"layer_params": [31, 43, 48], "learning_rate": 0.005358625628181804, "batch_size": 387, "loss": 0.0013268293696455657}, {"layer_params": [18, 17], "learning_rate": 0.00914797327637425, "batch_size": 288, "loss": 0.0045901612658053636}, {"layer_params": [63, 38], "learning_rate": 0.0080550791183858, "batch_size": 44, "loss": 0.0032868230750318617}, {"layer_params": [50, 30, 20, 35], "learning_rate": 0.008650529822205929, "batch_size": 90, "loss": 0.0030448566179256888}, {"layer_params": [58, 56, 27, 52], "learning_rate": 0.0015328914471487648, "batch_size": 261, "loss": 0.001936231718864292}, {"layer_params": [50, 36, 54, 45], "learning_rate": 0.005258990757276655, "batch_size": 379, "loss": 0.0013897256541531534}, {"layer_params": [62, 53, 44, 62], "learning_rate": 0.006437270253527444, "batch_size": 197, "loss": 0.0014006265625357628}, {"layer_params": [61, 64, 47, 63, 53], "learning_rate": 0.004342379937824594, "batch_size": 144, "loss": 0.0010821596084861086}, {"layer_params": [42, 59, 42, 32], "learning_rate": 0.0035293478075400977, "batch_size": 251, "loss": 0.0018527434405405075}, {"layer_params": [62, 43, 50], "learning_rate": 0.004817288952259028, "batch_size": 397, "loss": 0.0012392601894680411}, {"layer_params": [61, 35], "learning_rate": 0.0007586218601949715, "batch_size": 490, "loss": 0.004411198324523866}, {"layer_params": [43, 31, 47, 32, 20], "learning_rate": 0.006454623329664624, "batch_size": 366, "loss": 0.0009082410513656213}, {"layer_params": [42, 49, 48, 63], "learning_rate": 0.0047306718816016655, "batch_size": 241, "loss": 0.0009949211770435796}, {"layer_params": [23, 50], "learning_rate": 0.009902344535795322, "batch_size": 477, "loss": 0.003548980269115418}, {"layer_params": [47, 24], "learning_rate": 0.0031418649148635632, "batch_size": 104, "loss": 0.003270704017486423}, {"layer_params": [56, 34, 49, 37], "learning_rate": 0.009664789074684425, "batch_size": 41, "loss": 0.0030524011817760766}, {"layer_params": [47, 51], "learning_rate": 0.007141721389605299, "batch_size": 128, "loss": 0.002155930609442294}, {"layer_params": [38, 44], "learning_rate": 0.0012166837125236454, "batch_size": 38, "loss": 0.006550969413947314}, {"layer_params": [27, 39, 26, 51], "learning_rate": 0.003964681036861638, "batch_size": 365, "loss": 0.0021336499031167477}, {"layer_params": [24, 30], "learning_rate": 0.005012617527095038, "batch_size": 101, "loss": 0.004471561743412167}, {"layer_params": [34, 32], "learning_rate": 0.008449909041492254, "batch_size": 133, "loss": 0.004147450476884842}, {"layer_params": [25, 26], "learning_rate": 0.004935803009603072, "batch_size": 382, "loss": 0.005283100111410022}, {"layer_params": [43, 39, 59], "learning_rate": 0.009161270057399596, "batch_size": 19, "loss": 0.008414587751030923}, {"layer_params": [60, 56, 57, 49], "learning_rate": 0.003271685668118878, "batch_size": 173, "loss": 0.0013002672203583643}, {"layer_params": [48, 63], "learning_rate": 0.008398580894957344, "batch_size": 464, "loss": 0.0018843508046120405}, {"layer_params": [19, 49], "learning_rate": 0.004412239294435804, "batch_size": 278, "loss": 0.0029344827961176635}, {"layer_params": [61, 47, 59, 26, 49], "learning_rate": 0.009843729033476802, "batch_size": 21, "loss": 0.0062743772380053995}, {"layer_params": [23, 17], "learning_rate": 0.0035074500319392707, "batch_size": 252, "loss": 0.007870601741597056}, {"layer_params": [50, 44], "learning_rate": 0.00860430671272824, "batch_size": 441, "loss": 0.0014235004363581539}, {"layer_params": [17, 49, 59], "learning_rate": 0.005327219828422508, "batch_size": 230, "loss": 0.003134963447228074}, {"layer_params": [50, 44, 18, 17], "learning_rate": 0.0071961417348177965, "batch_size": 340, "loss": 0.0012107715016463772}, {"layer_params": [37, 51, 52, 27], "learning_rate": 0.0005491239564254785, "batch_size": 45, "loss": 0.005653707338497043}, {"layer_params": [46, 62], "learning_rate": 0.005913287582503771, "batch_size": 295, "loss": 0.001127509594662115}, {"layer_params": [57, 24, 43, 16, 46], "learning_rate": 0.00765977764154094, "batch_size": 363, "loss": 0.0019495828682556749}, {"layer_params": [38, 17, 26, 63, 23], "learning_rate": 0.0026386736695909628, "batch_size": 278, "loss": 0.003079091024119407}, {"layer_params": [28, 21, 20], "learning_rate": 0.00012559234248445445, "batch_size": 298, "loss": 0.02405089110136032}, {"layer_params": [54, 28, 25, 22], "learning_rate": 0.006798460463210756, "batch_size": 456, "loss": 0.0018032993900123984}, {"layer_params": [42, 61, 35, 51, 60], "learning_rate": 0.0014531595281165868, "batch_size": 119, "loss": 0.0026386916544288395}, {"layer_params": [40, 49], "learning_rate": 0.0030018197581149686, "batch_size": 345, "loss": 0.0023203848267439754}, {"layer_params": [20, 36], "learning_rate": 0.0055482171316581464, "batch_size": 244, "loss": 0.004796324679628015}, {"layer_params": [41, 28], "learning_rate": 0.0011444657041323302, "batch_size": 289, "loss": 0.00379264009417966}, {"layer_params": [35, 36], "learning_rate": 0.00945333774495352, "batch_size": 487, "loss": 0.0016495558142196388}, {"layer_params": [60, 57, 46, 27, 19], "learning_rate": 0.009285188681622565, "batch_size": 97, "loss": 0.0018044527585152537}, {"layer_params": [45, 42, 64, 20, 32], "learning_rate": 0.005589027950756005, "batch_size": 401, "loss": 0.0013093486882280558}, {"layer_params": [61, 29, 53, 35, 27], "learning_rate": 0.0051617517286324235, "batch_size": 232, "loss": 0.0016292472917120904}, {"layer_params": [34, 30, 34, 21], "learning_rate": 0.00026748480279032067, "batch_size": 502, "loss": 0.008411739175207912}, {"layer_params": [18, 31, 57, 53, 62], "learning_rate": 0.005264037339707265, "batch_size": 126, "loss": 0.002767734177177772}, {"layer_params": [27, 38, 16], "learning_rate": 0.004642753689774753, "batch_size": 402, "loss": 0.0020667475566733626}, {"layer_params": [54, 64], "learning_rate": 0.004272599936011719, "batch_size": 146, "loss": 0.0017184875684324653}, {"layer_params": [32, 30, 53, 30], "learning_rate": 0.006171493051445495, "batch_size": 274, "loss": 0.002327786979731172}, {"layer_params": [52, 30, 42], "learning_rate": 0.0031295180780234488, "batch_size": 128, "loss": 0.003460435480810702}, {"layer_params": [53, 62], "learning_rate": 0.004653741591552603, "batch_size": 198, "loss": 0.0018422896438278257}, {"layer_params": [59, 24], "learning_rate": 0.007172146346568011, "batch_size": 42, "loss": 0.004981668461114168}, {"layer_params": [45, 23, 27, 58, 38], "learning_rate": 0.008604610001188865, "batch_size": 29, "loss": 0.005836466092150658}, {"layer_params": [57, 59, 48], "learning_rate": 0.0003616663132729931, "batch_size": 361, "loss": 0.004313800600357354}, {"layer_params": [49, 47, 35], "learning_rate": 0.00570987219367471, "batch_size": 330, "loss": 0.0014537124719936402}, {"layer_params": [47, 55, 56, 44, 27], "learning_rate": 0.007712350825693331, "batch_size": 355, "loss": 0.0010368719772668555}, {"layer_params": [36, 45, 64, 30, 31], "learning_rate": 0.006845428514889168, "batch_size": 121, "loss": 0.001835674635367468}, {"layer_params": [48, 25, 60, 59], "learning_rate": 0.008751795562405117, "batch_size": 230, "loss": 0.0014477573637850583}, {"layer_params": [30, 56, 29, 50, 24], "learning_rate": 0.0011755032645434406, "batch_size": 300, "loss": 0.002655420443043113}, {"layer_params": [25, 43], "learning_rate": 0.0035387290018206166, "batch_size": 451, "loss": 0.002173822234617546}, {"layer_params": [17, 22, 59, 56], "learning_rate": 0.005137629036802993, "batch_size": 358, "loss": 0.003107734101358801}, {"layer_params": [32, 47, 40, 61], "learning_rate": 0.007299632496316218, "batch_size": 390, "loss": 0.0010348753584548832}, {"layer_params": [46, 19], "learning_rate": 0.005638366435746459, "batch_size": 248, "loss": 0.0037562699778936805}, {"layer_params": [60, 63], "learning_rate": 0.0032431089337963135, "batch_size": 21, "loss": 0.006283864576835186}, {"layer_params": [48, 51, 24, 62, 50], "learning_rate": 0.007540599524161555, "batch_size": 383, "loss": 0.00150479540345259}, {"layer_params": [33, 52], "learning_rate": 0.003420425580219501, "batch_size": 418, "loss": 0.0023702984454575925}, {"layer_params": [43, 34, 36], "learning_rate": 0.009862248418926889, "batch_size": 248, "loss": 0.0015425242565106601}, {"layer_params": [24, 59, 55, 27], "learning_rate": 3.117405919955881e-05, "batch_size": 430, "loss": 0.03805635649710894}, {"layer_params": [19, 46], "learning_rate": 0.006301215115967833, "batch_size": 234, "loss": 0.002844378596637398}, {"layer_params": [32, 21, 23], "learning_rate": 0.006703526887682397, "batch_size": 463, "loss": 0.0031786021334119143}, {"layer_params": [29, 39, 26, 19, 26], "learning_rate": 0.0007181751705156422, "batch_size": 92, "loss": 0.006744130062870681}, {"layer_params": [39, 47, 18, 41], "learning_rate": 0.004940660701268146, "batch_size": 422, "loss": 0.0012002887827111408}, {"layer_params": [55, 45, 49], "learning_rate": 0.004456463397082871, "batch_size": 460, "loss": 0.0013578925153706223}, {"layer_params": [29, 40, 46, 52], "learning_rate": 0.002983491446298945, "batch_size": 312, "loss": 0.00138646706007421}, {"layer_params": [55, 21, 22, 25, 63], "learning_rate": 0.0023376560620953896, "batch_size": 360, "loss": 0.0023576936777681113}, {"layer_params": [25, 31, 47, 59, 45], "learning_rate": 0.007300123494553166, "batch_size": 406, "loss": 0.002202628861414269}, {"layer_params": [17, 51, 39, 46, 31], "learning_rate": 0.00932270757761581, "batch_size": 486, "loss": 0.001763960561947897}, {"layer_params": [19, 48, 40, 63, 38], "learning_rate": 0.0021549230299893318, "batch_size": 214, "loss": 0.0040618462394922976}, {"layer_params": [31, 63, 58, 40, 22], "learning_rate": 0.007870936513744273, "batch_size": 242, "loss": 0.002245554296532646}, {"layer_params": [33, 49, 63, 31], "learning_rate": 0.004160470271317994, "batch_size": 31, "loss": 0.005255394917912781}, {"layer_params": [54, 64], "learning_rate": 0.006322815509489958, "batch_size": 474, "loss": 0.000907837834674865}, {"layer_params": [60, 37, 48, 40], "learning_rate": 0.003603223499034347, "batch_size": 218, "loss": 0.0016336244565900416}, {"layer_params": [45, 57], "learning_rate": 0.006508213592952117, "batch_size": 381, "loss": 0.0018591514742001892}, {"layer_params": [31, 54, 60, 30], "learning_rate": 0.0005706971440249298, "batch_size": 340, "loss": 0.004046773621812463}, {"layer_params": [50, 56], "learning_rate": 0.0065256786852132195, "batch_size": 336, "loss": 0.002095354812918231}, {"layer_params": [62, 59, 37], "learning_rate": 0.0010627547533883534, "batch_size": 31, "loss": 0.007275260169990361}, {"layer_params": [55, 18, 53, 61, 61], "learning_rate": 0.005863503412979616, "batch_size": 117, "loss": 0.003033388832118362}, {"layer_params": [35, 61], "learning_rate": 0.003198253464337976, "batch_size": 146, "loss": 0.0027030943671707062}, {"layer_params": [33, 22], "learning_rate": 0.004098683867555343, "batch_size": 40, "loss": 0.006393392707686871}, {"layer_params": [25, 28, 17], "learning_rate": 0.004123054470004652, "batch_size": 196, "loss": 0.004562728609889746}, {"layer_params": [19, 44, 30], "learning_rate": 0.0008260608840556153, "batch_size": 90, "loss": 0.006080802131909877}, {"layer_params": [63, 28, 53], "learning_rate": 0.00024332415477186696, "batch_size": 270, "loss": 0.007409447743557393}, {"layer_params": [20, 52, 35, 58, 57], "learning_rate": 0.006714280259346757, "batch_size": 115, "loss": 0.002959574400447309}, {"layer_params": [61, 36, 58], "learning_rate": 0.008224794416137134, "batch_size": 57, "loss": 0.002460952774854377}, {"layer_params": [44, 55, 39, 21], "learning_rate": 0.004367825015768408, "batch_size": 423, "loss": 0.0011001161223975942}, {"layer_params": [25, 30, 40], "learning_rate": 0.001788663325027696, "batch_size": 345, "loss": 0.0038217778713442387}, {"layer_params": [47, 56, 49, 43], "learning_rate": 0.00217064196397437, "batch_size": 455, "loss": 0.0013707993179559708}, {"layer_params": [44, 33, 63, 50, 45], "learning_rate": 0.004642158363347645, "batch_size": 286, "loss": 0.0015810016926843674}, {"layer_params": [20, 25, 26, 22, 21], "learning_rate": 0.006631545387218685, "batch_size": 121, "loss": 0.0033513683895580472}, {"layer_params": [28, 31, 52, 30], "learning_rate": 0.0015116494334781307, "batch_size": 191, "loss": 0.0043672947562299665}, {"layer_params": [37, 46], "learning_rate": 0.0066229487112976545, "batch_size": 419, "loss": 0.0019093398889526725}, {"layer_params": [22, 34, 48, 47, 27], "learning_rate": 0.008647469021851602, "batch_size": 258, "loss": 0.0016873987205326558}, {"layer_params": [54, 58], "learning_rate": 0.0016755146859313743, "batch_size": 167, "loss": 0.0027634849352762103}, {"layer_params": [42, 45, 23, 47, 42], "learning_rate": 0.0003174707033014531, "batch_size": 64, "loss": 0.007898345328867436}, {"layer_params": [39, 53], "learning_rate": 0.007226732836084104, "batch_size": 429, "loss": 0.0018480963446199895}, {"layer_params": [35, 29, 24], "learning_rate": 0.0022550918284097343, "batch_size": 511, "loss": 0.0021300803509075195}, {"layer_params": [33, 34, 49, 61], "learning_rate": 0.00668232276937144, "batch_size": 259, "loss": 0.001212024245178327}, {"layer_params": [59, 24, 28, 38], "learning_rate": 0.007399534420305578, "batch_size": 49, "loss": 0.00360943375620991}, {"layer_params": [21, 22, 55], "learning_rate": 0.008623403553180219, "batch_size": 183, "loss": 0.0030999178718775513}, {"layer_params": [55, 47, 61, 51], "learning_rate": 0.002124177138662083, "batch_size": 230, "loss": 0.0014137916511390359}, {"layer_params": [24, 49, 49], "learning_rate": 0.0029766023327302774, "batch_size": 496, "loss": 0.001395193721400574}, {"layer_params": [22, 36, 54], "learning_rate": 0.0014981113408052966, "batch_size": 81, "loss": 0.005269573058467358}, {"layer_params": [43, 28], "learning_rate": 9.124262844533277e-05, "batch_size": 390, "loss": 0.020075324699282648}, {"layer_params": [28, 47, 35, 62, 30], "learning_rate": 0.007590120339659641, "batch_size": 214, "loss": 0.0018429699575062842}, {"layer_params": [49, 42, 16], "learning_rate": 0.00280467940890744, "batch_size": 430, "loss": 0.0011346295883413403}, {"layer_params": [60, 48, 45], "learning_rate": 0.005287362674392213, "batch_size": 185, "loss": 0.0013819623261224479}, {"layer_params": [22, 47, 25], "learning_rate": 0.008002094196745515, "batch_size": 140, "loss": 0.002052473775111139}, {"layer_params": [58, 42], "learning_rate": 0.001926891203284415, "batch_size": 323, "loss": 0.0027059594984166326}, {"layer_params": [50, 42], "learning_rate": 0.005032358977105043, "batch_size": 448, "loss": 0.002139787091873586}, {"layer_params": [58, 62, 30, 27, 32], "learning_rate": 0.006429814325881602, "batch_size": 89, "loss": 0.0018438283156137914}, {"layer_params": [44, 42, 48], "learning_rate": 0.001095549953462544, "batch_size": 25, "loss": 0.007075495368335396}, {"layer_params": [60, 62, 20, 37, 49], "learning_rate": 9.725527745077963e-05, "batch_size": 271, "loss": 0.009978443887084722}, {"layer_params": [30, 20], "learning_rate": 0.0002952579884737895, "batch_size": 401, "loss": 0.01882313990034163}, {"layer_params": [62, 58, 43, 37, 42], "learning_rate": 0.006734322429191452, "batch_size": 305, "loss": 0.0008542859874432906}, {"layer_params": [31, 33, 30], "learning_rate": 0.003638223984445039, "batch_size": 107, "loss": 0.00361617686226964}, {"layer_params": [40, 24, 47], "learning_rate": 0.0041531292733816855, "batch_size": 65, "loss": 0.0035623982676770537}, {"layer_params": [18, 47, 40, 63, 63], "learning_rate": 0.006240753937096032, "batch_size": 40, "loss": 0.006856644812505692}, {"layer_params": [32, 56, 56, 62, 36], "learning_rate": 0.00013917345210801048, "batch_size": 186, "loss": 0.008272332423366606}, {"layer_params": [38, 54, 41], "learning_rate": 0.0017670764116366766, "batch_size": 473, "loss": 0.0022978101402986793}, {"layer_params": [18, 60, 40, 53], "learning_rate": 0.004757251062496077, "batch_size": 227, "loss": 0.0019629786582663657}, {"layer_params": [40, 33], "learning_rate": 0.009674167756004519, "batch_size": 90, "loss": 0.0033615025645121932}, {"layer_params": [40, 24, 39], "learning_rate": 0.001298015785860672, "batch_size": 330, "loss": 0.005015471619553864}, {"layer_params": [43, 51], "learning_rate": 0.005923155561349778, "batch_size": 21, "loss": 0.004075059425667859}, {"layer_params": [21, 50, 57], "learning_rate": 0.00843100667855438, "batch_size": 202, "loss": 0.0030023960093967616}, {"layer_params": [61, 41, 64, 37, 44], "learning_rate": 0.007388070885753691, "batch_size": 405, "loss": 0.0013833247369620949}, {"layer_params": [35, 43, 62], "learning_rate": 0.0066498362254881855, "batch_size": 32, "loss": 0.005916457849089056}, {"layer_params": [59, 36], "learning_rate": 0.0008097436914371859, "batch_size": 166, "loss": 0.004284379212185741}, {"layer_params": [53, 53, 54, 57, 48], "learning_rate": 0.00830670466138366, "batch_size": 111, "loss": 0.0021657359215896577}, {"layer_params": [30, 51], "learning_rate": 0.000525529750393952, "batch_size": 221, "loss": 0.00649659619666636}, {"layer_params": [24, 60], "learning_rate": 0.0004997532769075374, "batch_size": 503, "loss": 0.006659324183128774}, {"layer_params": [17, 30, 44], "learning_rate": 0.008509677195474939, "batch_size": 48, "loss": 0.006715096903499216}, {"layer_params": [44, 34, 46, 40, 17], "learning_rate": 0.0021115282433236708, "batch_size": 277, "loss": 0.0017322425625752658}, {"layer_params": [36, 28, 29, 59], "learning_rate": 0.007244323475620793, "batch_size": 489, "loss": 0.0017226432147435843}, {"layer_params": [40, 54, 35, 45, 54], "learning_rate": 0.008802646238295736, "batch_size": 205, "loss": 0.002289815101539716}, {"layer_params": [63, 59, 44, 27], "learning_rate": 0.009093762037621574, "batch_size": 325, "loss": 0.00100073563226033}, {"layer_params": [45, 24], "learning_rate": 0.005325249933058861, "batch_size": 316, "loss": 0.0021613065747078507}, {"layer_params": [24, 51, 20, 30, 18], "learning_rate": 0.005792444861810823, "batch_size": 73, "loss": 0.0032344542746432126}, {"layer_params": [43, 30, 54, 23], "learning_rate": 0.002087895079488033, "batch_size": 63, "loss": 0.004886959157884121}, {"layer_params": [46, 56, 23, 39, 23], "learning_rate": 0.004060128551956571, "batch_size": 144, "loss": 0.0019592680421192197}, {"layer_params": [45, 33, 25], "learning_rate": 0.0026727306443319566, "batch_size": 446, "loss": 0.00298624460818246}, {"layer_params": [48, 47], "learning_rate": 0.009630715961087236, "batch_size": 83, "loss": 0.003363574920222163}, {"layer_params": [33, 20, 55, 56, 22], "learning_rate": 0.00737684948069009, "batch_size": 350, "loss": 0.0023365721805021166}, {"layer_params": [24, 23, 24], "learning_rate": 0.009982693042485651, "batch_size": 82, "loss": 0.006454538321122527}, {"layer_params": [49, 36, 18, 27, 30], "learning_rate": 0.00794671049527643, "batch_size": 281, "loss": 0.0008771338500082493}, {"layer_params": [42, 34], "learning_rate": 0.007095924463506617, "batch_size": 358, "loss": 0.002156227211235091}, {"layer_params": [64, 29, 60, 16], "learning_rate": 0.00391223856098211, "batch_size": 372, "loss": 0.001649559201905504}, {"layer_params": [24, 55, 20], "learning_rate": 0.0015935979386914806, "batch_size": 503, "loss": 0.0022786690620705484}, {"layer_params": [28, 64, 18, 16, 43], "learning_rate": 0.004415529647107861, "batch_size": 326, "loss": 0.0021149861661251632}, {"layer_params": [40, 53, 42, 62, 50], "learning_rate": 0.005288583440772402, "batch_size": 390, "loss": 0.0013335267559159546}, {"layer_params": [21, 50, 39], "learning_rate": 0.0019413973625749654, "batch_size": 83, "loss": 0.004546554198022932}, {"layer_params": [53, 20], "learning_rate": 0.0043521725176984705, "batch_size": 29, "loss": 0.00646168764680624}, {"layer_params": [52, 63, 39, 55, 55], "learning_rate": 0.006400177078352581, "batch_size": 220, "loss": 0.00117616337898653}, {"layer_params": [19, 29, 22, 53, 44], "learning_rate": 0.0072988461477161695, "batch_size": 409, "loss": 0.0024242490180768073}, {"layer_params": [27, 34, 36, 33, 19], "learning_rate": 0.003920898102888088, "batch_size": 262, "loss": 0.0015980292938183992}, {"layer_params": [32, 42], "learning_rate": 0.005089949996067928, "batch_size": 275, "loss": 0.0018782295030541718}, {"layer_params": [58, 58, 35, 26], "learning_rate": 0.008275314492281628, "batch_size": 256, "loss": 0.0014656114403624088}, {"layer_params": [43, 51, 60, 43], "learning_rate": 0.0005187439018216533, "batch_size": 199, "loss": 0.00503282672027126}, {"layer_params": [51, 53, 52, 32], "learning_rate": 0.0039778888522176955, "batch_size": 304, "loss": 0.0012212718144292013}, {"layer_params": [19, 38], "learning_rate": 0.002086319064600797, "batch_size": 269, "loss": 0.004112563971430064}, {"layer_params": [50, 28, 54, 46, 47], "learning_rate": 0.0013582812154634132, "batch_size": 283, "loss": 0.0023424062749836595}, {"layer_params": [38, 61], "learning_rate": 0.0016120464008284924, "batch_size": 190, "loss": 0.0027935695531778036}, {"layer_params": [53, 28, 17, 48, 52], "learning_rate": 0.004167542626233851, "batch_size": 96, "loss": 0.003470279946923256}, {"layer_params": [40, 35], "learning_rate": 0.005337882164444269, "batch_size": 121, "loss": 0.0026852369646076114}, {"layer_params": [34, 22, 44, 52], "learning_rate": 0.005378839452795701, "batch_size": 364, "loss": 0.0023262487107422202}, {"layer_params": [34, 34, 60, 19], "learning_rate": 0.001278631055440992, "batch_size": 263, "loss": 0.002650426111649722}, {"layer_params": [43, 47], "learning_rate": 0.0006043437032244875, "batch_size": 217, "loss": 0.006825245073996484}, {"layer_params": [57, 46, 44, 33], "learning_rate": 0.005296455170130432, "batch_size": 293, "loss": 0.0022375729389023037}, {"layer_params": [25, 28, 26, 41, 25], "learning_rate": 0.00966277648095484, "batch_size": 148, "loss": 0.00517135466914624}, {"layer_params": [51, 55], "learning_rate": 0.0003988059513538348, "batch_size": 48, "loss": 0.009630148424766958}, {"layer_params": [32, 40, 38], "learning_rate": 0.009623776730135605, "batch_size": 71, "loss": 0.0032827322313096373}, {"layer_params": [19, 62], "learning_rate": 0.005788752816276723, "batch_size": 427, "loss": 0.0029314743634313344}, {"layer_params": [38, 64, 64, 30], "learning_rate": 0.007864242201244319, "batch_size": 246, "loss": 0.0012734234757954255}, {"layer_params": [62, 26, 30, 56, 17], "learning_rate": 0.007394924793987002, "batch_size": 189, "loss": 0.0025376676942687484}, {"layer_params": [59, 61, 61, 48, 50], "learning_rate": 0.0011361748236477438, "batch_size": 233, "loss": 0.001705716639989987}, {"layer_params": [37, 32], "learning_rate": 0.005881874722037131, "batch_size": 496, "loss": 0.0015708961593918502}, {"layer_params": [21, 61, 28, 34], "learning_rate": 0.009264404417771084, "batch_size": 202, "loss": 0.0029462722502648832}, {"layer_params": [64, 24, 44, 41], "learning_rate": 0.002385569103787997, "batch_size": 445, "loss": 0.0020226253278087824}, {"layer_params": [45, 23], "learning_rate": 0.0010550368365135616, "batch_size": 232, "loss": 0.006282557570375502}, {"layer_params": [30, 18, 30, 44], "learning_rate": 0.0086434757208104, "batch_size": 256, "loss": 0.0035956446453928948}, {"layer_params": [60, 37, 35], "learning_rate": 0.0070186879170715775, "batch_size": 199, "loss": 0.0027485170075669885}, {"layer_params": [23, 56, 60], "learning_rate": 0.008503788836059631, "batch_size": 296, "loss": 0.0015469761134590955}, {"layer_params": [48, 63], "learning_rate": 0.0074671852204302785, "batch_size": 31, "loss": 0.004702525578904897}, {"layer_params": [53, 46, 58, 40, 52], "learning_rate": 0.006104372673970464, "batch_size": 239, "loss": 0.0017115201544947922}, {"layer_params": [16, 36, 61, 28], "learning_rate": 0.003064633867225499, "batch_size": 434, "loss": 0.002863101966213435}, {"layer_params": [34, 36, 51], "learning_rate": 0.0020493536388195193, "batch_size": 25, "loss": 0.006642774322535842}, {"layer_params": [48, 59], "learning_rate": 0.004283121912751095, "batch_size": 407, "loss": 0.0012074757972732185}, {"layer_params": [52, 49, 27, 58, 64], "learning_rate": 0.008390531963903476, "batch_size": 20, "loss": 0.006916142418049276}, {"layer_params": [37, 60, 60, 49], "learning_rate": 0.005567115427890566, "batch_size": 61, "loss": 0.0028978104086127133}, {"layer_params": [62, 24, 22], "learning_rate": 0.004564488124557942, "batch_size": 470, "loss": 0.0022794181294739247}, {"layer_params": [29, 32, 63, 26], "learning_rate": 0.003120093583127049, "batch_size": 361, "loss": 0.002047072254354134}, {"layer_params": [58, 61, 36, 23], "learning_rate": 0.008715310675088846, "batch_size": 25, "loss": 0.006730950870551169}, {"layer_params": [50, 21], "learning_rate": 0.0030301679818599144, "batch_size": 41, "loss": 0.005811348508577794}, {"layer_params": [54, 47], "learning_rate": 0.0006247084285449405, "batch_size": 91, "loss": 0.0066561927157454195}, {"layer_params": [35, 32], "learning_rate": 0.0027410299599631006, "batch_size": 180, "loss": 0.00352433200692758}, {"layer_params": [45, 29, 25, 53, 44], "learning_rate": 0.004968277412410676, "batch_size": 64, "loss": 0.0038848165632225573}, {"layer_params": [47, 42, 59], "learning_rate": 0.005952927739992072, "batch_size": 197, "loss": 0.002269930539187044}, {"layer_params": [60, 51, 40, 31, 29], "learning_rate": 0.005220026552427719, "batch_size": 324, "loss": 0.001374051437014714}, {"layer_params": [24, 20, 16, 32], "learning_rate": 0.008879914471486602, "batch_size": 437, "loss": 0.0049702701764181255}, {"layer_params": [53, 60, 23, 47], "learning_rate": 0.004309790508377075, "batch_size": 38, "loss": 0.00412237538723275}, {"layer_params": [33, 27], "learning_rate": 0.003419643595890941, "batch_size": 248, "loss": 0.0034896349580958485}, {"layer_params": [57, 35, 42], "learning_rate": 0.004271948787641078, "batch_size": 37, "loss": 0.0036600615666247905}, {"layer_params": [28, 59], "learning_rate": 0.006560885091867108, "batch_size": 424, "loss": 0.0020253217534627766}, {"layer_params": [35, 17, 60, 16], "learning_rate": 0.006720943875672182, "batch_size": 168, "loss": 0.003472832168918103}, {"layer_params": [30, 45], "learning_rate": 0.002850885397499156, "batch_size": 510, "loss": 0.003189608796965331}, {"layer_params": [54, 26, 48], "learning_rate": 0.006165094231240454, "batch_size": 65, "loss": 0.0036670765141025184}, {"layer_params": [17, 42], "learning_rate": 0.0029467415162585417, "batch_size": 43, "loss": 0.007137292725965381}, {"layer_params": [45, 28, 58], "learning_rate": 0.0005813986555228254, "batch_size": 337, "loss": 0.0037071577925235034}, {"layer_params": [41, 23, 56, 25, 32], "learning_rate": 0.0019442046612280675, "batch_size": 43, "loss": 0.00587332374881953}, {"layer_params": [37, 62, 48, 52, 34], "learning_rate": 0.004645769936359505, "batch_size": 69, "loss": 0.0031585765536874533}, {"layer_params": [31, 57, 58, 54], "learning_rate": 0.005389602507362574, "batch_size": 165, "loss": 0.002083975544665009}, {"layer_params": [48, 30], "learning_rate": 0.003772252651257323, "batch_size": 70, "loss": 0.00307396411546506}, {"layer_params": [39, 51, 60, 46], "learning_rate": 0.007592839527224915, "batch_size": 221, "loss": 0.0014136649621650577}, {"layer_params": [40, 22], "learning_rate": 3.263092306293788e-05, "batch_size": 208, "loss": 0.03638769332319498}, {"layer_params": [25, 16, 28], "learning_rate": 0.009509486452702245, "batch_size": 413, "loss": 0.0028293662401847543}, {"layer_params": [56, 53], "learning_rate": 0.0015473412355496222, "batch_size": 337, "loss": 0.0027312494651414456}, {"layer_params": [36, 46, 40], "learning_rate": 0.006248463736769772, "batch_size": 372, "loss": 0.001137661388493143}, {"layer_params": [52, 28, 59, 20, 29], "learning_rate": 0.0017435004826533488, "batch_size": 346, "loss": 0.0019045437546446919}, {"layer_params": [41, 61, 43, 36, 60], "learning_rate": 0.00140131979757168, "batch_size": 316, "loss": 0.0018188954051584006}, {"layer_params": [45, 49, 20], "learning_rate": 0.006473854174668302, "batch_size": 217, "loss": 0.0015969738108105958}, {"layer_params": [37, 34], "learning_rate": 0.00010337228861242149, "batch_size": 350, "loss": 0.02712046729400754}, {"layer_params": [41, 62, 56, 36], "learning_rate": 0.00047801213007048004, "batch_size": 424, "loss": 0.0029448456480167806}, {"layer_params": [26, 21, 31], "learning_rate": 0.0037292662215163874, "batch_size": 190, "loss": 0.004243580244947225}, {"layer_params": [33, 30, 35], "learning_rate": 0.009877262276880067, "batch_size": 501, "loss": 0.0012261843198211864}, {"layer_params": [33, 19, 24, 26, 60], "learning_rate": 0.002908482398554396, "batch_size": 422, "loss": 0.0018447725242003799}, {"layer_params": [56, 58, 55, 62, 48], "learning_rate": 0.008277015414202893, "batch_size": 41, "loss": 0.004793538555968552}, {"layer_params": [40, 51, 22], "learning_rate": 0.00596950880804301, "batch_size": 136, "loss": 0.0022638578165788204}, {"layer_params": [50, 20, 22], "learning_rate": 0.008221733139830762, "batch_size": 59, "loss": 0.005899872798472643}, {"layer_params": [26, 18], "learning_rate": 0.0048213745969218815, "batch_size": 149, "loss": 0.004925715662539005}, {"layer_params": [38, 55], "learning_rate": 0.008699539163591202, "batch_size": 381, "loss": 0.0015605391736607998}, {"layer_params": [17, 31, 34, 53], "learning_rate": 0.005422084576422873, "batch_size": 152, "loss": 0.0036206675274297593}, {"layer_params": [53, 34, 52], "learning_rate": 0.003701094003877, "batch_size": 253, "loss": 0.0014829864748753608}, {"layer_params": [20, 56, 17, 21, 49], "learning_rate": 0.0029509490034140993, "batch_size": 318, "loss": 0.0021325363812502475}, {"layer_params": [36, 33, 47, 33, 36], "learning_rate": 0.006457779453130266, "batch_size": 98, "loss": 0.0028705873712897303}, {"layer_params": [22, 24, 53, 58, 55], "learning_rate": 0.000986823244682602, "batch_size": 269, "loss": 0.0053732977248728275}, {"layer_params": [23, 38, 34, 54], "learning_rate": 0.0016573413232144137, "batch_size": 114, "loss": 0.003482000483199954}, {"layer_params": [59, 45, 52], "learning_rate": 0.003018744745571278, "batch_size": 413, "loss": 0.0013963846140541136}, {"layer_params": [21, 55], "learning_rate": 0.007919905024820635, "batch_size": 68, "loss": 0.004411946265026927}, {"layer_params": [49, 18, 42], "learning_rate": 0.005873370557962049, "batch_size": 402, "loss": 0.0019074713450390845}, {"layer_params": [59, 61], "learning_rate": 0.00431170170522679, "batch_size": 393, "loss": 0.0012011024006642402}, {"layer_params": [22, 49, 21], "learning_rate": 0.00829889847755667, "batch_size": 213, "loss": 0.0030962782143615186}, {"layer_params": [43, 59, 35], "learning_rate": 0.00621924865988938, "batch_size": 283, "loss": 0.0014369522576453163}, {"layer_params": [37, 37, 23, 58], "learning_rate": 0.007832082094216044, "batch_size": 233, "loss": 0.0024256712011992932}, {"layer_params": [62, 18], "learning_rate": 0.00789123951728412, "batch_size": 341, "loss": 0.002433928546961397}, {"layer_params": [47, 28, 38], "learning_rate": 0.006857799959273394, "batch_size": 167, "loss": 0.0027101323090028017}, {"layer_params": [44, 46], "learning_rate": 0.005722078498170462, "batch_size": 502, "loss": 0.001484517811331898}, {"layer_params": [24, 44, 63, 17, 18], "learning_rate": 0.003866186692302072, "batch_size": 470, "loss": 0.0024468034110032024}, {"layer_params": [23, 42], "learning_rate": 0.004066567905302485, "batch_size": 331, "loss": 0.002923139380291104}, {"layer_params": [30, 48, 47, 24], "learning_rate": 0.005741486682525959, "batch_size": 362, "loss": 0.001077060445677489}, {"layer_params": [25, 26], "learning_rate": 0.008869548168872832, "batch_size": 224, "loss": 0.0024269962904509158}, {"layer_params": [25, 22, 19], "learning_rate": 0.004684570148506116, "batch_size": 234, "loss": 0.004054373567923903}, {"layer_params": [60, 32, 29], "learning_rate": 0.008212662894837292, "batch_size": 342, "loss": 0.0011695891438284888}, {"layer_params": [42, 52, 33, 28, 59], "learning_rate": 0.004148946561081612, "batch_size": 473, "loss": 0.001480450559174642}, {"layer_params": [53, 51, 32], "learning_rate": 0.003880772669277865, "batch_size": 53, "loss": 0.002489215236855671}, {"layer_params": [20, 28, 60], "learning_rate": 0.005159948574194351, "batch_size": 134, "loss": 0.00327953239204362}, {"layer_params": [50, 62], "learning_rate": 0.007093041656740669, "batch_size": 165, "loss": 0.0016084733884781598}, {"layer_params": [64, 63, 54, 27, 48], "learning_rate": 0.008711267077705417, "batch_size": 426, "loss": 0.0008847886108560488}, {"layer_params": [20, 21, 45, 35], "learning_rate": 0.004265563743657545, "batch_size": 141, "loss": 0.004504906015936286}, {"layer_params": [52, 54], "learning_rate": 0.0009105832497102084, "batch_size": 397, "loss": 0.003174269744195044}, {"layer_params": [58, 52, 43, 52, 44], "learning_rate": 0.003667156227234798, "batch_size": 203, "loss": 0.002050303742289543}, {"layer_params": [53, 19, 32, 37], "learning_rate": 5.786857510542281e-05, "batch_size": 201, "loss": 0.0371816248819232}, {"layer_params": [24, 25, 28, 19, 29], "learning_rate": 0.009708986905927352, "batch_size": 157, "loss": 0.0032585613569244744}, {"layer_params": [38, 63], "learning_rate": 0.004655091408452982, "batch_size": 343, "loss": 0.002047662570839748}, {"layer_params": [57, 25, 30], "learning_rate": 0.0024566864762475917, "batch_size": 176, "loss": 0.004286735423374921}, {"layer_params": [18, 27, 45, 16, 24], "learning_rate": 0.0017167160238896217, "batch_size": 493, "loss": 0.0032790418807417156}, {"layer_params": [36, 59, 54], "learning_rate": 0.0019036984664288336, "batch_size": 408, "loss": 0.002043514089891687}, {"layer_params": [32, 19, 39, 30, 50], "learning_rate": 0.009275648016979766, "batch_size": 254, "loss": 0.002175157886231318}, {"layer_params": [42, 54, 62], "learning_rate": 0.006592699610628755, "batch_size": 305, "loss": 0.0013599763321690262}, {"layer_params": [63, 64, 34, 50, 57], "learning_rate": 0.0068184387988625425, "batch_size": 432, "loss": 0.0006066072906833142}, {"layer_params": [32, 64, 38, 20, 50], "learning_rate": 0.002550839331868224, "batch_size": 434, "loss": 0.0013744143769145011}, {"layer_params": [32, 38, 50, 47, 57], "learning_rate": 0.006904282864353963, "batch_size": 476, "loss": 0.0015268126921728254}, {"layer_params": [55, 57, 42, 37, 40], "learning_rate": 0.004726207758297011, "batch_size": 128, "loss": 0.0012871803052257747}, {"layer_params": [32, 16, 43, 62], "learning_rate": 0.007581381916219104, "batch_size": 372, "loss": 0.002243498150492087}, {"layer_params": [63, 46, 21], "learning_rate": 0.001138963154987556, "batch_size": 351, "loss": 0.0029574976093135774}, {"layer_params": [24, 56, 33], "learning_rate": 0.0022187757161252412, "batch_size": 353, "loss": 0.002042388723930344}, {"layer_params": [49, 30, 32, 37, 56], "learning_rate": 0.004044516787751708, "batch_size": 461, "loss": 0.0014623608521651477}, {"layer_params": [51, 42, 24, 42, 43], "learning_rate": 0.0060034334372944375, "batch_size": 462, "loss": 0.001268250850844197}, {"layer_params": [45, 35, 23], "learning_rate": 0.009052480752403917, "batch_size": 282, "loss": 0.0017673639405984432}, {"layer_params": [56, 60, 29, 30], "learning_rate": 0.000581040447246894, "batch_size": 441, "loss": 0.0027313795499503612}, {"layer_params": [25, 25, 61, 60, 39], "learning_rate": 0.00734776765339505, "batch_size": 221, "loss": 0.0024278772342950106}, {"layer_params": [60, 56], "learning_rate": 0.006835553717256267, "batch_size": 233, "loss": 0.0018766925018280744}, {"layer_params": [54, 63, 29, 48, 40], "learning_rate": 0.0007553154829454522, "batch_size": 388, "loss": 0.0019839705049525948}, {"layer_params": [61, 52, 46], "learning_rate": 0.006541890763008836, "batch_size": 417, "loss": 0.0010820732684805989}, {"layer_params": [50, 47, 43], "learning_rate": 0.004912617108592907, "batch_size": 48, "loss": 0.002790434856433421}, {"layer_params": [34, 47, 52, 27], "learning_rate": 0.005108606012529373, "batch_size": 220, "loss": 0.0019434361753519625}, {"layer_params": [47, 46, 24, 62, 44], "learning_rate": 0.00012877436149328345, "batch_size": 83, "loss": 0.014828874990344047}, {"layer_params": [63, 16, 64, 37], "learning_rate": 0.0022271693719140687, "batch_size": 464, "loss": 0.0025840460788458587}, {"layer_params": [20, 16, 41], "learning_rate": 0.009803593985621133, "batch_size": 46, "loss": 0.007620441869366914}, {"layer_params": [60, 34, 18], "learning_rate": 0.0006544020230993615, "batch_size": 125, "loss": 0.006088479505851865}, {"layer_params": [55, 27, 59, 64, 54], "learning_rate": 0.0038309668266244164, "batch_size": 365, "loss": 0.0019727059290744363}, {"layer_params": [55, 23, 62, 60, 37], "learning_rate": 0.002434746587196634, "batch_size": 54, "loss": 0.00487687167013064}, {"layer_params": [55, 26, 53, 42, 37], "learning_rate": 0.0054312719565900195, "batch_size": 348, "loss": 0.0018106199428439141}, {"layer_params": [17, 62, 44, 45], "learning_rate": 0.007536011507979776, "batch_size": 241, "loss": 0.001579744383925572}, {"layer_params": [49, 19, 44, 34, 49], "learning_rate": 0.0007147974355987707, "batch_size": 244, "loss": 0.00481574181932956}, {"layer_params": [57, 29, 56, 61], "learning_rate": 0.00490325736960065, "batch_size": 86, "loss": 0.0022446528216823938}, {"layer_params": [19, 20, 29, 26, 25], "learning_rate": 0.007805682178380518, "batch_size": 48, "loss": 0.007655979129485786}, {"layer_params": [59, 24, 34, 43, 44], "learning_rate": 0.004099132929127043, "batch_size": 327, "loss": 0.0016617589257657528}, {"layer_params": [17, 43, 16, 29], "learning_rate": 0.0029951262439089736, "batch_size": 295, "loss": 0.002540020641172305}, {"layer_params": [64, 56, 53, 38], "learning_rate": 0.009986423435001649, "batch_size": 34, "loss": 0.0042374392203055325}, {"layer_params": [22, 46, 38, 24, 46], "learning_rate": 0.008703307943545338, "batch_size": 461, "loss": 0.0016594367602374405}, {"layer_params": [30, 24, 22], "learning_rate": 0.008690303757198758, "batch_size": 194, "loss": 0.004517281183507293}, {"layer_params": [64, 42, 31, 19], "learning_rate": 0.006881526772967734, "batch_size": 78, "loss": 0.001999042903771624}, {"layer_params": [16, 41], "learning_rate": 0.0067212292351194886, "batch_size": 194, "loss": 0.0035404785233549775}, {"layer_params": [16, 57, 36, 44, 39], "learning_rate": 0.002190655600188537, "batch_size": 437, "loss": 0.0028744913218542935}, {"layer_params": [52, 31], "learning_rate": 0.0027211701636960213, "batch_size": 132, "loss": 0.0020445641386322676}, {"layer_params": [50, 53, 28, 50], "learning_rate": 0.009153614525987109, "batch_size": 41, "loss": 0.0033950041874777526}, {"layer_params": [21, 36], "learning_rate": 0.0026561277284705355, "batch_size": 422, "loss": 0.003959184240084141}, {"layer_params": [47, 30, 47, 51, 20], "learning_rate": 0.00609821303858024, "batch_size": 287, "loss": 0.0013466343603795393}, {"layer_params": [23, 21], "learning_rate": 0.002849109592115278, "batch_size": 411, "loss": 0.004907235908322036}, {"layer_params": [43, 29, 38], "learning_rate": 0.0044850026763840365, "batch_size": 366, "loss": 0.0017180845863185824}, {"layer_params": [63, 35, 26, 44], "learning_rate": 0.007640597376892871, "batch_size": 387, "loss": 0.0019257888209540397}, {"layer_params": [48, 46, 18, 46], "learning_rate": 0.00480382008913456, "batch_size": 461, "loss": 0.0014421782223507762}, {"layer_params": [23, 48], "learning_rate": 0.006866958287682597, "batch_size": 436, "loss": 0.001820527972886339}, {"layer_params": [19, 16, 25, 25], "learning_rate": 0.008909282767861435, "batch_size": 53, "loss": 0.007374565503560007}, {"layer_params": [17, 61, 18], "learning_rate": 0.0006522818557192366, "batch_size": 277, "loss": 0.007823951034806669}, {"layer_params": [51, 55, 41, 47, 16], "learning_rate": 0.006476784395786379, "batch_size": 508, "loss": 0.0007589137746253982}, {"layer_params": [20, 50, 24, 44, 62], "learning_rate": 0.009208498507484337, "batch_size": 497, "loss": 0.002673331394325942}, {"layer_params": [43, 35], "learning_rate": 0.00879455185430092, "batch_size": 138, "loss": 0.0018964964791666717}, {"layer_params": [24, 34, 42, 29], "learning_rate": 0.009271356207626109, "batch_size": 394, "loss": 0.0016008083207998424}, {"layer_params": [59, 51, 21, 57, 51], "learning_rate": 0.004044776862480075, "batch_size": 82, "loss": 0.0027512549783568828}, {"layer_params": [25, 43, 16], "learning_rate": 0.0027957553037547293, "batch_size": 28, "loss": 0.006227945107966661}, {"layer_params": [58, 45], "learning_rate": 0.003219780599561047, "batch_size": 472, "loss": 0.0031320796883665025}, {"layer_params": [51, 26, 47, 56], "learning_rate": 0.00554763019048091, "batch_size": 494, "loss": 0.0016308686730917544}, {"layer_params": [53, 53, 57, 39], "learning_rate": 0.005389865982685411, "batch_size": 262, "loss": 0.0010625387821346522}, {"layer_params": [26, 63], "learning_rate": 0.009143691513810387, "batch_size": 400, "loss": 0.002210166045697406}, {"layer_params": [37, 45, 26, 18, 40], "learning_rate": 0.0024178097886421515, "batch_size": 30, "loss": 0.006590949746314436}, {"layer_params": [48, 19, 64, 26, 39], "learning_rate": 0.005872988473403142, "batch_size": 473, "loss": 0.0016652119054924696}, {"layer_params": [44, 16, 17], "learning_rate": 0.008762896244836435, "batch_size": 153, "loss": 0.0029467537195887418}, {"layer_params": [53, 55, 16, 36], "learning_rate": 0.0012669819630094369, "batch_size": 496, "loss": 0.0030412347917445006}, {"layer_params": [46, 57, 37, 48], "learning_rate": 0.00010217445699630807, "batch_size": 207, "loss": 0.018881253795698286}, {"layer_params": [60, 41, 28], "learning_rate": 0.006509158614032457, "batch_size": 338, "loss": 0.0012395821628160774}, {"layer_params": [28, 64, 26], "learning_rate": 0.0010386610419770717, "batch_size": 439, "loss": 0.0036111417459324}, {"layer_params": [48, 44, 51], "learning_rate": 0.008042723941837394, "batch_size": 205, "loss": 0.0021837931231129914}, {"layer_params": [43, 16], "learning_rate": 0.0003776844641862917, "batch_size": 171, "loss": 0.009038724368438125}, {"layer_params": [33, 35, 19], "learning_rate": 0.008159564031504297, "batch_size": 195, "loss": 0.0011634112434694543}, {"layer_params": [54, 21], "learning_rate": 0.007316754246028189, "batch_size": 140, "loss": 0.0029485857300460337}, {"layer_params": [28, 37, 28], "learning_rate": 0.004967081138624124, "batch_size": 344, "loss": 0.0029861390450969336}, {"layer_params": [17, 29, 32, 32, 25], "learning_rate": 0.008980942897992382, "batch_size": 212, "loss": 0.00291622152319178}, {"layer_params": [64, 32, 63, 45, 34], "learning_rate": 0.008189171120482407, "batch_size": 92, "loss": 0.002297655289294198}, {"layer_params": [59, 26, 59, 41, 59], "learning_rate": 0.008491450756752686, "batch_size": 73, "loss": 0.0028057728649582715}, {"layer_params": [60, 18, 23], "learning_rate": 0.002559598964378403, "batch_size": 206, "loss": 0.0027493157493881882}, {"layer_params": [36, 27, 34, 21], "learning_rate": 0.005737799945709157, "batch_size": 78, "loss": 0.0053286913456395265}, {"layer_params": [27, 34, 61], "learning_rate": 0.00496145684978799, "batch_size": 194, "loss": 0.0030538158025592566}, {"layer_params": [58, 57, 53], "learning_rate": 0.003494018030895105, "batch_size": 435, "loss": 0.0010605121549451724}, {"layer_params": [42, 26, 58, 30], "learning_rate": 0.0015133035232323389, "batch_size": 487, "loss": 0.002501842484343797}, {"layer_params": [36, 48, 18, 44, 45], "learning_rate": 0.005365891905929589, "batch_size": 64, "loss": 0.003136068623280153}, {"layer_params": [62, 38, 45, 51], "learning_rate": 0.005110544413543738, "batch_size": 130, "loss": 0.0016606265492737293}, {"layer_params": [63, 39], "learning_rate": 0.008888621476527577, "batch_size": 28, "loss": 0.006316647725179791}, {"layer_params": [34, 60], "learning_rate": 0.0033419671060926064, "batch_size": 320, "loss": 0.002185684739379212}, {"layer_params": [35, 30, 34, 44], "learning_rate": 0.006587129564918692, "batch_size": 209, "loss": 0.0015134585346095264}, {"layer_params": [61, 58, 24, 22], "learning_rate": 0.0006499674065390528, "batch_size": 303, "loss": 0.005045164860785007}, {"layer_params": [40, 37], "learning_rate": 0.0011466067318040344, "batch_size": 372, "loss": 0.00385022351751104}, {"layer_params": [59, 34, 19, 18], "learning_rate": 0.00480688980074425, "batch_size": 486, "loss": 0.0016014195559546352}, {"layer_params": [22, 45], "learning_rate": 0.006683609625370178, "batch_size": 336, "loss": 0.003944985324051231}, {"layer_params": [56, 58, 34], "learning_rate": 0.00883598552322397, "batch_size": 99, "loss": 0.001158167914254591}, {"layer_params": [37, 47], "learning_rate": 0.004871696282824706, "batch_size": 165, "loss": 0.0021560039429459723}, {"layer_params": [60, 25, 53], "learning_rate": 0.0028672822239679675, "batch_size": 210, "loss": 0.0021820545243099333}, {"layer_params": [64, 30, 51], "learning_rate": 0.002121108734282022, "batch_size": 165, "loss": 0.002524040084099397}, {"layer_params": [26, 27, 60, 28], "learning_rate": 0.0007444105964515243, "batch_size": 497, "loss": 0.004685609864536673}, {"layer_params": [35, 18, 32], "learning_rate": 0.0015709771299531727, "batch_size": 146, "loss": 0.005645531178452075}, {"layer_params": [61, 60, 47], "learning_rate": 0.00743562532770775, "batch_size": 409, "loss": 0.0008626941434340551}, {"layer_params": [38, 56, 56, 27], "learning_rate": 0.0010921343106555373, "batch_size": 389, "loss": 0.0028302746964618563}, {"layer_params": [42, 36, 30], "learning_rate": 0.005784233693665621, "batch_size": 357, "loss": 0.0012305993045447394}, {"layer_params": [44, 23, 49, 43, 35], "learning_rate": 0.004196397762873275, "batch_size": 367, "loss": 0.001732749732909724}, {"layer_params": [62, 19, 34], "learning_rate": 0.005365710586190149, "batch_size": 463, "loss": 0.001523493502754718}, {"layer_params": [16, 44, 64, 27], "learning_rate": 0.002323770127643168, "batch_size": 289, "loss": 0.002210166654549539}, {"layer_params": [49, 49], "learning_rate": 0.001841619071170923, "batch_size": 42, "loss": 0.00603440395090729}, {"layer_params": [50, 53, 40, 20], "learning_rate": 0.009097570901638855, "batch_size": 103, "loss": 0.001766346248332411}, {"layer_params": [25, 32], "learning_rate": 0.0013129959892293117, "batch_size": 464, "loss": 0.006150407842360437}, {"layer_params": [23, 50, 59], "learning_rate": 0.00885276371105983, "batch_size": 283, "loss": 0.002200729823671281}, {"layer_params": [57, 63, 48, 17, 39], "learning_rate": 0.0006509281671851619, "batch_size": 438, "loss": 0.002848860560916364}, {"layer_params": [36, 28, 30, 20], "learning_rate": 0.008724517837645869, "batch_size": 44, "loss": 0.0034427360713016244}, {"layer_params": [35, 20, 60], "learning_rate": 0.008232775439224072, "batch_size": 421, "loss": 0.0013711691147182137}, {"layer_params": [28, 59, 44, 39], "learning_rate": 0.0013648040831509066, "batch_size": 217, "loss": 0.00202816266217269}, {"layer_params": [40, 30], "learning_rate": 0.003974976586865392, "batch_size": 189, "loss": 0.0034368127724155786}, {"layer_params": [25, 47, 61], "learning_rate": 0.005843389165881464, "batch_size": 340, "loss": 0.0014048446249216794}, {"layer_params": [63, 41, 31, 33], "learning_rate": 0.0022816428187397856, "batch_size": 266, "loss": 0.003549537768121809}, {"layer_params": [19, 64, 41, 28], "learning_rate": 0.00533686568462713, "batch_size": 493, "loss": 0.002155439951457083}, {"layer_params": [62, 20], "learning_rate": 0.00884444116418794, "batch_size": 448, "loss": 0.0033583208918571473}, {"layer_params": [56, 18, 17, 25, 42], "learning_rate": 0.005705896328949906, "batch_size": 397, "loss": 0.0022553396760486067}, {"layer_params": [19, 46, 28, 56, 48], "learning_rate": 0.003852510600031382, "batch_size": 130, "loss": 0.003375928022433072}, {"layer_params": [20, 24, 60], "learning_rate": 4.841913569358894e-05, "batch_size": 432, "loss": 0.03845783915370703}, {"layer_params": [43, 55, 50, 25, 61], "learning_rate": 0.005342787779232397, "batch_size": 434, "loss": 0.0015755929658189415}, {"layer_params": [43, 26, 52, 30, 29], "learning_rate": 0.00224915278836157, "batch_size": 468, "loss": 0.0022410287661477923}, {"layer_params": [45, 25, 24, 24, 63], "learning_rate": 0.008326913392621791, "batch_size": 100, "loss": 0.002268820805475116}, {"layer_params": [31, 46], "learning_rate": 0.003181985187929173, "batch_size": 203, "loss": 0.0035950535512529313}, {"layer_params": [48, 20, 50, 25, 33], "learning_rate": 0.002073776425688288, "batch_size": 357, "loss": 0.0031739617860876024}, {"layer_params": [52, 42], "learning_rate": 0.00565907389542978, "batch_size": 459, "loss": 0.0009080073097720743}, {"layer_params": [19, 16], "learning_rate": 0.0074924604190822865, "batch_size": 143, "loss": 0.0028445906238630412}, {"layer_params": [40, 49], "learning_rate": 0.0014347992075048176, "batch_size": 265, "loss": 0.0035026664659380913}, {"layer_params": [59, 60, 44, 31, 35], "learning_rate": 0.008823014690731563, "batch_size": 323, "loss": 0.0007819112029392272}, {"layer_params": [40, 19], "learning_rate": 0.0011633105000969511, "batch_size": 390, "loss": 0.0044322825991548595}, {"layer_params": [31, 49, 50, 64, 49], "learning_rate": 0.004353634597542752, "batch_size": 512, "loss": 0.0009823879163013772}, {"layer_params": [17, 22, 30], "learning_rate": 0.004724554939576959, "batch_size": 430, "loss": 0.003258512527681887}, {"layer_params": [48, 43], "learning_rate": 0.003955920365471621, "batch_size": 304, "loss": 0.00222225338104181}, {"layer_params": [63, 23, 63], "learning_rate": 0.0011030931714619333, "batch_size": 19, "loss": 0.0055217698239721355}, {"layer_params": [16, 64, 17, 21], "learning_rate": 0.0037023035582088907, "batch_size": 506, "loss": 0.0023666781338397415}, {"layer_params": [38, 49, 57, 28], "learning_rate": 0.009537109453708878, "batch_size": 26, "loss": 0.006173901984002441}, {"layer_params": [18, 36, 60, 17, 25], "learning_rate": 0.0007749227525744652, "batch_size": 466, "loss": 0.0055889967083930965}, {"layer_params": [58, 62, 48, 57], "learning_rate": 0.008569391855074411, "batch_size": 282, "loss": 0.0009739257098408415}, {"layer_params": [61, 29, 41, 50, 57], "learning_rate": 0.0050328151263129735, "batch_size": 81, "loss": 0.003156565590761602}, {"layer_params": [38, 28], "learning_rate": 0.006297884785684452, "batch_size": 196, "loss": 0.0024717781110666693}, {"layer_params": [32, 35, 33], "learning_rate": 0.003943399237753489, "batch_size": 472, "loss": 0.001278164759860374}, {"layer_params": [19, 20, 24, 26], "learning_rate": 0.000535949487641823, "batch_size": 374, "loss": 0.007665270087309182}, {"layer_params": [42, 24, 51, 26], "learning_rate": 0.009001350809969683, "batch_size": 499, "loss": 0.002404836588539183}, {"layer_params": [22, 40, 30], "learning_rate": 0.00132459505547866, "batch_size": 193, "loss": 0.004604073748923838}, {"layer_params": [16, 21, 62, 45], "learning_rate": 0.0028499261021026107, "batch_size": 199, "loss": 0.004124106240924448}, {"layer_params": [53, 48, 18], "learning_rate": 0.00430260054745662, "batch_size": 254, "loss": 0.003460441194474697}, {"layer_params": [20, 19], "learning_rate": 0.003186688589132173, "batch_size": 20, "loss": 0.01029922800604254}, {"layer_params": [19, 63, 51, 45], "learning_rate": 0.0015100157760213335, "batch_size": 48, "loss": 0.006260778559371829}, {"layer_params": [33, 16, 16, 57, 47], "learning_rate": 0.003763745323256974, "batch_size": 422, "loss": 0.0031877852394245564}, {"layer_params": [42, 50, 62, 54, 56], "learning_rate": 0.007860277014487558, "batch_size": 113, "loss": 0.002341963789658621}, {"layer_params": [53, 64], "learning_rate": 0.0014074063449601947, "batch_size": 510, "loss": 0.002287546783918515}, {"layer_params": [44, 33, 39, 27, 37], "learning_rate": 0.001776150960607406, "batch_size": 150, "loss": 0.003220324085559696}, {"layer_params": [43, 43], "learning_rate": 0.002243322058660612, "batch_size": 203, "loss": 0.0032124232943169773}, {"layer_params": [56, 44, 40], "learning_rate": 0.008853270395300287, "batch_size": 408, "loss": 0.0012161257572006435}, {"layer_params": [59, 59, 21, 16], "learning_rate": 0.0024814393633551847, "batch_size": 337, "loss": 0.0023316878953482958}, {"layer_params": [39, 22, 63, 49], "learning_rate": 0.009405350731543227, "batch_size": 46, "loss": 0.004248425774276257}, {"layer_params": [63, 54, 53], "learning_rate": 0.00323327706042524, "batch_size": 337, "loss": 0.0009596918255556375}, {"layer_params": [35, 32, 53, 33, 29], "learning_rate": 0.0026841991861851332, "batch_size": 140, "loss": 0.002189216351835057}, {"layer_params": [62, 33, 48], "learning_rate": 0.00012239984044576087, "batch_size": 102, "loss": 0.009646905940026046}, {"layer_params": [23, 20, 48], "learning_rate": 0.004212931459583348, "batch_size": 216, "loss": 0.004675843662116676}, {"layer_params": [60, 45, 20, 39], "learning_rate": 0.006799356463746672, "batch_size": 179, "loss": 0.0024399850866757334}, {"layer_params": [34, 30], "learning_rate": 0.0061626872502603585, "batch_size": 503, "loss": 0.00231398971285671}, {"layer_params": [26, 56, 45, 21, 26], "learning_rate": 0.00952099269825775, "batch_size": 405, "loss": 0.0012070892832707614}, {"layer_params": [40, 36, 57, 24], "learning_rate": 0.00286976764192878, "batch_size": 152, "loss": 0.002654104690300301}, {"layer_params": [64, 27, 50, 46], "learning_rate": 0.008765996066434805, "batch_size": 457, "loss": 0.000696409794036299}, {"layer_params": [43, 26, 31], "learning_rate": 0.008840227214320056, "batch_size": 181, "loss": 0.00314091841224581}, {"layer_params": [63, 28], "learning_rate": 0.004410142872399384, "batch_size": 139, "loss": 0.0024021002335939557}, {"layer_params": [24, 19, 61, 26, 36], "learning_rate": 0.00713327995329953, "batch_size": 53, "loss": 0.004803117820993066}, {"layer_params": [51, 37, 58, 35], "learning_rate": 0.004729782006865338, "batch_size": 457, "loss": 0.0013203090277966111}, {"layer_params": [45, 22], "learning_rate": 0.003695959198085797, "batch_size": 446, "loss": 0.0028611560235731305}, {"layer_params": [18, 62, 39, 26], "learning_rate": 0.0043988793805288685, "batch_size": 223, "loss": 0.0030899466923438013}, {"layer_params": [38, 49], "learning_rate": 0.002008957227482992, "batch_size": 202, "loss": 0.00394012629520148}, {"layer_params": [17, 39], "learning_rate": 0.0010533347011993431, "batch_size": 67, "loss": 0.007527259918861091}, {"layer_params": [33, 25, 50], "learning_rate": 0.0008651101387548183, "batch_size": 377, "loss": 0.005017412793822586}, {"layer_params": [27, 44], "learning_rate": 0.0049970661942108805, "batch_size": 254, "loss": 0.0029420861741527916}, {"layer_params": [36, 28, 38, 45], "learning_rate": 0.006203256997239612, "batch_size": 141, "loss": 0.0034261376084759832}, {"layer_params": [58, 41], "learning_rate": 0.0029281179986758808, "batch_size": 500, "loss": 0.0018830364965833723}, {"layer_params": [19, 51, 36, 53], "learning_rate": 0.007763228339206997, "batch_size": 361, "loss": 0.002296406830428168}, {"layer_params": [29, 42], "learning_rate": 0.008647631310192336, "batch_size": 512, "loss": 0.0024699202342890205}, {"layer_params": [58, 49, 23, 56, 61], "learning_rate": 0.009620666361529227, "batch_size": 505, "loss": 0.001505047233076766}, {"layer_params": [53, 19, 55, 59, 54], "learning_rate": 0.001550773561862448, "batch_size": 345, "loss": 0.003516034190542996}, {"layer_params": [21, 38, 64, 40], "learning_rate": 0.005703152915814087, "batch_size": 81, "loss": 0.0038172331475652753}, {"layer_params": [27, 25, 51], "learning_rate": 0.006192926106490026, "batch_size": 95, "loss": 0.0035041147470474244}, {"layer_params": [22, 35, 57], "learning_rate": 0.002281484936446048, "batch_size": 149, "loss": 0.005019273601938039}, {"layer_params": [60, 57, 49, 53], "learning_rate": 0.008496262843638957, "batch_size": 472, "loss": 0.0008192945754854009}, {"layer_params": [36, 38, 44, 16, 41], "learning_rate": 0.0003483303298352267, "batch_size": 354, "loss": 0.0070420245686545965}, {"layer_params": [18, 34, 51, 45], "learning_rate": 0.0031087253057267153, "batch_size": 67, "loss": 0.006200988586060703}, {"layer_params": [50, 47, 23, 61], "learning_rate": 0.006791826484312435, "batch_size": 76, "loss": 0.0018718014447949827}, {"layer_params": [52, 59, 25, 49, 61], "learning_rate": 0.0031099544182901398, "batch_size": 302, "loss": 0.001636763383867219}, {"layer_params": [31, 42, 45, 28], "learning_rate": 0.00954486279887488, "batch_size": 310, "loss": 0.002387132711010054}, {"layer_params": [36, 28], "learning_rate": 0.0053579829602671235, "batch_size": 262, "loss": 0.0027433308539912106}, {"layer_params": [18, 48], "learning_rate": 0.007872221682311303, "batch_size": 60, "loss": 0.0060347343306057155}, {"layer_params": [29, 60, 22, 53, 24], "learning_rate": 0.0002789957758707787, "batch_size": 249, "loss": 0.006524584591388703}, {"layer_params": [35, 41], "learning_rate": 0.008130003031452787, "batch_size": 63, "loss": 0.0032756863348186015}, {"layer_params": [17, 22, 46, 41], "learning_rate": 0.006725947286145634, "batch_size": 57, "loss": 0.005384464324451983}, {"layer_params": [54, 29, 31], "learning_rate": 0.001946848984032466, "batch_size": 110, "loss": 0.005156097235158086}, {"layer_params": [27, 53], "learning_rate": 0.008102546337837486, "batch_size": 66, "loss": 0.003179833213798702}, {"layer_params": [55, 44], "learning_rate": 0.0014304948976879982, "batch_size": 183, "loss": 0.00285551265347749}, {"layer_params": [44, 35, 59, 60], "learning_rate": 0.0007443537440514088, "batch_size": 445, "loss": 0.0025716173416003587}, {"layer_params": [42, 60, 25, 63, 37], "learning_rate": 0.0050156278151472725, "batch_size": 147, "loss": 0.0017565096809994429}, {"layer_params": [59, 18, 55, 50, 45], "learning_rate": 0.004419176417593266, "batch_size": 343, "loss": 0.001786954653216526}, {"layer_params": [49, 18, 41], "learning_rate": 0.0003323348231394942, "batch_size": 425, "loss": 0.0067700034007430075}, {"layer_params": [40, 34], "learning_rate": 0.009385161114601389, "batch_size": 157, "loss": 0.0028607283858582376}, {"layer_params": [24, 30, 30, 62], "learning_rate": 0.007625265456134804, "batch_size": 267, "loss": 0.0028632704936899247}, {"layer_params": [63, 57], "learning_rate": 0.002656889986449752, "batch_size": 83, "loss": 0.002874651699094102}, {"layer_params": [29, 21, 42, 36], "learning_rate": 0.008821709246860474, "batch_size": 303, "loss": 0.002104515415849164}, {"layer_params": [64, 34], "learning_rate": 0.009788377245586385, "batch_size": 422, "loss": 0.0019850004056934266}, {"layer_params": [35, 55, 32, 27], "learning_rate": 0.0004287718325471257, "batch_size": 265, "loss": 0.007269620010629296}, {"layer_params": [42, 54, 29, 40], "learning_rate": 0.00021581663634424666, "batch_size": 401, "loss": 0.00696170118637383}, {"layer_params": [27, 41, 61], "learning_rate": 0.0004807288623998225, "batch_size": 332, "loss": 0.006233469354920089}, {"layer_params": [42, 28, 44], "learning_rate": 0.007995715924126505, "batch_size": 263, "loss": 0.0022709362115710973}, {"layer_params": [24, 53], "learning_rate": 0.009377463901755126, "batch_size": 446, "loss": 0.0022498049517162143}, {"layer_params": [33, 64, 20, 17, 53], "learning_rate": 0.00014990003353691067, "batch_size": 185, "loss": 0.01925244360230863}, {"layer_params": [37, 58, 26, 41], "learning_rate": 0.0062994932532834235, "batch_size": 428, "loss": 0.0011552847630809993}, {"layer_params": [46, 49, 29], "learning_rate": 0.0016798945738632878, "batch_size": 400, "loss": 0.0023779173602815717}, {"layer_params": [59, 56], "learning_rate": 0.007265397071746355, "batch_size": 62, "loss": 0.002541902274824679}, {"layer_params": [48, 21, 60], "learning_rate": 0.0066929228288011315, "batch_size": 457, "loss": 0.0033869946282356978}, {"layer_params": [60, 59, 29, 41], "learning_rate": 0.0068567594734397115, "batch_size": 380, "loss": 0.0007527037186082452}, {"layer_params": [20, 27, 41, 50], "learning_rate": 0.003755132818658354, "batch_size": 267, "loss": 0.0029062209697440266}, {"layer_params": [49, 21, 30], "learning_rate": 0.002248296229243331, "batch_size": 453, "loss": 0.002291513760574162}, {"layer_params": [34, 31, 18], "learning_rate": 0.008625665135168497, "batch_size": 446, "loss": 0.002028994959546253}, {"layer_params": [60, 29, 50, 49], "learning_rate": 0.009781240011568486, "batch_size": 442, "loss": 0.0011919152626069262}, {"layer_params": [37, 28], "learning_rate": 0.00972808580993876, "batch_size": 492, "loss": 0.002492348364321515}, {"layer_params": [63, 62, 28, 34], "learning_rate": 0.004206947895765062, "batch_size": 373, "loss": 0.0008849562203977257}, {"layer_params": [36, 62, 64], "learning_rate": 0.006129619615170783, "batch_size": 129, "loss": 0.002223100820556283}, {"layer_params": [61, 45], "learning_rate": 0.007283243475638927, "batch_size": 360, "loss": 0.0010091697098687292}, {"layer_params": [45, 46, 47, 38, 29], "learning_rate": 0.003107486197853583, "batch_size": 189, "loss": 0.0020788484590593724}, {"layer_params": [63, 46, 29], "learning_rate": 0.0001611433211699474, "batch_size": 325, "loss": 0.008079078672453761}, {"layer_params": [47, 39, 53], "learning_rate": 0.0026715206597969355, "batch_size": 383, "loss": 0.001605846667662263}, {"layer_params": [63, 39, 53, 40], "learning_rate": 0.006211986122458267, "batch_size": 85, "loss": 0.0021858233865350487}, {"layer_params": [18, 16, 42], "learning_rate": 0.008330828101841489, "batch_size": 342, "loss": 0.0036278738267719744}, {"layer_params": [44, 47, 41, 55, 44], "learning_rate": 0.006880014546776578, "batch_size": 159, "loss": 0.0014582879090448842}, {"layer_params": [27, 26], "learning_rate": 0.009560848178218548, "batch_size": 274, "loss": 0.0023769873625133185}, {"layer_params": [36, 64, 30, 60, 61], "learning_rate": 0.0028270429579880163, "batch_size": 296, "loss": 0.00178152295993641}, {"layer_params": [59, 45], "learning_rate": 0.00926245689183818, "batch_size": 19, "loss": 0.007654333605896682}, {"layer_params": [33, 51, 35, 29, 24], "learning_rate": 0.009444707411723534, "batch_size": 28, "loss": 0.006521697246935219}, {"layer_params": [33, 63, 36], "learning_rate": 0.005760192698808415, "batch_size": 503, "loss": 0.0014047442271839827}, {"layer_params": [23, 53, 28, 35, 28], "learning_rate": 0.0016181315024046622, "batch_size": 228, "loss": 0.002788809344638139}, {"layer_params": [30, 46], "learning_rate": 0.004192430328257016, "batch_size": 192, "loss": 0.004828614736907184}, {"layer_params": [34, 44, 29, 62, 55], "learning_rate": 0.0042152922008748305, "batch_size": 32, "loss": 0.005576619838830083}, {"layer_params": [55, 54, 46], "learning_rate": 0.0003011558105110743, "batch_size": 488, "loss": 0.005636912365444005}, {"layer_params": [52, 41, 40, 31, 19], "learning_rate": 0.0057483917906345616, "batch_size": 460, "loss": 0.001189522671047598}, {"layer_params": [18, 28, 38], "learning_rate": 0.0098547026774341, "batch_size": 51, "loss": 0.0067539393482729795}, {"layer_params": [19, 55, 32], "learning_rate": 0.0074996874140397796, "batch_size": 60, "loss": 0.005799688966944814}, {"layer_params": [64, 29, 61, 18], "learning_rate": 0.006167829290971178, "batch_size": 166, "loss": 0.0019244732975494117}, {"layer_params": [23, 33], "learning_rate": 0.006383565744815837, "batch_size": 205, "loss": 0.0034897591220214965}, {"layer_params": [24, 63, 16], "learning_rate": 0.0012660702470072018, "batch_size": 120, "loss": 0.006719587603583932}, {"layer_params": [59, 54], "learning_rate": 0.004326384547969528, "batch_size": 125, "loss": 0.004097386859357357}, {"layer_params": [64, 27, 52], "learning_rate": 0.0013733931698118819, "batch_size": 46, "loss": 0.006396824046969413}, {"layer_params": [49, 40], "learning_rate": 0.0036835771388006324, "batch_size": 87, "loss": 0.0032873209891840817}, {"layer_params": [35, 60, 61], "learning_rate": 0.004242295014610019, "batch_size": 442, "loss": 0.0009738180070417002}, {"layer_params": [17, 48], "learning_rate": 0.008008758469156196, "batch_size": 223, "loss": 0.0032233077846467494}, {"layer_params": [62, 38, 28], "learning_rate": 0.005901180448551028, "batch_size": 54, "loss": 0.002875313716940582}, {"layer_params": [17, 45], "learning_rate": 0.0028609198992390417, "batch_size": 501, "loss": 0.004946842114441097}, {"layer_params": [61, 45, 26, 54], "learning_rate": 0.00929686897564439, "batch_size": 416, "loss": 0.0014278281573206187}, {"layer_params": [28, 33], "learning_rate": 0.0027846258437499776, "batch_size": 344, "loss": 0.0031996779958717524}, {"layer_params": [44, 37, 49, 44, 38], "learning_rate": 0.006332236494848705, "batch_size": 260, "loss": 0.0012897021631943062}, {"layer_params": [27, 50, 25, 64, 53], "learning_rate": 0.0042366294323039596, "batch_size": 432, "loss": 0.0016443923045881092}, {"layer_params": [18, 49, 59, 21], "learning_rate": 0.0008865076273557046, "batch_size": 361, "loss": 0.004377964036539197}, {"layer_params": [39, 50], "learning_rate": 0.00841410751897008, "batch_size": 135, "loss": 0.0018147083348594606}, {"layer_params": [57, 17, 56, 61, 34], "learning_rate": 0.007997290835122902, "batch_size": 107, "loss": 0.0023628548136912287}, {"layer_params": [28, 40], "learning_rate": 0.0009624010848419187, "batch_size": 74, "loss": 0.007483955402858555}, {"layer_params": [20, 38], "learning_rate": 0.003446260031524025, "batch_size": 62, "loss": 0.005190077715087682}, {"layer_params": [37, 61, 30, 54], "learning_rate": 0.009868162797778133, "batch_size": 271, "loss": 0.0013001200335565955}, {"layer_params": [22, 27], "learning_rate": 0.006217215977819735, "batch_size": 243, "loss": 0.004253078056499362}, {"layer_params": [19, 19, 62, 45, 39], "learning_rate": 0.0014207296936840385, "batch_size": 404, "loss": 0.0031632212060503664}, {"layer_params": [19, 62, 32, 52, 18], "learning_rate": 0.006625323580988799, "batch_size": 50, "loss": 0.004518312506843358}, {"layer_params": [22, 41, 41, 16, 43], "learning_rate": 0.004831698822433485, "batch_size": 191, "loss": 0.003411265490576625}, {"layer_params": [45, 20], "learning_rate": 0.009226662893342152, "batch_size": 370, "loss": 0.0015850805898662656}, {"layer_params": [63, 36, 44, 50], "learning_rate": 0.0037364969632189297, "batch_size": 232, "loss": 0.0013769737805705519}, {"layer_params": [44, 28, 64, 34], "learning_rate": 0.0059330470957141964, "batch_size": 198, "loss": 0.0019296458759345114}, {"layer_params": [52, 47, 58], "learning_rate": 0.0035050920498224834, "batch_size": 34, "loss": 0.0029369802516885104}, {"layer_params": [38, 16, 18, 36], "learning_rate": 0.006971101043937032, "batch_size": 303, "loss": 0.0026119243749417364}, {"layer_params": [62, 52], "learning_rate": 0.002547043331497866, "batch_size": 229, "loss": 0.0017364411999005824}, {"layer_params": [29, 20, 39], "learning_rate": 0.0008504959802972882, "batch_size": 440, "loss": 0.004703981198836118}, {"layer_params": [22, 24, 39, 34], "learning_rate": 0.009997244259958116, "batch_size": 161, "loss": 0.0032554913288913665}, {"layer_params": [44, 45, 62, 31, 35], "learning_rate": 0.009354303483496824, "batch_size": 461, "loss": 0.001394520375179127}, {"layer_params": [27, 43, 62, 34], "learning_rate": 0.0029567139553530785, "batch_size": 64, "loss": 0.005613667354919016}, {"layer_params": [57, 39, 61, 41], "learning_rate": 0.00048471132867320213, "batch_size": 34, "loss": 0.0063652579835616055}, {"layer_params": [24, 52, 51, 25], "learning_rate": 0.0020420487925546854, "batch_size": 19, "loss": 0.0066616755700670185}, {"layer_params": [16, 51, 37], "learning_rate": 0.006959727295373963, "batch_size": 128, "loss": 0.0036932532815262676}, {"layer_params": [36, 20, 60, 56], "learning_rate": 0.005824342345981138, "batch_size": 481, "loss": 0.0012370269116945564}, {"layer_params": [33, 40], "learning_rate": 0.004669603967465236, "batch_size": 418, "loss": 0.002915251322556287}, {"layer_params": [41, 38, 55], "learning_rate": 0.00332773933695081, "batch_size": 283, "loss": 0.001695645903237164}, {"layer_params": [44, 48], "learning_rate": 0.0017318749677109942, "batch_size": 316, "loss": 0.0025428372411988674}, {"layer_params": [29, 47, 16, 53], "learning_rate": 0.006514889444724554, "batch_size": 195, "loss": 0.002090194053016603}, {"layer_params": [44, 43, 18, 46], "learning_rate": 0.007946156725129631, "batch_size": 227, "loss": 0.0017772540962323546}, {"layer_params": [54, 32], "learning_rate": 0.006988783325695716, "batch_size": 352, "loss": 0.0023810984648298473}, {"layer_params": [49, 61, 28], "learning_rate": 0.004271254848399902, "batch_size": 461, "loss": 0.0017435667919926344}, {"layer_params": [60, 26], "learning_rate": 0.009747981352572474, "batch_size": 160, "loss": 0.0016741765092592687}, {"layer_params": [59, 52, 37, 52, 43], "learning_rate": 0.005614767041257781, "batch_size": 496, "loss": 0.0010650441219331697}, {"layer_params": [16, 50, 45, 22], "learning_rate": 0.0013169936048105602, "batch_size": 120, "loss": 0.0066729375813156366}, {"layer_params": [59, 40, 46], "learning_rate": 0.008183139920160416, "batch_size": 96, "loss": 0.0016934402997139841}, {"layer_params": [16, 54, 32, 30, 60], "learning_rate": 0.00924188000754758, "batch_size": 328, "loss": 0.002346939326962456}, {"layer_params": [42, 19], "learning_rate": 0.005973145057531532, "batch_size": 136, "loss": 0.004190575056709349}, {"layer_params": [31, 54, 47, 48], "learning_rate": 0.0015144811907630972, "batch_size": 399, "loss": 0.002769700565841049}, {"layer_params": [33, 18, 51, 64], "learning_rate": 0.0025262996130306476, "batch_size": 267, "loss": 0.0029601894435472786}, {"layer_params": [63, 49, 41, 19], "learning_rate": 0.009017267308867113, "batch_size": 200, "loss": 0.0014382422936614603}, {"layer_params": [64, 56], "learning_rate": 0.009411218626661754, "batch_size": 306, "loss": 0.0008630399446701631}, {"layer_params": [41, 29, 49], "learning_rate": 0.000603019121411177, "batch_size": 133, "loss": 0.006415448407642544}, {"layer_params": [38, 54, 48, 26], "learning_rate": 0.007983962339285708, "batch_size": 125, "loss": 0.001831535384990275}, {"layer_params": [16, 46, 24, 48], "learning_rate": 0.008308629294298207, "batch_size": 163, "loss": 0.002702354866778478}, {"layer_params": [41, 31, 16, 50], "learning_rate": 0.009678481514799905, "batch_size": 458, "loss": 0.0018320030812174082}, {"layer_params": [59, 47, 18, 26, 45], "learning_rate": 0.008457254197641994, "batch_size": 189, "loss": 0.0012830918008694425}, {"layer_params": [43, 30], "learning_rate": 0.0022964640706134125, "batch_size": 147, "loss": 0.003027209909632802}, {"layer_params": [48, 32, 40, 28], "learning_rate": 0.0019360029669263908, "batch_size": 408, "loss": 0.002083246518159285}, {"layer_params": [44, 44, 56], "learning_rate": 0.005295493908601041, "batch_size": 509, "loss": 0.0010385413852054626}, {"layer_params": [30, 37], "learning_rate": 0.005115283737858683, "batch_size": 365, "loss": 0.0031459312327206134}, {"layer_params": [28, 55, 54, 27], "learning_rate": 0.002191526374779025, "batch_size": 334, "loss": 0.0015134899038821458}, {"layer_params": [55, 40, 18], "learning_rate": 0.004795257083730823, "batch_size": 219, "loss": 0.0019651034730486573}, {"layer_params": [52, 63, 17, 62, 20], "learning_rate": 0.006112469880364146, "batch_size": 90, "loss": 0.002619182582711801}, {"layer_params": [44, 24, 22, 56, 54], "learning_rate": 0.0036812514027161555, "batch_size": 369, "loss": 0.0020538893109187484}, {"layer_params": [39, 34], "learning_rate": 0.008742538012504795, "batch_size": 449, "loss": 0.002582535487599671}, {"layer_params": [59, 42, 40], "learning_rate": 0.007319252662155542, "batch_size": 377, "loss": 0.0011718954431125894}, {"layer_params": [56, 30, 26, 35], "learning_rate": 0.009455863802575596, "batch_size": 495, "loss": 0.002549123493954539}, {"layer_params": [49, 31, 55, 35, 33], "learning_rate": 0.0005966256144968387, "batch_size": 132, "loss": 0.004891091114841401}, {"layer_params": [25, 34], "learning_rate": 0.008629563670298244, "batch_size": 156, "loss": 0.002668441456044093}, {"layer_params": [38, 39, 45, 41, 39], "learning_rate": 3.0005831884669313e-05, "batch_size": 68, "loss": 0.03742277013137937}, {"layer_params": [49, 21, 47, 47, 17], "learning_rate": 0.009686270183309285, "batch_size": 190, "loss": 0.0016900421405443922}, {"layer_params": [35, 24, 31, 56, 55], "learning_rate": 0.004335659352652765, "batch_size": 265, "loss": 0.0022819317947141825}, {"layer_params": [32, 60, 57, 45], "learning_rate": 0.001962169549039872, "batch_size": 110, "loss": 0.0024446960329078137}, {"layer_params": [62, 28, 24, 31], "learning_rate": 0.004057624714248923, "batch_size": 27, "loss": 0.006419717122334987}, {"layer_params": [33, 43], "learning_rate": 0.005777852332213638, "batch_size": 45, "loss": 0.004055210596416146}, {"layer_params": [42, 60, 26, 46], "learning_rate": 0.005066314042679208, "batch_size": 34, "loss": 0.0055896353139542046}, {"layer_params": [55, 49, 22], "learning_rate": 0.001300544725934091, "batch_size": 175, "loss": 0.0032411792036145925}, {"layer_params": [62, 23], "learning_rate": 0.004359048934162236, "batch_size": 83, "loss": 0.0025019079889170826}, {"layer_params": [48, 46, 23, 21], "learning_rate": 0.001996031770774825, "batch_size": 53, "loss": 0.003506084044929594}, {"layer_params": [41, 27], "learning_rate": 0.005972918682022541, "batch_size": 84, "loss": 0.0022891252615954726}, {"layer_params": [44, 18, 63, 19, 41], "learning_rate": 0.0001613936189753887, "batch_size": 369, "loss": 0.00825306742452085}, {"layer_params": [25, 34, 60], "learning_rate": 0.005041670908917809, "batch_size": 168, "loss": 0.0021314826887100934}, {"layer_params": [40, 47, 19, 53, 26], "learning_rate": 0.004029838025836163, "batch_size": 362, "loss": 0.001383502121316269}, {"layer_params": [62, 40, 40, 18, 25], "learning_rate": 2.5080545517438144e-05, "batch_size": 176, "loss": 0.03994550896808505}, {"layer_params": [57, 60, 27], "learning_rate": 0.009335956813838042, "batch_size": 500, "loss": 0.0013947741570882498}, {"layer_params": [51, 47, 46, 57], "learning_rate": 0.004241617245816071, "batch_size": 41, "loss": 0.003713028496131301}, {"layer_params": [38, 18, 28, 29, 27], "learning_rate": 0.00785466377437124, "batch_size": 169, "loss": 0.0019411246362142265}, {"layer_params": [63, 29, 36, 20, 27], "learning_rate": 0.0044828376509495555, "batch_size": 446, "loss": 0.00125027235946618}, {"layer_params": [31, 60, 35, 51, 21], "learning_rate": 0.004009779608483508, "batch_size": 426, "loss": 0.0012866736564319582}, {"layer_params": [35, 19, 47, 19], "learning_rate": 0.002760204263083302, "batch_size": 422, "loss": 0.0027934407838620247}, {"layer_params": [32, 19, 64], "learning_rate": 0.008978616382200657, "batch_size": 136, "loss": 0.0034022151376120746}, {"layer_params": [50, 31], "learning_rate": 0.005651395036585032, "batch_size": 472, "loss": 0.0029284385195933282}, {"layer_params": [45, 44, 22, 58, 47], "learning_rate": 0.0012870657374857081, "batch_size": 62, "loss": 0.004967243557330221}, {"layer_params": [57, 26, 29, 33, 23], "learning_rate": 0.00673432667403222, "batch_size": 258, "loss": 0.0014536749164108186}, {"layer_params": [25, 40, 32, 17, 33], "learning_rate": 0.003828096914932572, "batch_size": 300, "loss": 0.002398256957530975}, {"layer_params": [49, 42, 46, 25], "learning_rate": 0.003552153457516876, "batch_size": 293, "loss": 0.0011193333938717843}, {"layer_params": [30, 46, 60, 58], "learning_rate": 0.00518334756195601, "batch_size": 147, "loss": 0.0022258213651366533}, {"layer_params": [56, 51, 34], "learning_rate": 0.001179211237391008, "batch_size": 108, "loss": 0.003251719597028568}, {"layer_params": [51, 58, 31], "learning_rate": 0.001743146736903086, "batch_size": 478, "loss": 0.0011951758014038206}, {"layer_params": [41, 54, 42], "learning_rate": 0.0077137925176827184, "batch_size": 137, "loss": 0.0019088952825404703}, {"layer_params": [41, 31, 42], "learning_rate": 0.0008346160443004495, "batch_size": 176, "loss": 0.004966383057180792}, {"layer_params": [49, 51, 20], "learning_rate": 0.005460824282761814, "batch_size": 416, "loss": 0.00174215967184864}, {"layer_params": [35, 48, 48, 28], "learning_rate": 0.0023412681491598083, "batch_size": 279, "loss": 0.0023296692746225746}, {"layer_params": [48, 39], "learning_rate": 0.0016802705876541462, "batch_size": 199, "loss": 0.004563407683745027}, {"layer_params": [64, 53, 19], "learning_rate": 0.0004918498708687184, "batch_size": 77, "loss": 0.007239277383778244}, {"layer_params": [56, 60, 41, 49, 52], "learning_rate": 0.007303313743463425, "batch_size": 256, "loss": 0.001791922281263396}, {"layer_params": [41, 46], "learning_rate": 0.007446859052960721, "batch_size": 94, "loss": 0.0032941407628823073}, {"layer_params": [51, 53], "learning_rate": 0.003028569103486158, "batch_size": 501, "loss": 0.002202691148268059}, {"layer_params": [54, 41, 53], "learning_rate": 0.0017353881630157795, "batch_size": 403, "loss": 0.001742228085640818}, {"layer_params": [37, 58, 40, 29, 22], "learning_rate": 0.005316760552527042, "batch_size": 277, "loss": 0.0009442413534270599}, {"layer_params": [27, 54, 51, 37], "learning_rate": 0.0012377279175462051, "batch_size": 24, "loss": 0.007522312738001346}, {"layer_params": [24, 17, 55], "learning_rate": 0.005505564418266726, "batch_size": 41, "loss": 0.0079773283097893}, {"layer_params": [19, 59], "learning_rate": 0.006910807181601643, "batch_size": 103, "loss": 0.0046867987303994595}, {"layer_params": [20, 44, 39, 22, 20], "learning_rate": 0.0052894418396922365, "batch_size": 465, "loss": 0.0019207784708123654}, {"layer_params": [46, 25, 62, 45], "learning_rate": 0.006583204119993189, "batch_size": 270, "loss": 0.00210254933219403}, {"layer_params": [47, 35], "learning_rate": 0.006720031667869802, "batch_size": 383, "loss": 0.0027382413332816213}, {"layer_params": [60, 25, 47], "learning_rate": 0.0030461808446866144, "batch_size": 384, "loss": 0.001556495038093999}, {"layer_params": [29, 59], "learning_rate": 0.0066990884523070475, "batch_size": 507, "loss": 0.001889417003840208}, {"layer_params": [35, 22, 51], "learning_rate": 0.006927794863228984, "batch_size": 242, "loss": 0.0013987135817296803}, {"layer_params": [27, 23, 60, 19, 61], "learning_rate": 0.0013795832616549657, "batch_size": 130, "loss": 0.004412061350885779}, {"layer_params": [43, 36], "learning_rate": 0.008828893269424876, "batch_size": 444, "loss": 0.0016396735364105552}, {"layer_params": [35, 20, 49], "learning_rate": 0.007913823650074677, "batch_size": 433, "loss": 0.0020861313364002854}, {"layer_params": [39, 41, 36], "learning_rate": 0.00031010579966724407, "batch_size": 465, "loss": 0.00745523258112371}, {"layer_params": [40, 59, 55, 31], "learning_rate": 0.006581514498897557, "batch_size": 109, "loss": 0.0019001091620884836}, {"layer_params": [62, 52, 46, 49, 46], "learning_rate": 0.004634011967614143, "batch_size": 307, "loss": 0.0009969376801745966}, {"layer_params": [26, 20, 28, 43], "learning_rate": 0.003353458360166012, "batch_size": 462, "loss": 0.003940431231167167}, {"layer_params": [59, 54, 38, 49], "learning_rate": 0.002933459117371704, "batch_size": 451, "loss": 0.000702796489931643}, {"layer_params": [44, 49, 28, 29, 18], "learning_rate": 0.0032461049595769115, "batch_size": 290, "loss": 0.0016121839906554668}, {"layer_params": [64, 33], "learning_rate": 0.003557677510037487, "batch_size": 392, "loss": 0.001597474527079612}, {"layer_params": [45, 61, 34, 31, 33], "learning_rate": 0.00551557515939222, "batch_size": 498, "loss": 0.0011392305325716734}, {"layer_params": [58, 30, 32], "learning_rate": 0.003925843522251645, "batch_size": 81, "loss": 0.002426141283940524}, {"layer_params": [51, 38, 32, 17, 61], "learning_rate": 0.00018724293636543333, "batch_size": 265, "loss": 0.007981279958039522}, {"layer_params": [56, 60, 40, 39, 51], "learning_rate": 0.0076136804947296586, "batch_size": 244, "loss": 0.0010097957134712488}, {"layer_params": [40, 53, 45], "learning_rate": 0.006204576269963685, "batch_size": 71, "loss": 0.002920915494905785}, {"layer_params": [62, 63, 38], "learning_rate": 0.0024995493365023826, "batch_size": 369, "loss": 0.0015080398845020682}, {"layer_params": [34, 43, 16, 31], "learning_rate": 0.0016164605552918426, "batch_size": 247, "loss": 0.0039897099928930405}, {"layer_params": [58, 30, 21, 46, 43], "learning_rate": 0.006207448823946875, "batch_size": 106, "loss": 0.003060338799841702}, {"layer_params": [32, 35, 50, 39], "learning_rate": 0.006407098605284471, "batch_size": 461, "loss": 0.0017763562721665948}, {"layer_params": [61, 59, 33, 17], "learning_rate": 0.0070502405603910905, "batch_size": 348, "loss": 0.00168354747351259}, {"layer_params": [23, 39, 53], "learning_rate": 0.00047330479230352825, "batch_size": 273, "loss": 0.006959199639968574}, {"layer_params": [43, 31], "learning_rate": 0.009132535786635894, "batch_size": 203, "loss": 0.004502395277377218}, {"layer_params": [25, 38], "learning_rate": 0.0017329232251841896, "batch_size": 496, "loss": 0.003168018942233175}, {"layer_params": [33, 38], "learning_rate": 0.008018979780939621, "batch_size": 180, "loss": 0.0023303344217129054}, {"layer_params": [40, 17, 20], "learning_rate": 0.00714903377690728, "batch_size": 509, "loss": 0.0025222176709212363}, {"layer_params": [50, 18, 17], "learning_rate": 0.008454892995833954, "batch_size": 478, "loss": 0.001636376251699403}, {"layer_params": [61, 29, 22, 19], "learning_rate": 0.002088638721619576, "batch_size": 438, "loss": 0.0017801887390669435}, {"layer_params": [20, 60, 17, 53], "learning_rate": 0.009340875480161761, "batch_size": 386, "loss": 0.002611375735141337}, {"layer_params": [21, 48, 39, 23, 42], "learning_rate": 0.004249050795391924, "batch_size": 444, "loss": 0.0015739951352588832}, {"layer_params": [33, 51, 44], "learning_rate": 0.006577205642211646, "batch_size": 22, "loss": 0.005961448333691805}, {"layer_params": [20, 17, 56, 29], "learning_rate": 0.0070095675656635225, "batch_size": 32, "loss": 0.007498804966453463}, {"layer_params": [30, 41, 64, 49], "learning_rate": 0.005845617325656803, "batch_size": 193, "loss": 0.0018322652694769204}, {"layer_params": [23, 46, 24, 64, 60], "learning_rate": 0.007813944396269994, "batch_size": 207, "loss": 0.003644251865334809}, {"layer_params": [18, 18], "learning_rate": 0.002420534628887884, "batch_size": 134, "loss": 0.007385928118601441}, {"layer_params": [54, 18, 44, 45, 33], "learning_rate": 0.006181127704472482, "batch_size": 253, "loss": 0.0016338921536225826}, {"layer_params": [28, 56, 55, 50], "learning_rate": 0.0015111240019227232, "batch_size": 349, "loss": 0.0016494575852993875}, {"layer_params": [29, 17, 44, 26, 52], "learning_rate": 0.002096665380055662, "batch_size": 26, "loss": 0.007808496428187936}, {"layer_params": [57, 20, 43], "learning_rate": 0.0003031383097873157, "batch_size": 232, "loss": 0.006921146628446877}, {"layer_params": [16, 20, 38, 63, 54], "learning_rate": 0.008094334096512583, "batch_size": 31, "loss": 0.008166451973374933}, {"layer_params": [31, 53, 64], "learning_rate": 0.006756471774213724, "batch_size": 155, "loss": 0.0015361424686852843}, {"layer_params": [59, 41, 45], "learning_rate": 0.007989184245310312, "batch_size": 36, "loss": 0.004832750849891454}, {"layer_params": [38, 35, 50, 31], "learning_rate": 0.006948684698911703, "batch_size": 403, "loss": 0.0013293268519919367}, {"layer_params": [24, 25], "learning_rate": 0.00892396104903449, "batch_size": 169, "loss": 0.0037159750727005303}, {"layer_params": [46, 42, 57, 56, 51], "learning_rate": 0.005034773001357413, "batch_size": 233, "loss": 0.0016346343734767288}, {"layer_params": [62, 52, 54], "learning_rate": 0.009973412484723807, "batch_size": 29, "loss": 0.0048187052900902924}, {"layer_params": [17, 51, 37], "learning_rate": 0.0013814207708947302, "batch_size": 22, "loss": 0.007782368308398873}, {"layer_params": [21, 28], "learning_rate": 0.004986539593010068, "batch_size": 367, "loss": 0.00312767690513283}, {"layer_params": [25, 40], "learning_rate": 0.000540473324384759, "batch_size": 292, "loss": 0.0074114342452958224}, {"layer_params": [31, 52, 28], "learning_rate": 0.0012162975585428037, "batch_size": 156, "loss": 0.004506665351800621}, {"layer_params": [62, 33, 43, 59, 35], "learning_rate": 0.005978003968912868, "batch_size": 501, "loss": 0.0011278149735881016}, {"layer_params": [61, 35, 23], "learning_rate": 0.0006562967593480472, "batch_size": 190, "loss": 0.004357307457830757}, {"layer_params": [30, 26], "learning_rate": 0.009089093509077596, "batch_size": 65, "loss": 0.0046150565706193445}, {"layer_params": [49, 62], "learning_rate": 0.005055958207046965, "batch_size": 103, "loss": 0.002846493487013504}, {"layer_params": [60, 42], "learning_rate": 0.0069481141958096845, "batch_size": 372, "loss": 0.0010553732444532216}, {"layer_params": [54, 61, 58, 25, 49], "learning_rate": 0.0004997875123776279, "batch_size": 253, "loss": 0.0027394091186579315}, {"layer_params": [48, 35, 36, 20, 53], "learning_rate": 0.00034541615560477275, "batch_size": 126, "loss": 0.007052882872521878}, {"layer_params": [57, 40, 49, 50, 30], "learning_rate": 0.0046750240811291545, "batch_size": 241, "loss": 0.0016531736799515783}, {"layer_params": [35, 38, 17, 31, 62], "learning_rate": 0.008350961154143353, "batch_size": 332, "loss": 0.003275547092780471}, {"layer_params": [19, 33, 47], "learning_rate": 0.008176468358433036, "batch_size": 35, "loss": 0.008030781757552176}, {"layer_params": [17, 59, 29, 58, 34], "learning_rate": 0.007939574941621199, "batch_size": 290, "loss": 0.002384091968415305}, {"layer_params": [52, 50], "learning_rate": 0.007267578664497124, "batch_size": 144, "loss": 0.0019050730252638459}, {"layer_params": [37, 29, 30, 57, 39], "learning_rate": 0.005216558505651214, "batch_size": 58, "loss": 0.00296362342312932}, {"layer_params": [30, 43, 53, 44, 59], "learning_rate": 0.003935306885331119, "batch_size": 100, "loss": 0.002758249059552327}, {"layer_params": [34, 61, 23, 44, 31], "learning_rate": 0.004872392698266656, "batch_size": 272, "loss": 0.0012298643070971593}, {"layer_params": [22, 28, 28, 22], "learning_rate": 0.004729241482100542, "batch_size": 241, "loss": 0.004110469790175557}, {"layer_params": [20, 25, 58, 60, 30], "learning_rate": 0.0007233972604291742, "batch_size": 40, "loss": 0.0075262483349069955}, {"layer_params": [44, 43, 29, 63], "learning_rate": 0.005217365701508512, "batch_size": 327, "loss": 0.00172760998015292}, {"layer_params": [52, 28, 38, 19], "learning_rate": 0.009202520987899148, "batch_size": 248, "loss": 0.0023088003031443804}, {"layer_params": [29, 20, 20], "learning_rate": 0.007025785412585541, "batch_size": 266, "loss": 0.0028822661098092794}, {"layer_params": [50, 52, 56], "learning_rate": 0.0015363794418385593, "batch_size": 315, "loss": 0.001841615146258846}, {"layer_params": [46, 17], "learning_rate": 0.007192268987243549, "batch_size": 494, "loss": 0.002073221044847742}, {"layer_params": [61, 25, 17, 24, 20], "learning_rate": 0.009633796142731434, "batch_size": 309, "loss": 0.0026927917439024895}, {"layer_params": [54, 43], "learning_rate": 0.009798101970242019, "batch_size": 360, "loss": 0.0013979382283287123}, {"layer_params": [59, 48, 24, 56], "learning_rate": 0.006155673528915668, "batch_size": 107, "loss": 0.0023575879831332714}, {"layer_params": [62, 53, 37], "learning_rate": 0.00905645665530497, "batch_size": 153, "loss": 0.0020489258505403994}, {"layer_params": [64, 42, 17, 24, 55], "learning_rate": 0.002113586691201487, "batch_size": 183, "loss": 0.0030216656369157135}, {"layer_params": [23, 42], "learning_rate": 0.00014935105760882273, "batch_size": 108, "loss": 0.02574245700612664}, {"layer_params": [61, 53], "learning_rate": 0.0014088906674471734, "batch_size": 93, "loss": 0.003673998734448105}, {"layer_params": [37, 53, 48, 47, 35], "learning_rate": 0.005859398946336688, "batch_size": 320, "loss": 0.0011717670533107594}, {"layer_params": [59, 63], "learning_rate": 0.0020791278120068234, "batch_size": 493, "loss": 0.0023915547563228756}, {"layer_params": [49, 60, 57, 54, 56], "learning_rate": 0.0031070007299236375, "batch_size": 54, "loss": 0.003186834168154746}, {"layer_params": [48, 27, 62], "learning_rate": 0.005838119826002969, "batch_size": 171, "loss": 0.0020845159667078404}, {"layer_params": [31, 30, 45, 21, 42], "learning_rate": 0.004727329442818533, "batch_size": 64, "loss": 0.0031520231312606485}, {"layer_params": [41, 57, 44, 48, 20], "learning_rate": 0.00630762535775887, "batch_size": 72, "loss": 0.0030363366031087935}, {"layer_params": [60, 16, 36, 44, 50], "learning_rate": 0.006545147471403564, "batch_size": 328, "loss": 0.002390662154648453}, {"layer_params": [54, 46, 36], "learning_rate": 0.00665124551846285, "batch_size": 385, "loss": 0.001858961913967505}, {"layer_params": [46, 37, 39, 34], "learning_rate": 0.003912795636963883, "batch_size": 403, "loss": 0.0013982868916355073}, {"layer_params": [21, 19, 58, 61, 39], "learning_rate": 0.004000955317598768, "batch_size": 217, "loss": 0.00253349220729433}, {"layer_params": [63, 40, 39, 18, 27], "learning_rate": 0.009905666592418675, "batch_size": 340, "loss": 0.0009964308695634826}, {"layer_params": [33, 34, 22, 46], "learning_rate": 0.0014870550101618502, "batch_size": 494, "loss": 0.001842775468248874}, {"layer_params": [61, 48, 28, 30], "learning_rate": 0.001868787372619796, "batch_size": 411, "loss": 0.0023316335957497356}, {"layer_params": [22, 56, 51], "learning_rate": 0.008957276893857726, "batch_size": 139, "loss": 0.002723990473896265}, {"layer_params": [32, 47, 16], "learning_rate": 0.008518644358292806, "batch_size": 333, "loss": 0.001978772091679275}, {"layer_params": [42, 27, 55, 63, 31], "learning_rate": 0.002165612153158265, "batch_size": 446, "loss": 0.0017588653054554015}, {"layer_params": [25, 58], "learning_rate": 0.007689547435410866, "batch_size": 400, "loss": 0.001349446000531316}, {"layer_params": [30, 48, 44], "learning_rate": 0.009363125739396403, "batch_size": 154, "loss": 0.0018831153854262084}, {"layer_params": [54, 60], "learning_rate": 0.00862361135435688, "batch_size": 444, "loss": 0.0013312716112704947}, {"layer_params": [44, 29, 48], "learning_rate": 0.0067554377768975025, "batch_size": 172, "loss": 0.0018148760369513183}, {"layer_params": [55, 53, 45], "learning_rate": 0.000899577563354479, "batch_size": 347, "loss": 0.0025028204848058524}, {"layer_params": [30, 36, 40], "learning_rate": 0.0074594439696910155, "batch_size": 218, "loss": 0.0017969682230614126}, {"layer_params": [62, 45, 41, 29, 22], "learning_rate": 0.004507217473170417, "batch_size": 309, "loss": 0.0009903931687586008}, {"layer_params": [44, 26, 38], "learning_rate": 0.00020776670158906938, "batch_size": 166, "loss": 0.007642350867390632}, {"layer_params": [18, 45, 26, 64], "learning_rate": 0.002940296063180221, "batch_size": 210, "loss": 0.002984831489156932}, {"layer_params": [58, 22, 64, 35, 63], "learning_rate": 0.0023515904568916185, "batch_size": 429, "loss": 0.0017225581745151431}, {"layer_params": [56, 55, 23, 20, 61], "learning_rate": 0.0009232522865228473, "batch_size": 415, "loss": 0.0022214735089801253}, {"layer_params": [49, 54, 35, 31, 32], "learning_rate": 0.0016653552316988375, "batch_size": 234, "loss": 0.0025283350725658236}, {"layer_params": [47, 29], "learning_rate": 0.004224374505287208, "batch_size": 350, "loss": 0.0019014528626576067}, {"layer_params": [36, 49, 51], "learning_rate": 0.004400217556535577, "batch_size": 102, "loss": 0.002079800333594903}, {"layer_params": [18, 28], "learning_rate": 0.0032719902611556308, "batch_size": 304, "loss": 0.0028471861407160758}, {"layer_params": [30, 62], "learning_rate": 0.006867772199844665, "batch_size": 299, "loss": 0.001709330363664776}, {"layer_params": [23, 33, 20], "learning_rate": 0.004228561805605616, "batch_size": 372, "loss": 0.0036027626460418106}, {"layer_params": [44, 30, 64], "learning_rate": 0.00490692747357651, "batch_size": 471, "loss": 0.0011857282812707127}, {"layer_params": [21, 20, 49, 64, 28], "learning_rate": 0.002097806371996926, "batch_size": 17, "loss": 0.00904222208657302}, {"layer_params": [47, 55, 22], "learning_rate": 0.006184522487678455, "batch_size": 396, "loss": 0.0014274290506727993}, {"layer_params": [26, 28, 51, 43, 50], "learning_rate": 0.006947478788621875, "batch_size": 96, "loss": 0.003232734566554427}, {"layer_params": [57, 26, 60, 35], "learning_rate": 0.00571340730679226, "batch_size": 169, "loss": 0.0027553582238033416}, {"layer_params": [29, 29, 38, 43], "learning_rate": 0.002304576656310899, "batch_size": 38, "loss": 0.007756754301954061}, {"layer_params": [46, 52, 23, 24, 32], "learning_rate": 0.008925870464890849, "batch_size": 405, "loss": 0.001026706787524745}, {"layer_params": [32, 34, 50, 45], "learning_rate": 0.0012180322521712405, "batch_size": 373, "loss": 0.00305415476905182}, {"layer_params": [20, 18], "learning_rate": 0.00773619584894153, "batch_size": 314, "loss": 0.002156810796586797}, {"layer_params": [62, 57, 50, 19], "learning_rate": 0.004061362703456519, "batch_size": 93, "loss": 0.0022718477621674537}, {"layer_params": [29, 33], "learning_rate": 1.0344102895878034e-05, "batch_size": 210, "loss": 0.15606358394026756}, {"layer_params": [42, 47], "learning_rate": 0.0064829100868997154, "batch_size": 116, "loss": 0.0018603376887040212}, {"layer_params": [18, 33, 32], "learning_rate": 0.008629572464172106, "batch_size": 18, "loss": 0.00943154928740114}, {"layer_params": [24, 40], "learning_rate": 0.005882930707349624, "batch_size": 95, "loss": 0.003194676146376878}, {"layer_params": [36, 62, 16], "learning_rate": 0.002662088837829395, "batch_size": 442, "loss": 0.0022489977779332547}, {"layer_params": [63, 35, 37, 33, 29], "learning_rate": 0.0033392964068654466, "batch_size": 409, "loss": 0.0019834424019791186}, {"layer_params": [38, 27], "learning_rate": 0.002371677182585984, "batch_size": 363, "loss": 0.0042621090146712955}, {"layer_params": [33, 45, 41, 35, 38], "learning_rate": 0.004342342755559749, "batch_size": 198, "loss": 0.0025046374020166696}, {"layer_params": [35, 50, 40], "learning_rate": 0.0066629621295548344, "batch_size": 43, "loss": 0.003706218096194789}, {"layer_params": [33, 34, 49], "learning_rate": 0.006344492662930624, "batch_size": 115, "loss": 0.002173488031839952}, {"layer_params": [41, 26, 28, 48, 55], "learning_rate": 0.001281152661703575, "batch_size": 139, "loss": 0.0035300998250022532}, {"layer_params": [53, 60], "learning_rate": 0.007517552891365337, "batch_size": 381, "loss": 0.001210676629561931}, {"layer_params": [45, 17, 33, 30, 30], "learning_rate": 0.008663960225487639, "batch_size": 376, "loss": 0.002230607722885907}, {"layer_params": [34, 64, 52, 16, 25], "learning_rate": 0.009657514386896559, "batch_size": 149, "loss": 0.0020424055820330977}, {"layer_params": [23, 25, 57], "learning_rate": 0.00163660851331142, "batch_size": 198, "loss": 0.004659681569319218}, {"layer_params": [48, 33, 42], "learning_rate": 0.009278873548655408, "batch_size": 33, "loss": 0.006246590376831591}, {"layer_params": [48, 18, 63], "learning_rate": 0.007317667345773164, "batch_size": 125, "loss": 0.0025781354564242067}, {"layer_params": [63, 36, 40, 35], "learning_rate": 0.001939567174887645, "batch_size": 61, "loss": 0.0036010247701779006}, {"layer_params": [39, 63], "learning_rate": 0.009434495321154686, "batch_size": 81, "loss": 0.0024427670508157463}, {"layer_params": [56, 20, 63, 17], "learning_rate": 7.001255613480422e-05, "batch_size": 345, "loss": 0.03543684970587492}, {"layer_params": [31, 52, 23, 51], "learning_rate": 0.007901090328270188, "batch_size": 266, "loss": 0.002841938380151987}, {"layer_params": [57, 26, 63, 47, 34], "learning_rate": 0.002178527988244092, "batch_size": 275, "loss": 0.002943144435994327}, {"layer_params": [18, 31, 34, 20], "learning_rate": 0.00726674724462262, "batch_size": 163, "loss": 0.0032550260331481694}, {"layer_params": [16, 24, 20], "learning_rate": 0.0023109334098436176, "batch_size": 97, "loss": 0.007549352729693055}, {"layer_params": [59, 26], "learning_rate": 0.004203238354945232, "batch_size": 277, "loss": 0.0022704358550254254}, {"layer_params": [25, 22, 42, 63], "learning_rate": 0.005892623957627848, "batch_size": 418, "loss": 0.0025165047158952803}, {"layer_params": [27, 17, 46], "learning_rate": 0.007898260726579853, "batch_size": 278, "loss": 0.003033900063019246}, {"layer_params": [56, 16], "learning_rate": 0.0027476017533751597, "batch_size": 387, "loss": 0.002565012709237635}, {"layer_params": [64, 38, 34], "learning_rate": 0.00752352087332223, "batch_size": 322, "loss": 0.0009139619156485424}, {"layer_params": [56, 24], "learning_rate": 0.007335558434838739, "batch_size": 215, "loss": 0.0025219496537465603}, {"layer_params": [31, 44, 60, 46], "learning_rate": 0.008856991715305473, "batch_size": 308, "loss": 0.0015149609255604446}, {"layer_params": [40, 50], "learning_rate": 0.0023158466053650032, "batch_size": 275, "loss": 0.003796486316714436}, {"layer_params": [19, 64, 29, 18, 63], "learning_rate": 0.008833754479052646, "batch_size": 116, "loss": 0.004189090493600816}, {"layer_params": [19, 20, 41, 34], "learning_rate": 0.000949512995368343, "batch_size": 460, "loss": 0.0055577309150248765}, {"layer_params": [42, 62, 54], "learning_rate": 0.008472830732197784, "batch_size": 475, "loss": 0.0010733272781362757}, {"layer_params": [33, 45, 57, 62], "learning_rate": 8.351189409443806e-05, "batch_size": 473, "loss": 0.009196321666240691}, {"layer_params": [37, 33, 47], "learning_rate": 0.000880697331028101, "batch_size": 172, "loss": 0.004989409057889134}, {"layer_params": [60, 53, 59, 52, 58], "learning_rate": 0.0002579154243552355, "batch_size": 480, "loss": 0.004211045154370367}, {"layer_params": [31, 64, 41], "learning_rate": 0.009082688437322276, "batch_size": 376, "loss": 0.0009995676839025692}, {"layer_params": [51, 42], "learning_rate": 0.006328945190528591, "batch_size": 125, "loss": 0.002147176522994414}, {"layer_params": [51, 16, 31], "learning_rate": 0.001793242246309642, "batch_size": 445, "loss": 0.0019056124228518457}, {"layer_params": [53, 43], "learning_rate": 0.002610906227740248, "batch_size": 87, "loss": 0.0034944572777021675}, {"layer_params": [31, 25], "learning_rate": 0.009893182800811287, "batch_size": 426, "loss": 0.0035867339791730048}, {"layer_params": [29, 47], "learning_rate": 0.006467144901875905, "batch_size": 388, "loss": 0.002801173951011151}, {"layer_params": [22, 52, 23, 29, 49], "learning_rate": 0.007537299077504031, "batch_size": 327, "loss": 0.0019894231064245104}, {"layer_params": [49, 47, 44, 28], "learning_rate": 0.004470982907049086, "batch_size": 403, "loss": 0.0013926901388913392}, {"layer_params": [62, 23], "learning_rate": 0.0018501801243984788, "batch_size": 394, "loss": 0.001747293275548145}, {"layer_params": [30, 64, 20, 35, 61], "learning_rate": 0.0006606209817360738, "batch_size": 42, "loss": 0.006889411264564842}, {"layer_params": [38, 38, 51, 51, 57], "learning_rate": 0.002958648158748037, "batch_size": 392, "loss": 0.0015785128285642712}, {"layer_params": [26, 43, 23], "learning_rate": 0.0009342850892082849, "batch_size": 308, "loss": 0.004333196962252259}, {"layer_params": [34, 18, 43], "learning_rate": 0.0018666266646555868, "batch_size": 488, "loss": 0.002641633483581245}, {"layer_params": [24, 53, 61, 26, 54], "learning_rate": 0.00919826550111236, "batch_size": 378, "loss": 0.00174619946279563}, {"layer_params": [58, 62], "learning_rate": 0.006818244417111206, "batch_size": 257, "loss": 0.0011068607808556409}, {"layer_params": [40, 22, 64, 51, 35], "learning_rate": 0.0010817687785387674, "batch_size": 102, "loss": 0.004740868667140603}, {"layer_params": [46, 33, 24, 39, 60], "learning_rate": 0.0017292990681022375, "batch_size": 173, "loss": 0.002855616032611579}, {"layer_params": [47, 62, 56, 56, 43], "learning_rate": 0.0024133983487027067, "batch_size": 341, "loss": 0.0024479938321746884}, {"layer_params": [56, 52], "learning_rate": 0.00868096624002446, "batch_size": 468, "loss": 0.0010854071355424822}, {"layer_params": [20, 16, 30, 44, 26], "learning_rate": 0.0024086982807183122, "batch_size": 383, "loss": 0.003159639446530491}, {"layer_params": [30, 16], "learning_rate": 0.0025388367490969724, "batch_size": 334, "loss": 0.006013852097094059}, {"layer_params": [62, 62, 34, 32, 61], "learning_rate": 0.005925734118229402, "batch_size": 321, "loss": 0.0010956722119590267}, {"layer_params": [42, 28, 42], "learning_rate": 0.008332711879307874, "batch_size": 183, "loss": 0.002248274702578783}, {"layer_params": [28, 44, 49, 64], "learning_rate": 0.006041460323155796, "batch_size": 119, "loss": 0.00186501529882662}, {"layer_params": [42, 29, 55, 64], "learning_rate": 0.005987034791226215, "batch_size": 159, "loss": 0.0019411737145856023}, {"layer_params": [25, 55, 23, 17], "learning_rate": 0.005702739448830329, "batch_size": 439, "loss": 0.0018341760127805174}, {"layer_params": [38, 29], "learning_rate": 0.003607167695165029, "batch_size": 23, "loss": 0.007545117165427655}, {"layer_params": [63, 29, 59, 29, 38], "learning_rate": 0.003804581440232422, "batch_size": 266, "loss": 0.0015777147782500833}, {"layer_params": [46, 54, 54, 28], "learning_rate": 0.002945434002841926, "batch_size": 149, "loss": 0.001973504176130518}, {"layer_params": [58, 54, 60, 19], "learning_rate": 0.006242891915369987, "batch_size": 117, "loss": 0.001470968367648311}, {"layer_params": [38, 64], "learning_rate": 0.0077973873201735485, "batch_size": 456, "loss": 0.001117834533797577}, {"layer_params": [21, 29], "learning_rate": 0.007765853302220044, "batch_size": 244, "loss": 0.005184776231180877}, {"layer_params": [61, 52], "learning_rate": 0.004680934629512886, "batch_size": 359, "loss": 0.0014199612941592932}, {"layer_params": [46, 43, 16], "learning_rate": 0.008615458473417631, "batch_size": 448, "loss": 0.0008103853528155014}, {"layer_params": [35, 37, 40], "learning_rate": 0.0013360033478436672, "batch_size": 426, "loss": 0.0030671767774038015}, {"layer_params": [34, 37, 37, 33], "learning_rate": 0.006925257633988751, "batch_size": 372, "loss": 0.0015758367208763956}, {"layer_params": [27, 40, 29, 51, 49], "learning_rate": 0.00564110322362761, "batch_size": 497, "loss": 0.0019203511776868254}, {"layer_params": [26, 49, 60, 46], "learning_rate": 0.0060717989382815425, "batch_size": 335, "loss": 0.0019529309880454092}, {"layer_params": [52, 34, 63], "learning_rate": 0.0008585119070222201, "batch_size": 498, "loss": 0.00323947427328676}, {"layer_params": [37, 21], "learning_rate": 0.009318398699529565, "batch_size": 17, "loss": 0.007484822048572823}, {"layer_params": [56, 60, 33, 57, 44], "learning_rate": 0.0054729209833416165, "batch_size": 358, "loss": 0.0010585975996218622}, {"layer_params": [52, 26, 33, 27], "learning_rate": 0.008348482434592696, "batch_size": 85, "loss": 0.0022607005224563183}, {"layer_params": [63, 47], "learning_rate": 0.0008864054339346695, "batch_size": 219, "loss": 0.004659236615989357}, {"layer_params": [18, 35, 54, 42], "learning_rate": 0.0010478275529847288, "batch_size": 55, "loss": 0.006946877022273839}, {"layer_params": [42, 27, 34, 64, 27], "learning_rate": 0.0030920899338352805, "batch_size": 143, "loss": 0.002562209735624492}, {"layer_params": [40, 50, 18, 61, 57], "learning_rate": 0.006642467192437769, "batch_size": 213, "loss": 0.0012866979866521433}, {"layer_params": [19, 26, 50, 30], "learning_rate": 0.009923877960480871, "batch_size": 450, "loss": 0.002992274928838015}, {"layer_params": [61, 23, 40, 55], "learning_rate": 0.007166107655902709, "batch_size": 286, "loss": 0.002298895322019234}, {"layer_params": [17, 45, 37, 46, 47], "learning_rate": 0.005703173522534046, "batch_size": 318, "loss": 0.0026959808962419628}, {"layer_params": [37, 25], "learning_rate": 0.008398324274710075, "batch_size": 447, "loss": 0.0021804032812360674}, {"layer_params": [53, 29, 22], "learning_rate": 0.003961451609547549, "batch_size": 32, "loss": 0.006654522868338972}, {"layer_params": [64, 44], "learning_rate": 0.002167652164052717, "batch_size": 144, "loss": 0.004075034097768366}, {"layer_params": [45, 51, 17, 43, 53], "learning_rate": 0.0026843083246345075, "batch_size": 207, "loss": 0.0015148540725931526}, {"layer_params": [38, 40, 43, 58], "learning_rate": 0.005594382583483796, "batch_size": 244, "loss": 0.002015580873703584}, {"layer_params": [28, 61], "learning_rate": 0.003885534208953726, "batch_size": 286, "loss": 0.0021717640780843793}, {"layer_params": [59, 63], "learning_rate": 0.004738147531413162, "batch_size": 121, "loss": 0.0018833791371434927}, {"layer_params": [63, 47], "learning_rate": 0.008294284102704946, "batch_size": 374, "loss": 0.002346624539932236}, {"layer_params": [26, 30, 49], "learning_rate": 0.009598320033186232, "batch_size": 118, "loss": 0.0032494130288250743}, {"layer_params": [20, 48], "learning_rate": 0.0019277377850759048, "batch_size": 251, "loss": 0.004052041620016098}, {"layer_params": [35, 60, 16], "learning_rate": 0.0051927423088066705, "batch_size": 459, "loss": 0.002245159710291773}, {"layer_params": [61, 24, 45], "learning_rate": 0.0014217423476685141, "batch_size": 59, "loss": 0.005887923566624522}, {"layer_params": [49, 56, 54], "learning_rate": 0.005062623395824163, "batch_size": 302, "loss": 0.0021863921405747533}, {"layer_params": [46, 27], "learning_rate": 0.0029628830541414547, "batch_size": 182, "loss": 0.003966073119081557}, {"layer_params": [26, 40, 41, 39, 27], "learning_rate": 0.0038461899160079486, "batch_size": 86, "loss": 0.004282451462931931}, {"layer_params": [46, 19], "learning_rate": 0.0029067532831897345, "batch_size": 324, "loss": 0.004767788776662201}, {"layer_params": [38, 35, 47], "learning_rate": 0.008981535007733433, "batch_size": 478, "loss": 0.0010924447030993178}, {"layer_params": [61, 28, 40, 29, 49], "learning_rate": 0.0065091531423724265, "batch_size": 260, "loss": 0.002345698035787791}, {"layer_params": [22, 50], "learning_rate": 0.0059552174920551445, "batch_size": 373, "loss": 0.0019765662401914595}, {"layer_params": [25, 22, 28, 40], "learning_rate": 0.0005185795718216377, "batch_size": 417, "loss": 0.006810656166635454}, {"layer_params": [16, 63, 29, 60], "learning_rate": 0.008263070859305596, "batch_size": 376, "loss": 0.0014758178452029824}, {"layer_params": [31, 55], "learning_rate": 0.007247516136556959, "batch_size": 36, "loss": 0.004892086910549551}, {"layer_params": [39, 57], "learning_rate": 0.002109140562728461, "batch_size": 377, "loss": 0.0029289371613413096}, {"layer_params": [44, 44, 42, 58, 17], "learning_rate": 0.007693292654156173, "batch_size": 261, "loss": 0.001465349675854668}, {"layer_params": [29, 34], "learning_rate": 0.008301892690689408, "batch_size": 379, "loss": 0.002667758199386299}, {"layer_params": [61, 56, 52, 48], "learning_rate": 0.0069722157874722475, "batch_size": 52, "loss": 0.0029679090436547993}, {"layer_params": [56, 30, 21], "learning_rate": 0.00375327197145691, "batch_size": 333, "loss": 0.002497753172647208}, {"layer_params": [25, 35, 29], "learning_rate": 0.0026126603301018063, "batch_size": 251, "loss": 0.003976094294339419}, {"layer_params": [23, 57, 43, 33, 46], "learning_rate": 0.002819486827490417, "batch_size": 412, "loss": 0.0018204877513926477}, {"layer_params": [32, 58, 44, 56], "learning_rate": 0.0030719463936930967, "batch_size": 461, "loss": 0.0014148743939585984}, {"layer_params": [19, 49, 54, 30], "learning_rate": 0.008398290156821257, "batch_size": 297, "loss": 0.0014168556069489569}, {"layer_params": [17, 47, 47], "learning_rate": 0.0005367368399658034, "batch_size": 36, "loss": 0.007493921432178467}, {"layer_params": [40, 56, 50, 25], "learning_rate": 0.003461575323041309, "batch_size": 449, "loss": 0.0008336568658705801}, {"layer_params": [52, 61], "learning_rate": 0.0034073581809011236, "batch_size": 380, "loss": 0.0020130724413320424}, {"layer_params": [28, 35], "learning_rate": 0.007465895867626166, "batch_size": 309, "loss": 0.003176309580449015}, {"layer_params": [38, 37, 51], "learning_rate": 0.0023311076645420505, "batch_size": 460, "loss": 0.0019346390932332724}, {"layer_params": [33, 40], "learning_rate": 0.001931911891478893, "batch_size": 190, "loss": 0.0050750226224772635}, {"layer_params": [61, 51, 29, 28], "learning_rate": 0.007338004191680136, "batch_size": 270, "loss": 0.0009677771222777664}, {"layer_params": [52, 63], "learning_rate": 0.004752738007812094, "batch_size": 465, "loss": 0.0011571718740742655}, {"layer_params": [17, 61], "learning_rate": 0.008903945953943948, "batch_size": 279, "loss": 0.0028961863834410908}, {"layer_params": [30, 58, 49, 22], "learning_rate": 0.002427164632562137, "batch_size": 71, "loss": 0.0035447157407179474}, {"layer_params": [30, 41], "learning_rate": 0.008346292491351843, "batch_size": 504, "loss": 0.0028968145186081527}, {"layer_params": [19, 25, 57, 43], "learning_rate": 0.00470108920852101, "batch_size": 315, "loss": 0.0029081111401319504}, {"layer_params": [29, 47], "learning_rate": 0.005897524917973456, "batch_size": 278, "loss": 0.0023558574449270963}, {"layer_params": [62, 29, 38, 30], "learning_rate": 0.0059179722183575565, "batch_size": 506, "loss": 0.0010665654874173925}, {"layer_params": [37, 28], "learning_rate": 0.008098080505831079, "batch_size": 379, "loss": 0.0015804995771031827}, {"layer_params": [29, 58, 57, 31, 40], "learning_rate": 0.0006936397847590995, "batch_size": 194, "loss": 0.0036163080157712102}, {"layer_params": [28, 54], "learning_rate": 0.0037586986775595584, "batch_size": 112, "loss": 0.0032502651447430253}, {"layer_params": [44, 50, 32, 19, 49], "learning_rate": 0.009309670228338703, "batch_size": 330, "loss": 0.001540942288702354}, {"layer_params": [62, 21, 17], "learning_rate": 0.007821198842304202, "batch_size": 511, "loss": 0.0017991062893997877}, {"layer_params": [17, 61], "learning_rate": 0.0044075481970997045, "batch_size": 483, "loss": 0.0033697304734960198}, {"layer_params": [41, 49, 39], "learning_rate": 0.0034533033363035814, "batch_size": 217, "loss": 0.001923300124472007}, {"layer_params": [32, 51, 24, 34], "learning_rate": 0.008759221121553461, "batch_size": 449, "loss": 0.0018593621894251555}, {"layer_params": [63, 40, 17, 63], "learning_rate": 0.006034878483847749, "batch_size": 137, "loss": 0.0021276065520942212}, {"layer_params": [51, 54, 40], "learning_rate": 0.00102613005063547, "batch_size": 511, "loss": 0.0025545519962906836}, {"layer_params": [54, 17, 23, 57, 43], "learning_rate": 0.009056799043748237, "batch_size": 376, "loss": 0.001078930370276794}, {"layer_params": [50, 16, 42, 56], "learning_rate": 0.009348866206528462, "batch_size": 358, "loss": 0.0020250448619481176}, {"layer_params": [62, 32], "learning_rate": 0.006737456830809971, "batch_size": 435, "loss": 0.0012183246214408428}, {"layer_params": [44, 22, 52], "learning_rate": 0.003450993982398062, "batch_size": 145, "loss": 0.0033783313632011415}, {"layer_params": [41, 18, 30, 56], "learning_rate": 0.0048470663710470634, "batch_size": 68, "loss": 0.0034269661514554173}, {"layer_params": [22, 22, 62, 51, 62], "learning_rate": 0.009874696126715831, "batch_size": 190, "loss": 0.002781194447306916}, {"layer_params": [36, 51, 17], "learning_rate": 0.0013095953344708423, "batch_size": 293, "loss": 0.00293362659169361}, {"layer_params": [51, 37, 48], "learning_rate": 0.005132598128865313, "batch_size": 178, "loss": 0.002522759255953133}, {"layer_params": [24, 54, 33, 19, 22], "learning_rate": 0.002628712729211199, "batch_size": 246, "loss": 0.002303131335647777}, {"layer_params": [30, 57, 24], "learning_rate": 0.008230354586089726, "batch_size": 362, "loss": 0.0019300752819981426}, {"layer_params": [29, 57, 41], "learning_rate": 0.008644682445659555, "batch_size": 39, "loss": 0.004786352061200887}, {"layer_params": [54, 45, 58], "learning_rate": 0.0028444411683877123, "batch_size": 395, "loss": 0.0011204492679098622}, {"layer_params": [43, 64], "learning_rate": 0.009996088165790189, "batch_size": 219, "loss": 0.001524948060978204}, {"layer_params": [61, 46, 58, 23, 28], "learning_rate": 0.0012410045349443783, "batch_size": 360, "loss": 0.00207899249275215}, {"layer_params": [38, 21, 55], "learning_rate": 0.0026503054478450912, "batch_size": 366, "loss": 0.001835046763299033}, {"layer_params": [52, 41, 26, 28], "learning_rate": 0.00036412676575059573, "batch_size": 350, "loss": 0.006405290295369923}, {"layer_params": [63, 16, 40, 18, 58], "learning_rate": 0.004787119788793631, "batch_size": 48, "loss": 0.0038599138450808824}, {"layer_params": [54, 51, 52, 52, 22], "learning_rate": 0.009275870984225998, "batch_size": 141, "loss": 0.0016267556673847138}, {"layer_params": [44, 52, 46, 44], "learning_rate": 0.004957449019602585, "batch_size": 289, "loss": 0.001314067189814523}, {"layer_params": [23, 57], "learning_rate": 0.009588512075390873, "batch_size": 487, "loss": 0.0022820090455934407}, {"layer_params": [45, 62], "learning_rate": 0.007301725135675864, "batch_size": 121, "loss": 0.0014248021185630933}, {"layer_params": [62, 17], "learning_rate": 0.0028610323088740317, "batch_size": 275, "loss": 0.0023876717244274916}, {"layer_params": [23, 53, 62, 55], "learning_rate": 0.008108780576143863, "batch_size": 63, "loss": 0.0032969403767492624}, {"layer_params": [21, 53, 27], "learning_rate": 0.00608227764361474, "batch_size": 497, "loss": 0.002485542434733361}, {"layer_params": [53, 27, 17], "learning_rate": 0.007772598871784706, "batch_size": 139, "loss": 0.0016561025683768094}, {"layer_params": [55, 21, 61, 48, 22], "learning_rate": 0.006796403150039174, "batch_size": 30, "loss": 0.0067114522214978935}, {"layer_params": [31, 25, 49], "learning_rate": 0.006398462903635273, "batch_size": 462, "loss": 0.002367859719088301}, {"layer_params": [36, 60, 47, 27], "learning_rate": 0.006368355971382765, "batch_size": 372, "loss": 0.0021849710668902845}, {"layer_params": [56, 58, 33, 20], "learning_rate": 0.009066228947171146, "batch_size": 204, "loss": 0.0016999609407503157}, {"layer_params": [19, 36, 25, 51, 48], "learning_rate": 0.00500373360676647, "batch_size": 470, "loss": 0.0018571118789259345}, {"layer_params": [19, 33], "learning_rate": 0.006497170058157163, "batch_size": 175, "loss": 0.0036831611674278974}, {"layer_params": [27, 16], "learning_rate": 0.004090582104770686, "batch_size": 245, "loss": 0.00429401001194492}, {"layer_params": [20, 48, 33, 55, 57], "learning_rate": 0.0007316371837354103, "batch_size": 284, "loss": 0.0054124135384336115}, {"layer_params": [46, 54, 27, 62], "learning_rate": 0.005794509191639174, "batch_size": 55, "loss": 0.0028310653218068184}, {"layer_params": [50, 61, 47, 40], "learning_rate": 0.0005695299519937677, "batch_size": 154, "loss": 0.005798724400810897}, {"layer_params": [17, 46, 36, 18], "learning_rate": 0.0039729090570968595, "batch_size": 413, "loss": 0.0033534225798211993}, {"layer_params": [18, 63, 16, 17], "learning_rate": 0.0034539751109865157, "batch_size": 423, "loss": 0.002293139491230249}, {"layer_params": [52, 17], "learning_rate": 0.00817507278558693, "batch_size": 292, "loss": 0.002160450933733955}, {"layer_params": [25, 28, 55, 57], "learning_rate": 0.005407509746322011, "batch_size": 302, "loss": 0.0017595433769747614}, {"layer_params": [21, 27, 18, 26], "learning_rate": 0.0024495688665983075, "batch_size": 281, "loss": 0.004644848443567753}, {"layer_params": [35, 28, 38], "learning_rate": 0.001688757595404758, "batch_size": 323, "loss": 0.0023748437582980842}, {"layer_params": [43, 33, 42, 33, 51], "learning_rate": 0.0035651262436283745, "batch_size": 126, "loss": 0.002223488425370306}, {"layer_params": [16, 47], "learning_rate": 0.004812740993008483, "batch_size": 152, "loss": 0.005160577876958996}, {"layer_params": [60, 42, 34, 20], "learning_rate": 0.002345098041225035, "batch_size": 275, "loss": 0.0019160588085651398}, {"layer_params": [18, 57, 56, 54, 27], "learning_rate": 0.005841553677145334, "batch_size": 56, "loss": 0.004860368508379906}, {"layer_params": [19, 32, 63], "learning_rate": 0.0003129059306390584, "batch_size": 326, "loss": 0.00792198978830129}, {"layer_params": [51, 41, 34, 45, 16], "learning_rate": 0.003055602629761933, "batch_size": 395, "loss": 0.001793787645874545}, {"layer_params": [25, 46, 23, 16], "learning_rate": 0.0074684520779172365, "batch_size": 206, "loss": 0.0017636188142932951}, {"layer_params": [33, 55], "learning_rate": 0.009556995042090611, "batch_size": 222, "loss": 0.0014523933012969793}, {"layer_params": [35, 39], "learning_rate": 0.009768713969475007, "batch_size": 102, "loss": 0.0030956647917628286}, {"layer_params": [48, 20, 63], "learning_rate": 0.007942235638054858, "batch_size": 278, "loss": 0.0013174907478969544}, {"layer_params": [54, 55, 48], "learning_rate": 0.007027814710734854, "batch_size": 64, "loss": 0.0024890399898868055}, {"layer_params": [43, 27, 24, 31, 25], "learning_rate": 0.007749833067125956, "batch_size": 454, "loss": 0.0014806591847445817}, {"layer_params": [61, 59, 59, 50, 42], "learning_rate": 0.007664711924939446, "batch_size": 83, "loss": 0.002598958919988945}, {"layer_params": [41, 33, 26, 59, 27], "learning_rate": 0.002785307085679303, "batch_size": 186, "loss": 0.0014674521086271853}, {"layer_params": [43, 62, 39, 43], "learning_rate": 0.004867408334992582, "batch_size": 327, "loss": 0.0008006538171321154}, {"layer_params": [29, 29, 51], "learning_rate": 0.0004517045078418529, "batch_size": 440, "loss": 0.006843950534239411}, {"layer_params": [27, 64], "learning_rate": 0.009167555239314272, "batch_size": 428, "loss": 0.0014026558049954473}, {"layer_params": [23, 30, 50], "learning_rate": 0.008714191650176069, "batch_size": 77, "loss": 0.003040494384476915}, {"layer_params": [36, 41], "learning_rate": 0.002852424295934826, "batch_size": 190, "loss": 0.0024842753761913625}, {"layer_params": [31, 34, 56, 52, 53], "learning_rate": 0.005126906948762794, "batch_size": 357, "loss": 0.001443586015375331}, {"layer_params": [22, 62, 16], "learning_rate": 0.006271582167986817, "batch_size": 231, "loss": 0.002355167366331443}, {"layer_params": [40, 19], "learning_rate": 0.0019167640495515194, "batch_size": 281, "loss": 0.0034031933452934025}, {"layer_params": [62, 62, 20, 57, 37], "learning_rate": 0.0040973059530890026, "batch_size": 76, "loss": 0.002636396661400795}, {"layer_params": [26, 41, 47, 20, 27], "learning_rate": 0.0016342171972942082, "batch_size": 366, "loss": 0.0018010498071089386}, {"layer_params": [37, 19, 39, 50], "learning_rate": 0.005251371246108905, "batch_size": 50, "loss": 0.005397353647276759}, {"layer_params": [29, 39, 30], "learning_rate": 0.009238116086518297, "batch_size": 21, "loss": 0.008593423888087273}, {"layer_params": [50, 43, 29], "learning_rate": 0.009941171523853362, "batch_size": 469, "loss": 0.0008352018386358395}, {"layer_params": [46, 55], "learning_rate": 0.002430843833074575, "batch_size": 327, "loss": 0.002936518476344645}, {"layer_params": [37, 26, 33, 31], "learning_rate": 0.0035847311032479482, "batch_size": 464, "loss": 0.002395880043040961}, {"layer_params": [51, 34, 19], "learning_rate": 0.00023842176682000886, "batch_size": 343, "loss": 0.007205209620296955}, {"layer_params": [35, 52, 45, 32, 39], "learning_rate": 0.006653245018344145, "batch_size": 445, "loss": 0.0020020776079036295}, {"layer_params": [50, 17], "learning_rate": 0.0034133192001035264, "batch_size": 21, "loss": 0.007878701917361468}, {"layer_params": [56, 63, 21], "learning_rate": 0.004657254054767147, "batch_size": 94, "loss": 0.0023205397417768838}, {"layer_params": [23, 34, 31, 21, 44], "learning_rate": 0.0030762698132000246, "batch_size": 403, "loss": 0.0018518031167332083}, {"layer_params": [57, 55, 20, 30, 40], "learning_rate": 0.00610358897113301, "batch_size": 56, "loss": 0.0022541517543140798}, {"layer_params": [29, 35], "learning_rate": 0.0005243807997778198, "batch_size": 504, "loss": 0.006369682154618203}, {"layer_params": [19, 28, 52, 18, 28], "learning_rate": 0.0026729822106355285, "batch_size": 72, "loss": 0.0068538739159703255}, {"layer_params": [58, 37, 19, 64], "learning_rate": 0.006127217655171204, "batch_size": 282, "loss": 0.0010971215966856108}, {"layer_params": [27, 54], "learning_rate": 0.009550613935198193, "batch_size": 84, "loss": 0.0037249563541263343}, {"layer_params": [38, 53, 25], "learning_rate": 0.00596710709808646, "batch_size": 149, "loss": 0.0014132780651561917}, {"layer_params": [34, 50], "learning_rate": 0.003995720855194787, "batch_size": 485, "loss": 0.0018475916690658778}, {"layer_params": [54, 33], "learning_rate": 0.0008478061303664644, "batch_size": 79, "loss": 0.007131597101688385}, {"layer_params": [62, 57, 22, 25], "learning_rate": 0.008733082769680631, "batch_size": 353, "loss": 0.001315704791340977}, {"layer_params": [63, 62, 45, 29], "learning_rate": 0.008813912458231625, "batch_size": 498, "loss": 0.0014230710605625063}, {"layer_params": [47, 16, 64, 52, 24], "learning_rate": 0.008611419453217216, "batch_size": 495, "loss": 0.0009749278845265507}, {"layer_params": [62, 63, 40, 28], "learning_rate": 0.0019067071812486176, "batch_size": 462, "loss": 0.0015638009028043599}, {"layer_params": [48, 55, 55, 59], "learning_rate": 0.005882528969574179, "batch_size": 428, "loss": 0.0008085452282102779}, {"layer_params": [52, 17], "learning_rate": 0.006877626803774574, "batch_size": 346, "loss": 0.0031257783505134282}, {"layer_params": [51, 56, 50], "learning_rate": 0.009401532368736426, "batch_size": 72, "loss": 0.003016953717451543}, {"layer_params": [64, 51, 46], "learning_rate": 0.005640351981561248, "batch_size": 464, "loss": 0.0012882440071552992}, {"layer_params": [21, 48, 51, 30, 16], "learning_rate": 0.005147581825069253, "batch_size": 501, "loss": 0.0015040782350115478}, {"layer_params": [56, 19], "learning_rate": 0.002363657470065613, "batch_size": 277, "loss": 0.0022637696540914478}, {"layer_params": [41, 61, 33, 47], "learning_rate": 0.001648673956241874, "batch_size": 246, "loss": 0.002251905327429995}, {"layer_params": [35, 20, 28, 59], "learning_rate": 0.002610680446223476, "batch_size": 356, "loss": 0.0022260796115733685}, {"layer_params": [23, 50, 19], "learning_rate": 0.0036163998707521173, "batch_size": 398, "loss": 0.0022032741410657765}, {"layer_params": [32, 59], "learning_rate": 0.007901170210588443, "batch_size": 411, "loss": 0.0016361262812279165}, {"layer_params": [62, 31, 33], "learning_rate": 0.0038948979597236066, "batch_size": 260, "loss": 0.0025568556133657694}, {"layer_params": [27, 38, 55], "learning_rate": 0.008155407200644525, "batch_size": 81, "loss": 0.004242944729048759}, {"layer_params": [37, 24, 25], "learning_rate": 0.009923306294211712, "batch_size": 315, "loss": 0.0026008924446068705}, {"layer_params": [64, 23, 59], "learning_rate": 0.006364780428286987, "batch_size": 498, "loss": 0.001165157310315408}, {"layer_params": [38, 63, 58], "learning_rate": 0.005673112184921155, "batch_size": 214, "loss": 0.0017644938279408962}, {"layer_params": [32, 42, 33, 43], "learning_rate": 0.0061928221654890285, "batch_size": 471, "loss": 0.002374620917253196}, {"layer_params": [23, 33, 56, 34], "learning_rate": 0.00016296774322184792, "batch_size": 307, "loss": 0.00794472633395344}, {"layer_params": [53, 36], "learning_rate": 0.00988890406833918, "batch_size": 19, "loss": 0.00855585120851174}, {"layer_params": [48, 34, 34, 59], "learning_rate": 0.008013986318808107, "batch_size": 347, "loss": 0.001321268549072556}, {"layer_params": [27, 27], "learning_rate": 0.0021813913399044518, "batch_size": 304, "loss": 0.0034022485022433104}, {"layer_params": [51, 40], "learning_rate": 0.008483487048602953, "batch_size": 435, "loss": 0.0027847847249358893}, {"layer_params": [49, 40], "learning_rate": 0.0061906927697495725, "batch_size": 470, "loss": 0.0013649998942855746}, {"layer_params": [45, 40], "learning_rate": 0.006947209272869137, "batch_size": 108, "loss": 0.002509576517622918}, {"layer_params": [61, 25, 28, 42], "learning_rate": 0.0013928900792096331, "batch_size": 425, "loss": 0.0031148793501779436}, {"layer_params": [61, 46, 30], "learning_rate": 0.005521189736343726, "batch_size": 364, "loss": 0.0007550345093477517}, {"layer_params": [42, 50, 39, 36], "learning_rate": 0.004938194605928514, "batch_size": 350, "loss": 0.0011031419865321368}, {"layer_params": [55, 52, 33, 59, 43], "learning_rate": 0.007870206947638956, "batch_size": 447, "loss": 0.0015300743421539664}, {"layer_params": [46, 38, 16, 30, 62], "learning_rate": 0.008246365621513822, "batch_size": 270, "loss": 0.0014486050239065661}, {"layer_params": [20, 44, 41, 51], "learning_rate": 0.00205748722378365, "batch_size": 288, "loss": 0.00206479815300554}, {"layer_params": [57, 40, 36, 40], "learning_rate": 0.001137191016522832, "batch_size": 339, "loss": 0.0023133743286598476}, {"layer_params": [21, 29], "learning_rate": 0.007616335270600003, "batch_size": 83, "loss": 0.004668183119501918}, {"layer_params": [21, 17, 61, 63, 49], "learning_rate": 0.00036563728130317057, "batch_size": 171, "loss": 0.007800838258117437}, {"layer_params": [56, 64], "learning_rate": 0.006080119793840484, "batch_size": 463, "loss": 0.001319157745456323}, {"layer_params": [44, 55, 29, 20, 40], "learning_rate": 0.0004207907457056735, "batch_size": 28, "loss": 0.007744461914990097}, {"layer_params": [56, 26, 28, 17], "learning_rate": 0.0067448056040657865, "batch_size": 62, "loss": 0.003367100760806352}, {"layer_params": [54, 56, 48], "learning_rate": 0.005927739464705948, "batch_size": 161, "loss": 0.002173058543121442}, {"layer_params": [23, 56], "learning_rate": 0.006746389682062586, "batch_size": 321, "loss": 0.001773061117855832}, {"layer_params": [23, 24, 20], "learning_rate": 0.0002184118532760545, "batch_size": 212, "loss": 0.010165759166702627}, {"layer_params": [17, 53, 31, 45, 39], "learning_rate": 0.003451065114255217, "batch_size": 397, "loss": 0.0017058434709906578}, {"layer_params": [56, 60], "learning_rate": 0.0033995925169248422, "batch_size": 365, "loss": 0.0021430666535161434}, {"layer_params": [40, 20, 38, 39, 56], "learning_rate": 0.007805090956734707, "batch_size": 160, "loss": 0.0025335351563990118}, {"layer_params": [16, 26, 56, 20], "learning_rate": 0.0008079179531586636, "batch_size": 175, "loss": 0.008053597952239215}, {"layer_params": [35, 39, 30, 18], "learning_rate": 0.0007206012844689102, "batch_size": 27, "loss": 0.008788529988378287}, {"layer_params": [43, 54], "learning_rate": 0.005908306792680564, "batch_size": 134, "loss": 0.0024258033744990826}, {"layer_params": [22, 28, 34, 27], "learning_rate": 0.00320170886497601, "batch_size": 323, "loss": 0.002728726544883102}, {"layer_params": [55, 33, 27, 39, 23], "learning_rate": 0.0040055990276333855, "batch_size": 297, "loss": 0.002154889745870605}, {"layer_params": [39, 18, 58, 61, 42], "learning_rate": 0.007825742530514749, "batch_size": 326, "loss": 0.0018465602060314269}, {"layer_params": [48, 22, 29, 56], "learning_rate": 0.005105090008990092, "batch_size": 455, "loss": 0.0018748905195388943}, {"layer_params": [31, 50, 41, 55, 47], "learning_rate": 0.009918828428721467, "batch_size": 427, "loss": 0.0013734141236636788}, {"layer_params": [16, 37, 32, 52, 43], "learning_rate": 0.0051997637631505614, "batch_size": 186, "loss": 0.002711321043316275}, {"layer_params": [39, 44, 48], "learning_rate": 0.008426974934351787, "batch_size": 420, "loss": 0.0009791474707890302}, {"layer_params": [47, 32, 29, 36, 23], "learning_rate": 0.0037384027966098406, "batch_size": 111, "loss": 0.002563119025435299}, {"layer_params": [20, 41, 21, 26, 37], "learning_rate": 0.004004749507015443, "batch_size": 284, "loss": 0.0027692611538805067}, {"layer_params": [17, 64], "learning_rate": 0.004402149467190273, "batch_size": 373, "loss": 0.005933378492482006}, {"layer_params": [63, 59], "learning_rate": 0.007522008963818194, "batch_size": 452, "loss": 0.0008258926722919569}, {"layer_params": [45, 25], "learning_rate": 0.006086956383699914, "batch_size": 331, "loss": 0.0027621873980388043}, {"layer_params": [58, 22], "learning_rate": 0.002574441404965909, "batch_size": 439, "loss": 0.002600694673601538}, {"layer_params": [34, 18, 40], "learning_rate": 0.0008363096286469284, "batch_size": 28, "loss": 0.008128307389561086}, {"layer_params": [52, 32, 47], "learning_rate": 0.00776729742175249, "batch_size": 130, "loss": 0.0017065880040172488}, {"layer_params": [22, 51, 46], "learning_rate": 0.004833431450599927, "batch_size": 98, "loss": 0.0034278767835348844}, {"layer_params": [22, 51, 34, 16, 57], "learning_rate": 0.0075533270751877565, "batch_size": 327, "loss": 0.001772318925941363}, {"layer_params": [56, 22, 63], "learning_rate": 0.009028280911666995, "batch_size": 127, "loss": 0.001745697057340294}, {"layer_params": [25, 37, 41, 53, 64], "learning_rate": 0.006090831958818712, "batch_size": 264, "loss": 0.0024239770998246966}, {"layer_params": [29, 20, 51, 50, 42], "learning_rate": 0.0015499667085268332, "batch_size": 479, "loss": 0.0029136829846538605}, {"layer_params": [52, 26, 63], "learning_rate": 0.0016338225278871173, "batch_size": 339, "loss": 0.0021620791393797845}, {"layer_params": [16, 27], "learning_rate": 0.00448019835841237, "batch_size": 250, "loss": 0.0051684977835975586}, {"layer_params": [52, 55, 52, 43], "learning_rate": 0.0009680654729661972, "batch_size": 186, "loss": 0.0028588109696283935}, {"layer_params": [40, 41, 56], "learning_rate": 0.00886768142460912, "batch_size": 474, "loss": 0.000899269349174574}, {"layer_params": [57, 29, 63], "learning_rate": 0.001145579450137804, "batch_size": 75, "loss": 0.005114811887033284}, {"layer_params": [42, 35], "learning_rate": 0.003145267499779, "batch_size": 119, "loss": 0.003528531224001199}, {"layer_params": [17, 53, 17, 45, 60], "learning_rate": 0.006985193242867179, "batch_size": 179, "loss": 0.003037873690482229}, {"layer_params": [19, 26, 20, 58], "learning_rate": 0.004425372676092327, "batch_size": 201, "loss": 0.0028201417974196372}, {"layer_params": [50, 63], "learning_rate": 0.0008207960302166279, "batch_size": 266, "loss": 0.0038943907222710548}, {"layer_params": [44, 27, 42, 63], "learning_rate": 0.0003203277873817936, "batch_size": 301, "loss": 0.006869855155237019}, {"layer_params": [36, 24, 36, 42, 54], "learning_rate": 0.005192492846198558, "batch_size": 442, "loss": 0.0021963620057795195}, {"layer_params": [53, 58, 58, 29], "learning_rate": 0.007411428736530067, "batch_size": 167, "loss": 0.0021239727397914976}, {"layer_params": [19, 24], "learning_rate": 0.009341555403409276, "batch_size": 495, "loss": 0.005100149912759661}, {"layer_params": [29, 37], "learning_rate": 0.00899973336809654, "batch_size": 204, "loss": 0.002678237841464579}, {"layer_params": [16, 32, 35, 24], "learning_rate": 0.006015598892769202, "batch_size": 195, "loss": 0.004314095969311893}, {"layer_params": [21, 57, 31, 26], "learning_rate": 0.0041559617222013436, "batch_size": 202, "loss": 0.0022123731567990036}, {"layer_params": [59, 47], "learning_rate": 0.00656425389248403, "batch_size": 456, "loss": 0.0011214849428506568}, {"layer_params": [38, 56], "learning_rate": 0.004029301735540616, "batch_size": 135, "loss": 0.0036819296213798226}, {"layer_params": [45, 39], "learning_rate": 0.0030011365413226293, "batch_size": 453, "loss": 0.0021980708779301495}, {"layer_params": [57, 57, 63, 26, 25], "learning_rate": 0.0023619632214513025, "batch_size": 496, "loss": 0.0008442001813091338}, {"layer_params": [54, 41], "learning_rate": 0.0022165024385128874, "batch_size": 51, "loss": 0.004314593395683915}, {"layer_params": [51, 45, 34], "learning_rate": 0.00202840800634558, "batch_size": 405, "loss": 0.002083012021612376}, {"layer_params": [29, 25, 24, 64], "learning_rate": 0.005068129109588422, "batch_size": 305, "loss": 0.002553041649516672}, {"layer_params": [50, 44, 55, 57], "learning_rate": 0.0014907060757679896, "batch_size": 236, "loss": 0.001633070515235886}, {"layer_params": [52, 29, 16, 60], "learning_rate": 0.008359503641856326, "batch_size": 60, "loss": 0.005124434302560985}, {"layer_params": [46, 26, 59, 39, 27], "learning_rate": 0.009016747041697606, "batch_size": 345, "loss": 0.0015662729647010565}, {"layer_params": [40, 19], "learning_rate": 0.0005379329875369282, "batch_size": 279, "loss": 0.006971152103506029}, {"layer_params": [36, 60, 62, 37], "learning_rate": 0.006903147214635142, "batch_size": 467, "loss": 0.0009939526318339632}, {"layer_params": [20, 17, 54, 19], "learning_rate": 0.001173329650602544, "batch_size": 428, "loss": 0.005183927770704031}, {"layer_params": [24, 30, 19], "learning_rate": 0.003558503291701166, "batch_size": 45, "loss": 0.0063972849072888496}, {"layer_params": [23, 38, 46, 34, 43], "learning_rate": 0.004076616284718418, "batch_size": 46, "loss": 0.00607929824385792}, {"layer_params": [47, 26, 49, 64], "learning_rate": 0.006807775664420864, "batch_size": 101, "loss": 0.0023502823698800055}, {"layer_params": [39, 63, 34], "learning_rate": 0.001864342394312271, "batch_size": 297, "loss": 0.00270205638371408}, {"layer_params": [23, 54, 57, 40, 61], "learning_rate": 0.0012576072556002625, "batch_size": 246, "loss": 0.0023923147947061806}, {"layer_params": [51, 33, 26, 26, 42], "learning_rate": 0.00373789865087455, "batch_size": 265, "loss": 0.001973545090295374}, {"layer_params": [47, 26], "learning_rate": 0.00954769048499321, "batch_size": 19, "loss": 0.00848026862833649}, {"layer_params": [31, 19, 35, 24], "learning_rate": 0.0037196931520987356, "batch_size": 379, "loss": 0.003467517823446542}, {"layer_params": [18, 34, 27, 49, 43], "learning_rate": 0.004179114488638344, "batch_size": 282, "loss": 0.004796344947535545}, {"layer_params": [33, 56, 52, 48, 24], "learning_rate": 0.0031228233110157494, "batch_size": 462, "loss": 0.0014260037906933575}, {"layer_params": [17, 44], "learning_rate": 0.0020710994659572236, "batch_size": 243, "loss": 0.005088138496503234}, {"layer_params": [35, 35, 23], "learning_rate": 0.0012366414403780258, "batch_size": 486, "loss": 0.0030652225948870184}, {"layer_params": [22, 47], "learning_rate": 0.005631221374731705, "batch_size": 319, "loss": 0.0027916960790753363}, {"layer_params": [31, 23, 21, 35], "learning_rate": 0.0008929455363813748, "batch_size": 439, "loss": 0.004920750805176795}, {"layer_params": [30, 53, 49, 34, 20], "learning_rate": 0.006499016617676054, "batch_size": 192, "loss": 0.001976161297643557}, {"layer_params": [50, 50, 59], "learning_rate": 0.008729392979338795, "batch_size": 260, "loss": 0.0011514127545524389}, {"layer_params": [21, 34, 59, 19], "learning_rate": 0.003557516222484794, "batch_size": 424, "loss": 0.001840120026608929}, {"layer_params": [44, 49, 19, 56], "learning_rate": 0.00730566098533552, "batch_size": 376, "loss": 0.0008803727879421786}, {"layer_params": [61, 35, 63], "learning_rate": 0.006931814305010442, "batch_size": 227, "loss": 0.0009549934201641008}, {"layer_params": [41, 26, 17], "learning_rate": 0.0008281013578210187, "batch_size": 192, "loss": 0.006973568145185709}, {"layer_params": [24, 26, 43], "learning_rate": 0.007689241709716958, "batch_size": 359, "loss": 0.0024090113572310654}, {"layer_params": [40, 21, 61, 54, 23], "learning_rate": 0.008123480502054014, "batch_size": 44, "loss": 0.006625238503329456}, {"layer_params": [48, 62, 24, 37], "learning_rate": 0.003977618542147293, "batch_size": 415, "loss": 0.001055576386861503}, {"layer_params": [53, 62, 39, 25], "learning_rate": 0.005227989825119684, "batch_size": 324, "loss": 0.001161626668763347}, {"layer_params": [52, 32], "learning_rate": 0.003930763990610399, "batch_size": 353, "loss": 0.0020093647052999587}, {"layer_params": [56, 34, 42], "learning_rate": 0.006924445289104031, "batch_size": 136, "loss": 0.0016373407852370292}, {"layer_params": [57, 58, 63, 26, 31], "learning_rate": 0.006069881046926919, "batch_size": 94, "loss": 0.0017553386464715004}, {"layer_params": [50, 34, 32, 16], "learning_rate": 0.0014454501369764656, "batch_size": 342, "loss": 0.003091198685579002}, {"layer_params": [31, 59], "learning_rate": 0.0072075743370012095, "batch_size": 152, "loss": 0.002026514436583966}, {"layer_params": [46, 30, 30, 22, 30], "learning_rate": 0.0030292780893709185, "batch_size": 58, "loss": 0.004174970216117799}, {"layer_params": [27, 37, 40, 46], "learning_rate": 0.00867448708277231, "batch_size": 210, "loss": 0.002937890619505197}, {"layer_params": [43, 20, 48, 29], "learning_rate": 0.007295208364639683, "batch_size": 91, "loss": 0.0023563507199287413}, {"layer_params": [56, 38, 61, 24], "learning_rate": 0.006750710228670011, "batch_size": 121, "loss": 0.0028784345870371906}, {"layer_params": [25, 16, 54, 38], "learning_rate": 0.006818374675878195, "batch_size": 303, "loss": 0.002555398178519681}, {"layer_params": [53, 25], "learning_rate": 0.005449591351845552, "batch_size": 445, "loss": 0.002150765755213797}, {"layer_params": [16, 30], "learning_rate": 2.865505767957207e-05, "batch_size": 335, "loss": 0.0910806880891323}, {"layer_params": [55, 64], "learning_rate": 0.0064406153786383475, "batch_size": 359, "loss": 0.0011368394875898957}, {"layer_params": [51, 58, 51, 64], "learning_rate": 0.005744460872519824, "batch_size": 417, "loss": 0.0011009467125404626}, {"layer_params": [63, 53, 56], "learning_rate": 0.003379215620723502, "batch_size": 327, "loss": 0.0012160930072423071}, {"layer_params": [24, 39, 22, 61], "learning_rate": 0.005874981226845361, "batch_size": 504, "loss": 0.0019146772613748907}, {"layer_params": [22, 35, 16, 21], "learning_rate": 0.0007283298596414984, "batch_size": 310, "loss": 0.006331018204800785}, {"layer_params": [40, 42, 25, 62, 23], "learning_rate": 0.0070137016184731804, "batch_size": 467, "loss": 0.0011036519485060126}, {"layer_params": [30, 36, 56, 21], "learning_rate": 0.006758149676812781, "batch_size": 30, "loss": 0.005796817528316751}, {"layer_params": [35, 38, 20, 49], "learning_rate": 0.0011726004204499047, "batch_size": 68, "loss": 0.005998597855214029}, {"layer_params": [63, 16, 41, 43], "learning_rate": 0.003846589878514273, "batch_size": 182, "loss": 0.00286811892176047}, {"layer_params": [28, 40], "learning_rate": 0.0016706256473023775, "batch_size": 216, "loss": 0.006781228608451784}, {"layer_params": [27, 42], "learning_rate": 0.0073480001202778835, "batch_size": 63, "loss": 0.0035304276226088404}, {"layer_params": [18, 33, 37], "learning_rate": 0.002015711908276755, "batch_size": 199, "loss": 0.006084241117350757}, {"layer_params": [18, 46], "learning_rate": 0.003309245983335914, "batch_size": 73, "loss": 0.005040006581693888}, {"layer_params": [43, 63, 21, 27], "learning_rate": 0.0041530047972604895, "batch_size": 114, "loss": 0.002508763052755967}, {"layer_params": [58, 36, 56, 45, 32], "learning_rate": 0.0020737014182365056, "batch_size": 234, "loss": 0.0021409585839137434}, {"layer_params": [52, 60], "learning_rate": 0.003265201080993547, "batch_size": 111, "loss": 0.001862652983982116}, {"layer_params": [33, 27, 35], "learning_rate": 0.006778801753622755, "batch_size": 160, "loss": 0.004464509380050004}, {"layer_params": [50, 20], "learning_rate": 0.008868142642736882, "batch_size": 184, "loss": 0.002203021681634709}, {"layer_params": [33, 49, 40, 57], "learning_rate": 0.004189028825579085, "batch_size": 141, "loss": 0.00268060956033878}, {"layer_params": [64, 38, 57, 63], "learning_rate": 0.0014662555872078371, "batch_size": 59, "loss": 0.0034296176035422832}, {"layer_params": [36, 58], "learning_rate": 0.0048008220967579365, "batch_size": 31, "loss": 0.003694369315635413}, {"layer_params": [28, 64, 18], "learning_rate": 0.003951218700546981, "batch_size": 255, "loss": 0.00340356930391863}, {"layer_params": [20, 48, 57, 24, 20], "learning_rate": 0.00805354917119422, "batch_size": 157, "loss": 0.002894519157707691}, {"layer_params": [31, 34], "learning_rate": 0.0023941212860458857, "batch_size": 480, "loss": 0.004328530381899327}, {"layer_params": [55, 42, 19, 47, 16], "learning_rate": 0.0049983992017523645, "batch_size": 293, "loss": 0.001581144550582394}, {"layer_params": [60, 35, 50, 52, 32], "learning_rate": 0.005512313654845557, "batch_size": 163, "loss": 0.0017117447964847088}, {"layer_params": [37, 49, 26, 42, 41], "learning_rate": 0.007749596825319997, "batch_size": 76, "loss": 0.002379262731410563}, {"layer_params": [41, 31, 47, 19], "learning_rate": 0.008629382430977205, "batch_size": 23, "loss": 0.0077646856312640015}, {"layer_params": [16, 22, 62, 21, 17], "learning_rate": 0.009973913967351724, "batch_size": 438, "loss": 0.0024547823157627137}, {"layer_params": [64, 58, 61, 59], "learning_rate": 0.007005855733073848, "batch_size": 440, "loss": 0.0010386829968774692}, {"layer_params": [20, 26, 52, 35, 55], "learning_rate": 0.0008345822678787596, "batch_size": 293, "loss": 0.00643432532902807}, {"layer_params": [22, 46, 42, 16], "learning_rate": 0.0005415795973000775, "batch_size": 397, "loss": 0.006331745744682848}, {"layer_params": [51, 59, 49, 23, 16], "learning_rate": 0.006746613045159554, "batch_size": 364, "loss": 0.000655972178792581}, {"layer_params": [45, 33], "learning_rate": 0.007802265393386692, "batch_size": 194, "loss": 0.0032210374996066095}, {"layer_params": [37, 37], "learning_rate": 0.00831882296590612, "batch_size": 305, "loss": 0.0034709703666158023}, {"layer_params": [63, 61, 27, 31, 16], "learning_rate": 0.007634925487142593, "batch_size": 410, "loss": 0.0013316291710361839}, {"layer_params": [42, 28, 16, 63], "learning_rate": 0.0016992551450405206, "batch_size": 446, "loss": 0.0031934559578076006}, {"layer_params": [28, 56, 40], "learning_rate": 0.0069879929577026266, "batch_size": 185, "loss": 0.0017082077311351895}, {"layer_params": [27, 36], "learning_rate": 0.0031885605356042606, "batch_size": 243, "loss": 0.003626472163014114}, {"layer_params": [31, 29, 36], "learning_rate": 0.006806412258598183, "batch_size": 331, "loss": 0.0026303166523575783}, {"layer_params": [21, 48, 43, 20, 28], "learning_rate": 0.009044569480131706, "batch_size": 176, "loss": 0.0034057215647771955}, {"layer_params": [60, 36, 56], "learning_rate": 0.007865185659220642, "batch_size": 450, "loss": 0.0009633101016515866}, {"layer_params": [51, 22, 31, 24, 28], "learning_rate": 0.0067416940314195045, "batch_size": 241, "loss": 0.0013984652096405625}, {"layer_params": [40, 37, 50, 54], "learning_rate": 0.004265002392202859, "batch_size": 48, "loss": 0.004384376911912113}, {"layer_params": [46, 23, 59], "learning_rate": 0.004042737139457597, "batch_size": 123, "loss": 0.002630332706030458}, {"layer_params": [29, 61, 32], "learning_rate": 0.0019475364642163435, "batch_size": 489, "loss": 0.0020667303900700064}, {"layer_params": [60, 32, 58, 35, 44], "learning_rate": 0.001407512787038934, "batch_size": 357, "loss": 0.0018519531621132045}, {"layer_params": [58, 40, 46], "learning_rate": 0.009068558296339483, "batch_size": 464, "loss": 0.001011183630907908}, {"layer_params": [32, 16, 26], "learning_rate": 0.00042848582385077855, "batch_size": 418, "loss": 0.006872382443398237}, {"layer_params": [40, 47], "learning_rate": 0.0016490208185224997, "batch_size": 19, "loss": 0.00703605969203636}, {"layer_params": [37, 32, 56], "learning_rate": 0.005183550624925498, "batch_size": 43, "loss": 0.004054231434129179}, {"layer_params": [39, 22, 37], "learning_rate": 0.004948805178275768, "batch_size": 92, "loss": 0.0030976791435386986}, {"layer_params": [21, 36, 27, 16, 53], "learning_rate": 0.008479473888567873, "batch_size": 170, "loss": 0.003285714027006179}, {"layer_params": [32, 24, 24, 17, 42], "learning_rate": 0.002511207036571108, "batch_size": 64, "loss": 0.004295584294013679}, {"layer_params": [48, 57, 19, 26], "learning_rate": 0.006183267684797516, "batch_size": 270, "loss": 0.0020829217170830814}, {"layer_params": [60, 47], "learning_rate": 0.004384032220242233, "batch_size": 426, "loss": 0.0015639863524120302}, {"layer_params": [31, 46, 41, 52, 62], "learning_rate": 0.004136653324842248, "batch_size": 306, "loss": 0.0019193984766025095}, {"layer_params": [21, 59, 60, 25, 53], "learning_rate": 0.0011534882040045425, "batch_size": 470, "loss": 0.0023025040270294992}, {"layer_params": [35, 49, 35, 24], "learning_rate": 0.003891969625520321, "batch_size": 286, "loss": 0.0019820793520193545}, {"layer_params": [50, 40, 53], "learning_rate": 0.002216271721506469, "batch_size": 493, "loss": 0.0013356704206671567}, {"layer_params": [44, 24], "learning_rate": 0.0008521977463491825, "batch_size": 227, "loss": 0.005567581201903522}, {"layer_params": [20, 52], "learning_rate": 0.00709160127646691, "batch_size": 241, "loss": 0.0026313691807445137}, {"layer_params": [43, 29, 53, 16], "learning_rate": 0.008389091391758844, "batch_size": 362, "loss": 0.0013189846463501453}, {"layer_params": [64, 32, 34, 23], "learning_rate": 0.00791844449085965, "batch_size": 449, "loss": 0.002062378352275118}, {"layer_params": [61, 42, 42, 41, 48], "learning_rate": 0.003008983649771801, "batch_size": 193, "loss": 0.0017549618252087383}, {"layer_params": [34, 60, 34, 54, 17], "learning_rate": 0.007366737011886994, "batch_size": 282, "loss": 0.0010226049268385396}, {"layer_params": [52, 31, 50, 42], "learning_rate": 0.00911589923375625, "batch_size": 199, "loss": 0.002821432515047491}, {"layer_params": [52, 28, 57, 40], "learning_rate": 0.009701629203941587, "batch_size": 285, "loss": 0.0011061615293147043}, {"layer_params": [45, 48], "learning_rate": 0.006311477111811354, "batch_size": 296, "loss": 0.0013371718756388872}, {"layer_params": [50, 34, 56, 41, 46], "learning_rate": 0.002101679197157477, "batch_size": 499, "loss": 0.0013199611240997911}, {"layer_params": [55, 30], "learning_rate": 0.009630731186017436, "batch_size": 240, "loss": 0.0037125178473070264}, {"layer_params": [30, 36], "learning_rate": 0.008136384578764337, "batch_size": 275, "loss": 0.0015225886250846087}, {"layer_params": [22, 35, 36, 34, 50], "learning_rate": 0.006232970635545813, "batch_size": 383, "loss": 0.0022261207515839486}, {"layer_params": [56, 55, 20, 52, 39], "learning_rate": 0.00027417198678393454, "batch_size": 297, "loss": 0.0062416357593610885}, {"layer_params": [39, 36, 43, 58, 60], "learning_rate": 0.006232827889265472, "batch_size": 504, "loss": 0.0015608512400649489}, {"layer_params": [26, 26, 22], "learning_rate": 0.0038998995356001815, "batch_size": 414, "loss": 0.0031615524226799607}, {"layer_params": [26, 39], "learning_rate": 0.0075561307357041654, "batch_size": 470, "loss": 0.0021137665619608017}, {"layer_params": [28, 33, 33, 30, 52], "learning_rate": 0.004786049017462537, "batch_size": 403, "loss": 0.0020772194373421373}, {"layer_params": [60, 58], "learning_rate": 0.008621260039164354, "batch_size": 419, "loss": 0.0018087341357022524}, {"layer_params": [20, 64, 26], "learning_rate": 0.008469411787348462, "batch_size": 269, "loss": 0.0021661465452052654}, {"layer_params": [61, 43, 18], "learning_rate": 0.009189923584676333, "batch_size": 377, "loss": 0.0014118812256492675}, {"layer_params": [30, 54, 40, 56, 52], "learning_rate": 0.008664501019018883, "batch_size": 360, "loss": 0.0016231495910324157}, {"layer_params": [36, 50, 60, 44], "learning_rate": 0.004979709317108271, "batch_size": 221, "loss": 0.0014118166913976893}, {"layer_params": [44, 33], "learning_rate": 0.0002678031707109259, "batch_size": 506, "loss": 0.009661436527967453}, {"layer_params": [45, 37], "learning_rate": 0.008266014927896755, "batch_size": 348, "loss": 0.0016113051038701086}, {"layer_params": [35, 42, 21], "learning_rate": 0.005631318882253992, "batch_size": 328, "loss": 0.0017650523537304252}, {"layer_params": [62, 21], "learning_rate": 0.0049360370725024215, "batch_size": 380, "loss": 0.0015940921800211073}, {"layer_params": [29, 27, 54, 51], "learning_rate": 0.0089486946815702, "batch_size": 433, "loss": 0.0017664102383423597}, {"layer_params": [29, 63, 29, 23], "learning_rate": 0.005768423918009027, "batch_size": 359, "loss": 0.0011758779792580753}, {"layer_params": [59, 39, 36, 21], "learning_rate": 0.0006975617837469366, "batch_size": 483, "loss": 0.0035454469895921646}, {"layer_params": [16, 54], "learning_rate": 0.0021258574675651915, "batch_size": 357, "loss": 0.004170145133975893}, {"layer_params": [20, 45, 43], "learning_rate": 0.000911602776581353, "batch_size": 105, "loss": 0.005875586732290685}, {"layer_params": [64, 55], "learning_rate": 0.006805933062921464, "batch_size": 280, "loss": 0.0014859386149328202}, {"layer_params": [50, 41, 23, 27], "learning_rate": 0.009373500474253522, "batch_size": 158, "loss": 0.0013909699843497947}, {"layer_params": [24, 19, 48, 22, 58], "learning_rate": 0.003540381572523668, "batch_size": 67, "loss": 0.0068964607128873465}, {"layer_params": [33, 18, 36, 64], "learning_rate": 0.0031105707146365925, "batch_size": 169, "loss": 0.00419044089037925}, {"layer_params": [45, 22], "learning_rate": 0.0030453836964509876, "batch_size": 204, "loss": 0.0033445332222618164}, {"layer_params": [22, 37, 26], "learning_rate": 0.0017264395865336738, "batch_size": 317, "loss": 0.0030397296883165835}, {"layer_params": [36, 52, 17, 58, 17], "learning_rate": 0.005898001645201157, "batch_size": 419, "loss": 0.0017740279401186854}, {"layer_params": [17, 44], "learning_rate": 0.004974464910268879, "batch_size": 335, "loss": 0.0034205756965093315}, {"layer_params": [37, 61], "learning_rate": 0.008137150739075012, "batch_size": 283, "loss": 0.002450327759142965}, {"layer_params": [26, 47, 16, 47, 28], "learning_rate": 0.007819567700730777, "batch_size": 119, "loss": 0.0027628260012716056}, {"layer_params": [45, 63, 62, 19], "learning_rate": 0.006744358958252956, "batch_size": 416, "loss": 0.0020567661826498807}, {"layer_params": [22, 62, 58], "learning_rate": 0.009861303267201225, "batch_size": 221, "loss": 0.0015895960188936442}, {"layer_params": [49, 21, 22, 22], "learning_rate": 0.00023712478835241285, "batch_size": 106, "loss": 0.008176988898776471}, {"layer_params": [59, 28], "learning_rate": 0.004007647435625518, "batch_size": 75, "loss": 0.0036487243650481106}, {"layer_params": [41, 56, 40, 53], "learning_rate": 0.009563675682628633, "batch_size": 423, "loss": 0.0012667586136376485}, {"layer_params": [30, 55, 48, 31], "learning_rate": 0.007155416516019416, "batch_size": 129, "loss": 0.0023198365967255084}, {"layer_params": [63, 47], "learning_rate": 0.00976016689046826, "batch_size": 340, "loss": 0.001184512103209272}, {"layer_params": [46, 38, 39], "learning_rate": 0.00799865165778849, "batch_size": 511, "loss": 0.0018070681905373932}, {"layer_params": [28, 62], "learning_rate": 0.006173386543140481, "batch_size": 161, "loss": 0.0024967601045500485}, {"layer_params": [25, 62, 47, 44], "learning_rate": 0.006441599482515538, "batch_size": 32, "loss": 0.004508273554965854}, {"layer_params": [46, 63, 41, 51], "learning_rate": 0.006326855922530807, "batch_size": 20, "loss": 0.005947072985582054}, {"layer_params": [29, 28, 60, 58], "learning_rate": 0.007225977732976789, "batch_size": 142, "loss": 0.0022213113214820624}, {"layer_params": [58, 64, 38], "learning_rate": 0.009092119249511529, "batch_size": 280, "loss": 0.0008434196311281994}, {"layer_params": [26, 45, 50, 34, 35], "learning_rate": 0.005473069485425156, "batch_size": 34, "loss": 0.004882434190949425}, {"layer_params": [20, 48, 42, 47, 26], "learning_rate": 0.006960366379953383, "batch_size": 222, "loss": 0.0024311393545940517}, {"layer_params": [41, 45], "learning_rate": 0.0017167888769093337, "batch_size": 332, "loss": 0.0025042473967187106}, {"layer_params": [62, 46, 40], "learning_rate": 0.009257868726250087, "batch_size": 134, "loss": 0.0020637384580913932}, {"layer_params": [59, 31, 47, 32, 23], "learning_rate": 0.005717058825654415, "batch_size": 379, "loss": 0.0007231818995205685}, {"layer_params": [42, 40, 50, 31, 19], "learning_rate": 0.0011447486803835179, "batch_size": 322, "loss": 0.0035183054069057107}, {"layer_params": [37, 60, 24, 32, 40], "learning_rate": 0.0030101623672452835, "batch_size": 292, "loss": 0.0017293987190350891}, {"layer_params": [53, 35, 45, 34, 56], "learning_rate": 0.007386184803065291, "batch_size": 357, "loss": 0.0009397820051526651}, {"layer_params": [17, 44, 38, 27, 50], "learning_rate": 0.0028652541350955105, "batch_size": 64, "loss": 0.005371277681551874}, {"layer_params": [62, 49, 62, 39, 37], "learning_rate": 0.004976727989155013, "batch_size": 134, "loss": 0.00146651147515513}, {"layer_params": [33, 64, 32], "learning_rate": 0.007013737822039135, "batch_size": 103, "loss": 0.0024501825112383815}, {"layer_params": [26, 22, 18, 47, 57], "learning_rate": 0.007188847727034649, "batch_size": 103, "loss": 0.0038552682800218462}, {"layer_params": [20, 43, 40, 16], "learning_rate": 0.006901194897722428, "batch_size": 106, "loss": 0.003100716832559556}, {"layer_params": [48, 36], "learning_rate": 0.008925965192207846, "batch_size": 43, "loss": 0.0029432728700339796}, {"layer_params": [56, 37, 16, 58], "learning_rate": 0.009670399479100348, "batch_size": 328, "loss": 0.002568524902453646}, {"layer_params": [16, 16, 62, 56, 26], "learning_rate": 0.007370008076577995, "batch_size": 255, "loss": 0.006002392168156802}, {"layer_params": [18, 64, 60, 63], "learning_rate": 0.006960399409858953, "batch_size": 111, "loss": 0.005046787930186838}, {"layer_params": [20, 29], "learning_rate": 0.006749784174045814, "batch_size": 264, "loss": 0.0026746742939576505}, {"layer_params": [40, 43, 21, 19, 44], "learning_rate": 0.0007556085065456012, "batch_size": 129, "loss": 0.004859966454096139}, {"layer_params": [41, 34, 53], "learning_rate": 0.0009523525198013654, "batch_size": 500, "loss": 0.003955154996365309}, {"layer_params": [32, 39], "learning_rate": 0.008021606959406137, "batch_size": 28, "loss": 0.004981074796523899}, {"layer_params": [42, 38, 38], "learning_rate": 0.007820481464912741, "batch_size": 260, "loss": 0.002696969718672335}, {"layer_params": [32, 55, 19, 38, 45], "learning_rate": 0.006384719737759433, "batch_size": 257, "loss": 0.0018810530251357704}, {"layer_params": [50, 37, 18], "learning_rate": 0.0030081098873872797, "batch_size": 19, "loss": 0.007966200571972877}, {"layer_params": [32, 52], "learning_rate": 0.0017969867149283426, "batch_size": 145, "loss": 0.004729254688136279}, {"layer_params": [37, 60, 47, 26, 31], "learning_rate": 0.004949427830916943, "batch_size": 81, "loss": 0.0021294467721600084}, {"layer_params": [28, 56, 47, 61], "learning_rate": 0.00993319154946959, "batch_size": 228, "loss": 0.0019790471252053975}, {"layer_params": [16, 17], "learning_rate": 0.0016891150899325908, "batch_size": 85, "loss": 0.01602381986565888}, {"layer_params": [21, 63, 32, 40], "learning_rate": 0.004016061749928841, "batch_size": 103, "loss": 0.004605641849339009}, {"layer_params": [44, 32], "learning_rate": 2.341628189591796e-05, "batch_size": 450, "loss": 0.037373436987400054}, {"layer_params": [44, 21, 25, 50, 29], "learning_rate": 0.0071076332053779554, "batch_size": 230, "loss": 0.002532271412201226}, {"layer_params": [52, 64, 51, 27, 22], "learning_rate": 0.0002685921155279106, "batch_size": 276, "loss": 0.007051690206862986}, {"layer_params": [60, 29, 47, 38], "learning_rate": 0.005345020775121302, "batch_size": 147, "loss": 0.0017945262137800456}, {"layer_params": [62, 48, 59, 29, 17], "learning_rate": 0.0038385466290803243, "batch_size": 75, "loss": 0.004036904911044985}, {"layer_params": [16, 42, 18, 20], "learning_rate": 0.00631203615048308, "batch_size": 352, "loss": 0.002744804418180138}, {"layer_params": [16, 16, 31, 60, 33], "learning_rate": 0.009062532278791438, "batch_size": 398, "loss": 0.0033461394743062554}, {"layer_params": [45, 28, 39], "learning_rate": 0.00405288977812085, "batch_size": 350, "loss": 0.0020169522939249875}, {"layer_params": [45, 53, 45], "learning_rate": 0.006371310356453892, "batch_size": 294, "loss": 0.001026641521602869}, {"layer_params": [64, 25, 17, 18, 17], "learning_rate": 0.009402685971954193, "batch_size": 349, "loss": 0.002638170684222132}, {"layer_params": [18, 56, 64], "learning_rate": 0.0022555319870542455, "batch_size": 248, "loss": 0.0021628548903390764}, {"layer_params": [19, 18], "learning_rate": 1.8211569573654577e-05, "batch_size": 424, "loss": 0.03872417030856013}, {"layer_params": [62, 20, 36, 18], "learning_rate": 0.009061940487314407, "batch_size": 320, "loss": 0.0013364713586634025}, {"layer_params": [24, 22], "learning_rate": 0.003203328958351729, "batch_size": 30, "loss": 0.007105668839067221}, {"layer_params": [49, 26], "learning_rate": 0.000116654786843808, "batch_size": 437, "loss": 0.025677945110946895}, {"layer_params": [49, 35, 53, 27, 53], "learning_rate": 0.008496874347159717, "batch_size": 174, "loss": 0.0018689287616871298}, {"layer_params": [42, 17, 40, 43, 28], "learning_rate": 0.008524838312197658, "batch_size": 277, "loss": 0.0030236858082935214}, {"layer_params": [59, 58, 61, 21, 37], "learning_rate": 0.008592559415020693, "batch_size": 386, "loss": 0.0016159339703153818}, {"layer_params": [44, 24, 60, 26], "learning_rate": 0.00123809933548889, "batch_size": 144, "loss": 0.005393254866357893}, {"layer_params": [41, 54, 49, 62, 36], "learning_rate": 0.0008672981634505443, "batch_size": 488, "loss": 0.0028851434658281505}, {"layer_params": [45, 45], "learning_rate": 0.006273242696284758, "batch_size": 285, "loss": 0.0015102547919377686}, {"layer_params": [53, 46, 19, 31, 26], "learning_rate": 0.004870727898868209, "batch_size": 439, "loss": 0.0011102296027820557}, {"layer_params": [59, 45], "learning_rate": 0.00650403450712329, "batch_size": 428, "loss": 0.001716307713650167}, {"layer_params": [48, 49], "learning_rate": 0.0008388833594672031, "batch_size": 37, "loss": 0.006694716077763587}, {"layer_params": [64, 27, 50, 43], "learning_rate": 0.006287242348234712, "batch_size": 303, "loss": 0.001215677380678244}, {"layer_params": [36, 62], "learning_rate": 0.00605719827576425, "batch_size": 77, "loss": 0.0023636270384304226}, {"layer_params": [51, 36, 23, 59], "learning_rate": 0.003358581475310228, "batch_size": 246, "loss": 0.0016861958801746369}, {"layer_params": [39, 16, 21], "learning_rate": 0.003591081391326102, "batch_size": 40, "loss": 0.00559752405853942}, {"layer_params": [21, 31, 57], "learning_rate": 0.00687666979008696, "batch_size": 247, "loss": 0.002919697519391775}, {"layer_params": [21, 16, 31], "learning_rate": 0.0006771937165881493, "batch_size": 177, "loss": 0.007195278303697705}, {"layer_params": [20, 28], "learning_rate": 0.002744835401444637, "batch_size": 118, "loss": 0.004860037674661726}, {"layer_params": [28, 35], "learning_rate": 0.0021685522320000553, "batch_size": 201, "loss": 0.0035640405374579133}, {"layer_params": [55, 41, 39], "learning_rate": 0.001294420485042007, "batch_size": 94, "loss": 0.003923850911669433}, {"layer_params": [50, 58], "learning_rate": 0.009405873913390966, "batch_size": 497, "loss": 0.0016447522514499724}, {"layer_params": [57, 27, 36, 61], "learning_rate": 0.0015924769166810924, "batch_size": 421, "loss": 0.0021303639945108445}, {"layer_params": [17, 62, 37], "learning_rate": 0.007914995894209347, "batch_size": 181, "loss": 0.002838159245438874}, {"layer_params": [60, 37, 41, 41, 52], "learning_rate": 0.009915876800332952, "batch_size": 495, "loss": 0.0008509918302297592}, {"layer_params": [28, 58, 40, 51, 28], "learning_rate": 0.00032862827365551467, "batch_size": 375, "loss": 0.0060564158670604225}, {"layer_params": [61, 52, 36, 45, 58], "learning_rate": 0.003141514146208178, "batch_size": 164, "loss": 0.0022569279791787265}, {"layer_params": [17, 25, 35, 52, 32], "learning_rate": 0.008858845113093082, "batch_size": 293, "loss": 0.004409419053699821}, {"layer_params": [54, 28, 22], "learning_rate": 0.00749818726090637, "batch_size": 238, "loss": 0.001921508345985785}, {"layer_params": [19, 26, 21, 35], "learning_rate": 0.00892348905479885, "batch_size": 355, "loss": 0.002171187250642106}, {"layer_params": [40, 60, 24], "learning_rate": 0.005017454550874625, "batch_size": 266, "loss": 0.0015304539841599761}, {"layer_params": [51, 30], "learning_rate": 0.0058573161926868764, "batch_size": 413, "loss": 0.001931161906104535}, {"layer_params": [55, 38], "learning_rate": 0.0060934025276408324, "batch_size": 367, "loss": 0.0028148813475854695}, {"layer_params": [44, 44, 39], "learning_rate": 0.00021317287758575377, "batch_size": 407, "loss": 0.00803315766621381}, {"layer_params": [34, 46, 55, 37], "learning_rate": 0.002911408931079212, "batch_size": 302, "loss": 0.002033537784591317}, {"layer_params": [49, 18], "learning_rate": 0.004341905105625667, "batch_size": 366, "loss": 0.0028589724539779125}, {"layer_params": [26, 56, 60], "learning_rate": 0.009354066776140792, "batch_size": 305, "loss": 0.0020159868628252297}, {"layer_params": [38, 26, 25], "learning_rate": 0.007029646602052638, "batch_size": 362, "loss": 0.002330492413602769}, {"layer_params": [32, 56, 23], "learning_rate": 0.0009172538678109159, "batch_size": 247, "loss": 0.005079347225837409}, {"layer_params": [20, 59], "learning_rate": 0.004204294065323437, "batch_size": 160, "loss": 0.0034790685935877264}, {"layer_params": [49, 26, 20, 38], "learning_rate": 0.004339939809353463, "batch_size": 315, "loss": 0.0018862483790144323}, {"layer_params": [18, 28, 43, 57, 59], "learning_rate": 0.007680010653417255, "batch_size": 57, "loss": 0.006079277868848294}, {"layer_params": [48, 20, 45, 22], "learning_rate": 0.006225124186327523, "batch_size": 241, "loss": 0.0018087642220780253}, {"layer_params": [27, 42], "learning_rate": 0.0024948432239668074, "batch_size": 75, "loss": 0.004305966966785491}, {"layer_params": [17, 50, 55, 55, 48], "learning_rate": 0.0017882536174861844, "batch_size": 463, "loss": 0.002158479243516922}, {"layer_params": [22, 58, 54], "learning_rate": 0.0003321299959590867, "batch_size": 180, "loss": 0.007580820852890611}, {"layer_params": [33, 28, 63, 61, 28], "learning_rate": 0.00912167899390309, "batch_size": 131, "loss": 0.0022842061519622804}, {"layer_params": [53, 21, 55, 39, 49], "learning_rate": 0.006183622126954627, "batch_size": 319, "loss": 0.0017281323508359491}, {"layer_params": [47, 26, 52, 35, 50], "learning_rate": 0.008883989631054592, "batch_size": 318, "loss": 0.002097678636200726}, {"layer_params": [54, 34, 18, 20, 25], "learning_rate": 0.005890798750803739, "batch_size": 333, "loss": 0.0013046249654144048}, {"layer_params": [32, 26, 21], "learning_rate": 0.0032379236616274917, "batch_size": 238, "loss": 0.004090977692976594}, {"layer_params": [42, 31, 57], "learning_rate": 0.009642792953453943, "batch_size": 171, "loss": 0.0025288894947152587}, {"layer_params": [29, 24, 62], "learning_rate": 0.0029072941839892357, "batch_size": 185, "loss": 0.003395849019289017}, {"layer_params": [39, 54, 43, 34, 60], "learning_rate": 0.007668010916143125, "batch_size": 307, "loss": 0.0009588818805059418}, {"layer_params": [21, 46], "learning_rate": 0.0025924861993767735, "batch_size": 469, "loss": 0.0033829639316536484}, {"layer_params": [17, 36, 20, 21, 47], "learning_rate": 0.00572838419639207, "batch_size": 378, "loss": 0.002356913900002837}, {"layer_params": [64, 47, 16], "learning_rate": 0.007893748880194005, "batch_size": 291, "loss": 0.001037860971991904}, {"layer_params": [53, 30], "learning_rate": 0.006139027847112089, "batch_size": 496, "loss": 0.0015832338889595122}, {"layer_params": [30, 26, 27, 62, 16], "learning_rate": 0.00977931580364246, "batch_size": 506, "loss": 0.0020501706388313325}, {"layer_params": [38, 20, 32, 45, 27], "learning_rate": 0.0005403474173067504, "batch_size": 133, "loss": 0.006372147472575307}, {"layer_params": [29, 16, 57, 60, 34], "learning_rate": 0.006246581494355077, "batch_size": 355, "loss": 0.0028629023395478725}, {"layer_params": [26, 33, 17, 17], "learning_rate": 0.0002257767344881574, "batch_size": 59, "loss": 0.009116541044786573}, {"layer_params": [26, 43, 31, 55, 38], "learning_rate": 0.0017781343558564361, "batch_size": 392, "loss": 0.0020570379274431616}, {"layer_params": [57, 49, 46], "learning_rate": 0.004854760778263254, "batch_size": 483, "loss": 0.0009738718467997387}, {"layer_params": [38, 27, 31], "learning_rate": 0.005311927798750486, "batch_size": 313, "loss": 0.0018544604617636651}, {"layer_params": [55, 63, 64], "learning_rate": 0.005966841883673585, "batch_size": 364, "loss": 0.0006577121684676968}, {"layer_params": [21, 57, 29, 52, 21], "learning_rate": 0.006594546231414106, "batch_size": 437, "loss": 0.00143215891555883}, {"layer_params": [23, 37, 36, 16, 61], "learning_rate": 0.0002245929263828216, "batch_size": 177, "loss": 0.0077944272151216866}, {"layer_params": [49, 53], "learning_rate": 0.002203567782500751, "batch_size": 223, "loss": 0.003008193471468985}, {"layer_params": [32, 39, 31], "learning_rate": 0.00611674973740034, "batch_size": 436, "loss": 0.0020599951432086526}, {"layer_params": [40, 22, 45, 56], "learning_rate": 0.005448027113056636, "batch_size": 30, "loss": 0.007127359046135098}, {"layer_params": [59, 25, 21, 45, 57], "learning_rate": 0.003405555604006807, "batch_size": 173, "loss": 0.002845867041032761}, {"layer_params": [38, 18, 44], "learning_rate": 0.0015166537122810488, "batch_size": 90, "loss": 0.004033792754635215}, {"layer_params": [57, 27, 33, 37, 48], "learning_rate": 0.002039523658135795, "batch_size": 314, "loss": 0.0025145225203596056}, {"layer_params": [44, 22], "learning_rate": 0.007327710451083337, "batch_size": 118, "loss": 0.003509897303301841}, {"layer_params": [19, 57, 57, 23], "learning_rate": 0.003789517039625094, "batch_size": 137, "loss": 0.0027427587285637853}, {"layer_params": [59, 43, 41, 54, 51], "learning_rate": 0.0011059204039554757, "batch_size": 169, "loss": 0.002495999848470092}, {"layer_params": [19, 18, 41, 32], "learning_rate": 0.007891121853736149, "batch_size": 71, "loss": 0.006021680333651603}, {"layer_params": [57, 34], "learning_rate": 0.0007693721757750792, "batch_size": 458, "loss": 0.004157888412009925}, {"layer_params": [20, 29], "learning_rate": 0.002463062464419037, "batch_size": 31, "loss": 0.008654847363941372}, {"layer_params": [24, 61, 17, 61, 45], "learning_rate": 0.001357361410504916, "batch_size": 315, "loss": 0.004390261322259903}, {"layer_params": [44, 38], "learning_rate": 0.00811492679107774, "batch_size": 282, "loss": 0.003374754840042442}, {"layer_params": [39, 26], "learning_rate": 0.006917023836448906, "batch_size": 302, "loss": 0.0022531931439880282}, {"layer_params": [16, 27, 17], "learning_rate": 0.007654584571179271, "batch_size": 111, "loss": 0.006543554696254433}, {"layer_params": [45, 37, 48, 26, 49], "learning_rate": 0.007312887086192432, "batch_size": 420, "loss": 0.0015221021324396133}, {"layer_params": [46, 45, 50, 33, 47], "learning_rate": 0.009552557537016905, "batch_size": 450, "loss": 0.0011612983554368838}, {"layer_params": [62, 19, 30, 22, 23], "learning_rate": 0.007675487855830682, "batch_size": 226, "loss": 0.0022662904544267803}, {"layer_params": [35, 47, 21, 32, 28], "learning_rate": 0.00998941092068178, "batch_size": 247, "loss": 0.0022331298631615938}, {"layer_params": [16, 50, 25, 37, 45], "learning_rate": 0.002110813938652847, "batch_size": 413, "loss": 0.0029301656992174684}, {"layer_params": [25, 42, 19, 28], "learning_rate": 0.006423592001535259, "batch_size": 205, "loss": 0.0025752557546366004}, {"layer_params": [30, 39, 44], "learning_rate": 0.003882394359371289, "batch_size": 167, "loss": 0.0027848137286491693}, {"layer_params": [35, 18, 62, 63], "learning_rate": 0.0085968757842362, "batch_size": 294, "loss": 0.0025393898296169936}, {"layer_params": [38, 20], "learning_rate": 0.00036552407937159273, "batch_size": 306, "loss": 0.009135136883705854}, {"layer_params": [34, 38, 63, 60], "learning_rate": 0.002315615981913566, "batch_size": 273, "loss": 0.0016237167618237435}, {"layer_params": [35, 33, 45, 19], "learning_rate": 0.0026546693447378603, "batch_size": 375, "loss": 0.001762611361918971}, {"layer_params": [40, 19], "learning_rate": 0.003722181171718573, "batch_size": 377, "loss": 0.002758220990654081}, {"layer_params": [20, 23, 55, 44, 62], "learning_rate": 0.0037990306901015316, "batch_size": 302, "loss": 0.0025008896947838364}, {"layer_params": [52, 61, 39, 53, 39], "learning_rate": 0.005768724397761998, "batch_size": 394, "loss": 0.0014494005881715566}, {"layer_params": [35, 16], "learning_rate": 0.007138516083805074, "batch_size": 200, "loss": 0.0021109943685587496}, {"layer_params": [27, 33, 41, 52, 50], "learning_rate": 0.009542075821250084, "batch_size": 212, "loss": 0.0035866200551390648}, {"layer_params": [20, 41], "learning_rate": 0.0004107195911604114, "batch_size": 255, "loss": 0.00877788346260786}, {"layer_params": [57, 38], "learning_rate": 0.008997306165623721, "batch_size": 433, "loss": 0.0024338337848894298}, {"layer_params": [42, 55, 52], "learning_rate": 0.008704114949881376, "batch_size": 210, "loss": 0.0016486558096949011}, {"layer_params": [50, 61, 33, 46], "learning_rate": 0.0021263747738750854, "batch_size": 121, "loss": 0.002280891773989424}, {"layer_params": [51, 64, 63], "learning_rate": 0.0056030446914899475, "batch_size": 474, "loss": 0.0008406544337049126}, {"layer_params": [32, 18, 24, 30, 43], "learning_rate": 0.00392497278289031, "batch_size": 130, "loss": 0.003596053854562342}, {"layer_params": [37, 23, 61, 28, 58], "learning_rate": 0.0014807384316718295, "batch_size": 200, "loss": 0.0034043572354130447}, {"layer_params": [48, 43, 48], "learning_rate": 0.004660271784312849, "batch_size": 57, "loss": 0.0028796694590710104}, {"layer_params": [47, 56, 44], "learning_rate": 0.0015278765691638767, "batch_size": 460, "loss": 0.0018490079417824744}, {"layer_params": [37, 36, 43], "learning_rate": 0.0004387536459043592, "batch_size": 211, "loss": 0.0073607784416526555}, {"layer_params": [25, 26, 38, 51, 50], "learning_rate": 0.00046762312021400137, "batch_size": 143, "loss": 0.007260158276185393}, {"layer_params": [42, 46, 54, 48], "learning_rate": 0.0048182971722208175, "batch_size": 169, "loss": 0.0015102609270252287}, {"layer_params": [42, 49, 39, 37, 27], "learning_rate": 0.0025653392974577605, "batch_size": 103, "loss": 0.0025944824365433305}, {"layer_params": [29, 61], "learning_rate": 0.008076663917451949, "batch_size": 211, "loss": 0.0023124099744018167}, {"layer_params": [17, 18, 29, 35], "learning_rate": 0.0012160943281355552, "batch_size": 215, "loss": 0.007385363359935582}, {"layer_params": [35, 46, 32, 49], "learning_rate": 0.005583851678774963, "batch_size": 213, "loss": 0.0017178219370543957}, {"layer_params": [20, 19, 42], "learning_rate": 0.005315917358440961, "batch_size": 329, "loss": 0.002734815930016339}, {"layer_params": [17, 26, 39, 19, 45], "learning_rate": 0.0017658763202366152, "batch_size": 433, "loss": 0.0029016181221231817}, {"layer_params": [46, 55, 50, 59, 44], "learning_rate": 0.004129866615562041, "batch_size": 84, "loss": 0.002119097898248583}, {"layer_params": [33, 39, 48, 39, 24], "learning_rate": 0.008893423224274666, "batch_size": 209, "loss": 0.0022270904935430737}, {"layer_params": [18, 46], "learning_rate": 0.0028987219322551554, "batch_size": 486, "loss": 0.004129970371723175}, {"layer_params": [42, 35, 38], "learning_rate": 0.003403802234202008, "batch_size": 367, "loss": 0.002165964365703985}, {"layer_params": [20, 18, 41, 44], "learning_rate": 0.009860075040812589, "batch_size": 368, "loss": 0.002459498953539878}, {"layer_params": [50, 63, 24, 52], "learning_rate": 0.009726096854196968, "batch_size": 293, "loss": 0.0015979534399230032}, {"layer_params": [42, 23], "learning_rate": 0.0016209006670689285, "batch_size": 468, "loss": 0.004435003753751516}, {"layer_params": [16, 33], "learning_rate": 0.005544670606008858, "batch_size": 454, "loss": 0.004565435857512057}, {"layer_params": [49, 58, 30], "learning_rate": 0.005734749068164273, "batch_size": 365, "loss": 0.0013701195560861378}, {"layer_params": [35, 47, 21], "learning_rate": 0.0022082373618785315, "batch_size": 139, "loss": 0.0037017427617684006}, {"layer_params": [51, 55], "learning_rate": 0.0006963497867725682, "batch_size": 61, "loss": 0.007712685372680426}, {"layer_params": [32, 40, 23], "learning_rate": 0.009967678664891162, "batch_size": 147, "loss": 0.0023693848168477418}, {"layer_params": [50, 59], "learning_rate": 0.008814963344013228, "batch_size": 121, "loss": 0.0018339726375415921}, {"layer_params": [32, 57, 50, 33], "learning_rate": 0.008445455780779876, "batch_size": 333, "loss": 0.0015640702750533819}, {"layer_params": [59, 18, 24, 61], "learning_rate": 0.008180050313518598, "batch_size": 148, "loss": 0.002059108583489433}, {"layer_params": [52, 33, 54, 17], "learning_rate": 0.00319310982515136, "batch_size": 244, "loss": 0.0029908090084791185}, {"layer_params": [58, 57, 21, 44], "learning_rate": 0.004041424638035456, "batch_size": 167, "loss": 0.0017385549622122199}, {"layer_params": [60, 57, 41, 59, 26], "learning_rate": 0.003672668100703042, "batch_size": 313, "loss": 0.0008199500065529719}, {"layer_params": [58, 60, 30, 63, 31], "learning_rate": 0.007259563284858348, "batch_size": 37, "loss": 0.0037190865783486514}, {"layer_params": [55, 50, 56, 18], "learning_rate": 0.009793040157937933, "batch_size": 429, "loss": 0.0008931518363533542}, {"layer_params": [40, 55, 63, 40], "learning_rate": 0.0029282107094152827, "batch_size": 342, "loss": 0.0013051328290021047}, {"layer_params": [24, 18, 55], "learning_rate": 0.009037904310320689, "batch_size": 40, "loss": 0.006552582634612918}, {"layer_params": [33, 25, 39, 47, 50], "learning_rate": 0.0031704512708195342, "batch_size": 414, "loss": 0.0027599683962762356}, {"layer_params": [60, 52, 64], "learning_rate": 0.007719949923858901, "batch_size": 274, "loss": 0.000761234009405598}, {"layer_params": [34, 25, 27, 62, 26], "learning_rate": 0.009993736934907075, "batch_size": 452, "loss": 0.0009118036268046125}, {"layer_params": [41, 23, 36], "learning_rate": 0.004399961377799713, "batch_size": 274, "loss": 0.0025679631566163153}, {"layer_params": [36, 21, 56, 19], "learning_rate": 0.003067408997171063, "batch_size": 300, "loss": 0.0017531347111798823}, {"layer_params": [17, 55, 60, 33, 22], "learning_rate": 0.002276534199987376, "batch_size": 480, "loss": 0.0022489360976032913}, {"layer_params": [27, 44, 31, 56], "learning_rate": 0.009204522626998758, "batch_size": 506, "loss": 0.0013466697710100561}, {"layer_params": [43, 30], "learning_rate": 0.007820605872815942, "batch_size": 298, "loss": 0.0026776880980469288}, {"layer_params": [30, 40, 16, 41, 21], "learning_rate": 0.0021687651955787724, "batch_size": 247, "loss": 0.0027483991626650094}, {"layer_params": [34, 29], "learning_rate": 0.008574882644673536, "batch_size": 193, "loss": 0.003109517190605402}, {"layer_params": [54, 20], "learning_rate": 0.002229217040912955, "batch_size": 401, "loss": 0.0023293995286803692}, {"layer_params": [48, 63], "learning_rate": 0.000796129064913465, "batch_size": 213, "loss": 0.003562822958920151}, {"layer_params": [53, 21, 63, 40], "learning_rate": 0.006726954960021505, "batch_size": 240, "loss": 0.0016266244964208453}, {"layer_params": [54, 33], "learning_rate": 0.0034742963836196586, "batch_size": 173, "loss": 0.0038837690255604683}, {"layer_params": [42, 51, 42, 27], "learning_rate": 0.005220147943603901, "batch_size": 426, "loss": 0.0017639309854712336}, {"layer_params": [54, 32, 36], "learning_rate": 0.009053187916051014, "batch_size": 61, "loss": 0.00218215404311195}, {"layer_params": [31, 42, 39, 52, 38], "learning_rate": 0.004544421829883428, "batch_size": 499, "loss": 0.0013007663463940845}, {"layer_params": [19, 50, 42], "learning_rate": 0.006440404185407723, "batch_size": 328, "loss": 0.001739741851342842}, {"layer_params": [60, 61, 32, 19], "learning_rate": 0.007183199851720155, "batch_size": 132, "loss": 0.0016695658746175468}, {"layer_params": [30, 50, 18, 36], "learning_rate": 0.004091113688673831, "batch_size": 386, "loss": 0.0018597322783898563}, {"layer_params": [53, 39, 22], "learning_rate": 9.498214926607134e-05, "batch_size": 97, "loss": 0.025842129550874234}, {"layer_params": [40, 40, 21, 32, 22], "learning_rate": 0.007513200907180328, "batch_size": 347, "loss": 0.0022551238641608505}, {"layer_params": [59, 20], "learning_rate": 0.00977105331760132, "batch_size": 426, "loss": 0.0032780705438926814}, {"layer_params": [22, 52], "learning_rate": 0.0011417559734411438, "batch_size": 438, "loss": 0.004741338200401515}, {"layer_params": [38, 52, 52, 47], "learning_rate": 0.006609985670364569, "batch_size": 234, "loss": 0.0013459773792419583}, {"layer_params": [41, 22], "learning_rate": 0.004990769739054823, "batch_size": 97, "loss": 0.004156546117737889}, {"layer_params": [39, 39, 19, 61], "learning_rate": 0.002607127992417721, "batch_size": 223, "loss": 0.0022121285367757084}, {"layer_params": [43, 46, 30, 29, 42], "learning_rate": 0.002590879156623076, "batch_size": 75, "loss": 0.003196933566359803}, {"layer_params": [42, 40, 26], "learning_rate": 0.004957165821542427, "batch_size": 207, "loss": 0.002201738546136767}, {"layer_params": [56, 57, 50, 60, 45], "learning_rate": 0.0011519764604477538, "batch_size": 228, "loss": 0.0025547873403411357}, {"layer_params": [21, 64, 60], "learning_rate": 0.003149265414096088, "batch_size": 316, "loss": 0.0023975733178667725}, {"layer_params": [37, 31, 45], "learning_rate": 0.008396185456456257, "batch_size": 403, "loss": 0.0011938558775000275}, {"layer_params": [17, 57], "learning_rate": 0.008716926192528196, "batch_size": 240, "loss": 0.003610247829928994}, {"layer_params": [47, 63, 54, 60], "learning_rate": 0.003972154494554993, "batch_size": 323, "loss": 0.0011894708964973687}, {"layer_params": [30, 63, 16], "learning_rate": 0.0007700554491029221, "batch_size": 174, "loss": 0.007067041601985693}, {"layer_params": [39, 32, 19, 51, 22], "learning_rate": 0.006813449353619198, "batch_size": 373, "loss": 0.001288810216356069}, {"layer_params": [59, 41, 36, 59, 46], "learning_rate": 0.009904424191853955, "batch_size": 248, "loss": 0.0012508676637662574}, {"layer_params": [64, 29, 43, 64, 32], "learning_rate": 0.004835415368074529, "batch_size": 460, "loss": 0.0008353800838813186}, {"layer_params": [17, 56], "learning_rate": 0.004035417903985632, "batch_size": 287, "loss": 0.002860282307956368}, {"layer_params": [58, 42, 46, 58, 27], "learning_rate": 0.004339081540363276, "batch_size": 297, "loss": 0.001567720799939707}, {"layer_params": [54, 60, 43, 36, 31], "learning_rate": 0.0056997876898631965, "batch_size": 446, "loss": 0.0008831756544532255}, {"layer_params": [53, 40], "learning_rate": 0.008585929823203924, "batch_size": 351, "loss": 0.0015336434042546897}, {"layer_params": [42, 20, 42], "learning_rate": 0.005990532879518459, "batch_size": 246, "loss": 0.0020999750087503342}, {"layer_params": [31, 40, 49, 61, 39], "learning_rate": 0.005559329128448617, "batch_size": 254, "loss": 0.0022690765873994677}, {"layer_params": [23, 55, 47, 33], "learning_rate": 0.004739772519856073, "batch_size": 238, "loss": 0.0018726943270303308}, {"layer_params": [17, 47, 22, 39, 30], "learning_rate": 0.00298771021008851, "batch_size": 374, "loss": 0.0019142584560904652}, {"layer_params": [21, 54, 27, 29, 19], "learning_rate": 0.009853254407668138, "batch_size": 498, "loss": 0.002520771329291165}, {"layer_params": [16, 54, 37, 44], "learning_rate": 0.0029163996866028025, "batch_size": 115, "loss": 0.0036490620044060053}, {"layer_params": [37, 34, 44], "learning_rate": 8.876747679091725e-05, "batch_size": 254, "loss": 0.030650434009730818}, {"layer_params": [57, 47, 25, 60, 59], "learning_rate": 0.003151358431156978, "batch_size": 219, "loss": 0.0016648872091900558}, {"layer_params": [61, 51, 60], "learning_rate": 0.006033122783478834, "batch_size": 472, "loss": 0.0009083575144177302}, {"layer_params": [19, 24, 64, 50], "learning_rate": 0.000813478957264308, "batch_size": 204, "loss": 0.004743440439924597}, {"layer_params": [38, 42, 34, 20], "learning_rate": 0.008192556190195996, "batch_size": 137, "loss": 0.0020329222094733266}, {"layer_params": [63, 46], "learning_rate": 0.00883664491496141, "batch_size": 396, "loss": 0.001372709267307073}, {"layer_params": [31, 26, 35, 20, 23], "learning_rate": 0.00354251037993913, "batch_size": 502, "loss": 0.002580260552931577}, {"layer_params": [32, 53, 53, 41], "learning_rate": 0.005663192676860313, "batch_size": 242, "loss": 0.0011952473182464019}, {"layer_params": [28, 47], "learning_rate": 0.007625849113741188, "batch_size": 343, "loss": 0.0019478731357958168}, {"layer_params": [16, 59, 16, 49, 40], "learning_rate": 0.007603614866263662, "batch_size": 491, "loss": 0.0019567568553611634}, {"layer_params": [47, 20, 41, 32, 41], "learning_rate": 0.005029427831242582, "batch_size": 299, "loss": 0.0021642847708426417}, {"layer_params": [52, 47, 36, 64], "learning_rate": 0.005811469402614298, "batch_size": 184, "loss": 0.0023956968518905344}, {"layer_params": [60, 59, 27], "learning_rate": 0.0035004662036402043, "batch_size": 321, "loss": 0.002331412199418992}, {"layer_params": [32, 44, 36, 28, 56], "learning_rate": 0.0008387345075517033, "batch_size": 474, "loss": 0.0035332512273453178}, {"layer_params": [39, 16, 17, 23], "learning_rate": 0.007577999035639138, "batch_size": 155, "loss": 0.005405445676296949}, {"layer_params": [37, 54, 23, 17], "learning_rate": 0.006162556540235179, "batch_size": 316, "loss": 0.0012474074633792042}, {"layer_params": [54, 48, 27, 32], "learning_rate": 0.0011824522727244533, "batch_size": 52, "loss": 0.004592245917301625}, {"layer_params": [40, 50, 34], "learning_rate": 0.007247075227483284, "batch_size": 461, "loss": 0.00112503458163701}, {"layer_params": [38, 57], "learning_rate": 0.000967338801694679, "batch_size": 417, "loss": 0.003787217070348561}, {"layer_params": [31, 41, 41], "learning_rate": 0.0037074023303114824, "batch_size": 442, "loss": 0.0026852123718708754}, {"layer_params": [56, 49], "learning_rate": 0.007528580994498997, "batch_size": 260, "loss": 0.0013505644822726026}, {"layer_params": [50, 47, 48, 30, 40], "learning_rate": 0.006869334477518896, "batch_size": 252, "loss": 0.0018932876677718014}, {"layer_params": [38, 63, 20, 32], "learning_rate": 0.003918488534993533, "batch_size": 92, "loss": 0.0035628217668272556}, {"layer_params": [35, 57, 49], "learning_rate": 0.00824149436483474, "batch_size": 176, "loss": 0.0018078882317058742}, {"layer_params": [24, 17, 63, 42], "learning_rate": 0.00018370933045363345, "batch_size": 308, "loss": 0.008571424731053412}, {"layer_params": [48, 63, 62, 18], "learning_rate": 0.00742320697132666, "batch_size": 53, "loss": 0.0034562269027810545}, {"layer_params": [46, 23, 42, 55, 39], "learning_rate": 0.004668232978892302, "batch_size": 71, "loss": 0.0031641936185769735}, {"layer_params": [24, 41, 23], "learning_rate": 0.0007865445451331135, "batch_size": 109, "loss": 0.007150307819247245}, {"layer_params": [35, 59], "learning_rate": 0.0058113623561220126, "batch_size": 30, "loss": 0.00666160630993545}, {"layer_params": [51, 35], "learning_rate": 8.585585174790404e-05, "batch_size": 198, "loss": 0.02983289711177349}, {"layer_params": [39, 33, 36, 42, 43], "learning_rate": 0.008616761575536926, "batch_size": 345, "loss": 0.0009488845791202038}, {"layer_params": [64, 42], "learning_rate": 0.0023820234335323914, "batch_size": 409, "loss": 0.0016224280511960387}, {"layer_params": [43, 38], "learning_rate": 0.0026516846443192907, "batch_size": 36, "loss": 0.005948818849865347}, {"layer_params": [16, 53], "learning_rate": 0.009495482093366165, "batch_size": 237, "loss": 0.0031683846609666944}, {"layer_params": [45, 55, 39], "learning_rate": 0.0006594114567042898, "batch_size": 390, "loss": 0.0037252334877848625}, {"layer_params": [60, 20, 36], "learning_rate": 0.006538868218788909, "batch_size": 144, "loss": 0.002822107190731913}, {"layer_params": [54, 59], "learning_rate": 0.00641300784482556, "batch_size": 291, "loss": 0.0012891734455479308}, {"layer_params": [58, 46], "learning_rate": 0.004018049731306049, "batch_size": 40, "loss": 0.004313879611436278}, {"layer_params": [35, 51, 39], "learning_rate": 0.009769258721325464, "batch_size": 438, "loss": 0.0019672665605321524}, {"layer_params": [43, 50, 35], "learning_rate": 0.008164397887059084, "batch_size": 371, "loss": 0.0009264859691029415}, {"layer_params": [53, 46, 37], "learning_rate": 0.008399094348268984, "batch_size": 423, "loss": 0.0009418014093535021}, {"layer_params": [24, 60, 48], "learning_rate": 0.005930325552223735, "batch_size": 456, "loss": 0.0018263588380068542}, {"layer_params": [30, 48, 37], "learning_rate": 0.0009438137949767327, "batch_size": 111, "loss": 0.005260215932503342}, {"layer_params": [63, 31, 52, 59, 58], "learning_rate": 0.006962526963899088, "batch_size": 454, "loss": 0.0009877479955321179}, {"layer_params": [50, 29, 28], "learning_rate": 0.008438402085514829, "batch_size": 120, "loss": 0.002015138384886086}, {"layer_params": [54, 54], "learning_rate": 0.005140329668334092, "batch_size": 88, "loss": 0.0023489744844846427}, {"layer_params": [24, 52, 41, 33, 27], "learning_rate": 0.008456237615174972, "batch_size": 88, "loss": 0.0035192337282933294}, {"layer_params": [22, 33], "learning_rate": 0.008060642866103829, "batch_size": 336, "loss": 0.002022681243252009}, {"layer_params": [35, 45, 17, 35], "learning_rate": 0.004316285888479497, "batch_size": 467, "loss": 0.0017850675841327756}, {"layer_params": [39, 29, 50, 59, 29], "learning_rate": 0.009004697279734433, "batch_size": 228, "loss": 0.001998628274304792}, {"layer_params": [37, 36, 38, 62], "learning_rate": 0.0053169324621761115, "batch_size": 230, "loss": 0.0028068355051800607}, {"layer_params": [23, 58, 18], "learning_rate": 0.005503309318325626, "batch_size": 260, "loss": 0.0030101142427884043}, {"layer_params": [30, 49, 45], "learning_rate": 0.005515773619607649, "batch_size": 285, "loss": 0.0016821309737861155}, {"layer_params": [42, 29], "learning_rate": 0.005309296882338361, "batch_size": 112, "loss": 0.002821319105569273}, {"layer_params": [45, 33, 42], "learning_rate": 8.95492872504653e-05, "batch_size": 92, "loss": 0.028033390063792466}, {"layer_params": [63, 25], "learning_rate": 0.002165312534918301, "batch_size": 80, "loss": 0.003986708736047149}, {"layer_params": [33, 16, 44, 38], "learning_rate": 0.005279534211928263, "batch_size": 351, "loss": 0.0022721038875170053}, {"layer_params": [45, 59, 49, 41], "learning_rate": 0.007553089122965134, "batch_size": 383, "loss": 0.0012303044815780595}, {"layer_params": [25, 31, 34, 63, 53], "learning_rate": 0.0005515178650587639, "batch_size": 481, "loss": 0.003684821487404406}, {"layer_params": [20, 23, 43, 21], "learning_rate": 0.006490225621898071, "batch_size": 476, "loss": 0.0019670905149541795}, {"layer_params": [59, 42, 43, 40, 23], "learning_rate": 0.005203372191317638, "batch_size": 447, "loss": 0.001847370129544288}, {"layer_params": [26, 57, 36, 32, 54], "learning_rate": 0.0036789653040463, "batch_size": 98, "loss": 0.003059282449539751}, {"layer_params": [36, 60, 53, 32], "learning_rate": 0.007569728008210718, "batch_size": 369, "loss": 0.0011290361621649936}, {"layer_params": [42, 49, 18], "learning_rate": 0.005191721641162093, "batch_size": 420, "loss": 0.0013631123275263234}, {"layer_params": [55, 56], "learning_rate": 0.006529041655486708, "batch_size": 468, "loss": 0.0013717335474211722}, {"layer_params": [55, 51, 57, 18, 20], "learning_rate": 0.0003027086611300649, "batch_size": 207, "loss": 0.005947569608688355}, {"layer_params": [52, 60], "learning_rate": 0.008039758962969932, "batch_size": 151, "loss": 0.0019163799786474556}, {"layer_params": [41, 50, 18], "learning_rate": 0.0034139884289063477, "batch_size": 363, "loss": 0.0028847394278272986}, {"layer_params": [24, 50, 56], "learning_rate": 0.005718113264115765, "batch_size": 132, "loss": 0.0037125121150165794}, {"layer_params": [52, 28], "learning_rate": 0.0009756142966458808, "batch_size": 254, "loss": 0.005583676514215767}, {"layer_params": [36, 30, 30, 42, 23], "learning_rate": 0.008575634726574098, "batch_size": 239, "loss": 0.0023591893375851216}, {"layer_params": [55, 61, 63, 32, 26], "learning_rate": 0.001018842873742364, "batch_size": 303, "loss": 0.0021183531952556223}, {"layer_params": [16, 25, 20], "learning_rate": 0.00017771494889824856, "batch_size": 95, "loss": 0.0193768703751266}, {"layer_params": [29, 17], "learning_rate": 0.005463383428479595, "batch_size": 347, "loss": 0.0050247261347249154}, {"layer_params": [54, 28, 32, 40, 59], "learning_rate": 0.0016801606617471772, "batch_size": 483, "loss": 0.0025315500539727508}, {"layer_params": [26, 29, 48], "learning_rate": 0.008967625881343153, "batch_size": 487, "loss": 0.0018078653491102159}, {"layer_params": [28, 60, 58, 60], "learning_rate": 0.0014086166047787242, "batch_size": 62, "loss": 0.004531070443335921}, {"layer_params": [23, 44, 57, 52, 25], "learning_rate": 0.009999544763407506, "batch_size": 157, "loss": 0.003122768772300333}, {"layer_params": [35, 54, 56, 23, 41], "learning_rate": 0.005843956905278165, "batch_size": 451, "loss": 0.0012564906157786027}, {"layer_params": [41, 61], "learning_rate": 9.158947376215136e-05, "batch_size": 57, "loss": 0.02843264115974307}, {"layer_params": [23, 21], "learning_rate": 0.006245433800468576, "batch_size": 80, "loss": 0.004383661483880133}, {"layer_params": [27, 45, 19], "learning_rate": 0.003835835377899407, "batch_size": 193, "loss": 0.002354546821443364}, {"layer_params": [41, 61, 50, 41, 27], "learning_rate": 0.008057302168794774, "batch_size": 374, "loss": 0.0015155521151609718}, {"layer_params": [18, 57, 49, 49, 42], "learning_rate": 0.0009524511596213218, "batch_size": 118, "loss": 0.004357366145122796}, {"layer_params": [24, 61, 51, 38], "learning_rate": 0.009874186726133495, "batch_size": 86, "loss": 0.0038090184330940246}, {"layer_params": [60, 60, 37, 45], "learning_rate": 0.005370758227560908, "batch_size": 33, "loss": 0.004044703564140946}, {"layer_params": [34, 64, 54, 25, 36], "learning_rate": 0.009563062816057713, "batch_size": 50, "loss": 0.003821614992339164}, {"layer_params": [22, 50, 26, 62], "learning_rate": 0.004746869629023109, "batch_size": 372, "loss": 0.0015824766422156244}, {"layer_params": [39, 43], "learning_rate": 0.004747697032623059, "batch_size": 149, "loss": 0.002592323006829247}, {"layer_params": [48, 37, 63, 24], "learning_rate": 0.004202944656582579, "batch_size": 193, "loss": 0.001325336034060456}, {"layer_params": [42, 42, 33, 51], "learning_rate": 0.0038939530859965726, "batch_size": 487, "loss": 0.0008779911563033239}, {"layer_params": [16, 43, 46, 27], "learning_rate": 0.0026713222004798526, "batch_size": 70, "loss": 0.005788074410520494}, {"layer_params": [16, 44], "learning_rate": 0.00032034948679271453, "batch_size": 24, "loss": 0.030764380600303412}, {"layer_params": [38, 36], "learning_rate": 0.0023442343431737886, "batch_size": 247, "loss": 0.004602432125248015}, {"layer_params": [54, 25, 26, 24, 51], "learning_rate": 0.004418102884190797, "batch_size": 289, "loss": 0.001498975628055632}, {"layer_params": [32, 48, 23, 19, 60], "learning_rate": 0.0021392612003139078, "batch_size": 403, "loss": 0.002489771170075983}, {"layer_params": [23, 48], "learning_rate": 0.00839909006610583, "batch_size": 190, "loss": 0.0032134678098373116}, {"layer_params": [58, 33, 60], "learning_rate": 0.0014940213534753435, "batch_size": 395, "loss": 0.002105737664969638}, {"layer_params": [57, 47], "learning_rate": 0.00793159476502034, "batch_size": 437, "loss": 0.0013311239355243741}, {"layer_params": [42, 46, 61, 58, 27], "learning_rate": 0.0009050529355969099, "batch_size": 284, "loss": 0.0021334943315014245}, {"layer_params": [20, 34], "learning_rate": 0.0025906178693256947, "batch_size": 226, "loss": 0.007368568228557706}, {"layer_params": [24, 60], "learning_rate": 0.0071284679899181235, "batch_size": 373, "loss": 0.002038938992191106}, {"layer_params": [56, 44, 50], "learning_rate": 0.0013142917131740918, "batch_size": 253, "loss": 0.001921185125829652}, {"layer_params": [25, 50, 20, 44], "learning_rate": 0.000572540937119138, "batch_size": 252, "loss": 0.005908790337853134}, {"layer_params": [23, 56, 33, 42], "learning_rate": 0.002172473632348019, "batch_size": 331, "loss": 0.0027751007163897157}, {"layer_params": [40, 42], "learning_rate": 0.0015309636236027996, "batch_size": 338, "loss": 0.004383613632526249}, {"layer_params": [61, 21], "learning_rate": 0.00028776418465583715, "batch_size": 170, "loss": 0.007901978185400367}, {"layer_params": [63, 27, 54], "learning_rate": 0.0033862012626457967, "batch_size": 418, "loss": 0.0016591855010483414}, {"layer_params": [35, 46, 63, 40, 36], "learning_rate": 0.00139909824394287, "batch_size": 61, "loss": 0.005979426871053874}, {"layer_params": [25, 36, 33, 22, 45], "learning_rate": 0.002796468108825151, "batch_size": 497, "loss": 0.001953973196214065}, {"layer_params": [59, 33], "learning_rate": 0.003980677748534074, "batch_size": 373, "loss": 0.0021288934128824624}, {"layer_params": [39, 27, 50, 64, 24], "learning_rate": 0.008468039594058653, "batch_size": 339, "loss": 0.0012856918247416615}, {"layer_params": [40, 51], "learning_rate": 0.0051879647656041744, "batch_size": 114, "loss": 0.002097007515840232}, {"layer_params": [56, 62], "learning_rate": 0.003952604712938287, "batch_size": 31, "loss": 0.006132486457936466}, {"layer_params": [30, 36, 53, 33, 25], "learning_rate": 0.0023007297599913724, "batch_size": 445, "loss": 0.0019575696007814256}, {"layer_params": [59, 21], "learning_rate": 0.0013410495088671543, "batch_size": 438, "loss": 0.004103712299838662}, {"layer_params": [52, 29], "learning_rate": 0.005036187907183014, "batch_size": 448, "loss": 0.0017380179057363422}, {"layer_params": [61, 40, 30, 58], "learning_rate": 0.0054281473354324036, "batch_size": 95, "loss": 0.0027327122376300393}, {"layer_params": [48, 44], "learning_rate": 0.002526914617259372, "batch_size": 456, "loss": 0.001806693241233006}, {"layer_params": [21, 39, 47, 57], "learning_rate": 0.008288008914204425, "batch_size": 110, "loss": 0.002852925502229482}, {"layer_params": [48, 28, 29, 22, 57], "learning_rate": 0.0032218539072662975, "batch_size": 248, "loss": 0.0009093472838867456}, {"layer_params": [59, 51, 56, 27], "learning_rate": 0.001271015236460325, "batch_size": 458, "loss": 0.0016027132852468639}, {"layer_params": [40, 38, 21, 48], "learning_rate": 0.0045839833312813555, "batch_size": 350, "loss": 0.001918971559498459}, {"layer_params": [51, 60], "learning_rate": 0.006168997778584218, "batch_size": 482, "loss": 0.0012239864084403961}, {"layer_params": [56, 39], "learning_rate": 0.004317333355186689, "batch_size": 488, "loss": 0.0014097598451189696}, {"layer_params": [31, 24], "learning_rate": 0.008984088406902586, "batch_size": 362, "loss": 0.005056352976243943}, {"layer_params": [45, 22, 30, 47, 31], "learning_rate": 0.0018953888559488695, "batch_size": 318, "loss": 0.0020860932557843627}, {"layer_params": [50, 27, 23], "learning_rate": 0.007256545023442136, "batch_size": 164, "loss": 0.002658544247969985}, {"layer_params": [37, 63, 25, 47], "learning_rate": 0.005633920597425831, "batch_size": 255, "loss": 0.0013947542780078947}, {"layer_params": [25, 24, 26, 28, 42], "learning_rate": 0.0050435508993870734, "batch_size": 73, "loss": 0.006566118618939072}, {"layer_params": [38, 38], "learning_rate": 0.009227253922715435, "batch_size": 37, "loss": 0.004302265151636675}, {"layer_params": [50, 47], "learning_rate": 0.0016249719568621228, "batch_size": 443, "loss": 0.002552478415891528}, {"layer_params": [19, 54, 28], "learning_rate": 0.0015021663948566783, "batch_size": 102, "loss": 0.0054944699909538035}, {"layer_params": [38, 54], "learning_rate": 0.0055632398536916644, "batch_size": 135, "loss": 0.002132688211277127}, {"layer_params": [18, 31, 62, 41, 17], "learning_rate": 0.004500955241643696, "batch_size": 242, "loss": 0.0029025741876102986}, {"layer_params": [24, 49], "learning_rate": 0.0035249791404836795, "batch_size": 309, "loss": 0.00252463556593284}, {"layer_params": [23, 33, 39, 18, 47], "learning_rate": 0.006092896266210665, "batch_size": 250, "loss": 0.0018181533960159868}, {"layer_params": [37, 57], "learning_rate": 0.009397978711135492, "batch_size": 125, "loss": 0.0023746041988488287}, {"layer_params": [16, 63], "learning_rate": 0.005452588668534062, "batch_size": 118, "loss": 0.003881069445051253}, {"layer_params": [19, 26, 51, 45], "learning_rate": 0.008688094559716511, "batch_size": 324, "loss": 0.002632210128940642}, {"layer_params": [64, 29, 57, 62, 47], "learning_rate": 0.005391185928615015, "batch_size": 156, "loss": 0.0019439337821677326}, {"layer_params": [25, 30, 38], "learning_rate": 0.009908647173339665, "batch_size": 441, "loss": 0.00215563356759958}, {"layer_params": [16, 36, 16], "learning_rate": 0.00845008125012648, "batch_size": 405, "loss": 0.003670673172455281}, {"layer_params": [25, 46, 55, 21, 32], "learning_rate": 0.009706276559379298, "batch_size": 164, "loss": 0.002721707244636491}, {"layer_params": [16, 19, 36], "learning_rate": 0.006160900324673414, "batch_size": 421, "loss": 0.004330286153126508}, {"layer_params": [26, 35], "learning_rate": 0.004910903133767568, "batch_size": 199, "loss": 0.003031413953285664}, {"layer_params": [29, 55, 25], "learning_rate": 0.009278073599164141, "batch_size": 310, "loss": 0.0012873666628729552}, {"layer_params": [23, 36, 56, 57, 46], "learning_rate": 0.002495651786871327, "batch_size": 366, "loss": 0.003025372673291713}, {"layer_params": [63, 37, 33], "learning_rate": 0.004823472206853185, "batch_size": 221, "loss": 0.0009010406711604446}, {"layer_params": [40, 41, 54, 61, 38], "learning_rate": 0.005316808330566998, "batch_size": 422, "loss": 0.0015219298214651643}, {"layer_params": [20, 43, 36, 61, 45], "learning_rate": 0.009369834518121463, "batch_size": 165, "loss": 0.0029639590135775505}, {"layer_params": [47, 51], "learning_rate": 0.0042391619051188895, "batch_size": 35, "loss": 0.006480952955316752}, {"layer_params": [42, 16, 45, 55, 19], "learning_rate": 0.0021038647319210264, "batch_size": 85, "loss": 0.005801422796212137}, {"layer_params": [51, 37, 18], "learning_rate": 7.947708655318064e-05, "batch_size": 281, "loss": 0.03192549400031566}, {"layer_params": [41, 48, 34, 25], "learning_rate": 0.001644395577556153, "batch_size": 245, "loss": 0.0025868766102939843}, {"layer_params": [16, 57], "learning_rate": 0.003973237227755733, "batch_size": 302, "loss": 0.0033946818858385085}, {"layer_params": [56, 32, 27, 54, 58], "learning_rate": 0.00046739199320638324, "batch_size": 496, "loss": 0.004117467966862023}, {"layer_params": [49, 62, 46, 20, 45], "learning_rate": 0.006047684250025336, "batch_size": 434, "loss": 0.0010187891375971958}, {"layer_params": [56, 17, 62, 53], "learning_rate": 0.007949067569742332, "batch_size": 243, "loss": 0.0023206037236377596}, {"layer_params": [24, 61, 45, 52], "learning_rate": 0.004155951134695372, "batch_size": 104, "loss": 0.0030099035950843247}, {"layer_params": [49, 30, 63, 58], "learning_rate": 0.008463496082197482, "batch_size": 207, "loss": 0.001723182196728885}, {"layer_params": [59, 31], "learning_rate": 0.0029152756741342724, "batch_size": 242, "loss": 0.0021838768210727722}, {"layer_params": [23, 52], "learning_rate": 0.004879540238062233, "batch_size": 273, "loss": 0.002586826568003744}, {"layer_params": [64, 50, 45, 37], "learning_rate": 0.007346611567254437, "batch_size": 80, "loss": 0.002990968970116228}, {"layer_params": [57, 46, 42, 16, 21], "learning_rate": 0.009991647430945667, "batch_size": 395, "loss": 0.002192948159063235}, {"layer_params": [44, 51, 26, 28, 16], "learning_rate": 0.006289001479112063, "batch_size": 479, "loss": 0.0015312869928311556}, {"layer_params": [37, 20, 45], "learning_rate": 0.001936704210972431, "batch_size": 477, "loss": 0.0031521797901950775}, {"layer_params": [28, 33, 50, 20], "learning_rate": 0.007907044483886544, "batch_size": 234, "loss": 0.0020750202029012144}, {"layer_params": [56, 34], "learning_rate": 0.004755245528017649, "batch_size": 475, "loss": 0.0021137084322981536}, {"layer_params": [62, 38, 54], "learning_rate": 0.004864764865209537, "batch_size": 194, "loss": 0.001691698000067845}, {"layer_params": [59, 17, 41, 61, 63], "learning_rate": 0.002697344729182038, "batch_size": 512, "loss": 0.0014208635757677257}, {"layer_params": [50, 38, 42], "learning_rate": 0.0007685845488021245, "batch_size": 154, "loss": 0.004174981091637164}, {"layer_params": [44, 62], "learning_rate": 0.005096983989863876, "batch_size": 360, "loss": 0.001404359989101067}, {"layer_params": [19, 43, 64, 54, 21], "learning_rate": 0.006287813081627528, "batch_size": 453, "loss": 0.0020227006229106338}, {"layer_params": [39, 56, 53], "learning_rate": 0.00902343568192903, "batch_size": 167, "loss": 0.0014494952047243714}, {"layer_params": [35, 17, 28], "learning_rate": 0.006717331650712487, "batch_size": 462, "loss": 0.002080521296011284}, {"layer_params": [41, 45, 21, 60], "learning_rate": 4.412386525915656e-05, "batch_size": 484, "loss": 0.034383415672928096}, {"layer_params": [39, 28, 18], "learning_rate": 0.0031383434424482374, "batch_size": 476, "loss": 0.004517284252215177}, {"layer_params": [33, 35, 20], "learning_rate": 0.009537920484140476, "batch_size": 95, "loss": 0.003464350146241486}, {"layer_params": [57, 24, 42, 60, 47], "learning_rate": 0.002684074003021974, "batch_size": 17, "loss": 0.00715122478082776}, {"layer_params": [16, 62, 32], "learning_rate": 0.004934910773803319, "batch_size": 351, "loss": 0.0026903661922551693}, {"layer_params": [48, 43, 38, 33, 21], "learning_rate": 0.006200902969230142, "batch_size": 324, "loss": 0.001349987138528377}, {"layer_params": [31, 28, 34], "learning_rate": 0.00830095266833335, "batch_size": 44, "loss": 0.0064001122466288505}, {"layer_params": [18, 39, 20], "learning_rate": 0.008475469618892307, "batch_size": 230, "loss": 0.005222377288155258}, {"layer_params": [57, 48, 18], "learning_rate": 0.0011305193316379885, "batch_size": 91, "loss": 0.0041206082399003205}, {"layer_params": [64, 46], "learning_rate": 0.0040950343393903734, "batch_size": 183, "loss": 0.0011783657647902147}, {"layer_params": [53, 56, 46, 33, 23], "learning_rate": 0.0032855433893443724, "batch_size": 88, "loss": 0.0019941017287783327}, {"layer_params": [29, 36, 29, 24], "learning_rate": 0.006843389765992847, "batch_size": 152, "loss": 0.0031332332082092762}, {"layer_params": [30, 22, 56], "learning_rate": 0.009629077833918268, "batch_size": 135, "loss": 0.003121495663654059}, {"layer_params": [31, 44, 48, 55, 19], "learning_rate": 0.00397049480532225, "batch_size": 353, "loss": 0.001813684537773952}, {"layer_params": [24, 25, 49, 36, 22], "learning_rate": 0.0012617369116650116, "batch_size": 146, "loss": 0.005180037054233253}, {"layer_params": [58, 19], "learning_rate": 0.008591020668638968, "batch_size": 139, "loss": 0.003806952612940222}, {"layer_params": [42, 26, 47], "learning_rate": 0.004507250365192786, "batch_size": 233, "loss": 0.0022533279610797764}, {"layer_params": [47, 61, 19], "learning_rate": 0.007830662970318154, "batch_size": 441, "loss": 0.0012331571994582192}, {"layer_params": [25, 23], "learning_rate": 0.002729634657316746, "batch_size": 93, "loss": 0.005320632320363074}, {"layer_params": [23, 61, 33, 44], "learning_rate": 0.002655558124698238, "batch_size": 227, "loss": 0.003617597841657698}, {"layer_params": [26, 31, 59, 30, 50], "learning_rate": 0.007669560584141994, "batch_size": 114, "loss": 0.0032892867887858303}, {"layer_params": [26, 57, 51, 22, 23], "learning_rate": 0.0009088792057727148, "batch_size": 146, "loss": 0.004685203863773495}, {"layer_params": [22, 48, 59, 21], "learning_rate": 0.00873798296811322, "batch_size": 288, "loss": 0.0021120783174410464}, {"layer_params": [27, 32, 31, 62], "learning_rate": 0.005906294831678133, "batch_size": 396, "loss": 0.0021622153010685}, {"layer_params": [60, 55, 29], "learning_rate": 0.00023273289169831898, "batch_size": 256, "loss": 0.007096867533400655}, {"layer_params": [26, 19], "learning_rate": 0.009962307696977049, "batch_size": 230, "loss": 0.006380536551587284}, {"layer_params": [18, 17, 39], "learning_rate": 0.00487165596873982, "batch_size": 192, "loss": 0.003876780029386282}, {"layer_params": [47, 37], "learning_rate": 0.003842212415563486, "batch_size": 460, "loss": 0.0015550005028489976}, {"layer_params": [20, 54, 30], "learning_rate": 0.008249162585326002, "batch_size": 173, "loss": 0.003096726352814585}, {"layer_params": [23, 23, 55, 22], "learning_rate": 0.002464216201231491, "batch_size": 146, "loss": 0.0035659469454549252}, {"layer_params": [62, 28, 23, 40, 27], "learning_rate": 0.001457703171709092, "batch_size": 451, "loss": 0.0019346329115796834}, {"layer_params": [31, 57], "learning_rate": 0.006323258518675512, "batch_size": 59, "loss": 0.0029980823036748917}, {"layer_params": [34, 52, 21, 52, 62], "learning_rate": 0.006884703911102986, "batch_size": 102, "loss": 0.0023646712000481786}, {"layer_params": [26, 41, 44], "learning_rate": 0.0015066527713074344, "batch_size": 81, "loss": 0.004725300748832524}, {"layer_params": [35, 52], "learning_rate": 0.0023485792232155055, "batch_size": 432, "loss": 0.0025773060158826413}, {"layer_params": [59, 22, 52, 45, 28], "learning_rate": 0.003047638719529038, "batch_size": 494, "loss": 0.0018455782684031873}, {"layer_params": [34, 25, 43], "learning_rate": 0.0003842076198303673, "batch_size": 70, "loss": 0.008075094199739397}, {"layer_params": [32, 33, 26], "learning_rate": 0.005058717735253757, "batch_size": 171, "loss": 0.0039651703252457085}, {"layer_params": [62, 34, 57], "learning_rate": 0.004521391584152415, "batch_size": 260, "loss": 0.0016199518623761832}, {"layer_params": [28, 44, 21, 23], "learning_rate": 0.006438044197493136, "batch_size": 99, "loss": 0.002951564664253965}, {"layer_params": [17, 45, 46, 21], "learning_rate": 0.0026824563378911813, "batch_size": 125, "loss": 0.005182447114493698}, {"layer_params": [53, 49, 41], "learning_rate": 0.009169635662983658, "batch_size": 209, "loss": 0.0012784967914922162}, {"layer_params": [55, 16, 41, 64, 42], "learning_rate": 0.0016421170542593856, "batch_size": 35, "loss": 0.0066775332321412865}, {"layer_params": [59, 32, 49], "learning_rate": 0.008272540021707275, "batch_size": 412, "loss": 0.00149624609737657}, {"layer_params": [39, 60, 42], "learning_rate": 0.0011551472392003284, "batch_size": 135, "loss": 0.003681668962817639}, {"layer_params": [56, 22, 26, 35, 63], "learning_rate": 0.006593947711370579, "batch_size": 164, "loss": 0.0030054565030150117}, {"layer_params": [16, 34, 44, 16, 46], "learning_rate": 0.0038795787910137695, "batch_size": 430, "loss": 0.0028046559542417525}, {"layer_params": [32, 47, 47, 49, 29], "learning_rate": 0.009832566355825035, "batch_size": 401, "loss": 0.0016317304968833924}, {"layer_params": [63, 25, 33], "learning_rate": 0.007302760916346918, "batch_size": 234, "loss": 0.0025735041964799164}, {"layer_params": [28, 57], "learning_rate": 0.005376299820643472, "batch_size": 494, "loss": 0.0021555592608638106}, {"layer_params": [36, 17], "learning_rate": 0.002493786022871595, "batch_size": 161, "loss": 0.004097006474621594}, {"layer_params": [21, 22, 32, 64, 16], "learning_rate": 0.007486716615625992, "batch_size": 131, "loss": 0.0041356714093126355}, {"layer_params": [36, 39], "learning_rate": 0.005719091877827478, "batch_size": 49, "loss": 0.0048937788209877904}, {"layer_params": [35, 51], "learning_rate": 0.009677287017351537, "batch_size": 34, "loss": 0.004833212422672659}, {"layer_params": [19, 34, 35], "learning_rate": 0.001740843006663267, "batch_size": 373, "loss": 0.005267067169770598}, {"layer_params": [31, 40, 48], "learning_rate": 0.0026864463426606415, "batch_size": 322, "loss": 0.0022071817459072916}, {"layer_params": [21, 44, 29, 17], "learning_rate": 0.006954211570532898, "batch_size": 160, "loss": 0.002006603826303035}, {"layer_params": [56, 52, 20, 50, 34], "learning_rate": 0.0058052725770133965, "batch_size": 458, "loss": 0.0009372438228456303}, {"layer_params": [44, 61, 33, 27], "learning_rate": 0.0038845978915883353, "batch_size": 61, "loss": 0.0027962462371215226}, {"layer_params": [49, 34, 56], "learning_rate": 0.008088354313032127, "batch_size": 161, "loss": 0.0017742408043704928}, {"layer_params": [31, 64, 31, 42], "learning_rate": 0.0048753708635882334, "batch_size": 77, "loss": 0.0027283864549826832}, {"layer_params": [58, 25], "learning_rate": 0.0070695969366824036, "batch_size": 137, "loss": 0.00256304151378572}, {"layer_params": [43, 57, 33, 19, 42], "learning_rate": 0.008669895273500728, "batch_size": 113, "loss": 0.0032865632115863263}, {"layer_params": [42, 39, 63, 50], "learning_rate": 0.008596935300988007, "batch_size": 81, "loss": 0.0032914818567223846}, {"layer_params": [61, 37, 41], "learning_rate": 0.007776067276181448, "batch_size": 177, "loss": 0.0032150821294635533}, {"layer_params": [39, 43, 45, 52, 24], "learning_rate": 0.0008556550743097675, "batch_size": 399, "loss": 0.003978522126562894}, {"layer_params": [16, 28], "learning_rate": 0.0009101735929869465, "batch_size": 480, "loss": 0.00748924174811691}, {"layer_params": [54, 26], "learning_rate": 0.003839400099513896, "batch_size": 111, "loss": 0.003024046889040619}, {"layer_params": [24, 31, 33, 48, 45], "learning_rate": 0.00988272256951715, "batch_size": 399, "loss": 0.002045290309470147}, {"layer_params": [28, 64], "learning_rate": 0.007902778454140315, "batch_size": 464, "loss": 0.002317565500270575}, {"layer_params": [21, 42], "learning_rate": 0.0034236453311365525, "batch_size": 270, "loss": 0.00348107774509117}, {"layer_params": [19, 37, 25], "learning_rate": 0.00788476467470922, "batch_size": 179, "loss": 0.003202749858610332}, {"layer_params": [17, 34, 55, 49, 55], "learning_rate": 0.005106863922962083, "batch_size": 295, "loss": 0.0033796346047893166}, {"layer_params": [26, 33, 23], "learning_rate": 0.00099509436514538, "batch_size": 499, "loss": 0.004201210630126298}, {"layer_params": [41, 22, 54], "learning_rate": 0.004067868276034464, "batch_size": 333, "loss": 0.0029922478483058513}, {"layer_params": [45, 17, 45], "learning_rate": 0.007419254245430039, "batch_size": 147, "loss": 0.0032006190065294506}, {"layer_params": [28, 55, 19, 55, 36], "learning_rate": 0.005102830124053933, "batch_size": 300, "loss": 0.002505594885442406}, {"layer_params": [43, 26, 48, 21, 55], "learning_rate": 0.004002906085684458, "batch_size": 504, "loss": 0.0018022870994172991}, {"layer_params": [59, 51, 63, 53], "learning_rate": 0.004379024892758171, "batch_size": 85, "loss": 0.002522795251570642}, {"layer_params": [62, 64, 25, 19, 43], "learning_rate": 0.003735860409223653, "batch_size": 78, "loss": 0.004656165093183518}, {"layer_params": [25, 30, 34, 50, 23], "learning_rate": 0.003013515320210534, "batch_size": 462, "loss": 0.0024043018813244997}, {"layer_params": [43, 62, 57, 22], "learning_rate": 0.006528392640787927, "batch_size": 416, "loss": 0.0015457715652883054}, {"layer_params": [60, 36, 16, 27], "learning_rate": 0.007226804042336264, "batch_size": 30, "loss": 0.0038965678843669595}, {"layer_params": [48, 19, 34, 31, 32], "learning_rate": 0.0009347819456376981, "batch_size": 22, "loss": 0.0072068696958012875}, {"layer_params": [62, 58], "learning_rate": 0.00501662368395005, "batch_size": 415, "loss": 0.0008050394849851727}, {"layer_params": [48, 17, 54, 20, 29], "learning_rate": 0.003756192555605021, "batch_size": 259, "loss": 0.0023478157678619026}, {"layer_params": [52, 57, 63, 24], "learning_rate": 0.0018547882223646087, "batch_size": 381, "loss": 0.0015851646999362856}, {"layer_params": [49, 63, 30], "learning_rate": 0.009858678492904175, "batch_size": 315, "loss": 0.0009357993304729462}, {"layer_params": [52, 16, 21, 52], "learning_rate": 0.009542017822243568, "batch_size": 183, "loss": 0.0024982737738173453}, {"layer_params": [17, 32, 47], "learning_rate": 0.003928803106788612, "batch_size": 232, "loss": 0.00412272113841027}, {"layer_params": [45, 31, 58], "learning_rate": 0.0005548163257142803, "batch_size": 157, "loss": 0.00635903051123023}, {"layer_params": [17, 35, 24], "learning_rate": 0.006442537113302844, "batch_size": 328, "loss": 0.002460744674317539}, {"layer_params": [42, 59, 38, 44], "learning_rate": 0.006096686103735402, "batch_size": 462, "loss": 0.0011253751878393815}, {"layer_params": [17, 17, 53], "learning_rate": 0.009355671007624338, "batch_size": 227, "loss": 0.00430563808651641}, {"layer_params": [56, 47, 23, 46, 18], "learning_rate": 0.00855931153812815, "batch_size": 495, "loss": 0.002248772056773305}, {"layer_params": [24, 25], "learning_rate": 0.0021481495475519363, "batch_size": 238, "loss": 0.006150109609588981}, {"layer_params": [24, 51, 33, 44], "learning_rate": 0.0053643485540213615, "batch_size": 90, "loss": 0.004256154103204608}, {"layer_params": [38, 33, 47, 40], "learning_rate": 0.0013370873746581242, "batch_size": 260, "loss": 0.003225174583494663}, {"layer_params": [18, 42], "learning_rate": 0.003857761729448611, "batch_size": 127, "loss": 0.0041147861955687405}, {"layer_params": [27, 55, 61, 29, 20], "learning_rate": 0.008231316286251266, "batch_size": 290, "loss": 0.0016348617849871517}, {"layer_params": [63, 48, 48, 18], "learning_rate": 0.006366914488510032, "batch_size": 364, "loss": 0.0011446539050666616}, {"layer_params": [29, 47, 50, 63, 47], "learning_rate": 0.009065584956899755, "batch_size": 384, "loss": 0.0009983309818198905}, {"layer_params": [49, 63, 50, 22], "learning_rate": 0.0065113331779839394, "batch_size": 392, "loss": 0.000726523088524118}, {"layer_params": [52, 60, 39], "learning_rate": 0.00029170888764872124, "batch_size": 48, "loss": 0.007780577433295548}, {"layer_params": [48, 58, 53, 21, 40], "learning_rate": 0.007466126139455597, "batch_size": 139, "loss": 0.0013377019809558987}, {"layer_params": [52, 23, 52], "learning_rate": 0.003781761200310006, "batch_size": 92, "loss": 0.004918193956837058}, {"layer_params": [62, 25, 56, 24, 20], "learning_rate": 0.007689421516727875, "batch_size": 419, "loss": 0.0009933547128457576}, {"layer_params": [50, 38, 21], "learning_rate": 0.005681958036890555, "batch_size": 512, "loss": 0.001669192840345204}, {"layer_params": [64, 35], "learning_rate": 0.0075812792349284515, "batch_size": 463, "loss": 0.0017339266673661769}, {"layer_params": [21, 22, 56], "learning_rate": 0.0029062378693934057, "batch_size": 337, "loss": 0.00514289568644017}, {"layer_params": [41, 53], "learning_rate": 0.00249748879033101, "batch_size": 30, "loss": 0.0067216728045605125}, {"layer_params": [59, 22, 55, 45], "learning_rate": 0.009106949182952274, "batch_size": 486, "loss": 0.0019991256284993143}, {"layer_params": [25, 42, 26], "learning_rate": 0.009504228565817152, "batch_size": 394, "loss": 0.0015580326679628343}, {"layer_params": [49, 58], "learning_rate": 0.004422435805148522, "batch_size": 241, "loss": 0.0018076708214357494}, {"layer_params": [62, 31, 54, 51, 42], "learning_rate": 0.008021689013712937, "batch_size": 109, "loss": 0.0030960542347747834}, {"layer_params": [55, 21, 41], "learning_rate": 0.008439442661506601, "batch_size": 297, "loss": 0.001511220580432564}, {"layer_params": [33, 47], "learning_rate": 0.009920311193393446, "batch_size": 270, "loss": 0.0019336625200230629}, {"layer_params": [57, 43], "learning_rate": 0.0006601473417973424, "batch_size": 319, "loss": 0.00540872298181057}, {"layer_params": [37, 29, 26, 54, 20], "learning_rate": 0.007936014692724843, "batch_size": 285, "loss": 0.003280448887962848}, {"layer_params": [19, 54, 60], "learning_rate": 0.00035343915615288136, "batch_size": 351, "loss": 0.00769122046418488}, {"layer_params": [31, 35, 55], "learning_rate": 0.006606737481741211, "batch_size": 462, "loss": 0.0023095599934458734}, {"layer_params": [16, 44, 64], "learning_rate": 0.007040433149493835, "batch_size": 508, "loss": 0.00268215618096292}, {"layer_params": [46, 42, 18, 20, 33], "learning_rate": 0.006377103546349779, "batch_size": 150, "loss": 0.002300542751327157}, {"layer_params": [33, 55], "learning_rate": 0.0036686621000024504, "batch_size": 142, "loss": 0.003037572305183858}, {"layer_params": [43, 61, 32], "learning_rate": 0.007154249490995044, "batch_size": 385, "loss": 0.0010589064069790766}, {"layer_params": [38, 20, 61, 18, 40], "learning_rate": 0.0005515213300282085, "batch_size": 111, "loss": 0.007107119294814766}, {"layer_params": [26, 23], "learning_rate": 0.009373894310675545, "batch_size": 239, "loss": 0.002242821103427559}, {"layer_params": [52, 16, 41, 32, 22], "learning_rate": 0.008080404687971563, "batch_size": 336, "loss": 0.000999502159538679}, {"layer_params": [30, 55, 52, 21], "learning_rate": 0.0010625316910600753, "batch_size": 453, "loss": 0.0027976070228032768}, {"layer_params": [41, 36, 61, 41, 39], "learning_rate": 0.009310401237204778, "batch_size": 369, "loss": 0.0026843620883300902}, {"layer_params": [64, 39, 53], "learning_rate": 0.006649733498229186, "batch_size": 433, "loss": 0.0025673486897721887}, {"layer_params": [31, 59, 59, 55, 55], "learning_rate": 0.002640226723759197, "batch_size": 200, "loss": 0.0017177205835469068}, {"layer_params": [21, 21], "learning_rate": 0.008034578181914196, "batch_size": 439, "loss": 0.003067727054003626}, {"layer_params": [20, 21], "learning_rate": 0.003208255180157479, "batch_size": 275, "loss": 0.0073181088967248795}, {"layer_params": [38, 48, 37], "learning_rate": 0.00877786129656626, "batch_size": 357, "loss": 0.002287889103172347}, {"layer_params": [62, 34], "learning_rate": 0.003187376584425683, "batch_size": 345, "loss": 0.0025719026662409305}, {"layer_params": [37, 35], "learning_rate": 0.002899027088678274, "batch_size": 452, "loss": 0.0024221629067324103}, {"layer_params": [29, 51], "learning_rate": 0.0012947785196516428, "batch_size": 184, "loss": 0.005211127810180187}, {"layer_params": [37, 48], "learning_rate": 0.0088079188929249, "batch_size": 446, "loss": 0.0010412552073830739}, {"layer_params": [22, 36, 55, 43, 54], "learning_rate": 0.009848078716011809, "batch_size": 347, "loss": 0.0027517715166322887}, {"layer_params": [23, 63, 31, 50], "learning_rate": 0.006820262457469499, "batch_size": 335, "loss": 0.001660174772841856}, {"layer_params": [34, 29], "learning_rate": 0.006834429342352767, "batch_size": 135, "loss": 0.003042710709851235}, {"layer_params": [60, 52, 49, 40, 43], "learning_rate": 0.0050789357793378604, "batch_size": 193, "loss": 0.0009724473051028326}, {"layer_params": [59, 55, 53, 46, 35], "learning_rate": 0.005300419061978904, "batch_size": 117, "loss": 0.0015839147462975234}, {"layer_params": [23, 18, 33], "learning_rate": 0.006907444115739283, "batch_size": 210, "loss": 0.005312152029946446}, {"layer_params": [50, 16, 59, 44, 25], "learning_rate": 0.0031022300902410183, "batch_size": 364, "loss": 0.0020036564720794557}, {"layer_params": [55, 42, 52, 55, 48], "learning_rate": 0.00785595503667923, "batch_size": 289, "loss": 0.0010937617428135127}, {"layer_params": [24, 25, 58, 48, 35], "learning_rate": 0.009119971603082451, "batch_size": 414, "loss": 0.0023406837147194894}, {"layer_params": [52, 50, 33, 61, 54], "learning_rate": 0.007515770724926464, "batch_size": 291, "loss": 0.001030159309739247}, {"layer_params": [57, 35, 50], "learning_rate": 0.004429816536583655, "batch_size": 145, "loss": 0.001800257930299267}, {"layer_params": [19, 17, 25], "learning_rate": 0.007895025561367093, "batch_size": 319, "loss": 0.0029324056394398213}, {"layer_params": [34, 35, 58, 50, 54], "learning_rate": 0.006691371731985022, "batch_size": 511, "loss": 0.0013949924323242158}, {"layer_params": [27, 21, 51, 49], "learning_rate": 0.00023695751363526983, "batch_size": 68, "loss": 0.009997065099887549}, {"layer_params": [21, 29], "learning_rate": 0.0089679212066148, "batch_size": 105, "loss": 0.0052769985469058155}, {"layer_params": [30, 44, 50, 39], "learning_rate": 0.008037352456008144, "batch_size": 108, "loss": 0.0022500060137826947}, {"layer_params": [42, 64], "learning_rate": 0.007269558293035588, "batch_size": 333, "loss": 0.0014965529460459947}, {"layer_params": [62, 18, 48], "learning_rate": 0.005965312382994103, "batch_size": 212, "loss": 0.0026307047810405493}, {"layer_params": [31, 38, 63], "learning_rate": 0.004190830288812612, "batch_size": 32, "loss": 0.0048701439099386335}, {"layer_params": [61, 63, 57, 53], "learning_rate": 0.006063664330691602, "batch_size": 360, "loss": 0.0009736239042831585}, {"layer_params": [35, 35, 64], "learning_rate": 0.007173509370066751, "batch_size": 444, "loss": 0.001076335952966474}, {"layer_params": [35, 46, 31, 31, 45], "learning_rate": 0.004827692275871858, "batch_size": 260, "loss": 0.0017299309943336993}, {"layer_params": [51, 26, 60, 63, 28], "learning_rate": 0.00663849386403463, "batch_size": 307, "loss": 0.0013098435796564446}, {"layer_params": [59, 19], "learning_rate": 0.005122599752279353, "batch_size": 501, "loss": 0.0026090672821737827}, {"layer_params": [42, 60, 22], "learning_rate": 0.005758261361795669, "batch_size": 278, "loss": 0.0013838634570129216}, {"layer_params": [37, 59], "learning_rate": 0.00012527532260226068, "batch_size": 71, "loss": 0.0247363699413836}, {"layer_params": [53, 16, 22, 60], "learning_rate": 0.00982348812092142, "batch_size": 467, "loss": 0.001124894653330557}, {"layer_params": [18, 24], "learning_rate": 0.005240051854452755, "batch_size": 272, "loss": 0.004836538718082011}, {"layer_params": [46, 59], "learning_rate": 0.007295479780592377, "batch_size": 347, "loss": 0.0010845013859216125}, {"layer_params": [18, 52, 23], "learning_rate": 0.008104630487734231, "batch_size": 475, "loss": 0.004604397132061422}, {"layer_params": [58, 58, 31, 62], "learning_rate": 0.004284318823921363, "batch_size": 290, "loss": 0.0012171715282602235}, {"layer_params": [33, 26, 61, 42, 61], "learning_rate": 0.004185446236655632, "batch_size": 50, "loss": 0.004624979875516146}, {"layer_params": [63, 55, 17, 16], "learning_rate": 0.007169888280970439, "batch_size": 329, "loss": 0.000783304629730992}, {"layer_params": [26, 48, 36, 19, 50], "learning_rate": 0.001405506717902572, "batch_size": 24, "loss": 0.008001196726690979}, {"layer_params": [21, 32, 55], "learning_rate": 0.0032811375181177947, "batch_size": 266, "loss": 0.002364693492418155}, {"layer_params": [23, 50, 61], "learning_rate": 0.0008800293361122676, "batch_size": 139, "loss": 0.005683862552978099}, {"layer_params": [22, 17, 45, 42, 22], "learning_rate": 0.006499903656531572, "batch_size": 293, "loss": 0.003121204450726509}, {"layer_params": [63, 49], "learning_rate": 0.0075843217203382055, "batch_size": 277, "loss": 0.00128748620278202}, {"layer_params": [57, 22, 49, 44, 60], "learning_rate": 0.0017049739196206815, "batch_size": 82, "loss": 0.003325186602305621}, {"layer_params": [34, 45, 31], "learning_rate": 0.00890636595320854, "batch_size": 66, "loss": 0.0031529627984855325}, {"layer_params": [44, 36, 42, 60], "learning_rate": 0.003866638270519352, "batch_size": 454, "loss": 0.0020928501640446484}, {"layer_params": [26, 54, 42, 21, 28], "learning_rate": 0.006816159347807155, "batch_size": 346, "loss": 0.002266899637179449}, {"layer_params": [64, 25], "learning_rate": 0.007206723698398959, "batch_size": 499, "loss": 0.0019449002167675645}, {"layer_params": [38, 60], "learning_rate": 0.008223666718912068, "batch_size": 366, "loss": 0.0015705652988981455}, {"layer_params": [30, 63, 45], "learning_rate": 0.003754650035741799, "batch_size": 130, "loss": 0.0027539787034038454}, {"layer_params": [31, 55], "learning_rate": 0.009818413666775822, "batch_size": 223, "loss": 0.0019223298912402242}, {"layer_params": [31, 25], "learning_rate": 0.005356704629745378, "batch_size": 200, "loss": 0.0025843842700123787}, {"layer_params": [28, 64, 40, 60, 25], "learning_rate": 0.002784174380083801, "batch_size": 404, "loss": 0.0014806824119295925}, {"layer_params": [21, 20], "learning_rate": 0.0068156202175969705, "batch_size": 96, "loss": 0.003128608320839703}, {"layer_params": [31, 49, 43, 61, 59], "learning_rate": 0.003264810022010709, "batch_size": 503, "loss": 0.0008185015973867848}, {"layer_params": [20, 17], "learning_rate": 0.002528544800472917, "batch_size": 17, "loss": 0.008210242323111743}, {"layer_params": [58, 26], "learning_rate": 0.00686324239359643, "batch_size": 235, "loss": 0.002542791082523763}, {"layer_params": [24, 44, 63, 46], "learning_rate": 0.004815025452475301, "batch_size": 23, "loss": 0.004872626236174255}, {"layer_params": [39, 20, 36, 43], "learning_rate": 0.001358683369998249, "batch_size": 113, "loss": 0.0049446329567581415}, {"layer_params": [60, 36, 41, 61, 25], "learning_rate": 0.009014622592543837, "batch_size": 445, "loss": 0.0013440060627181083}, {"layer_params": [20, 35], "learning_rate": 0.000245912870814441, "batch_size": 321, "loss": 0.02587491074576974}, {"layer_params": [50, 36, 24], "learning_rate": 0.0041223357105628555, "batch_size": 362, "loss": 0.0014071538869757205}, {"layer_params": [17, 32], "learning_rate": 0.009920026011047946, "batch_size": 20, "loss": 0.007674563121981919}, {"layer_params": [18, 18, 63, 32], "learning_rate": 0.00562386330518022, "batch_size": 334, "loss": 0.0022947135067079216}, {"layer_params": [40, 16, 28, 32, 35], "learning_rate": 0.00861125568625168, "batch_size": 173, "loss": 0.007205446856096387}, {"layer_params": [58, 61], "learning_rate": 0.007214680279470301, "batch_size": 338, "loss": 0.001472983779385686}, {"layer_params": [24, 61, 44, 52], "learning_rate": 0.005538621926634585, "batch_size": 178, "loss": 0.002165304678492248}, {"layer_params": [23, 18, 44], "learning_rate": 0.003331426551901111, "batch_size": 326, "loss": 0.005514867939054966}, {"layer_params": [61, 37], "learning_rate": 0.0015523924091217322, "batch_size": 17, "loss": 0.007299717969726771}, {"layer_params": [46, 24, 23, 19], "learning_rate": 0.007551839138340117, "batch_size": 79, "loss": 0.00261215912993066}, {"layer_params": [35, 41, 22], "learning_rate": 0.007396281575734952, "batch_size": 202, "loss": 0.0010222045355476439}, {"layer_params": [24, 45, 26], "learning_rate": 0.0031285653326111125, "batch_size": 212, "loss": 0.0037650389689952136}, {"layer_params": [53, 22, 35], "learning_rate": 0.0017319352556631838, "batch_size": 384, "loss": 0.001416954294545576}, {"layer_params": [33, 41, 28], "learning_rate": 0.006165125757390223, "batch_size": 306, "loss": 0.0032117031421512367}, {"layer_params": [34, 48], "learning_rate": 0.00334762643249214, "batch_size": 25, "loss": 0.005701897947583348}, {"layer_params": [47, 52, 58, 24, 37], "learning_rate": 0.0022620928108280647, "batch_size": 377, "loss": 0.0016679136536549776}, {"layer_params": [21, 37, 55, 23], "learning_rate": 0.0003019068813477678, "batch_size": 361, "loss": 0.007082125307060778}, {"layer_params": [49, 29, 17, 55], "learning_rate": 0.005343035650673838, "batch_size": 84, "loss": 0.003989897044375539}, {"layer_params": [26, 49, 33], "learning_rate": 0.00463454624859452, "batch_size": 57, "loss": 0.0033379939757287504}, {"layer_params": [22, 46, 34], "learning_rate": 0.008683517757028733, "batch_size": 133, "loss": 0.002878802358172834}, {"layer_params": [34, 16, 36], "learning_rate": 0.00765694514026367, "batch_size": 489, "loss": 0.002531691852491349}, {"layer_params": [27, 60, 35], "learning_rate": 0.008496834667221302, "batch_size": 282, "loss": 0.0019567956519313157}, {"layer_params": [34, 55, 59, 40], "learning_rate": 0.0030300522608575887, "batch_size": 425, "loss": 0.0010625539592001587}, {"layer_params": [33, 63, 56], "learning_rate": 0.009772818155808381, "batch_size": 105, "loss": 0.0022819027199875563}, {"layer_params": [55, 55, 38, 48, 52], "learning_rate": 0.0037734113656716175, "batch_size": 407, "loss": 0.0011446124111535027}, {"layer_params": [39, 18, 51], "learning_rate": 0.009266195814640353, "batch_size": 488, "loss": 0.0018959251220803707}, {"layer_params": [62, 17], "learning_rate": 0.0008649437893398674, "batch_size": 351, "loss": 0.005956539162434637}, {"layer_params": [18, 25, 23], "learning_rate": 0.0031413187036693343, "batch_size": 124, "loss": 0.005256062971893698}, {"layer_params": [33, 64, 47, 39], "learning_rate": 0.005301745491437246, "batch_size": 185, "loss": 0.0013902414182666689}, {"layer_params": [61, 17, 57, 32, 35], "learning_rate": 0.0041018899441019685, "batch_size": 438, "loss": 0.002991762573365122}, {"layer_params": [31, 30], "learning_rate": 0.0012794100569224415, "batch_size": 181, "loss": 0.00698228704277426}, {"layer_params": [58, 40, 55, 28, 58], "learning_rate": 0.00862487860165637, "batch_size": 160, "loss": 0.0015628150047268718}, {"layer_params": [54, 36, 53, 18], "learning_rate": 0.0006761657538072195, "batch_size": 82, "loss": 0.005315576693974435}, {"layer_params": [17, 46, 22], "learning_rate": 0.006151232797557899, "batch_size": 297, "loss": 0.002739514117129147}, {"layer_params": [23, 43, 50, 46], "learning_rate": 0.001091068856271461, "batch_size": 41, "loss": 0.006289394660852849}, {"layer_params": [63, 19, 47, 47, 59], "learning_rate": 0.007833686729371438, "batch_size": 237, "loss": 0.0011771646194392816}, {"layer_params": [60, 22, 21, 22, 60], "learning_rate": 0.0012929408681225626, "batch_size": 493, "loss": 0.002010327362222597}, {"layer_params": [52, 63, 41], "learning_rate": 0.0018459232884916988, "batch_size": 209, "loss": 0.0019480913341976703}, {"layer_params": [39, 39, 57, 46, 63], "learning_rate": 0.009579741027307246, "batch_size": 162, "loss": 0.0029371252655982973}, {"layer_params": [54, 52, 56], "learning_rate": 0.0011361416928681127, "batch_size": 469, "loss": 0.001920878334203735}, {"layer_params": [42, 36, 62, 52, 33], "learning_rate": 0.009542018506660985, "batch_size": 388, "loss": 0.0009170995035674423}, {"layer_params": [54, 33, 55], "learning_rate": 0.005534789311806843, "batch_size": 436, "loss": 0.002448135253507644}, {"layer_params": [62, 36], "learning_rate": 0.009828280388540443, "batch_size": 105, "loss": 0.002066051468718797}, {"layer_params": [48, 58, 40, 34, 21], "learning_rate": 0.002162460548437861, "batch_size": 407, "loss": 0.0017100566870067268}, {"layer_params": [39, 64, 63], "learning_rate": 0.006409728023083629, "batch_size": 236, "loss": 0.0015328009764198215}, {"layer_params": [59, 31, 53, 37, 45], "learning_rate": 0.008805662650621094, "batch_size": 157, "loss": 0.0009893570124404505}, {"layer_params": [27, 20], "learning_rate": 0.009199300766418339, "batch_size": 221, "loss": 0.002805698316078633}, {"layer_params": [44, 21, 56, 60], "learning_rate": 0.007487080513310554, "batch_size": 299, "loss": 0.0013757182599510997}, {"layer_params": [33, 21, 42], "learning_rate": 0.0008660133208691526, "batch_size": 81, "loss": 0.006534079546108842}, {"layer_params": [64, 34, 48, 28, 54], "learning_rate": 0.008237695254907501, "batch_size": 292, "loss": 0.0015972801763564348}, {"layer_params": [38, 55], "learning_rate": 0.008551433513579116, "batch_size": 306, "loss": 0.001332048434414901}, {"layer_params": [42, 64], "learning_rate": 0.00296504599360891, "batch_size": 427, "loss": 0.001318894575815648}, {"layer_params": [26, 42], "learning_rate": 0.0071577894290241134, "batch_size": 422, "loss": 0.0018618616159074008}, {"layer_params": [61, 63], "learning_rate": 0.006289075923140321, "batch_size": 348, "loss": 0.0010662059427704663}, {"layer_params": [44, 29, 45], "learning_rate": 0.0012106489605716564, "batch_size": 447, "loss": 0.002993333712220192}, {"layer_params": [24, 54, 44, 27, 29], "learning_rate": 0.00059450412712619, "batch_size": 451, "loss": 0.0029216945334337653}, {"layer_params": [56, 28, 29, 52], "learning_rate": 0.008710939998355422, "batch_size": 320, "loss": 0.0009097614022903145}, {"layer_params": [51, 51, 18, 19], "learning_rate": 0.007718310281706715, "batch_size": 508, "loss": 0.0007104661699850112}, {"layer_params": [39, 49, 48, 62, 19], "learning_rate": 0.005871936275981661, "batch_size": 445, "loss": 0.001171385242487304}, {"layer_params": [33, 58, 59, 43, 56], "learning_rate": 0.009153799952865868, "batch_size": 191, "loss": 0.0015454942651558668}, {"layer_params": [52, 24, 46, 54, 25], "learning_rate": 0.000804819409957258, "batch_size": 319, "loss": 0.0037457617255859076}, {"layer_params": [24, 31, 19], "learning_rate": 0.008620982686245598, "batch_size": 466, "loss": 0.002775774660985917}, {"layer_params": [22, 24, 55], "learning_rate": 0.00013182364380749436, "batch_size": 172, "loss": 0.021786054354161023}, {"layer_params": [59, 22, 33, 20], "learning_rate": 0.009787652161169502, "batch_size": 72, "loss": 0.002553677251562476}, {"layer_params": [61, 43, 35, 21], "learning_rate": 0.0007798948181446617, "batch_size": 434, "loss": 0.0021971140161622317}, {"layer_params": [61, 24, 51, 49], "learning_rate": 0.00033437252663066306, "batch_size": 399, "loss": 0.005957808932289481}, {"layer_params": [26, 38, 55, 60], "learning_rate": 0.0018356940790706755, "batch_size": 431, "loss": 0.0021922378556337207}, {"layer_params": [55, 31, 62], "learning_rate": 0.007964977753673086, "batch_size": 233, "loss": 0.0009083788224961609}, {"layer_params": [33, 54, 42, 23, 26], "learning_rate": 0.0038245473432268703, "batch_size": 242, "loss": 0.0022431069368030877}, {"layer_params": [25, 19, 51, 27], "learning_rate": 0.000877106812275524, "batch_size": 409, "loss": 0.0051709632994607095}, {"layer_params": [44, 16, 18, 60], "learning_rate": 0.004164515604701085, "batch_size": 95, "loss": 0.004045472950674593}, {"layer_params": [16, 16, 36, 17], "learning_rate": 0.007644110861200389, "batch_size": 307, "loss": 0.0052123871026560666}, {"layer_params": [16, 25, 38], "learning_rate": 0.004239421771616588, "batch_size": 88, "loss": 0.006751540102995932}, {"layer_params": [16, 55, 20], "learning_rate": 0.003025747276514865, "batch_size": 404, "loss": 0.00222406143322587}, {"layer_params": [24, 43], "learning_rate": 0.006171192740417102, "batch_size": 112, "loss": 0.003131446313345805}, {"layer_params": [44, 26], "learning_rate": 0.0011044503632026308, "batch_size": 201, "loss": 0.006013632174581289}, {"layer_params": [53, 18, 18, 61], "learning_rate": 0.008106869526533689, "batch_size": 237, "loss": 0.0013940260943491013}, {"layer_params": [43, 46, 21], "learning_rate": 0.0005354808987459998, "batch_size": 254, "loss": 0.006212356127798557}, {"layer_params": [57, 38], "learning_rate": 0.005513644732097594, "batch_size": 280, "loss": 0.0014401355537120254}, {"layer_params": [27, 35, 63], "learning_rate": 0.0019293180202211188, "batch_size": 66, "loss": 0.004477646176237613}, {"layer_params": [24, 46], "learning_rate": 0.006098420192428032, "batch_size": 321, "loss": 0.003609086775686592}, {"layer_params": [53, 58, 26], "learning_rate": 0.008002084562524834, "batch_size": 250, "loss": 0.0010803668055450544}, {"layer_params": [19, 58, 31], "learning_rate": 0.00021615840284972568, "batch_size": 72, "loss": 0.015939191645011307}, {"layer_params": [41, 53, 43, 33, 23], "learning_rate": 0.003987951823024928, "batch_size": 490, "loss": 0.0013698834064416587}, {"layer_params": [48, 56, 44, 52, 22], "learning_rate": 0.00781067324756461, "batch_size": 185, "loss": 0.0014065997547004373}, {"layer_params": [43, 64, 51, 19, 42], "learning_rate": 0.008039581691197646, "batch_size": 113, "loss": 0.002579839932732284}, {"layer_params": [30, 41, 53, 59], "learning_rate": 0.00019874180432165816, "batch_size": 160, "loss": 0.008703117803670467}, {"layer_params": [47, 22], "learning_rate": 0.006528539575257066, "batch_size": 435, "loss": 0.002970494243782014}, {"layer_params": [39, 22], "learning_rate": 0.005112669844513761, "batch_size": 419, "loss": 0.0023026333865709602}, {"layer_params": [26, 64, 64], "learning_rate": 0.00838238970455462, "batch_size": 402, "loss": 0.0020176023279782386}, {"layer_params": [22, 20, 58, 61], "learning_rate": 0.006482049015179443, "batch_size": 231, "loss": 0.0030897069163620472}, {"layer_params": [35, 34, 47, 53, 43], "learning_rate": 0.009391245501433637, "batch_size": 147, "loss": 0.0028481021488551053}, {"layer_params": [52, 52, 46], "learning_rate": 0.0016505641031535005, "batch_size": 36, "loss": 0.004167005359195172}, {"layer_params": [59, 31], "learning_rate": 0.008980617533268166, "batch_size": 456, "loss": 0.0014072457887232303}, {"layer_params": [30, 23, 31, 28], "learning_rate": 0.0034789300015947316, "batch_size": 485, "loss": 0.0023173305904492735}, {"layer_params": [16, 41, 21, 33, 58], "learning_rate": 0.004419995626176309, "batch_size": 366, "loss": 0.003613575629424304}, {"layer_params": [28, 19], "learning_rate": 0.0028074314607991987, "batch_size": 479, "loss": 0.002977434874046594}, {"layer_params": [42, 27, 18, 19, 16], "learning_rate": 0.004461201799183729, "batch_size": 356, "loss": 0.0023907520703505725}, {"layer_params": [63, 30, 32, 22], "learning_rate": 0.008243946582998405, "batch_size": 72, "loss": 0.0036042699276003986}, {"layer_params": [22, 51, 54, 63], "learning_rate": 0.004018519440712199, "batch_size": 424, "loss": 0.0013962371984962375}, {"layer_params": [32, 54, 19, 52], "learning_rate": 0.003559796870651906, "batch_size": 480, "loss": 0.0014765605377033352}, {"layer_params": [20, 47, 34], "learning_rate": 0.008035825647290488, "batch_size": 76, "loss": 0.004655886732507497}, {"layer_params": [18, 50, 62, 63, 43], "learning_rate": 0.000179599467932475, "batch_size": 217, "loss": 0.008858965104445815}, {"layer_params": [25, 21, 56], "learning_rate": 0.00806469148163829, "batch_size": 247, "loss": 0.00444792477414012}, {"layer_params": [24, 35], "learning_rate": 0.007670828578417689, "batch_size": 82, "loss": 0.003364769567269832}, {"layer_params": [35, 49, 60, 39], "learning_rate": 0.00636050105870128, "batch_size": 190, "loss": 0.0015813182888086885}, {"layer_params": [42, 48], "learning_rate": 0.009091607238082666, "batch_size": 39, "loss": 0.003193355828989297}, {"layer_params": [17, 21], "learning_rate": 0.009148281328175054, "batch_size": 402, "loss": 0.0037708130432292817}, {"layer_params": [20, 46, 36, 52, 44], "learning_rate": 0.009612800822520704, "batch_size": 267, "loss": 0.0023776257294230163}, {"layer_params": [31, 35, 39, 49], "learning_rate": 0.0026222956424358903, "batch_size": 314, "loss": 0.0022324000403750686}, {"layer_params": [31, 44], "learning_rate": 0.008183680571008042, "batch_size": 296, "loss": 0.001592005299171433}, {"layer_params": [24, 61], "learning_rate": 0.006131010031475779, "batch_size": 319, "loss": 0.001855971502372995}, {"layer_params": [55, 63], "learning_rate": 0.002671290256988378, "batch_size": 217, "loss": 0.0023162335401866584}, {"layer_params": [21, 31, 52, 43], "learning_rate": 0.0039010523552624756, "batch_size": 60, "loss": 0.006714634192176164}, {"layer_params": [26, 53], "learning_rate": 0.0033512967859884585, "batch_size": 61, "loss": 0.00403727438300848}, {"layer_params": [47, 45], "learning_rate": 1.08716973594605e-05, "batch_size": 125, "loss": 0.07246526017785072}, {"layer_params": [57, 39, 48], "learning_rate": 0.007533464666487733, "batch_size": 304, "loss": 0.0013138550554867834}, {"layer_params": [18, 27, 16, 63], "learning_rate": 0.0017778987881649155, "batch_size": 469, "loss": 0.005972676556557417}, {"layer_params": [27, 32, 55], "learning_rate": 0.0007371604694747265, "batch_size": 267, "loss": 0.005188487770501524}, {"layer_params": [64, 17, 30, 60, 32], "learning_rate": 0.009870419407717998, "batch_size": 196, "loss": 0.004092868263833225}, {"layer_params": [46, 17], "learning_rate": 0.006002049939339522, "batch_size": 70, "loss": 0.004783852081745863}, {"layer_params": [43, 62, 16, 61, 49], "learning_rate": 0.008511842744544003, "batch_size": 207, "loss": 0.001764220466138795}, {"layer_params": [23, 50], "learning_rate": 0.004672935695036149, "batch_size": 117, "loss": 0.0031569974846206604}, {"layer_params": [58, 22], "learning_rate": 0.0049774122442885, "batch_size": 249, "loss": 0.002526628146879375}, {"layer_params": [34, 58, 37], "learning_rate": 0.0036608582258898354, "batch_size": 383, "loss": 0.0011840752308489755}, {"layer_params": [59, 44, 35], "learning_rate": 0.0075907706524957885, "batch_size": 483, "loss": 0.0009565409034257755}, {"layer_params": [49, 44, 59, 27], "learning_rate": 0.006711255702231197, "batch_size": 400, "loss": 0.0016468995669856668}, {"layer_params": [41, 29, 35, 42, 55], "learning_rate": 0.00779892833017183, "batch_size": 296, "loss": 0.0017033454054035245}, {"layer_params": [58, 33, 57], "learning_rate": 0.0007858713896061775, "batch_size": 33, "loss": 0.0061807035538367925}, {"layer_params": [60, 35, 32], "learning_rate": 0.005542724344747672, "batch_size": 484, "loss": 0.0014540984842460602}, {"layer_params": [62, 25], "learning_rate": 0.005707632152192375, "batch_size": 427, "loss": 0.0029717040760442615}, {"layer_params": [42, 54], "learning_rate": 0.001925095936085237, "batch_size": 22, "loss": 0.0076571783144027}, {"layer_params": [61, 57, 43, 33, 33], "learning_rate": 0.002648701711147636, "batch_size": 478, "loss": 0.0008957488212035969}, {"layer_params": [25, 61, 18, 61, 40], "learning_rate": 8.152254301803018e-05, "batch_size": 63, "loss": 0.035657935068011286}, {"layer_params": [29, 33, 38, 52], "learning_rate": 0.007483496071838669, "batch_size": 483, "loss": 0.001928770103259012}, {"layer_params": [39, 37, 21], "learning_rate": 0.0020577359538738664, "batch_size": 37, "loss": 0.0061313235526904465}, {"layer_params": [42, 21, 52], "learning_rate": 0.009070880947881145, "batch_size": 506, "loss": 0.0022072356147691606}, {"layer_params": [34, 36], "learning_rate": 0.005104680801741261, "batch_size": 187, "loss": 0.003249591023195535}, {"layer_params": [38, 59, 51, 19, 47], "learning_rate": 0.0013459976876308971, "batch_size": 475, "loss": 0.0016029477817937731}, {"layer_params": [41, 62, 30, 39, 49], "learning_rate": 0.007703567055227292, "batch_size": 151, "loss": 0.002839590786024928}, {"layer_params": [61, 61, 60, 59], "learning_rate": 0.003860540365927583, "batch_size": 206, "loss": 0.0010780039126984775}, {"layer_params": [37, 47, 50, 37], "learning_rate": 0.0012787513219745807, "batch_size": 430, "loss": 0.0024252846790477635}, {"layer_params": [27, 38, 27], "learning_rate": 0.0072551206158738965, "batch_size": 105, "loss": 0.004019829430617392}, {"layer_params": [46, 49, 39], "learning_rate": 0.00490459283297505, "batch_size": 202, "loss": 0.0018525998992845417}, {"layer_params": [40, 18, 52], "learning_rate": 0.006355581572734911, "batch_size": 138, "loss": 0.001873678269330412}, {"layer_params": [62, 61, 46], "learning_rate": 0.0024919174487328354, "batch_size": 127, "loss": 0.00241443557664752}, {"layer_params": [40, 55, 28, 37], "learning_rate": 0.0033084229705511855, "batch_size": 214, "loss": 0.0018477322068065406}, {"layer_params": [16, 64, 20, 31, 43], "learning_rate": 0.004490334188481794, "batch_size": 316, "loss": 0.0027545653469860554}, {"layer_params": [46, 49], "learning_rate": 0.007366923050820004, "batch_size": 225, "loss": 0.0016251428646501154}, {"layer_params": [39, 56, 62, 31, 23], "learning_rate": 0.0076521295258098095, "batch_size": 193, "loss": 0.0016221728629898279}, {"layer_params": [63, 28, 51, 40], "learning_rate": 0.0057488269637723625, "batch_size": 147, "loss": 0.0014559591381112114}, {"layer_params": [21, 57, 34], "learning_rate": 0.00798016174007918, "batch_size": 458, "loss": 0.0019433748931623996}, {"layer_params": [38, 55, 53], "learning_rate": 0.009264505517487129, "batch_size": 305, "loss": 0.0017860995687078685}, {"layer_params": [45, 44, 44], "learning_rate": 0.0030380681975189444, "batch_size": 120, "loss": 0.0020022561121731995}, {"layer_params": [61, 47], "learning_rate": 0.008906690671204451, "batch_size": 339, "loss": 0.0010005579685093836}, {"layer_params": [29, 36, 62, 48, 61], "learning_rate": 0.006020616365698878, "batch_size": 297, "loss": 0.0009480894973967224}, {"layer_params": [53, 41], "learning_rate": 0.008053415962300664, "batch_size": 341, "loss": 0.0017389668826945125}, {"layer_params": [35, 46, 61, 46], "learning_rate": 0.002650988857435463, "batch_size": 241, "loss": 0.0022946156305260956}, {"layer_params": [46, 31], "learning_rate": 0.004842220177424439, "batch_size": 242, "loss": 0.001396798975765705}, {"layer_params": [44, 46, 38], "learning_rate": 0.00926703106510264, "batch_size": 121, "loss": 0.0014116736984578892}, {"layer_params": [38, 22], "learning_rate": 0.00863623209859024, "batch_size": 97, "loss": 0.004148109883535653}, {"layer_params": [30, 56, 17, 27], "learning_rate": 0.006842873635236901, "batch_size": 242, "loss": 0.002559504508972168}, {"layer_params": [57, 18, 56, 51, 22], "learning_rate": 0.009714159378673957, "batch_size": 478, "loss": 0.002020259357523173}, {"layer_params": [58, 57, 18, 53, 55], "learning_rate": 0.0006924243806826424, "batch_size": 298, "loss": 0.003049337756820023}, {"layer_params": [23, 43], "learning_rate": 0.0007236321378357941, "batch_size": 307, "loss": 0.007182891326956451}, {"layer_params": [52, 26], "learning_rate": 0.008825490913415156, "batch_size": 220, "loss": 0.002494553312426433}, {"layer_params": [26, 19], "learning_rate": 0.009298008810792291, "batch_size": 246, "loss": 0.003219663808122277}, {"layer_params": [36, 29], "learning_rate": 0.0088173873224593, "batch_size": 256, "loss": 0.0012282803817652167}, {"layer_params": [48, 60, 32], "learning_rate": 0.007296797410683665, "batch_size": 329, "loss": 0.0007089651102432981}, {"layer_params": [27, 45, 45, 51, 61], "learning_rate": 0.0013452628921552415, "batch_size": 137, "loss": 0.004471375274006277}, {"layer_params": [53, 29, 27, 42], "learning_rate": 0.0007818614646302403, "batch_size": 348, "loss": 0.003665114745963365}, {"layer_params": [37, 59], "learning_rate": 0.0035428594720243547, "batch_size": 251, "loss": 0.002968878671526909}, {"layer_params": [59, 55], "learning_rate": 0.005705286171106468, "batch_size": 226, "loss": 0.0014432510163169354}, {"layer_params": [62, 57, 29], "learning_rate": 0.006936985604901447, "batch_size": 55, "loss": 0.002613416245440021}, {"layer_params": [55, 22], "learning_rate": 0.007684794200272695, "batch_size": 130, "loss": 0.0032612654427066445}, {"layer_params": [57, 23, 28, 59, 23], "learning_rate": 0.003503640718717876, "batch_size": 220, "loss": 0.0012713049387093633}, {"layer_params": [21, 29, 41], "learning_rate": 0.004570865491715694, "batch_size": 298, "loss": 0.003208635419141501}, {"layer_params": [16, 18, 62, 56], "learning_rate": 0.008633134260231401, "batch_size": 388, "loss": 0.003296311025042087}, {"layer_params": [52, 33, 39, 51], "learning_rate": 0.00742982574674091, "batch_size": 492, "loss": 0.0010148436145391315}, {"layer_params": [38, 49, 59, 50, 63], "learning_rate": 0.0016519525111031918, "batch_size": 226, "loss": 0.001921581922797486}, {"layer_params": [16, 18, 48], "learning_rate": 0.0029906038306882175, "batch_size": 281, "loss": 0.004290984729304909}, {"layer_params": [27, 31], "learning_rate": 0.0030353158996008424, "batch_size": 435, "loss": 0.0023721782863140107}, {"layer_params": [27, 39, 37, 46], "learning_rate": 0.006792852355992031, "batch_size": 231, "loss": 0.00218879182706587}, {"layer_params": [51, 33, 57], "learning_rate": 0.006955546489114989, "batch_size": 226, "loss": 0.0012051252176752314}, {"layer_params": [47, 56], "learning_rate": 0.009300521680541908, "batch_size": 44, "loss": 0.0031057925696950407}, {"layer_params": [25, 39, 24, 30], "learning_rate": 0.007103959429372502, "batch_size": 465, "loss": 0.0017118382651824505}, {"layer_params": [61, 45, 30], "learning_rate": 0.0007488275739345377, "batch_size": 475, "loss": 0.002499550487846136}, {"layer_params": [31, 53, 19, 48], "learning_rate": 0.0022841238661187864, "batch_size": 349, "loss": 0.0023355081281624733}, {"layer_params": [26, 42, 23, 37], "learning_rate": 0.004928259032258773, "batch_size": 264, "loss": 0.0026605347846634687}, {"layer_params": [39, 20, 19, 17, 39], "learning_rate": 0.0024454662462666294, "batch_size": 71, "loss": 0.0043770342762582005}, {"layer_params": [62, 28, 30, 52, 63], "learning_rate": 0.003094990077044584, "batch_size": 323, "loss": 0.0014873419562354683}, {"layer_params": [20, 47, 23], "learning_rate": 0.009171237422083, "batch_size": 308, "loss": 0.0017349723703227937}, {"layer_params": [45, 24], "learning_rate": 0.008535480965247902, "batch_size": 151, "loss": 0.0029724699235521256}, {"layer_params": [51, 47, 32, 30], "learning_rate": 0.008224627313331751, "batch_size": 194, "loss": 0.001540966632310301}, {"layer_params": [41, 29, 44, 48, 42], "learning_rate": 0.003574685872155485, "batch_size": 35, "loss": 0.005230871289968491}, {"layer_params": [54, 54, 51], "learning_rate": 0.008327484713008664, "batch_size": 199, "loss": 0.0014186463668011129}, {"layer_params": [54, 20, 64, 48], "learning_rate": 0.008469510469022886, "batch_size": 417, "loss": 0.0023385155317373575}, {"layer_params": [51, 32, 54], "learning_rate": 0.0057550422819904684, "batch_size": 170, "loss": 0.0018967598327435554}, {"layer_params": [24, 18, 23], "learning_rate": 0.0035966690865378292, "batch_size": 137, "loss": 0.0041818467294797304}, {"layer_params": [17, 37, 22, 40, 27], "learning_rate": 0.007701065698314766, "batch_size": 385, "loss": 0.002507107248529792}, {"layer_params": [35, 19], "learning_rate": 0.009730847597364862, "batch_size": 44, "loss": 0.005500034948345274}, {"layer_params": [58, 34], "learning_rate": 0.007361959473940882, "batch_size": 42, "loss": 0.006088167347479611}, {"layer_params": [29, 54, 19, 59, 56], "learning_rate": 0.000808511154752035, "batch_size": 320, "loss": 0.003052156150806695}, {"layer_params": [16, 22, 63, 31], "learning_rate": 0.005821170527909809, "batch_size": 134, "loss": 0.0034322198713198303}, {"layer_params": [26, 25, 32], "learning_rate": 0.008631995374615615, "batch_size": 446, "loss": 0.002418079774361104}, {"layer_params": [45, 35], "learning_rate": 0.001818406865550734, "batch_size": 133, "loss": 0.00353686518734321}, {"layer_params": [25, 42], "learning_rate": 0.0038605102514238385, "batch_size": 253, "loss": 0.002268349472433329}, {"layer_params": [17, 24, 60, 41, 36], "learning_rate": 0.0037181161455983078, "batch_size": 38, "loss": 0.0076087812706828115}, {"layer_params": [51, 32, 47, 37, 20], "learning_rate": 0.009104490327629885, "batch_size": 41, "loss": 0.005553038648795337}, {"layer_params": [38, 51, 45, 25], "learning_rate": 0.0015625644463669439, "batch_size": 149, "loss": 0.0025172613526228817}, {"layer_params": [54, 55, 46], "learning_rate": 0.007466627942150502, "batch_size": 418, "loss": 0.0008154139242833481}, {"layer_params": [58, 23, 32, 62, 44], "learning_rate": 0.009689560023280166, "batch_size": 462, "loss": 0.0014090966782532633}, {"layer_params": [41, 20], "learning_rate": 0.007098602350469787, "batch_size": 307, "loss": 0.0021341043524444104}, {"layer_params": [17, 53, 22, 46], "learning_rate": 0.008700584431110336, "batch_size": 354, "loss": 0.0030350596550852062}, {"layer_params": [30, 61, 31, 57], "learning_rate": 0.007856365900952653, "batch_size": 44, "loss": 0.0053295080363750455}, {"layer_params": [58, 32, 39, 60], "learning_rate": 0.004631302007597025, "batch_size": 168, "loss": 0.002049351828172803}, {"layer_params": [17, 24], "learning_rate": 0.004657891839295263, "batch_size": 130, "loss": 0.006369192521087825}, {"layer_params": [57, 40], "learning_rate": 0.004905339789452185, "batch_size": 460, "loss": 0.0016345975594595074}, {"layer_params": [26, 26, 50, 59, 54], "learning_rate": 0.004190326163682342, "batch_size": 266, "loss": 0.0036353696254082025}, {"layer_params": [24, 28, 63, 38], "learning_rate": 0.007924565306465691, "batch_size": 450, "loss": 0.001956777350278571}, {"layer_params": [17, 42], "learning_rate": 0.0074653246182808984, "batch_size": 394, "loss": 0.002693055977579206}, {"layer_params": [21, 43, 48], "learning_rate": 0.0002444014389188332, "batch_size": 102, "loss": 0.010345205063931644}, {"layer_params": [43, 31, 37], "learning_rate": 0.0026974885694404046, "batch_size": 44, "loss": 0.004384693307802081}, {"layer_params": [30, 58, 49], "learning_rate": 0.0039926618478917575, "batch_size": 485, "loss": 0.0021367950434796512}, {"layer_params": [29, 19, 41], "learning_rate": 0.0003228365461645426, "batch_size": 260, "loss": 0.00803375740069896}, {"layer_params": [16, 42, 57, 49, 63], "learning_rate": 0.004255320646230577, "batch_size": 109, "loss": 0.002922399591188878}, {"layer_params": [21, 18, 42], "learning_rate": 0.007201820755201822, "batch_size": 510, "loss": 0.003403115360997617}, {"layer_params": [38, 47, 30, 29], "learning_rate": 0.0007439746821659601, "batch_size": 376, "loss": 0.002544419144978747}, {"layer_params": [38, 32, 24], "learning_rate": 0.00915178474457812, "batch_size": 496, "loss": 0.0016617585299536586}, {"layer_params": [20, 19, 44, 26], "learning_rate": 0.007193019205987596, "batch_size": 470, "loss": 0.004108433192595839}, {"layer_params": [59, 45], "learning_rate": 0.008702451752009422, "batch_size": 204, "loss": 0.0015898260148242116}, {"layer_params": [37, 30], "learning_rate": 0.0027813166801747133, "batch_size": 46, "loss": 0.0057957293721847235}, {"layer_params": [16, 23, 28], "learning_rate": 0.008337493678825294, "batch_size": 403, "loss": 0.0031638157390989365}, {"layer_params": [35, 30, 16], "learning_rate": 0.0026478722269658063, "batch_size": 496, "loss": 0.004153171856887639}, {"layer_params": [31, 62, 23, 50], "learning_rate": 0.005952304441364066, "batch_size": 428, "loss": 0.0009332786191953346}, {"layer_params": [56, 18, 23, 22, 51], "learning_rate": 0.007331125336424345, "batch_size": 43, "loss": 0.005562446245457977}, {"layer_params": [52, 56, 49, 34, 31], "learning_rate": 0.0055977676104114246, "batch_size": 59, "loss": 0.0031601594551466405}, {"layer_params": [49, 26], "learning_rate": 0.00025187944564165394, "batch_size": 291, "loss": 0.008929800651967525}, {"layer_params": [21, 42, 61, 63], "learning_rate": 0.002026195318685917, "batch_size": 426, "loss": 0.003210648596286774}, {"layer_params": [16, 23, 48, 40], "learning_rate": 0.005061651538864464, "batch_size": 402, "loss": 0.0027325206715613603}, {"layer_params": [44, 59, 25], "learning_rate": 0.008997256838758655, "batch_size": 463, "loss": 0.0009832273720530792}, {"layer_params": [49, 21], "learning_rate": 0.0005200557383387184, "batch_size": 461, "loss": 0.006590323215350509}, {"layer_params": [28, 37, 20, 49, 59], "learning_rate": 0.0026821369172747873, "batch_size": 346, "loss": 0.0020937437936663626}, {"layer_params": [43, 24, 17], "learning_rate": 0.0005271264236074652, "batch_size": 54, "loss": 0.007741587092168629}, {"layer_params": [36, 25, 56, 45, 21], "learning_rate": 0.003319599886883489, "batch_size": 336, "loss": 0.0022450874163769184}, {"layer_params": [20, 46, 25, 35], "learning_rate": 0.0056569070928569635, "batch_size": 391, "loss": 0.0013844396208878606}, {"layer_params": [48, 21, 19, 48], "learning_rate": 0.00858702842725751, "batch_size": 282, "loss": 0.002247316571883857}, {"layer_params": [39, 24], "learning_rate": 0.008252225882398257, "batch_size": 185, "loss": 0.0020593664108309894}, {"layer_params": [47, 62, 16, 22], "learning_rate": 0.0047604145233704894, "batch_size": 305, "loss": 0.001723604864673689}, {"layer_params": [53, 64, 38, 57, 29], "learning_rate": 0.002003505536082516, "batch_size": 89, "loss": 0.0024488776363432406}, {"layer_params": [47, 41, 30, 17], "learning_rate": 0.00011728672147922179, "batch_size": 321, "loss": 0.017476203870028257}, {"layer_params": [31, 64, 22], "learning_rate": 0.005830814503287769, "batch_size": 148, "loss": 0.0024910549842752515}, {"layer_params": [39, 27], "learning_rate": 0.008175472546090704, "batch_size": 361, "loss": 0.0018086308683268725}, {"layer_params": [16, 60, 20, 48, 56], "learning_rate": 0.008659553853632162, "batch_size": 180, "loss": 0.0038162602949887514}, {"layer_params": [37, 52, 25, 61], "learning_rate": 0.0014060086601745587, "batch_size": 315, "loss": 0.0018552718753926457}, {"layer_params": [52, 31, 18], "learning_rate": 0.008733991890598711, "batch_size": 146, "loss": 0.0021748268452938648}, {"layer_params": [35, 33, 53, 44, 17], "learning_rate": 0.007493600003939087, "batch_size": 479, "loss": 0.0016676764423027635}, {"layer_params": [38, 33, 52, 18], "learning_rate": 0.009954733430964091, "batch_size": 242, "loss": 0.0018187196215149015}, {"layer_params": [52, 46, 39], "learning_rate": 0.006203422182370536, "batch_size": 51, "loss": 0.0032688706635963173}, {"layer_params": [19, 64, 30, 47], "learning_rate": 0.0030213068201579408, "batch_size": 324, "loss": 0.002011047190753743}, {"layer_params": [62, 24, 16, 42], "learning_rate": 0.001864235855292732, "batch_size": 413, "loss": 0.002996687055565417}, {"layer_params": [47, 38], "learning_rate": 0.0021364085575802725, "batch_size": 335, "loss": 0.0019625541404820978}, {"layer_params": [32, 27, 21, 49], "learning_rate": 0.008787957951203807, "batch_size": 511, "loss": 0.00184549740399234}, {"layer_params": [51, 19, 31], "learning_rate": 0.00038787872809881293, "batch_size": 176, "loss": 0.007393653024919331}, {"layer_params": [56, 23, 45], "learning_rate": 0.006140521118108703, "batch_size": 245, "loss": 0.0017416317970491947}, {"layer_params": [22, 41], "learning_rate": 0.005284811414010412, "batch_size": 167, "loss": 0.0044326480594463645}, {"layer_params": [30, 36, 32, 31, 17], "learning_rate": 0.004182795206939403, "batch_size": 93, "loss": 0.004257909941952675}, {"layer_params": [40, 53], "learning_rate": 0.003356916475714544, "batch_size": 70, "loss": 0.002983915631193668}, {"layer_params": [20, 18, 47], "learning_rate": 0.004105204737283636, "batch_size": 510, "loss": 0.0032304370938800275}, {"layer_params": [61, 22, 64, 41, 44], "learning_rate": 0.0075120698238682225, "batch_size": 154, "loss": 0.0012730367429321632}, {"layer_params": [23, 35, 34], "learning_rate": 0.0011642057005118655, "batch_size": 339, "loss": 0.004356421604752541}, {"layer_params": [64, 44, 30, 27], "learning_rate": 0.0065724290872496436, "batch_size": 316, "loss": 0.0008885527774691582}, {"layer_params": [26, 56, 25, 38, 23], "learning_rate": 0.00899203935308076, "batch_size": 486, "loss": 0.0017700251133646815}, {"layer_params": [23, 48, 62, 55, 40], "learning_rate": 0.00955502299958891, "batch_size": 249, "loss": 0.0018677259562537075}, {"layer_params": [46, 47, 47, 24], "learning_rate": 0.0031413248726325864, "batch_size": 42, "loss": 0.00417372435098514}, {"layer_params": [38, 28, 37, 23, 21], "learning_rate": 0.00886566789521297, "batch_size": 461, "loss": 0.0015581480832770466}, {"layer_params": [57, 45, 29, 17, 49], "learning_rate": 0.005188232390117801, "batch_size": 271, "loss": 0.0010538993502268567}, {"layer_params": [49, 41], "learning_rate": 0.0075915480575855995, "batch_size": 146, "loss": 0.0024947404384147377}, {"layer_params": [47, 51, 59], "learning_rate": 0.007146227060076197, "batch_size": 412, "loss": 0.0009332628827542067}, {"layer_params": [20, 57, 22], "learning_rate": 0.004509159657265351, "batch_size": 153, "loss": 0.003744467217475176}, {"layer_params": [41, 27, 61, 38, 18], "learning_rate": 0.008920165670941796, "batch_size": 268, "loss": 0.0021745542925782502}, {"layer_params": [39, 57, 18, 30], "learning_rate": 0.00021441508262133702, "batch_size": 58, "loss": 0.009947085599415005}, {"layer_params": [17, 16, 18, 19], "learning_rate": 0.006297557772040461, "batch_size": 100, "loss": 0.0038692328683100643}, {"layer_params": [25, 59, 52, 33, 60], "learning_rate": 0.0007560228574411086, "batch_size": 240, "loss": 0.005055694039911031}, {"layer_params": [30, 60, 32, 53, 24], "learning_rate": 0.004249402386275836, "batch_size": 58, "loss": 0.0030476644670125097}, {"layer_params": [41, 49], "learning_rate": 0.007658991394790463, "batch_size": 489, "loss": 0.0021458623907528816}, {"layer_params": [47, 36], "learning_rate": 0.007460736261719891, "batch_size": 302, "loss": 0.0023717634729109706}, {"layer_params": [24, 29], "learning_rate": 0.0065798175980495985, "batch_size": 370, "loss": 0.004291257245931775}, {"layer_params": [19, 24, 37, 18], "learning_rate": 0.004095035425285796, "batch_size": 396, "loss": 0.003577060524839908}, {"layer_params": [34, 62, 31], "learning_rate": 0.004210891591426217, "batch_size": 152, "loss": 0.0024739583814516663}, {"layer_params": [61, 41, 32, 20, 63], "learning_rate": 0.008648895843023325, "batch_size": 92, "loss": 0.002548696876037866}, {"layer_params": [43, 60], "learning_rate": 0.0052931072857786785, "batch_size": 116, "loss": 0.0016261127195321024}, {"layer_params": [24, 47, 45], "learning_rate": 0.005726042595635654, "batch_size": 503, "loss": 0.0019498496886808424}, {"layer_params": [44, 46, 61, 63, 25], "learning_rate": 0.006962891591264204, "batch_size": 208, "loss": 0.002083098749862984}, {"layer_params": [26, 41], "learning_rate": 0.00991258921434051, "batch_size": 268, "loss": 0.001701221651164815}, {"layer_params": [54, 51, 32, 29, 39], "learning_rate": 0.006616655897313361, "batch_size": 354, "loss": 0.0014070108532905578}, {"layer_params": [43, 61, 49, 34], "learning_rate": 0.006444803307029767, "batch_size": 99, "loss": 0.002198660868452862}, {"layer_params": [26, 50, 35, 63], "learning_rate": 0.006364095736505725, "batch_size": 308, "loss": 0.0014488923316821455}, {"layer_params": [56, 54, 64, 40, 32], "learning_rate": 0.0058143979470706994, "batch_size": 486, "loss": 0.0006885760993463919}, {"layer_params": [33, 55], "learning_rate": 0.009860231539508466, "batch_size": 95, "loss": 0.003089336159173399}, {"layer_params": [25, 55, 32, 45, 52], "learning_rate": 0.006105862586511001, "batch_size": 413, "loss": 0.00208541864878498}, {"layer_params": [55, 47, 56], "learning_rate": 0.008526628598214958, "batch_size": 112, "loss": 0.0011120346514508128}, {"layer_params": [53, 51], "learning_rate": 0.008441006106396257, "batch_size": 354, "loss": 0.001354997024172917}, {"layer_params": [43, 62, 32, 55], "learning_rate": 0.00010780017829462591, "batch_size": 384, "loss": 0.010162236727774143}, {"layer_params": [62, 23, 28, 59], "learning_rate": 0.003148072372457158, "batch_size": 410, "loss": 0.0014332427422050387}, {"layer_params": [28, 61, 32], "learning_rate": 0.0096697168989297, "batch_size": 329, "loss": 0.0015331089217215776}, {"layer_params": [37, 45, 26], "learning_rate": 0.00852392127618404, "batch_size": 207, "loss": 0.0018936750374268741}, {"layer_params": [35, 57, 52], "learning_rate": 0.009050015456529073, "batch_size": 297, "loss": 0.0014192984910914674}, {"layer_params": [24, 17], "learning_rate": 0.001443907336435232, "batch_size": 402, "loss": 0.007243324555456638}, {"layer_params": [64, 44, 52, 50, 30], "learning_rate": 0.0034307177008402177, "batch_size": 169, "loss": 0.0018658768106251955}, {"layer_params": [40, 53, 21], "learning_rate": 0.0003826877172312473, "batch_size": 454, "loss": 0.0066998548666015265}, {"layer_params": [62, 63, 22, 20, 29], "learning_rate": 0.006595849979561381, "batch_size": 207, "loss": 0.00132967357407324}, {"layer_params": [57, 26, 57], "learning_rate": 0.002553540433373945, "batch_size": 348, "loss": 0.0018006792408414185}, {"layer_params": [26, 38, 36], "learning_rate": 0.0003151497985466979, "batch_size": 307, "loss": 0.007933453959412872}, {"layer_params": [19, 41, 41], "learning_rate": 0.005377082654206611, "batch_size": 51, "loss": 0.005604635588824749}, {"layer_params": [37, 38, 52, 48], "learning_rate": 0.003492089945911101, "batch_size": 42, "loss": 0.004640966160222888}, {"layer_params": [56, 18, 54], "learning_rate": 0.0001038756192809058, "batch_size": 264, "loss": 0.022183008529245853}, {"layer_params": [58, 47, 63, 24, 39], "learning_rate": 0.0046557622458836675, "batch_size": 256, "loss": 0.00091608896269463}, {"layer_params": [22, 20, 63, 37, 37], "learning_rate": 0.007505940127839391, "batch_size": 78, "loss": 0.004253532431321218}, {"layer_params": [42, 21, 42], "learning_rate": 0.001624186244289875, "batch_size": 332, "loss": 0.0025944411498494448}, {"layer_params": [28, 49, 31, 52], "learning_rate": 0.0024667623213843006, "batch_size": 275, "loss": 0.0022539410006720572}, {"layer_params": [55, 38, 49, 21], "learning_rate": 0.0059857489877617525, "batch_size": 166, "loss": 0.0013425529486266897}, {"layer_params": [50, 64], "learning_rate": 0.0003241469416151255, "batch_size": 280, "loss": 0.0064964570058509705}, {"layer_params": [17, 51], "learning_rate": 0.006186996925943457, "batch_size": 36, "loss": 0.005378000875934958}, {"layer_params": [56, 55], "learning_rate": 0.009920765587009621, "batch_size": 360, "loss": 0.001632533100200817}, {"layer_params": [62, 43, 32, 42], "learning_rate": 0.0029876416709726794, "batch_size": 286, "loss": 0.001492432962404564}, {"layer_params": [36, 40], "learning_rate": 0.0032649167843566912, "batch_size": 388, "loss": 0.0024417381186503917}, {"layer_params": [54, 18], "learning_rate": 0.00338030316124094, "batch_size": 88, "loss": 0.005673285059165209}, {"layer_params": [34, 34, 31], "learning_rate": 0.002855726848307656, "batch_size": 282, "loss": 0.003159254644997418}, {"layer_params": [39, 50], "learning_rate": 0.0006786038661407256, "batch_size": 275, "loss": 0.005681480939965695}, {"layer_params": [24, 58, 27, 55], "learning_rate": 0.003754060200213698, "batch_size": 162, "loss": 0.0018809778068680316}, {"layer_params": [30, 58, 18, 20], "learning_rate": 0.0016900038576208314, "batch_size": 401, "loss": 0.002398562547750771}, {"layer_params": [36, 16, 58], "learning_rate": 0.008823992649684103, "batch_size": 24, "loss": 0.007329930095002055}, {"layer_params": [39, 18, 45, 35, 28], "learning_rate": 0.00816877564422642, "batch_size": 261, "loss": 0.0012794280424714088}, {"layer_params": [46, 39, 46, 62, 17], "learning_rate": 0.001276659529162907, "batch_size": 230, "loss": 0.0036601195530965923}, {"layer_params": [60, 22, 27, 45], "learning_rate": 0.006424075988507261, "batch_size": 134, "loss": 0.0021510512579698115}, {"layer_params": [17, 17], "learning_rate": 0.0049276089680722725, "batch_size": 105, "loss": 0.007565831108950078}, {"layer_params": [40, 33, 30, 39], "learning_rate": 0.0019932919777401626, "batch_size": 127, "loss": 0.003772584095131606}, {"layer_params": [30, 45, 56, 42], "learning_rate": 0.0024621249936033675, "batch_size": 450, "loss": 0.002175033784005791}, {"layer_params": [64, 63, 20], "learning_rate": 0.00793939264814, "batch_size": 371, "loss": 0.0007519614894408732}, {"layer_params": [40, 40], "learning_rate": 0.0011787875594047974, "batch_size": 495, "loss": 0.0033638172084465624}, {"layer_params": [27, 34, 39, 44], "learning_rate": 0.002001015313486429, "batch_size": 108, "loss": 0.003446136503480375}, {"layer_params": [30, 60, 52], "learning_rate": 0.004317641696373268, "batch_size": 204, "loss": 0.0019287170888856054}, {"layer_params": [35, 24, 36], "learning_rate": 0.007049693793851043, "batch_size": 419, "loss": 0.002127812900580466}, {"layer_params": [16, 23, 53, 60, 44], "learning_rate": 0.0054785997393478995, "batch_size": 355, "loss": 0.0017803056666161866}, {"layer_params": [21, 59, 51, 25, 62], "learning_rate": 0.005230528851535217, "batch_size": 410, "loss": 0.00161018475308083}, {"layer_params": [20, 41], "learning_rate": 0.00023451355551236977, "batch_size": 312, "loss": 0.01515859461389482}, {"layer_params": [33, 23], "learning_rate": 0.005491118737369733, "batch_size": 31, "loss": 0.0065618620370514694}, {"layer_params": [55, 25, 37], "learning_rate": 0.008835874794801846, "batch_size": 502, "loss": 0.0007084413649863563}, {"layer_params": [17, 63, 21, 20], "learning_rate": 0.003820329889462158, "batch_size": 178, "loss": 0.0030829201289452614}, {"layer_params": [30, 26], "learning_rate": 0.0007939274239594966, "batch_size": 313, "loss": 0.007457099272869527}, {"layer_params": [31, 18, 34, 20], "learning_rate": 0.00358252980906443, "batch_size": 42, "loss": 0.004981864858418703}, {"layer_params": [32, 19, 24, 54], "learning_rate": 0.004530619467866645, "batch_size": 218, "loss": 0.0032168569904752076}, {"layer_params": [39, 25, 44], "learning_rate": 0.001999395350098801, "batch_size": 377, "loss": 0.0016634193062782287}, {"layer_params": [18, 32, 54, 22, 64], "learning_rate": 0.007896698911207081, "batch_size": 189, "loss": 0.004206832093186677}, {"layer_params": [38, 48], "learning_rate": 0.0014482634619864586, "batch_size": 104, "loss": 0.004712201615329831}, {"layer_params": [42, 28, 51, 17], "learning_rate": 0.003861718009857474, "batch_size": 427, "loss": 0.0017008890246506781}, {"layer_params": [43, 59, 32, 33], "learning_rate": 0.003145970948669489, "batch_size": 250, "loss": 0.0015228788298554717}, {"layer_params": [46, 62, 62, 64], "learning_rate": 0.008335531488358975, "batch_size": 189, "loss": 0.001620189107488841}, {"layer_params": [33, 34, 61, 20], "learning_rate": 0.004526733436368443, "batch_size": 185, "loss": 0.002261532904813066}, {"layer_params": [42, 62, 62, 42], "learning_rate": 0.005216571395322016, "batch_size": 189, "loss": 0.0013073028920916841}, {"layer_params": [63, 30, 44], "learning_rate": 0.004764084147199682, "batch_size": 90, "loss": 0.002202863657148555}, {"layer_params": [60, 24], "learning_rate": 0.00770028975279014, "batch_size": 32, "loss": 0.0038281046343036}, {"layer_params": [63, 23], "learning_rate": 0.009814231779121028, "batch_size": 92, "loss": 0.00453722125152126}, {"layer_params": [45, 63, 54, 37], "learning_rate": 0.0018139704368737193, "batch_size": 313, "loss": 0.0019110394781455397}, {"layer_params": [43, 55, 42, 60, 43], "learning_rate": 0.005207007721865221, "batch_size": 509, "loss": 0.0010588420851854608}, {"layer_params": [58, 62, 35], "learning_rate": 0.002975843676326994, "batch_size": 264, "loss": 0.001163383864914067}, {"layer_params": [46, 50], "learning_rate": 0.006822912646051424, "batch_size": 194, "loss": 0.0016244117089081556}, {"layer_params": [47, 34, 22], "learning_rate": 0.008613363296464914, "batch_size": 363, "loss": 0.000990346196340397}, {"layer_params": [64, 58, 31, 63], "learning_rate": 0.0009185861414008569, "batch_size": 351, "loss": 0.0019088110304437578}, {"layer_params": [40, 34, 57, 34, 24], "learning_rate": 0.00341161547854849, "batch_size": 111, "loss": 0.0019175296707544475}, {"layer_params": [27, 52, 34], "learning_rate": 0.004165414153516037, "batch_size": 309, "loss": 0.002286282988497987}, {"layer_params": [51, 37, 33, 38, 16], "learning_rate": 0.002786433603452038, "batch_size": 503, "loss": 0.0010502764413831756}, {"layer_params": [49, 47, 52], "learning_rate": 6.176208103307425e-05, "batch_size": 256, "loss": 0.029669799823313952}, {"layer_params": [33, 35, 48, 32, 39], "learning_rate": 0.006201399924896851, "batch_size": 480, "loss": 0.0017508361826185136}, {"layer_params": [58, 31, 34, 32], "learning_rate": 0.008402755356894446, "batch_size": 320, "loss": 0.0007390854199184105}, {"layer_params": [42, 59, 38], "learning_rate": 0.000910600131526859, "batch_size": 17, "loss": 0.008080802334006876}, {"layer_params": [33, 42], "learning_rate": 0.0023298025348401042, "batch_size": 334, "loss": 0.0022066532215103507}, {"layer_params": [40, 63, 17, 64, 37], "learning_rate": 0.005436831494268448, "batch_size": 474, "loss": 0.0014146278437692672}, {"layer_params": [38, 33], "learning_rate": 0.0001877374921229019, "batch_size": 105, "loss": 0.014122423660010099}, {"layer_params": [51, 43, 44], "learning_rate": 0.004381369656900918, "batch_size": 415, "loss": 0.0013370357279200106}, {"layer_params": [52, 38, 57, 18, 24], "learning_rate": 0.002503259550491444, "batch_size": 146, "loss": 0.002535764335189015}, {"layer_params": [51, 60], "learning_rate": 0.0007239649386341294, "batch_size": 181, "loss": 0.005005395798943937}, {"layer_params": [25, 38], "learning_rate": 0.00690941773642169, "batch_size": 304, "loss": 0.003241660662461072}, {"layer_params": [41, 28], "learning_rate": 0.009490926865593292, "batch_size": 219, "loss": 0.0036857996974140406}, {"layer_params": [30, 40, 38], "learning_rate": 0.00335892390158392, "batch_size": 418, "loss": 0.0016690524690784513}, {"layer_params": [28, 38], "learning_rate": 0.006188402013930435, "batch_size": 103, "loss": 0.00351187129272148}, {"layer_params": [45, 62, 21], "learning_rate": 0.008877053630332171, "batch_size": 383, "loss": 0.0013675852701999247}, {"layer_params": [19, 49], "learning_rate": 9.72183930190645e-05, "batch_size": 240, "loss": 0.028889506477862596}, {"layer_params": [41, 28, 50, 55, 46], "learning_rate": 0.0024052857073354277, "batch_size": 302, "loss": 0.002487787022255361}, {"layer_params": [29, 37, 21], "learning_rate": 0.008983821640997442, "batch_size": 188, "loss": 0.002727202975656837}, {"layer_params": [47, 57, 26, 44, 36], "learning_rate": 0.004031334739105037, "batch_size": 150, "loss": 0.0023717684007715433}, {"layer_params": [31, 57, 24, 34], "learning_rate": 0.009784941570423682, "batch_size": 161, "loss": 0.002474710033275187}, {"layer_params": [64, 47], "learning_rate": 0.004043734295517447, "batch_size": 150, "loss": 0.002229280874598771}, {"layer_params": [42, 17, 56], "learning_rate": 0.0008775161081781875, "batch_size": 158, "loss": 0.006362556694075466}, {"layer_params": [17, 35, 47, 35], "learning_rate": 0.00441377694607181, "batch_size": 252, "loss": 0.002196962508605793}, {"layer_params": [17, 64, 29, 61], "learning_rate": 0.0007063874276745774, "batch_size": 417, "loss": 0.005995853948406875}, {"layer_params": [31, 42, 43, 60, 23], "learning_rate": 0.0051043949175960095, "batch_size": 317, "loss": 0.0018717458564788104}, {"layer_params": [33, 51, 24], "learning_rate": 0.008247862290256675, "batch_size": 360, "loss": 0.0015799983288161457}, {"layer_params": [46, 60, 52, 40], "learning_rate": 0.005120884668969551, "batch_size": 304, "loss": 0.0012256920541403814}, {"layer_params": [61, 56, 18, 26, 32], "learning_rate": 0.003073100294094114, "batch_size": 237, "loss": 0.0017617616755887867}, {"layer_params": [53, 53], "learning_rate": 0.009970948901748685, "batch_size": 447, "loss": 0.0011327779112616553}, {"layer_params": [24, 45, 18, 55, 58], "learning_rate": 0.000564119384520543, "batch_size": 360, "loss": 0.005544901816174388}, {"layer_params": [51, 43, 25, 34], "learning_rate": 0.002883054266339112, "batch_size": 296, "loss": 0.002476546703837812}, {"layer_params": [55, 54, 46, 27], "learning_rate": 0.006171267270745593, "batch_size": 116, "loss": 0.00275182893848978}, {"layer_params": [19, 43, 31, 45, 52], "learning_rate": 0.006334774734036247, "batch_size": 243, "loss": 0.0019449417991563678}, {"layer_params": [16, 33, 18], "learning_rate": 0.009904082532245806, "batch_size": 500, "loss": 0.0032969882409088313}, {"layer_params": [61, 44], "learning_rate": 0.003475095896956258, "batch_size": 103, "loss": 0.0033236194821074606}, {"layer_params": [63, 42, 39, 48, 47], "learning_rate": 0.0070033948462247825, "batch_size": 474, "loss": 0.0008065085054840892}, {"layer_params": [22, 47, 38, 19], "learning_rate": 0.0039634469286950295, "batch_size": 362, "loss": 0.0027609897986985744}, {"layer_params": [27, 47, 29, 42, 49], "learning_rate": 0.0068147307876863005, "batch_size": 105, "loss": 0.0036650036205537616}, {"layer_params": [21, 45], "learning_rate": 0.002201811729957074, "batch_size": 423, "loss": 0.004013347984291613}, {"layer_params": [61, 47], "learning_rate": 0.004912009831653698, "batch_size": 36, "loss": 0.0032489528623409567}, {"layer_params": [36, 62, 29, 47], "learning_rate": 0.007296513227816213, "batch_size": 443, "loss": 0.0008745722071034833}, {"layer_params": [46, 45], "learning_rate": 0.0007342504308564118, "batch_size": 100, "loss": 0.005538526056334377}, {"layer_params": [20, 54], "learning_rate": 0.008626408295667954, "batch_size": 214, "loss": 0.0026663792785257103}, {"layer_params": [46, 38, 19, 45], "learning_rate": 0.0027796313053671247, "batch_size": 145, "loss": 0.002444807671708986}, {"layer_params": [27, 18], "learning_rate": 0.005420678348456256, "batch_size": 288, "loss": 0.0040592491859570146}, {"layer_params": [60, 33], "learning_rate": 0.0043183321723232115, "batch_size": 110, "loss": 0.0027288626309018584}, {"layer_params": [17, 39], "learning_rate": 0.001095056211103562, "batch_size": 231, "loss": 0.007194869858212769}, {"layer_params": [33, 24, 29, 36], "learning_rate": 0.0019552816137095403, "batch_size": 251, "loss": 0.0033807195303961635}, {"layer_params": [54, 54, 18, 27, 55], "learning_rate": 0.0017340105528094079, "batch_size": 249, "loss": 0.0018780485400930046}, {"layer_params": [58, 58], "learning_rate": 0.008471660606705659, "batch_size": 371, "loss": 0.0011642616742756219}, {"layer_params": [19, 31, 19, 26, 44], "learning_rate": 0.002247403350032483, "batch_size": 434, "loss": 0.003587794424965978}, {"layer_params": [59, 31, 18, 19, 58], "learning_rate": 0.007039816579255702, "batch_size": 321, "loss": 0.0022608483978547155}, {"layer_params": [62, 61, 61, 18], "learning_rate": 0.0029179124517882157, "batch_size": 452, "loss": 0.0013360034802462905}, {"layer_params": [42, 60, 63], "learning_rate": 0.00655749355739809, "batch_size": 305, "loss": 0.0015984666987787933}, {"layer_params": [44, 24], "learning_rate": 0.009007408120688594, "batch_size": 122, "loss": 0.0025052797968965024}, {"layer_params": [33, 19, 38], "learning_rate": 0.004893034509159944, "batch_size": 482, "loss": 0.0027555576502345503}, {"layer_params": [24, 19], "learning_rate": 0.005412415815168369, "batch_size": 157, "loss": 0.0037847344297915696}, {"layer_params": [39, 54, 60, 27, 39], "learning_rate": 0.0011635305587687403, "batch_size": 31, "loss": 0.006128488886170089}, {"layer_params": [25, 64, 28], "learning_rate": 0.00625671520475067, "batch_size": 273, "loss": 0.0027852003229781987}, {"layer_params": [16, 53, 24], "learning_rate": 0.0031070972858113386, "batch_size": 233, "loss": 0.002533883497817442}, {"layer_params": [27, 28, 45], "learning_rate": 0.0009413385022688259, "batch_size": 198, "loss": 0.0058168509555980566}, {"layer_params": [61, 20, 40], "learning_rate": 0.0055429395881587745, "batch_size": 175, "loss": 0.0024654627370182423}, {"layer_params": [51, 55], "learning_rate": 0.005800275655498709, "batch_size": 142, "loss": 0.002004225584678352}, {"layer_params": [38, 16, 16, 22], "learning_rate": 0.009133799999751132, "batch_size": 437, "loss": 0.0024598469980992377}, {"layer_params": [21, 45, 57, 23, 40], "learning_rate": 0.005952795187744272, "batch_size": 508, "loss": 0.0016211990872398018}, {"layer_params": [19, 41, 56, 37], "learning_rate": 0.006014356836358285, "batch_size": 323, "loss": 0.002663491244893521}, {"layer_params": [39, 49, 19, 19, 45], "learning_rate": 0.001566028120049597, "batch_size": 30, "loss": 0.007923570051789284}, {"layer_params": [42, 61, 34], "learning_rate": 0.005429945211162903, "batch_size": 315, "loss": 0.0013812161469832062}, {"layer_params": [56, 32, 55, 41, 45], "learning_rate": 0.0011851204572267229, "batch_size": 403, "loss": 0.0017941425403114409}, {"layer_params": [59, 52], "learning_rate": 0.0046893570618743285, "batch_size": 272, "loss": 0.0014850860589649528}, {"layer_params": [42, 41, 19, 18], "learning_rate": 0.0009376577130892676, "batch_size": 30, "loss": 0.0074320856854319575}, {"layer_params": [37, 53, 60, 58, 32], "learning_rate": 0.007202991066173885, "batch_size": 362, "loss": 0.0015253807324916125}, {"layer_params": [42, 40, 34, 27], "learning_rate": 0.004569999954028242, "batch_size": 368, "loss": 0.0013434846978634596}, {"layer_params": [56, 41, 62, 31], "learning_rate": 0.004666812103276252, "batch_size": 510, "loss": 0.0011951455043163152}, {"layer_params": [19, 34, 41, 46], "learning_rate": 0.0014873755464020729, "batch_size": 498, "loss": 0.0027056733635254203}, {"layer_params": [30, 36, 25], "learning_rate": 0.0011376508757600173, "batch_size": 354, "loss": 0.005562342493794859}, {"layer_params": [33, 28], "learning_rate": 0.008417708056275723, "batch_size": 299, "loss": 0.00386134612839669}, {"layer_params": [53, 32, 27], "learning_rate": 0.0021931941893912565, "batch_size": 393, "loss": 0.00316468556644395}, {"layer_params": [53, 61, 30], "learning_rate": 0.009461432779545973, "batch_size": 176, "loss": 0.0015431505779270082}, {"layer_params": [50, 31, 46, 60], "learning_rate": 0.0065553206987279495, "batch_size": 75, "loss": 0.002577732055215165}, {"layer_params": [26, 43], "learning_rate": 0.00015090261977073635, "batch_size": 196, "loss": 0.01933816990815103}, {"layer_params": [42, 35, 29, 40, 25], "learning_rate": 0.0053565132481417956, "batch_size": 414, "loss": 0.0010143652267288416}, {"layer_params": [54, 30], "learning_rate": 0.005830282360687998, "batch_size": 385, "loss": 0.0011568688479019328}, {"layer_params": [39, 62], "learning_rate": 0.006043178706681981, "batch_size": 169, "loss": 0.001937255309894681}, {"layer_params": [18, 62, 27], "learning_rate": 0.007722230058940435, "batch_size": 380, "loss": 0.0021826937969308346}, {"layer_params": [53, 23, 37], "learning_rate": 0.008839405460032463, "batch_size": 330, "loss": 0.001139214265276678}, {"layer_params": [53, 24], "learning_rate": 0.0015705314325650064, "batch_size": 332, "loss": 0.003694675003644079}, {"layer_params": [60, 35, 31], "learning_rate": 0.008409664998594638, "batch_size": 194, "loss": 0.0022657985088881103}, {"layer_params": [52, 38, 59, 59], "learning_rate": 0.005855314591750088, "batch_size": 507, "loss": 0.0010749046201817692}, {"layer_params": [59, 55, 22, 45], "learning_rate": 0.007603001288824183, "batch_size": 332, "loss": 0.0013895255397073925}, {"layer_params": [33, 17], "learning_rate": 0.003361024757910073, "batch_size": 20, "loss": 0.007764409873634577}, {"layer_params": [26, 18], "learning_rate": 0.001259415567983712, "batch_size": 493, "loss": 0.006153930490836501}, {"layer_params": [23, 27, 17], "learning_rate": 0.008628890304177256, "batch_size": 272, "loss": 0.002967943660914898}, {"layer_params": [43, 36], "learning_rate": 0.006798272341590854, "batch_size": 187, "loss": 0.0018264085939154028}, {"layer_params": [21, 39], "learning_rate": 0.000866469754608694, "batch_size": 358, "loss": 0.007585349939763546}, {"layer_params": [51, 55], "learning_rate": 0.002905074936773399, "batch_size": 363, "loss": 0.0013768167002126575}, {"layer_params": [26, 26], "learning_rate": 0.0013316231069275132, "batch_size": 118, "loss": 0.0075171289406716826}, {"layer_params": [64, 21], "learning_rate": 0.006994385242211012, "batch_size": 137, "loss": 0.0018486821395345032}, {"layer_params": [58, 53], "learning_rate": 0.005495706131696202, "batch_size": 437, "loss": 0.0011140309943584725}, {"layer_params": [45, 49, 37, 24], "learning_rate": 0.008808210114588516, "batch_size": 139, "loss": 0.0022769644542131573}, {"layer_params": [42, 33, 19, 50], "learning_rate": 0.0005596905702247568, "batch_size": 390, "loss": 0.005048312088474631}, {"layer_params": [45, 30, 41, 18], "learning_rate": 0.005910486521661203, "batch_size": 335, "loss": 0.003122073165141046}, {"layer_params": [24, 35, 47], "learning_rate": 0.009955971108321724, "batch_size": 297, "loss": 0.003019381742924452}, {"layer_params": [58, 16, 26], "learning_rate": 0.00554693525024784, "batch_size": 333, "loss": 0.0029499788349494336}, {"layer_params": [52, 33, 36, 34, 39], "learning_rate": 0.0016787600360018108, "batch_size": 119, "loss": 0.0034814344882033764}, {"layer_params": [53, 16, 49, 46, 31], "learning_rate": 0.00970353185864694, "batch_size": 321, "loss": 0.0012672522640787066}, {"layer_params": [16, 40, 44], "learning_rate": 0.009570785524468184, "batch_size": 146, "loss": 0.0030926276673562824}, {"layer_params": [54, 24], "learning_rate": 0.0007716231640264696, "batch_size": 101, "loss": 0.006892692111432552}, {"layer_params": [52, 53], "learning_rate": 0.0033925796468277617, "batch_size": 122, "loss": 0.0018849040032364428}, {"layer_params": [16, 41, 54, 22], "learning_rate": 0.009219742221948594, "batch_size": 455, "loss": 0.0017934527969919146}, {"layer_params": [48, 55, 31, 25, 46], "learning_rate": 0.0007027452456038564, "batch_size": 436, "loss": 0.003622185776475817}, {"layer_params": [50, 42, 22, 59, 42], "learning_rate": 0.0012685310825589213, "batch_size": 140, "loss": 0.0037118205288425086}, {"layer_params": [18, 58, 29, 34, 53], "learning_rate": 0.009664623931084929, "batch_size": 204, "loss": 0.002696467863861471}, {"layer_params": [33, 57, 32], "learning_rate": 0.00747302915897773, "batch_size": 150, "loss": 0.003259550624061376}, {"layer_params": [58, 37, 50, 46, 53], "learning_rate": 0.009673647981541222, "batch_size": 269, "loss": 0.0018889516300987451}, {"layer_params": [32, 26, 21, 29, 52], "learning_rate": 0.007982647202169176, "batch_size": 232, "loss": 0.001159797494765371}, {"layer_params": [45, 30, 30, 38, 37], "learning_rate": 0.0037996032937355085, "batch_size": 350, "loss": 0.00183878009673208}, {"layer_params": [58, 33], "learning_rate": 0.009699459134148955, "batch_size": 428, "loss": 0.0008984468725975603}, {"layer_params": [64, 60], "learning_rate": 0.0021614156904379523, "batch_size": 102, "loss": 0.002878901617368683}, {"layer_params": [20, 57, 59, 39, 35], "learning_rate": 0.008981397919475836, "batch_size": 468, "loss": 0.0018044384918175637}, {"layer_params": [22, 43], "learning_rate": 0.002505232812539832, "batch_size": 52, "loss": 0.007593012331053615}, {"layer_params": [45, 59, 24], "learning_rate": 0.00807036942258485, "batch_size": 460, "loss": 0.0017268095375038684}, {"layer_params": [24, 24, 50, 51, 61], "learning_rate": 0.002871374959915673, "batch_size": 405, "loss": 0.0027276433259248735}, {"layer_params": [63, 24, 39], "learning_rate": 0.00976182167002431, "batch_size": 414, "loss": 0.002591073322109878}, {"layer_params": [19, 57], "learning_rate": 0.0030794935089811606, "batch_size": 169, "loss": 0.004685408277437091}, {"layer_params": [51, 22], "learning_rate": 0.004207742501731074, "batch_size": 344, "loss": 0.0020884745963849127}, {"layer_params": [22, 41, 47, 30, 35], "learning_rate": 0.007603603722871018, "batch_size": 411, "loss": 0.0021685073419939727}, {"layer_params": [51, 59], "learning_rate": 0.00504867672629364, "batch_size": 426, "loss": 0.0010744553757831455}, {"layer_params": [59, 49, 24, 29], "learning_rate": 0.00585741584906587, "batch_size": 449, "loss": 0.0007290404615923762}, {"layer_params": [35, 32, 34], "learning_rate": 0.0027030445103461464, "batch_size": 331, "loss": 0.0031370082241483034}, {"layer_params": [42, 30, 40, 32], "learning_rate": 0.0055798725285269475, "batch_size": 96, "loss": 0.003580957327503711}, {"layer_params": [48, 24], "learning_rate": 0.005865778371379527, "batch_size": 454, "loss": 0.00203789345221594}, {"layer_params": [29, 47, 61, 32], "learning_rate": 0.005343395540165519, "batch_size": 171, "loss": 0.0023193109652493147}, {"layer_params": [56, 16, 41, 38, 62], "learning_rate": 0.0032571546330188803, "batch_size": 260, "loss": 0.0019141983380541205}, {"layer_params": [43, 27, 39, 22], "learning_rate": 0.008446885273751916, "batch_size": 114, "loss": 0.003525553550571203}, {"layer_params": [57, 32, 27, 39], "learning_rate": 0.003467133235378928, "batch_size": 148, "loss": 0.003316172049380839}, {"layer_params": [56, 57], "learning_rate": 0.008196774265659523, "batch_size": 426, "loss": 0.0014398530882317572}, {"layer_params": [47, 45, 32, 45, 50], "learning_rate": 0.005868156017336651, "batch_size": 304, "loss": 0.002285181109327823}, {"layer_params": [61, 48, 33, 29, 45], "learning_rate": 0.0017460971279113764, "batch_size": 336, "loss": 0.0011532549641560764}, {"layer_params": [47, 24, 41, 58, 62], "learning_rate": 0.008014905017625812, "batch_size": 202, "loss": 0.00222190439584665}, {"layer_params": [54, 60, 46, 45], "learning_rate": 0.005683963964004428, "batch_size": 373, "loss": 0.0014214360481128096}, {"layer_params": [59, 64, 33], "learning_rate": 0.003995859656962275, "batch_size": 32, "loss": 0.004431396368891001}, {"layer_params": [49, 64], "learning_rate": 0.0022514368386721546, "batch_size": 22, "loss": 0.006690285010263324}, {"layer_params": [34, 57, 20, 35], "learning_rate": 0.009011883049483894, "batch_size": 106, "loss": 0.0028053599409759043}, {"layer_params": [32, 52, 44], "learning_rate": 0.0068109565516102245, "batch_size": 189, "loss": 0.001954682873329148}, {"layer_params": [58, 30, 41, 22], "learning_rate": 0.008907488937133874, "batch_size": 498, "loss": 0.0009327735804254189}, {"layer_params": [28, 56], "learning_rate": 0.006995726331828757, "batch_size": 271, "loss": 0.0019841898186132314}, {"layer_params": [49, 50], "learning_rate": 0.005050600162721055, "batch_size": 316, "loss": 0.0017875472130253912}, {"layer_params": [18, 49, 22, 29], "learning_rate": 0.008405593705281154, "batch_size": 197, "loss": 0.004576357847545296}, {"layer_params": [25, 51, 53], "learning_rate": 0.0006319798556146414, "batch_size": 188, "loss": 0.006668160073459149}, {"layer_params": [54, 53, 48], "learning_rate": 0.006529302750143261, "batch_size": 207, "loss": 0.0011942060670116917}, {"layer_params": [27, 63, 54, 43], "learning_rate": 0.0007871123109354009, "batch_size": 293, "loss": 0.003965389917138964}, {"layer_params": [31, 50, 45, 30, 34], "learning_rate": 0.0016636059543682993, "batch_size": 362, "loss": 0.0025281084002926947}, {"layer_params": [26, 48, 50], "learning_rate": 0.0022202010254565607, "batch_size": 351, "loss": 0.004042869629338384}, {"layer_params": [25, 17, 29, 60], "learning_rate": 0.0016420202184154514, "batch_size": 101, "loss": 0.004723460166715086}, {"layer_params": [62, 39, 27, 55, 20], "learning_rate": 0.0004917393921211573, "batch_size": 85, "loss": 0.006771057993173599}, {"layer_params": [22, 27], "learning_rate": 0.008023129951100287, "batch_size": 134, "loss": 0.0031325570377521215}, {"layer_params": [25, 16, 59, 37, 22], "learning_rate": 0.00884559350411865, "batch_size": 422, "loss": 0.002987728288862854}, {"layer_params": [34, 44, 33, 38, 21], "learning_rate": 0.005874599319802345, "batch_size": 498, "loss": 0.0018500564841087907}, {"layer_params": [50, 49, 34, 62], "learning_rate": 0.0023776844296329973, "batch_size": 109, "loss": 0.002511061157565564}, {"layer_params": [45, 52, 51], "learning_rate": 0.0004749649408036239, "batch_size": 462, "loss": 0.004850427373312414}, {"layer_params": [35, 62, 62, 58, 35], "learning_rate": 0.00157348410289231, "batch_size": 473, "loss": 0.0017842821346130222}, {"layer_params": [27, 47, 37, 26], "learning_rate": 0.007766836527070224, "batch_size": 374, "loss": 0.001886623208411038}, {"layer_params": [20, 35], "learning_rate": 0.0024991716987496785, "batch_size": 86, "loss": 0.004772438984364271}, {"layer_params": [35, 51, 50, 41, 58], "learning_rate": 0.003100956289724644, "batch_size": 125, "loss": 0.00236093032406643}, {"layer_params": [36, 59, 53], "learning_rate": 0.006588726990708559, "batch_size": 374, "loss": 0.0013376208150293679}, {"layer_params": [62, 61, 44], "learning_rate": 0.0019012760947808888, "batch_size": 17, "loss": 0.0061758768651634455}, {"layer_params": [33, 18, 57, 43], "learning_rate": 0.004133364261743527, "batch_size": 442, "loss": 0.0019075846555642784}, {"layer_params": [20, 57, 24], "learning_rate": 0.0073691724625658305, "batch_size": 116, "loss": 0.0026682073750998823}, {"layer_params": [30, 30, 48], "learning_rate": 0.0071572543937657536, "batch_size": 325, "loss": 0.0020205732726026326}, {"layer_params": [41, 50], "learning_rate": 0.006256670943058851, "batch_size": 136, "loss": 0.002416458446532488}, {"layer_params": [63, 33], "learning_rate": 0.0075442779822300484, "batch_size": 117, "loss": 0.0016140770085621625}, {"layer_params": [39, 58], "learning_rate": 0.007967264431240814, "batch_size": 36, "loss": 0.0031984377990011124}, {"layer_params": [47, 26, 24], "learning_rate": 0.009576103301120777, "batch_size": 422, "loss": 0.0018317170685622842}, {"layer_params": [44, 41, 45], "learning_rate": 0.005488509654326381, "batch_size": 329, "loss": 0.0012351181852864102}, {"layer_params": [60, 54, 45, 38], "learning_rate": 0.0018383370899195004, "batch_size": 347, "loss": 0.001584112134296447}, {"layer_params": [51, 36, 33, 17], "learning_rate": 0.005227794088269299, "batch_size": 307, "loss": 0.0010041538183577358}, {"layer_params": [51, 32, 27], "learning_rate": 0.001962530753126695, "batch_size": 179, "loss": 0.002753794041927904}, {"layer_params": [18, 24], "learning_rate": 0.0042607511988198, "batch_size": 74, "loss": 0.005113389038015157}, {"layer_params": [36, 59, 50, 64], "learning_rate": 0.0063926969432629354, "batch_size": 303, "loss": 0.0011472887103445828}, {"layer_params": [36, 33, 21, 64, 27], "learning_rate": 0.0010918944846132908, "batch_size": 238, "loss": 0.0028051248006522654}, {"layer_params": [21, 53, 22, 30], "learning_rate": 0.008264147957753891, "batch_size": 105, "loss": 0.004865805329754949}, {"layer_params": [21, 46], "learning_rate": 0.0007406423152435405, "batch_size": 189, "loss": 0.007543013500981033}, {"layer_params": [18, 24], "learning_rate": 0.0031500756505916717, "batch_size": 347, "loss": 0.0031914207083173097}, {"layer_params": [61, 56, 61, 33, 32], "learning_rate": 0.008884996944969775, "batch_size": 134, "loss": 0.0016141203267034142}, {"layer_params": [47, 16], "learning_rate": 0.004835896129330362, "batch_size": 124, "loss": 0.004240220997016877}, {"layer_params": [26, 58], "learning_rate": 0.007810089244819757, "batch_size": 259, "loss": 0.001618176643969491}, {"layer_params": [36, 54, 24, 17], "learning_rate": 0.008699926548096322, "batch_size": 53, "loss": 0.004139109530951828}, {"layer_params": [59, 58, 35, 64, 36], "learning_rate": 0.001895369634064469, "batch_size": 192, "loss": 0.0015968509926460683}, {"layer_params": [37, 16, 56, 58], "learning_rate": 0.0047602046217356565, "batch_size": 509, "loss": 0.00207159869838506}, {"layer_params": [34, 53, 27, 24, 24], "learning_rate": 0.001493266166170106, "batch_size": 395, "loss": 0.0024491997808218004}, {"layer_params": [42, 43, 35, 31], "learning_rate": 0.0027456717091190962, "batch_size": 313, "loss": 0.0020737156912218778}, {"layer_params": [26, 49, 57], "learning_rate": 0.004787541390633962, "batch_size": 151, "loss": 0.0017008120019454509}, {"layer_params": [61, 17, 45, 48], "learning_rate": 0.008957742072707822, "batch_size": 153, "loss": 0.0023153075366280974}, {"layer_params": [58, 42, 34], "learning_rate": 0.0010260619485795278, "batch_size": 167, "loss": 0.0026480117870960385}, {"layer_params": [57, 23], "learning_rate": 0.006942712020850337, "batch_size": 108, "loss": 0.002285824881400913}, {"layer_params": [60, 19, 32, 57, 58], "learning_rate": 0.009957761143118984, "batch_size": 47, "loss": 0.006646183435805142}, {"layer_params": [61, 18, 34], "learning_rate": 0.005741160453346646, "batch_size": 469, "loss": 0.001619233061792329}, {"layer_params": [27, 57, 22, 56, 36], "learning_rate": 0.004793492377731347, "batch_size": 129, "loss": 0.002361006207065657}, {"layer_params": [16, 47], "learning_rate": 0.0008473406985067173, "batch_size": 99, "loss": 0.007996462569572031}, {"layer_params": [17, 17], "learning_rate": 0.00815419853327151, "batch_size": 288, "loss": 0.005686272727325558}, {"layer_params": [60, 28, 23, 47], "learning_rate": 0.00017770430010470461, "batch_size": 36, "loss": 0.013344042473472656}, {"layer_params": [27, 17], "learning_rate": 0.0036066672181346783, "batch_size": 160, "loss": 0.004771216718945652}, {"layer_params": [34, 46, 46, 45, 45], "learning_rate": 0.0034021865658666463, "batch_size": 358, "loss": 0.002680229952093214}, {"layer_params": [20, 59, 40], "learning_rate": 0.009498698506329199, "batch_size": 168, "loss": 0.002302594234934077}, {"layer_params": [18, 17, 28, 53, 17], "learning_rate": 0.009883781023300278, "batch_size": 107, "loss": 0.007358661233447492}, {"layer_params": [36, 55, 62], "learning_rate": 0.0017825909819450259, "batch_size": 133, "loss": 0.0026768579997587948}, {"layer_params": [28, 39, 43, 50], "learning_rate": 0.0014188662921628937, "batch_size": 216, "loss": 0.0038281884603202344}, {"layer_params": [29, 32, 39, 26, 53], "learning_rate": 0.004693444741347619, "batch_size": 492, "loss": 0.0011076596763450652}, {"layer_params": [51, 50, 26, 34, 16], "learning_rate": 0.003298941443840571, "batch_size": 134, "loss": 0.037968874368816616}, {"layer_params": [30, 52, 20, 25], "learning_rate": 0.006568868782821987, "batch_size": 197, "loss": 0.001990293599665165}, {"layer_params": [62, 62], "learning_rate": 0.006906603451124395, "batch_size": 240, "loss": 0.0011154645297210663}, {"layer_params": [42, 17, 56, 57], "learning_rate": 0.0015914733135022167, "batch_size": 448, "loss": 0.002369948598789051}, {"layer_params": [55, 40, 32, 49, 50], "learning_rate": 0.004998686570333597, "batch_size": 73, "loss": 0.0028450972575228663}, {"layer_params": [46, 50, 18, 40, 21], "learning_rate": 0.0009319602534054722, "batch_size": 494, "loss": 0.0027805596054531635}, {"layer_params": [17, 36, 51, 54], "learning_rate": 0.008569237364896044, "batch_size": 83, "loss": 0.004524543688166887}, {"layer_params": [25, 43, 49, 53], "learning_rate": 0.006365404749189712, "batch_size": 128, "loss": 0.0032931603444740177}, {"layer_params": [46, 63, 22, 38], "learning_rate": 0.009049184413874261, "batch_size": 364, "loss": 0.0008889177505625412}, {"layer_params": [46, 18, 62], "learning_rate": 0.0059755027425467955, "batch_size": 128, "loss": 0.0038490547402761878}, {"layer_params": [61, 30, 24, 49], "learning_rate": 0.0027502951838796618, "batch_size": 372, "loss": 0.0019320490583777427}, {"layer_params": [51, 47, 34], "learning_rate": 0.0017416628638465856, "batch_size": 429, "loss": 0.0015568721923045815}, {"layer_params": [29, 21, 41, 30, 63], "learning_rate": 0.009507091360366478, "batch_size": 423, "loss": 0.002411989102838561}, {"layer_params": [25, 51], "learning_rate": 0.009924410594499226, "batch_size": 104, "loss": 0.0024299013486597685}, {"layer_params": [28, 63], "learning_rate": 0.00147574272681397, "batch_size": 26, "loss": 0.007199561004526913}, {"layer_params": [29, 35, 25, 25, 17], "learning_rate": 0.00960102125386247, "batch_size": 168, "loss": 0.0021937224688008427}, {"layer_params": [42, 42, 55], "learning_rate": 0.007380253345670873, "batch_size": 195, "loss": 0.0011719307990279049}, {"layer_params": [35, 49, 55, 39, 57], "learning_rate": 0.0063087025477660055, "batch_size": 379, "loss": 0.0007762775907758624}, {"layer_params": [50, 37, 38, 34], "learning_rate": 0.0004000203937601512, "batch_size": 310, "loss": 0.005937115824781358}, {"layer_params": [39, 25, 22, 21], "learning_rate": 0.006301630268978775, "batch_size": 17, "loss": 0.006837481642141938}, {"layer_params": [20, 23], "learning_rate": 0.007001464503325088, "batch_size": 49, "loss": 0.007771638841368258}, {"layer_params": [24, 47, 40, 59], "learning_rate": 0.007269440621608039, "batch_size": 378, "loss": 0.0017442417913116515}, {"layer_params": [52, 41, 16], "learning_rate": 0.006619799807499169, "batch_size": 142, "loss": 0.0017063928535208106}, {"layer_params": [40, 60], "learning_rate": 0.004439589413769502, "batch_size": 276, "loss": 0.0013724138401448726}, {"layer_params": [30, 59, 40, 41], "learning_rate": 0.007722121096008433, "batch_size": 315, "loss": 0.001756333624944091}, {"layer_params": [44, 38], "learning_rate": 0.005712347710228181, "batch_size": 393, "loss": 0.0017893842363264413}, {"layer_params": [53, 18], "learning_rate": 0.00016965177914621322, "batch_size": 368, "loss": 0.009007753636687994}, {"layer_params": [27, 36], "learning_rate": 0.004850333064023448, "batch_size": 145, "loss": 0.00428176547633484}, {"layer_params": [39, 61, 37], "learning_rate": 0.008158137991892243, "batch_size": 47, "loss": 0.003795923049328849}, {"layer_params": [36, 58, 57], "learning_rate": 0.006892419139156801, "batch_size": 476, "loss": 0.001157531151548028}, {"layer_params": [61, 22, 50, 34], "learning_rate": 0.004239776356781464, "batch_size": 384, "loss": 0.0011584421951556579}, {"layer_params": [31, 59, 52], "learning_rate": 0.00012630147383612016, "batch_size": 285, "loss": 0.00840833303052932}, {"layer_params": [24, 25], "learning_rate": 0.00958693130220139, "batch_size": 448, "loss": 0.002569845167454332}, {"layer_params": [53, 36, 26, 62, 28], "learning_rate": 0.008905603167942169, "batch_size": 35, "loss": 0.004464505693176761}, {"layer_params": [53, 62], "learning_rate": 0.006290191877814138, "batch_size": 46, "loss": 0.0031914348038844763}, {"layer_params": [19, 50, 34, 17], "learning_rate": 0.004859388424947347, "batch_size": 233, "loss": 0.002706277039833367}, {"layer_params": [37, 50, 58, 21], "learning_rate": 0.0024302290283421887, "batch_size": 397, "loss": 0.0013375310460105538}, {"layer_params": [42, 37, 61], "learning_rate": 0.003374018974158906, "batch_size": 182, "loss": 0.001920339516364038}, {"layer_params": [48, 35], "learning_rate": 0.0017633026186484302, "batch_size": 144, "loss": 0.004273300957866013}, {"layer_params": [58, 36, 22, 36, 59], "learning_rate": 0.0007143308082725904, "batch_size": 426, "loss": 0.002900155738461763}, {"layer_params": [32, 46, 54, 52], "learning_rate": 0.004741064007839286, "batch_size": 474, "loss": 0.0009985180047806352}, {"layer_params": [35, 22, 40], "learning_rate": 0.00226205838151696, "batch_size": 67, "loss": 0.004464382801670581}, {"layer_params": [58, 53], "learning_rate": 0.009893547678504389, "batch_size": 98, "loss": 0.0019678824685979636}, {"layer_params": [37, 29, 61, 31, 44], "learning_rate": 0.0004944412319085831, "batch_size": 359, "loss": 0.005648855287581682}, {"layer_params": [31, 17, 52], "learning_rate": 0.0011418946374787868, "batch_size": 182, "loss": 0.006109544546343386}, {"layer_params": [64, 55, 60], "learning_rate": 0.0006750705379918106, "batch_size": 479, "loss": 0.0021159119124058634}, {"layer_params": [24, 51, 53, 50, 27], "learning_rate": 0.005544565728005556, "batch_size": 496, "loss": 0.0011314857593970372}, {"layer_params": [22, 25], "learning_rate": 0.006566184495804333, "batch_size": 175, "loss": 0.004523861797060817}, {"layer_params": [41, 34, 17, 44, 23], "learning_rate": 2.384677650346188e-05, "batch_size": 55, "loss": 0.038071381449699404}, {"layer_params": [24, 31, 62, 57, 41], "learning_rate": 0.0009515661551861869, "batch_size": 312, "loss": 0.003239226832520217}, {"layer_params": [52, 45, 38, 61, 18], "learning_rate": 0.00032767236285340205, "batch_size": 353, "loss": 0.004183139554224908}, {"layer_params": [42, 48, 36, 31], "learning_rate": 0.00788230910803388, "batch_size": 357, "loss": 0.0013211480632890015}, {"layer_params": [55, 48, 34, 55], "learning_rate": 0.0023864149132112327, "batch_size": 172, "loss": 0.0016290433099493385}, {"layer_params": [47, 31, 64, 58], "learning_rate": 0.004509987892491806, "batch_size": 268, "loss": 0.0014539498812519015}, {"layer_params": [31, 23], "learning_rate": 0.004706476571789813, "batch_size": 459, "loss": 0.002148695377400145}, {"layer_params": [48, 22, 19, 55], "learning_rate": 0.006988865676270584, "batch_size": 256, "loss": 0.002050687347073108}, {"layer_params": [34, 60, 49, 37], "learning_rate": 0.008364175653525301, "batch_size": 216, "loss": 0.000825442336499691}, {"layer_params": [57, 25, 52], "learning_rate": 0.0012772440191726078, "batch_size": 66, "loss": 0.0040429970412515105}, {"layer_params": [36, 50, 17, 64], "learning_rate": 0.007496687608895934, "batch_size": 321, "loss": 0.0016862771206069738}, {"layer_params": [42, 36, 48, 34, 27], "learning_rate": 0.0031470614866830147, "batch_size": 439, "loss": 0.0016650166874751448}, {"layer_params": [17, 30, 18, 32], "learning_rate": 0.006998624245803803, "batch_size": 423, "loss": 0.0033422626298852264}, {"layer_params": [29, 61, 44, 25], "learning_rate": 0.0034814075493805516, "batch_size": 244, "loss": 0.001575768826296553}, {"layer_params": [37, 24, 49], "learning_rate": 0.008347887790604766, "batch_size": 315, "loss": 0.0014385832042898984}, {"layer_params": [58, 35, 38, 59, 35], "learning_rate": 0.009733704114849086, "batch_size": 329, "loss": 0.0017051710363011807}, {"layer_params": [35, 27, 40, 45, 17], "learning_rate": 0.002198437813191049, "batch_size": 311, "loss": 0.003152738749049604}, {"layer_params": [47, 44, 16, 50, 29], "learning_rate": 0.005343136024718939, "batch_size": 357, "loss": 0.0014313671807758511}, {"layer_params": [22, 25, 29], "learning_rate": 0.008465998362839589, "batch_size": 100, "loss": 0.005750965664628893}, {"layer_params": [55, 36, 49, 38], "learning_rate": 0.008968968159198143, "batch_size": 76, "loss": 0.0028536012012045833}, {"layer_params": [32, 36, 18], "learning_rate": 0.0011230257110650546, "batch_size": 326, "loss": 0.003583244732581079}, {"layer_params": [45, 51], "learning_rate": 0.0054680547715447924, "batch_size": 368, "loss": 0.0014451962138991802}, {"layer_params": [54, 25], "learning_rate": 0.004543432629436726, "batch_size": 425, "loss": 0.0023944499529898167}, {"layer_params": [29, 39], "learning_rate": 0.007335893741983373, "batch_size": 197, "loss": 0.002799592991359532}, {"layer_params": [54, 39, 49, 56], "learning_rate": 0.0033920499460170267, "batch_size": 268, "loss": 0.0016975824325345457}, {"layer_params": [27, 40], "learning_rate": 5.1104052053305545e-05, "batch_size": 429, "loss": 0.03570468014106155}, {"layer_params": [42, 39, 22, 38, 22], "learning_rate": 0.006731618717427256, "batch_size": 220, "loss": 0.002533748632995412}, {"layer_params": [24, 64, 25, 50], "learning_rate": 0.004114625446142652, "batch_size": 334, "loss": 0.001716336184181273}, {"layer_params": [64, 62, 62, 64], "learning_rate": 0.008846393558780823, "batch_size": 264, "loss": 0.0009823599446099251}, {"layer_params": [25, 37, 56, 63, 19], "learning_rate": 0.00223891610937878, "batch_size": 419, "loss": 0.0023222444811835884}, {"layer_params": [51, 45, 62], "learning_rate": 0.0030132571722296664, "batch_size": 354, "loss": 0.0014121178456116467}, {"layer_params": [40, 43], "learning_rate": 0.00035457512869109753, "batch_size": 60, "loss": 0.008385204845108091}, {"layer_params": [49, 64, 20, 35, 25], "learning_rate": 0.0023882726388599817, "batch_size": 421, "loss": 0.0014001521409954876}, {"layer_params": [43, 36, 24, 43, 63], "learning_rate": 0.0033897350391723867, "batch_size": 351, "loss": 0.0010852253250777722}, {"layer_params": [31, 27], "learning_rate": 0.0007610736388910791, "batch_size": 98, "loss": 0.008012944110669195}, {"layer_params": [24, 57, 36], "learning_rate": 0.004536274282397518, "batch_size": 169, "loss": 0.0020045050501357763}, {"layer_params": [43, 59, 27, 39, 32], "learning_rate": 0.0065081921219992825, "batch_size": 171, "loss": 0.0015987105458043515}, {"layer_params": [57, 53], "learning_rate": 0.008827689635484214, "batch_size": 43, "loss": 0.0034559552744030954}, {"layer_params": [51, 55, 41, 39, 38], "learning_rate": 0.0009780491889451479, "batch_size": 106, "loss": 0.0030529472185298803}, {"layer_params": [24, 43, 54], "learning_rate": 0.0009391522005102104, "batch_size": 240, "loss": 0.0037842010869644583}, {"layer_params": [40, 42, 29], "learning_rate": 0.005086950809984022, "batch_size": 414, "loss": 0.0016465293045621365}, {"layer_params": [20, 37], "learning_rate": 0.004679179163594628, "batch_size": 473, "loss": 0.0028944219183176757}, {"layer_params": [61, 16, 29, 22], "learning_rate": 0.005652467873951648, "batch_size": 402, "loss": 0.0029162711557000876}, {"layer_params": [54, 62, 47], "learning_rate": 0.00845963538843913, "batch_size": 335, "loss": 0.0011958926293300465}, {"layer_params": [63, 41, 33], "learning_rate": 0.004375954179285819, "batch_size": 49, "loss": 0.003940514943096786}, {"layer_params": [26, 20, 36, 37], "learning_rate": 0.0031258559215380367, "batch_size": 396, "loss": 0.0022074246359989045}, {"layer_params": [31, 59, 26, 31], "learning_rate": 0.008157361939612013, "batch_size": 201, "loss": 0.0026422217465005816}, {"layer_params": [35, 20, 38, 43, 31], "learning_rate": 0.0075711915060215915, "batch_size": 37, "loss": 0.005287268906831741}, {"layer_params": [46, 23], "learning_rate": 0.0018130474694668705, "batch_size": 310, "loss": 0.0044241165439598265}, {"layer_params": [19, 56, 16, 45, 17], "learning_rate": 0.009991361693256562, "batch_size": 451, "loss": 0.002335165572585538}, {"layer_params": [41, 56, 49, 50, 24], "learning_rate": 0.0013216146416669481, "batch_size": 201, "loss": 0.002546568042598665}, {"layer_params": [41, 34], "learning_rate": 0.00124663870954453, "batch_size": 359, "loss": 0.004008818513248116}, {"layer_params": [47, 18, 34], "learning_rate": 0.008114249994274762, "batch_size": 187, "loss": 0.0024232527730055154}, {"layer_params": [58, 29, 59], "learning_rate": 0.008978097907115958, "batch_size": 343, "loss": 0.0008540486317360773}, {"layer_params": [53, 18, 21], "learning_rate": 0.0001505513487820733, "batch_size": 267, "loss": 0.01890296841971576}, {"layer_params": [32, 58, 56, 28], "learning_rate": 0.004157610299857475, "batch_size": 359, "loss": 0.0011658072686986998}, {"layer_params": [33, 57, 48, 39, 29], "learning_rate": 0.003718679918997655, "batch_size": 473, "loss": 0.0015412472165189683}, {"layer_params": [55, 32, 19, 52, 40], "learning_rate": 0.007609800540689113, "batch_size": 95, "loss": 0.0033143537444993852}, {"layer_params": [39, 37, 52, 38], "learning_rate": 0.0032448265245210665, "batch_size": 61, "loss": 0.002736647088313475}, {"layer_params": [17, 64, 23, 51], "learning_rate": 0.0009117291680917394, "batch_size": 144, "loss": 0.006827649804763496}, {"layer_params": [23, 25, 34, 35], "learning_rate": 0.0060608535730009615, "batch_size": 156, "loss": 0.0033581159031018616}, {"layer_params": [19, 47, 38], "learning_rate": 0.003091248162599965, "batch_size": 331, "loss": 0.002346765100955963}, {"layer_params": [25, 34], "learning_rate": 0.006087783530124994, "batch_size": 297, "loss": 0.0034347787406295537}, {"layer_params": [55, 36, 63, 18, 34], "learning_rate": 0.0074742191813590595, "batch_size": 225, "loss": 0.001822546311886981}, {"layer_params": [26, 44], "learning_rate": 0.004646569257142917, "batch_size": 439, "loss": 0.003604912250302732}, {"layer_params": [37, 24], "learning_rate": 0.0045445186748284995, "batch_size": 286, "loss": 0.002747418333310634}, {"layer_params": [55, 60, 23, 17], "learning_rate": 0.009885300979177614, "batch_size": 316, "loss": 0.0016550173482391983}, {"layer_params": [45, 23, 39, 37], "learning_rate": 0.003263507260714305, "batch_size": 83, "loss": 0.003505363599397242}, {"layer_params": [46, 50], "learning_rate": 0.004862795840465992, "batch_size": 81, "loss": 0.0032071271538734437}, {"layer_params": [38, 18, 60, 56], "learning_rate": 0.004604232270560826, "batch_size": 140, "loss": 0.0021242427604738624}, {"layer_params": [26, 19], "learning_rate": 0.0035401839318408832, "batch_size": 442, "loss": 0.005022218632511795}, {"layer_params": [46, 45, 48, 16, 30], "learning_rate": 0.009372360089771877, "batch_size": 471, "loss": 0.0018806328251957894}, {"layer_params": [52, 42, 57, 26, 52], "learning_rate": 0.005082718629445259, "batch_size": 207, "loss": 0.0012423344724811613}, {"layer_params": [21, 36, 55], "learning_rate": 0.00812770559597335, "batch_size": 188, "loss": 0.0027283826167695223}, {"layer_params": [19, 53, 39, 60], "learning_rate": 0.003632446251888358, "batch_size": 20, "loss": 0.008158651918638498}, {"layer_params": [23, 63], "learning_rate": 0.008646422934863604, "batch_size": 90, "loss": 0.003993499111384153}, {"layer_params": [29, 32, 20, 42], "learning_rate": 0.0017614224329775476, "batch_size": 117, "loss": 0.005757871135137975}, {"layer_params": [37, 22], "learning_rate": 0.0076155118793186215, "batch_size": 100, "loss": 0.004778085569851101}, {"layer_params": [40, 37, 35, 33, 55], "learning_rate": 0.007952137105675484, "batch_size": 302, "loss": 0.0017079807515256106}, {"layer_params": [24, 40], "learning_rate": 0.002949881085874756, "batch_size": 366, "loss": 0.0032338994625024497}, {"layer_params": [52, 31], "learning_rate": 0.0013536713988224866, "batch_size": 140, "loss": 0.004011085957754404}, {"layer_params": [43, 48, 53, 47], "learning_rate": 0.007728642498679943, "batch_size": 197, "loss": 0.0015348414715845137}, {"layer_params": [38, 47, 21, 50, 40], "learning_rate": 0.0016621810323642825, "batch_size": 361, "loss": 0.0025916204240638762}, {"layer_params": [44, 20, 57, 52, 37], "learning_rate": 0.006032671268651412, "batch_size": 419, "loss": 0.0012544970994349568}, {"layer_params": [54, 30, 37], "learning_rate": 0.000548564641748693, "batch_size": 400, "loss": 0.00542110200971365}, {"layer_params": [48, 48], "learning_rate": 9.605794210712272e-05, "batch_size": 107, "loss": 0.02436261635273695}, {"layer_params": [22, 29, 36, 17], "learning_rate": 0.0009234633971021218, "batch_size": 311, "loss": 0.0049130589398555455}, {"layer_params": [24, 21], "learning_rate": 0.006065295695814238, "batch_size": 463, "loss": 0.002537483568303287}, {"layer_params": [35, 61, 55, 37], "learning_rate": 0.0017193384343897698, "batch_size": 157, "loss": 0.0021850392234046014}, {"layer_params": [42, 54], "learning_rate": 0.009015142744091669, "batch_size": 361, "loss": 0.001387614094419405}, {"layer_params": [51, 42, 18, 18], "learning_rate": 0.0010108627263307145, "batch_size": 90, "loss": 0.004745188658125699}, {"layer_params": [49, 26], "learning_rate": 0.0004291353615553253, "batch_size": 240, "loss": 0.007491848645731807}, {"layer_params": [62, 36, 40, 29, 35], "learning_rate": 0.0048805477676422465, "batch_size": 133, "loss": 0.002795649506151676}, {"layer_params": [36, 25, 42], "learning_rate": 0.00937869636318493, "batch_size": 257, "loss": 0.002110312640434131}, {"layer_params": [22, 39, 56, 47], "learning_rate": 7.360374066954355e-05, "batch_size": 224, "loss": 0.0174768643733114}, {"layer_params": [16, 35], "learning_rate": 0.00016956192602711725, "batch_size": 434, "loss": 0.02551268197596073}, {"layer_params": [57, 54, 59], "learning_rate": 0.006225110688286965, "batch_size": 504, "loss": 0.0010508365306304767}, {"layer_params": [50, 21, 64], "learning_rate": 0.009070974191236697, "batch_size": 317, "loss": 0.002733701737597585}, {"layer_params": [28, 34, 22, 19], "learning_rate": 0.004540617351852445, "batch_size": 169, "loss": 0.002958523901179433}, {"layer_params": [64, 24, 17, 19], "learning_rate": 0.002489017416094462, "batch_size": 312, "loss": 0.0018501062970608473}, {"layer_params": [45, 50, 21, 18, 24], "learning_rate": 0.004294310912787794, "batch_size": 274, "loss": 0.0019117733789607882}, {"layer_params": [38, 20, 30], "learning_rate": 0.008951873492818656, "batch_size": 135, "loss": 0.002454556431621313}, {"layer_params": [44, 44, 62, 35, 52], "learning_rate": 0.008240441119484779, "batch_size": 61, "loss": 0.002903045299462974}, {"layer_params": [32, 25], "learning_rate": 0.005565623274927428, "batch_size": 381, "loss": 0.0021716389269568026}, {"layer_params": [30, 44, 60, 16, 53], "learning_rate": 0.0058256846278565075, "batch_size": 501, "loss": 0.001452337974915281}, {"layer_params": [58, 51, 24, 43], "learning_rate": 0.0018446779231978403, "batch_size": 362, "loss": 0.0015937562624458224}, {"layer_params": [42, 64, 48], "learning_rate": 0.002773741392510812, "batch_size": 193, "loss": 0.001257300163852051}, {"layer_params": [54, 28, 39], "learning_rate": 0.0045186719217861545, "batch_size": 449, "loss": 0.0017965131567325443}, {"layer_params": [37, 39, 51, 48], "learning_rate": 0.004974328623348104, "batch_size": 466, "loss": 0.0012177434127079324}, {"layer_params": [59, 16, 34, 51], "learning_rate": 0.0024466025365058324, "batch_size": 351, "loss": 0.0025586946168914436}, {"layer_params": [28, 32, 51, 17, 20], "learning_rate": 0.007660614071937877, "batch_size": 336, "loss": 0.002397858212934807}, {"layer_params": [29, 55, 30], "learning_rate": 0.003475867561738393, "batch_size": 137, "loss": 0.0018405279738362879}, {"layer_params": [38, 25], "learning_rate": 0.008157260351316146, "batch_size": 91, "loss": 0.0050098582846112545}, {"layer_params": [28, 56], "learning_rate": 0.004485212313362936, "batch_size": 483, "loss": 0.0021604005293920634}, {"layer_params": [48, 64, 45, 17], "learning_rate": 0.009017065289124163, "batch_size": 181, "loss": 0.0012411921645980328}, {"layer_params": [64, 35, 57, 29, 33], "learning_rate": 0.008027152354054535, "batch_size": 84, "loss": 0.0026691709482111036}, {"layer_params": [31, 48], "learning_rate": 0.005330896611558438, "batch_size": 423, "loss": 0.001621613318566233}, {"layer_params": [34, 45, 42, 36], "learning_rate": 0.005560235883602314, "batch_size": 23, "loss": 0.005906097136903554}, {"layer_params": [58, 33, 21], "learning_rate": 0.0024457597610044817, "batch_size": 265, "loss": 0.0029220501612871887}, {"layer_params": [61, 33, 47, 50], "learning_rate": 0.0077568209665499896, "batch_size": 436, "loss": 0.002112771611427888}, {"layer_params": [24, 40, 33], "learning_rate": 0.0034477453944351086, "batch_size": 281, "loss": 0.003145331365521997}, {"layer_params": [21, 63], "learning_rate": 0.00374220562991057, "batch_size": 172, "loss": 0.004301116622518748}, {"layer_params": [30, 44, 45, 50, 20], "learning_rate": 0.001637865625636775, "batch_size": 127, "loss": 0.004678419437259436}, {"layer_params": [55, 62, 59], "learning_rate": 0.002752927685506574, "batch_size": 495, "loss": 0.0016238605545368045}, {"layer_params": [50, 35], "learning_rate": 0.0009944391424919576, "batch_size": 391, "loss": 0.0039438122138381005}, {"layer_params": [35, 32, 53], "learning_rate": 0.0022305681862500077, "batch_size": 492, "loss": 0.002382270684465766}, {"layer_params": [45, 57, 35, 18], "learning_rate": 0.00931193685213197, "batch_size": 405, "loss": 0.0008211930643301457}, {"layer_params": [31, 29], "learning_rate": 0.005431334461438822, "batch_size": 307, "loss": 0.0032551993755623697}, {"layer_params": [54, 54, 52], "learning_rate": 0.005532029307896104, "batch_size": 468, "loss": 0.0008814216282917186}, {"layer_params": [37, 63, 25, 43], "learning_rate": 0.006337476333631227, "batch_size": 280, "loss": 0.001154593451647088}, {"layer_params": [53, 37, 44], "learning_rate": 0.005295925894950267, "batch_size": 194, "loss": 0.0020126347860787066}, {"layer_params": [44, 44, 39], "learning_rate": 0.0059626450184621545, "batch_size": 477, "loss": 0.0017913233407307416}, {"layer_params": [35, 29, 60, 60, 30], "learning_rate": 0.0021729291140122446, "batch_size": 224, "loss": 0.002200103506911546}, {"layer_params": [28, 26, 58], "learning_rate": 0.007759582538217831, "batch_size": 61, "loss": 0.00503244117833674}, {"layer_params": [31, 39], "learning_rate": 1.4225259237603115e-05, "batch_size": 502, "loss": 0.0524589953571558}, {"layer_params": [56, 17, 55, 38, 38], "learning_rate": 0.009765270820377848, "batch_size": 464, "loss": 0.0016805843578185887}, {"layer_params": [20, 52, 18, 64], "learning_rate": 0.0036706372666542473, "batch_size": 110, "loss": 0.003957821391522885}, {"layer_params": [57, 23, 64, 30], "learning_rate": 0.00028864528981691686, "batch_size": 254, "loss": 0.006619350323453546}, {"layer_params": [30, 46, 48, 54], "learning_rate": 0.00675311758562605, "batch_size": 507, "loss": 0.001664925153600052}, {"layer_params": [38, 47, 20, 29], "learning_rate": 0.00013804017232355666, "batch_size": 316, "loss": 0.008944003158248962}, {"layer_params": [49, 31, 22, 22], "learning_rate": 0.001250984965380061, "batch_size": 297, "loss": 0.0030197045020759106}, {"layer_params": [16, 40, 33], "learning_rate": 0.005204455958088064, "batch_size": 295, "loss": 0.003842448794748634}, {"layer_params": [30, 64], "learning_rate": 0.00029934353919973806, "batch_size": 486, "loss": 0.007558363848365843}, {"layer_params": [40, 19, 54, 38], "learning_rate": 0.009191383638405465, "batch_size": 498, "loss": 0.001683269189670682}, {"layer_params": [17, 34, 18, 20, 47], "learning_rate": 0.0022409854908805554, "batch_size": 350, "loss": 0.003406982810702175}, {"layer_params": [40, 40, 27], "learning_rate": 0.009211934603025192, "batch_size": 205, "loss": 0.0014245519088581205}, {"layer_params": [50, 19, 47, 50], "learning_rate": 0.0028436224940272528, "batch_size": 133, "loss": 0.0027043437480460853}, {"layer_params": [39, 29, 24], "learning_rate": 0.007067159245836324, "batch_size": 298, "loss": 0.0025401659565977754}, {"layer_params": [57, 57], "learning_rate": 0.005096334544092541, "batch_size": 470, "loss": 0.001566812730161473}, {"layer_params": [55, 16], "learning_rate": 0.008018747584758285, "batch_size": 473, "loss": 0.0028464853344485164}, {"layer_params": [40, 23, 27], "learning_rate": 0.0035455960049505138, "batch_size": 129, "loss": 0.003083454973530024}, {"layer_params": [48, 42, 53], "learning_rate": 0.0010755689384107808, "batch_size": 379, "loss": 0.0024835271760821342}, {"layer_params": [41, 34, 30, 42], "learning_rate": 0.009213584295413616, "batch_size": 394, "loss": 0.003241360851097852}, {"layer_params": [41, 20, 62, 57, 22], "learning_rate": 0.007532919445570725, "batch_size": 231, "loss": 0.0018795270065311343}, {"layer_params": [21, 20, 31, 55, 30], "learning_rate": 0.003698243590106126, "batch_size": 247, "loss": 0.0048223617230542005}, {"layer_params": [64, 39, 19, 45], "learning_rate": 0.008234306985458446, "batch_size": 149, "loss": 0.001529067747760564}, {"layer_params": [45, 35], "learning_rate": 0.0003604724908770197, "batch_size": 376, "loss": 0.007046372056938708}, {"layer_params": [19, 29, 28, 20, 59], "learning_rate": 0.00824005863683007, "batch_size": 366, "loss": 0.0028643052047118544}, {"layer_params": [36, 47], "learning_rate": 0.004048211938569306, "batch_size": 226, "loss": 0.0038530452037230135}, {"layer_params": [52, 60], "learning_rate": 0.004404961519807679, "batch_size": 443, "loss": 0.0010450762498658151}, {"layer_params": [59, 30], "learning_rate": 0.00771608877852485, "batch_size": 477, "loss": 0.0016301980253774673}, {"layer_params": [16, 27, 16, 33, 45], "learning_rate": 0.008008205486039763, "batch_size": 240, "loss": 0.003730695191770792}, {"layer_params": [61, 40, 29, 48], "learning_rate": 0.009024147543883592, "batch_size": 104, "loss": 0.0023633271257858723}, {"layer_params": [46, 30, 33, 56, 45], "learning_rate": 0.00856056587092519, "batch_size": 261, "loss": 0.0014715569675900042}, {"layer_params": [43, 25], "learning_rate": 0.004658480903258533, "batch_size": 140, "loss": 0.004418388993944973}, {"layer_params": [37, 43], "learning_rate": 0.001659567473704434, "batch_size": 233, "loss": 0.0041804485907778145}, {"layer_params": [57, 44, 20, 19, 39], "learning_rate": 0.008438653088978133, "batch_size": 83, "loss": 0.003122203687671572}, {"layer_params": [35, 37], "learning_rate": 0.0025114130225910923, "batch_size": 232, "loss": 0.0023326319304760547}, {"layer_params": [61, 44, 28, 35], "learning_rate": 0.006367765427233745, "batch_size": 352, "loss": 0.0015186344785615802}, {"layer_params": [53, 48, 22, 28, 53], "learning_rate": 0.0015224005314920348, "batch_size": 147, "loss": 0.0027111091325059534}, {"layer_params": [48, 16], "learning_rate": 0.0009878188803300596, "batch_size": 211, "loss": 0.005918514826335013}, {"layer_params": [50, 20, 52, 40, 22], "learning_rate": 0.007435458023624505, "batch_size": 367, "loss": 0.0016153694165404887}, {"layer_params": [55, 34, 56, 37], "learning_rate": 0.007104501049696304, "batch_size": 126, "loss": 0.0014853220025543123}, {"layer_params": [26, 64], "learning_rate": 0.005889766174693164, "batch_size": 365, "loss": 0.0017473405576311051}, {"layer_params": [35, 54, 60, 20, 25], "learning_rate": 0.00572752726087808, "batch_size": 280, "loss": 0.0015289950231090188}, {"layer_params": [26, 47, 30], "learning_rate": 0.008703043948684722, "batch_size": 112, "loss": 0.00473435744876042}, {"layer_params": [26, 61, 25, 52], "learning_rate": 0.002451179225228959, "batch_size": 58, "loss": 0.004479470199439675}, {"layer_params": [23, 58, 57, 63], "learning_rate": 0.0036651673464273425, "batch_size": 314, "loss": 0.001616202153963968}, {"layer_params": [20, 42], "learning_rate": 0.00422281785592498, "batch_size": 445, "loss": 0.0024740850878879426}, {"layer_params": [32, 18, 48, 46], "learning_rate": 0.006485141635631997, "batch_size": 299, "loss": 0.001759997970657423}, {"layer_params": [33, 56], "learning_rate": 0.0035582323082226563, "batch_size": 53, "loss": 0.004661245888564735}, {"layer_params": [46, 21, 42], "learning_rate": 0.0001858050060763321, "batch_size": 405, "loss": 0.007780832569114864}, {"layer_params": [20, 46, 21, 33], "learning_rate": 0.005950563147143401, "batch_size": 472, "loss": 0.0021507375058718026}, {"layer_params": [64, 61, 25, 41, 38], "learning_rate": 0.009922105636226818, "batch_size": 342, "loss": 0.0015878322813659906}, {"layer_params": [18, 46, 49, 47, 45], "learning_rate": 0.0024230656164744733, "batch_size": 277, "loss": 0.002672006692737341}, {"layer_params": [40, 37, 52], "learning_rate": 0.00954915800166381, "batch_size": 201, "loss": 0.0012734499928774312}, {"layer_params": [30, 61], "learning_rate": 0.004891004064666136, "batch_size": 202, "loss": 0.002312681779731065}, {"layer_params": [39, 62, 29], "learning_rate": 0.008326570866462326, "batch_size": 487, "loss": 0.0010486848885193467}, {"layer_params": [31, 47, 50, 16], "learning_rate": 0.009194971667850601, "batch_size": 501, "loss": 0.0012259425141382962}, {"layer_params": [55, 42], "learning_rate": 0.0037304086495836804, "batch_size": 183, "loss": 0.001761328080901876}, {"layer_params": [27, 45], "learning_rate": 0.006818560219040265, "batch_size": 413, "loss": 0.0031607010285370054}, {"layer_params": [39, 60, 42, 58, 17], "learning_rate": 0.007153689604477361, "batch_size": 404, "loss": 0.0009762004431104288}, {"layer_params": [39, 52, 27], "learning_rate": 0.0033470871027629716, "batch_size": 36, "loss": 0.005703204711899161}, {"layer_params": [24, 45, 51, 37, 39], "learning_rate": 0.005350946156523825, "batch_size": 64, "loss": 0.004738611520733685}, {"layer_params": [53, 32, 45], "learning_rate": 0.003374115887283276, "batch_size": 351, "loss": 0.0018261131877079606}, {"layer_params": [49, 63, 25], "learning_rate": 0.007214549207971756, "batch_size": 447, "loss": 0.001129707784857601}, {"layer_params": [58, 29, 19], "learning_rate": 0.0004604385002363465, "batch_size": 200, "loss": 0.006485750530846417}, {"layer_params": [62, 20, 32, 43, 18], "learning_rate": 0.0001464119728576539, "batch_size": 370, "loss": 0.007907849857583643}, {"layer_params": [63, 49, 43, 49], "learning_rate": 6.823873352644597e-05, "batch_size": 432, "loss": 0.02104168275371194}, {"layer_params": [16, 35], "learning_rate": 0.0028739966497633085, "batch_size": 511, "loss": 0.004666532126720995}, {"layer_params": [52, 39], "learning_rate": 0.0073833239293133075, "batch_size": 496, "loss": 0.002894994814414531}, {"layer_params": [44, 19, 33, 59, 50], "learning_rate": 0.0011169347233990995, "batch_size": 176, "loss": 0.004193948502652347}, {"layer_params": [56, 43, 23], "learning_rate": 0.00378716903129597, "batch_size": 360, "loss": 0.00166733501246199}, {"layer_params": [58, 46, 34, 60, 64], "learning_rate": 0.0075955097923954456, "batch_size": 127, "loss": 0.0026061206869781015}, {"layer_params": [17, 61, 34, 36, 50], "learning_rate": 0.0027431766139986956, "batch_size": 501, "loss": 0.002650292732287198}, {"layer_params": [43, 62], "learning_rate": 0.008257314069107851, "batch_size": 373, "loss": 0.0013045572256669402}, {"layer_params": [45, 64, 35, 45], "learning_rate": 0.009522250720278819, "batch_size": 475, "loss": 0.0017847144196275623}, {"layer_params": [48, 25], "learning_rate": 0.005360121006076141, "batch_size": 51, "loss": 0.004084124162327498}, {"layer_params": [41, 45], "learning_rate": 0.009583405127847814, "batch_size": 303, "loss": 0.0023123953747563064}, {"layer_params": [32, 58], "learning_rate": 0.0067427954915825926, "batch_size": 464, "loss": 0.0017562464566435664}, {"layer_params": [31, 35, 48, 20, 19], "learning_rate": 0.007269748004090734, "batch_size": 243, "loss": 0.0021574941743165254}, {"layer_params": [51, 19], "learning_rate": 0.001642829708303331, "batch_size": 389, "loss": 0.0029795248154550792}, {"layer_params": [31, 61], "learning_rate": 0.0031968615180151673, "batch_size": 335, "loss": 0.002859071125276387}, {"layer_params": [54, 39, 24, 24], "learning_rate": 0.005668402851654111, "batch_size": 314, "loss": 0.0012625164387281985}, {"layer_params": [40, 56, 19], "learning_rate": 0.0033680884204574705, "batch_size": 370, "loss": 0.0014393574511632323}, {"layer_params": [39, 31, 51], "learning_rate": 0.007308512317623176, "batch_size": 377, "loss": 0.0016300191509071738}, {"layer_params": [42, 46, 17, 21, 30], "learning_rate": 0.0048860135881987204, "batch_size": 150, "loss": 0.0014697382308077067}, {"layer_params": [46, 50, 21], "learning_rate": 0.008538812965417433, "batch_size": 144, "loss": 0.0020550528820604086}, {"layer_params": [64, 29], "learning_rate": 0.002245349007506145, "batch_size": 110, "loss": 0.004328207483049482}, {"layer_params": [32, 48, 30, 30, 21], "learning_rate": 0.0012044089008494843, "batch_size": 335, "loss": 0.0027120642317458987}, {"layer_params": [28, 40, 51], "learning_rate": 0.000487289306143089, "batch_size": 371, "loss": 0.0051839238498359915}, {"layer_params": [62, 32, 60, 51], "learning_rate": 0.004857571758562091, "batch_size": 96, "loss": 0.0030767296836711464}, {"layer_params": [27, 35, 48, 46], "learning_rate": 0.005632845061784193, "batch_size": 395, "loss": 0.0016053707979153842}, {"layer_params": [44, 50, 51, 25], "learning_rate": 0.009747187255149978, "batch_size": 40, "loss": 0.0038813006691634654}, {"layer_params": [54, 59, 56, 43, 51], "learning_rate": 0.002715240925213253, "batch_size": 163, "loss": 0.0011038859613472596}, {"layer_params": [49, 24, 26, 58], "learning_rate": 0.004060632993747164, "batch_size": 469, "loss": 0.001806013355962932}, {"layer_params": [34, 44, 39], "learning_rate": 0.00404943247457925, "batch_size": 169, "loss": 0.0028201407031156122}, {"layer_params": [52, 42], "learning_rate": 0.009583193794243673, "batch_size": 39, "loss": 0.0037018407171126454}, {"layer_params": [24, 59, 43], "learning_rate": 0.006545638639048151, "batch_size": 111, "loss": 0.0025810088438447563}, {"layer_params": [37, 49, 32, 23], "learning_rate": 0.004581519754124347, "batch_size": 33, "loss": 0.005513770198449492}, {"layer_params": [37, 33, 49], "learning_rate": 0.0036119695169150377, "batch_size": 452, "loss": 0.002303300395142287}, {"layer_params": [64, 47], "learning_rate": 0.00122276869507452, "batch_size": 168, "loss": 0.0033848257409408687}, {"layer_params": [59, 59, 59, 47], "learning_rate": 0.00831160795182943, "batch_size": 426, "loss": 0.0009466436563525349}, {"layer_params": [56, 19, 58, 53, 43], "learning_rate": 0.008630261178087852, "batch_size": 50, "loss": 0.005554716107435524}, {"layer_params": [29, 17], "learning_rate": 0.004377423585903048, "batch_size": 341, "loss": 0.003829665584489703}, {"layer_params": [62, 53, 63, 63], "learning_rate": 0.0084220771814803, "batch_size": 399, "loss": 0.0010845221538329497}, {"layer_params": [20, 32], "learning_rate": 0.005385347890190011, "batch_size": 127, "loss": 0.0051567074470222}, {"layer_params": [49, 58, 38, 63], "learning_rate": 0.0026035414569448444, "batch_size": 200, "loss": 0.0021282415080349894}, {"layer_params": [30, 33, 62, 43, 53], "learning_rate": 0.0020068921763458374, "batch_size": 382, "loss": 0.0013685226277448236}, {"layer_params": [24, 37, 41], "learning_rate": 0.006355458026174937, "batch_size": 496, "loss": 0.0022574039129540325}, {"layer_params": [39, 23, 22, 25], "learning_rate": 0.004284974483863874, "batch_size": 48, "loss": 0.00543342376826331}, {"layer_params": [33, 21, 46, 58, 41], "learning_rate": 0.008538362939840605, "batch_size": 279, "loss": 0.0018994800804648549}, {"layer_params": [31, 59, 61], "learning_rate": 0.005294522906052456, "batch_size": 241, "loss": 0.0015159587922971695}, {"layer_params": [58, 52, 20, 41, 43], "learning_rate": 0.009899728154275922, "batch_size": 250, "loss": 0.0017025888303760439}, {"layer_params": [51, 19, 19, 46], "learning_rate": 0.006416577660632824, "batch_size": 191, "loss": 0.0021034166449680923}, {"layer_params": [47, 31, 24, 47, 28], "learning_rate": 0.005621577790907602, "batch_size": 461, "loss": 0.0011575921491021291}, {"layer_params": [17, 17, 18], "learning_rate": 0.0025567180882228257, "batch_size": 16, "loss": 0.008149790610186756}, {"layer_params": [53, 29], "learning_rate": 0.00466827133126282, "batch_size": 246, "loss": 0.0024495254654902966}, {"layer_params": [36, 25], "learning_rate": 0.0014271333890909107, "batch_size": 455, "loss": 0.004828750344458967}, {"layer_params": [20, 62, 49], "learning_rate": 0.001150580138977995, "batch_size": 117, "loss": 0.006034865216352045}, {"layer_params": [23, 39, 34, 46, 27], "learning_rate": 0.005233357713932031, "batch_size": 455, "loss": 0.0012645154719939456}, {"layer_params": [41, 26], "learning_rate": 0.007037419649490225, "batch_size": 169, "loss": 0.0036669992306269704}, {"layer_params": [51, 31, 61, 48], "learning_rate": 0.0015737082106845402, "batch_size": 226, "loss": 0.0018453719245735557}, {"layer_params": [21, 53], "learning_rate": 2.739876378333551e-05, "batch_size": 438, "loss": 0.03667985297739506}, {"layer_params": [36, 57, 17, 44, 61], "learning_rate": 0.006440960651348505, "batch_size": 119, "loss": 0.002556860065087676}, {"layer_params": [51, 20, 27, 61, 59], "learning_rate": 0.0050039530939429925, "batch_size": 366, "loss": 0.0021029159077443184}, {"layer_params": [35, 28, 34], "learning_rate": 0.0017868556514915067, "batch_size": 186, "loss": 0.003251389809884131}, {"layer_params": [24, 58, 47], "learning_rate": 0.003440860853358679, "batch_size": 447, "loss": 0.0019503293826710433}, {"layer_params": [18, 36, 38, 26], "learning_rate": 0.008560270148197503, "batch_size": 166, "loss": 0.0035832887911237776}, {"layer_params": [51, 46, 40, 55], "learning_rate": 0.006173159642205152, "batch_size": 286, "loss": 0.0016294302081223577}, {"layer_params": [41, 47], "learning_rate": 0.009187457351479841, "batch_size": 340, "loss": 0.002217711489647627}, {"layer_params": [54, 20, 40], "learning_rate": 0.008773750615492683, "batch_size": 468, "loss": 0.001959591544000432}, {"layer_params": [61, 35, 55], "learning_rate": 0.007307173423899764, "batch_size": 124, "loss": 0.001800328316166997}, {"layer_params": [47, 29, 31, 17, 49], "learning_rate": 0.006505769969783053, "batch_size": 94, "loss": 0.005155072410125285}, {"layer_params": [63, 54, 34, 45], "learning_rate": 0.0032337836492764118, "batch_size": 266, "loss": 0.0016229212051257491}, {"layer_params": [19, 22, 45], "learning_rate": 0.009827192471872066, "batch_size": 386, "loss": 0.002968226205557585}, {"layer_params": [40, 45], "learning_rate": 0.007691313476709156, "batch_size": 480, "loss": 0.0012638571456773206}, {"layer_params": [24, 54], "learning_rate": 0.0061254985085458895, "batch_size": 23, "loss": 0.006169747186359018}, {"layer_params": [25, 27], "learning_rate": 0.005062566965459206, "batch_size": 27, "loss": 0.007426285168621689}, {"layer_params": [49, 37, 64, 19], "learning_rate": 0.00046487295394869035, "batch_size": 471, "loss": 0.003911482484545559}, {"layer_params": [37, 59, 22, 62, 26], "learning_rate": 0.0019296647222401952, "batch_size": 56, "loss": 0.004385144524276257}, {"layer_params": [37, 40, 39], "learning_rate": 0.0035742985512420135, "batch_size": 223, "loss": 0.0022928462468553333}, {"layer_params": [33, 55], "learning_rate": 0.0059284756872584185, "batch_size": 401, "loss": 0.0016254548996221274}, {"layer_params": [48, 17, 32, 25], "learning_rate": 0.005606157193982664, "batch_size": 101, "loss": 0.0021911390882451086}, {"layer_params": [52, 46], "learning_rate": 0.001843435527987605, "batch_size": 205, "loss": 0.003084260858595371}, {"layer_params": [55, 51, 32, 49], "learning_rate": 0.0010716797483768465, "batch_size": 352, "loss": 0.0022692225605715067}, {"layer_params": [51, 56, 64, 16], "learning_rate": 0.005400855255597545, "batch_size": 317, "loss": 0.0010711236111819744}, {"layer_params": [32, 46, 43, 55], "learning_rate": 0.008505622701633003, "batch_size": 226, "loss": 0.0018764598481357097}, {"layer_params": [50, 16, 52, 22, 22], "learning_rate": 0.0044638369346612404, "batch_size": 458, "loss": 0.0032158312597312033}, {"layer_params": [53, 28], "learning_rate": 0.00829299415758706, "batch_size": 36, "loss": 0.006012695878744125}, {"layer_params": [45, 63, 57], "learning_rate": 0.0013894559840435586, "batch_size": 228, "loss": 0.001820085239596665}, {"layer_params": [58, 36, 29, 34], "learning_rate": 0.001531495884016324, "batch_size": 201, "loss": 0.002086669458076358}, {"layer_params": [61, 44, 19, 16, 48], "learning_rate": 0.0016354119882484317, "batch_size": 135, "loss": 0.0024134370009414852}, {"layer_params": [55, 56, 41, 17, 62], "learning_rate": 0.008193401064962585, "batch_size": 425, "loss": 0.0007307461678283289}, {"layer_params": [46, 63, 64], "learning_rate": 0.009831378417484922, "batch_size": 404, "loss": 0.001563975237077102}, {"layer_params": [40, 50, 48, 61, 51], "learning_rate": 0.0073453487730465485, "batch_size": 447, "loss": 0.0008494707808131352}, {"layer_params": [34, 43, 29, 35, 49], "learning_rate": 0.006177129265021266, "batch_size": 241, "loss": 0.0020652669633273034}, {"layer_params": [17, 49, 30, 58, 59], "learning_rate": 0.005648500205139319, "batch_size": 214, "loss": 0.0019806680106557906}, {"layer_params": [35, 27, 21, 28, 63], "learning_rate": 0.002341056328520624, "batch_size": 230, "loss": 0.003240189515054226}, {"layer_params": [29, 38], "learning_rate": 0.0014245412776280539, "batch_size": 427, "loss": 0.004080308403354138}, {"layer_params": [59, 54], "learning_rate": 0.00664119440441601, "batch_size": 372, "loss": 0.0022156437335070223}, {"layer_params": [55, 29], "learning_rate": 0.004764217658326409, "batch_size": 455, "loss": 0.002772589419037104}, {"layer_params": [63, 29, 16, 17], "learning_rate": 0.009404050194411075, "batch_size": 330, "loss": 0.002298377427505329}, {"layer_params": [63, 33, 46], "learning_rate": 0.003368343164505587, "batch_size": 419, "loss": 0.001358483664225787}, {"layer_params": [40, 29, 16], "learning_rate": 3.277651618562633e-05, "batch_size": 467, "loss": 0.03678338821977377}, {"layer_params": [24, 26, 24, 48, 34], "learning_rate": 0.0022254725795648497, "batch_size": 306, "loss": 0.002422758938046172}, {"layer_params": [44, 59, 20], "learning_rate": 0.00017008713553847657, "batch_size": 378, "loss": 0.007723331730812788}, {"layer_params": [37, 27, 26], "learning_rate": 0.00500115251129265, "batch_size": 462, "loss": 0.002033606709446758}, {"layer_params": [42, 52], "learning_rate": 0.009660543352231366, "batch_size": 119, "loss": 0.0024997096392326058}, {"layer_params": [34, 35, 55, 58], "learning_rate": 0.00357498008683334, "batch_size": 435, "loss": 0.0018603147903922944}, {"layer_params": [44, 46], "learning_rate": 0.00835183889919242, "batch_size": 98, "loss": 0.0021837063902057706}, {"layer_params": [30, 31], "learning_rate": 0.009980974594911034, "batch_size": 119, "loss": 0.004716412466950715}, {"layer_params": [49, 24, 44, 59], "learning_rate": 0.0007286565335392675, "batch_size": 434, "loss": 0.0034095782251097263}, {"layer_params": [39, 50, 48, 32, 34], "learning_rate": 0.009259963786398708, "batch_size": 30, "loss": 0.005332877251785249}, {"layer_params": [63, 17], "learning_rate": 0.000958195622278317, "batch_size": 155, "loss": 0.0059187063295394185}, {"layer_params": [28, 60, 53], "learning_rate": 0.0014130993606117225, "batch_size": 269, "loss": 0.0027255343506112696}, {"layer_params": [17, 21, 38, 36], "learning_rate": 0.009273406336969117, "batch_size": 193, "loss": 0.002565807212376967}, {"layer_params": [26, 49, 39], "learning_rate": 0.003339334912266615, "batch_size": 502, "loss": 0.0022260236355941742}, {"layer_params": [62, 47, 41, 55, 35], "learning_rate": 0.0019909522310626285, "batch_size": 150, "loss": 0.0017703826655633748}, {"layer_params": [18, 21, 30, 51, 30], "learning_rate": 0.008153996121357024, "batch_size": 81, "loss": 0.004078516447916627}, {"layer_params": [33, 55, 62, 57], "learning_rate": 0.00711254208650704, "batch_size": 269, "loss": 0.0009887862240429968}, {"layer_params": [60, 22, 46, 47], "learning_rate": 0.004553023385149847, "batch_size": 367, "loss": 0.0011167273548198864}, {"layer_params": [43, 35, 17, 39], "learning_rate": 0.007825550514300204, "batch_size": 477, "loss": 0.002089394717477262}, {"layer_params": [43, 21, 50], "learning_rate": 0.0008849400848375498, "batch_size": 184, "loss": 0.007256884085945785}, {"layer_params": [59, 17, 25, 48, 19], "learning_rate": 0.005094443812327816, "batch_size": 166, "loss": 0.0019352124305441975}, {"layer_params": [54, 47, 62, 56, 47], "learning_rate": 0.008028820109554803, "batch_size": 361, "loss": 0.0008917502203257755}, {"layer_params": [47, 47, 38, 64, 28], "learning_rate": 0.003864086218811589, "batch_size": 193, "loss": 0.0016076296579558402}, {"layer_params": [63, 48], "learning_rate": 0.0009691118423163042, "batch_size": 185, "loss": 0.004927454756107182}, {"layer_params": [18, 52], "learning_rate": 0.0007033884105500159, "batch_size": 311, "loss": 0.007173633952625096}, {"layer_params": [61, 18, 57], "learning_rate": 0.009184873121567542, "batch_size": 291, "loss": 0.0025760630762670187}, {"layer_params": [24, 33, 31, 50], "learning_rate": 0.005723037839379302, "batch_size": 475, "loss": 0.0013681114721111954}, {"layer_params": [41, 19, 25], "learning_rate": 0.0017267109659671583, "batch_size": 242, "loss": 0.0032622621720656752}, {"layer_params": [38, 42], "learning_rate": 0.006622880658060418, "batch_size": 253, "loss": 0.002270148113602772}, {"layer_params": [35, 64, 29], "learning_rate": 0.006463520294927907, "batch_size": 133, "loss": 0.0024521421606186777}, {"layer_params": [26, 29], "learning_rate": 0.009094593472736019, "batch_size": 106, "loss": 0.005976495486684144}, {"layer_params": [24, 48, 26, 29], "learning_rate": 0.007027135365335789, "batch_size": 291, "loss": 0.0020359760615974664}, {"layer_params": [35, 16], "learning_rate": 0.0013937596918647938, "batch_size": 27, "loss": 0.007746770465746522}, {"layer_params": [42, 64], "learning_rate": 0.001342598071026842, "batch_size": 45, "loss": 0.006855384260416031}, {"layer_params": [45, 50, 46], "learning_rate": 0.007937359089269541, "batch_size": 358, "loss": 0.0010479176859371365}, {"layer_params": [59, 20, 34, 21, 45], "learning_rate": 0.000613319591723517, "batch_size": 384, "loss": 0.0040871482691727575}, {"layer_params": [54, 21, 43, 35], "learning_rate": 0.0036979241614368526, "batch_size": 488, "loss": 0.0011878375872038304}, {"layer_params": [26, 34, 32, 63, 18], "learning_rate": 0.005144947060931165, "batch_size": 384, "loss": 0.0017252893932163714}, {"layer_params": [63, 34], "learning_rate": 0.0027375813649816888, "batch_size": 33, "loss": 0.005315655751619488}, {"layer_params": [46, 51, 46, 28, 47], "learning_rate": 0.005848376366295829, "batch_size": 221, "loss": 0.001551363862818107}, {"layer_params": [29, 27, 57, 45, 22], "learning_rate": 0.008008766810374438, "batch_size": 103, "loss": 0.004511215784586966}, {"layer_params": [47, 17, 22], "learning_rate": 0.008831959637487377, "batch_size": 352, "loss": 0.002598077522125095}, {"layer_params": [56, 59, 17, 32, 32], "learning_rate": 0.008796829917806562, "batch_size": 235, "loss": 0.0014894530456513167}, {"layer_params": [36, 60, 28], "learning_rate": 0.007993942867808237, "batch_size": 212, "loss": 0.0014629571174737065}, {"layer_params": [63, 48, 28], "learning_rate": 0.006837209268526724, "batch_size": 32, "loss": 0.0032689389144070448}, {"layer_params": [44, 61, 63, 63, 21], "learning_rate": 0.0055700571192854945, "batch_size": 334, "loss": 0.001133022855501622}, {"layer_params": [16, 30, 48, 50, 41], "learning_rate": 0.009702724172586337, "batch_size": 57, "loss": 0.008001193567179144}, {"layer_params": [36, 45, 60], "learning_rate": 0.003439591244194028, "batch_size": 292, "loss": 0.0014715709653683007}, {"layer_params": [32, 40, 21], "learning_rate": 0.0077033693114855195, "batch_size": 81, "loss": 0.0033024010527879}, {"layer_params": [24, 35, 47, 29], "learning_rate": 0.005759153795141372, "batch_size": 117, "loss": 0.0033243352361023424}, {"layer_params": [59, 60], "learning_rate": 0.00017928936586589868, "batch_size": 252, "loss": 0.008435317524708807}, {"layer_params": [29, 39, 55], "learning_rate": 0.00821388577561251, "batch_size": 153, "loss": 0.0018521644035354257}, {"layer_params": [25, 16], "learning_rate": 0.0050102047445164215, "batch_size": 506, "loss": 0.002784259472973645}, {"layer_params": [31, 34, 32, 28, 44], "learning_rate": 0.004562814730373712, "batch_size": 224, "loss": 0.0028506914037279784}, {"layer_params": [25, 37], "learning_rate": 0.00454439461118655, "batch_size": 454, "loss": 0.00295059823198244}, {"layer_params": [58, 24, 34], "learning_rate": 0.003237967957861715, "batch_size": 464, "loss": 0.0017839656479191036}, {"layer_params": [53, 41, 34, 48], "learning_rate": 0.00964557924454717, "batch_size": 39, "loss": 0.0029640368814580144}, {"layer_params": [25, 51, 33, 61], "learning_rate": 0.004688630474332943, "batch_size": 68, "loss": 0.003413634633179754}, {"layer_params": [35, 62, 49, 26, 23], "learning_rate": 0.006348786085137172, "batch_size": 465, "loss": 0.001363112411927432}, {"layer_params": [36, 33, 42, 34, 52], "learning_rate": 0.008559286440057944, "batch_size": 268, "loss": 0.0018858450453262776}, {"layer_params": [45, 64, 50, 63], "learning_rate": 0.0038762897017422986, "batch_size": 391, "loss": 0.0010209323978051543}, {"layer_params": [24, 61, 60, 21, 33], "learning_rate": 0.009358286502988727, "batch_size": 445, "loss": 0.0015082708757836372}, {"layer_params": [38, 61], "learning_rate": 0.0064158943949027755, "batch_size": 308, "loss": 0.001747127854032442}, {"layer_params": [49, 64], "learning_rate": 0.009875956690629467, "batch_size": 191, "loss": 0.0015243552206084133}, {"layer_params": [51, 21, 52, 25, 62], "learning_rate": 0.005929414766573569, "batch_size": 86, "loss": 0.004907582709565758}, {"layer_params": [40, 17, 47, 49, 48], "learning_rate": 0.0038771432720001997, "batch_size": 410, "loss": 0.0023532809608150275}, {"layer_params": [28, 23, 62], "learning_rate": 0.005943467329866393, "batch_size": 320, "loss": 0.0029379394045099616}, {"layer_params": [59, 54], "learning_rate": 0.007134279363961749, "batch_size": 490, "loss": 0.0009600731352111324}, {"layer_params": [61, 43, 55, 26], "learning_rate": 0.0013036581876906205, "batch_size": 395, "loss": 0.0018875875626690685}, {"layer_params": [26, 33, 16, 32, 64], "learning_rate": 0.006873456783108717, "batch_size": 96, "loss": 0.0032989481650292874}, {"layer_params": [26, 45], "learning_rate": 0.00855167686248421, "batch_size": 473, "loss": 0.0027245225477963687}, {"layer_params": [26, 62, 38, 34], "learning_rate": 0.006191711764516748, "batch_size": 57, "loss": 0.0037067010230384767}, {"layer_params": [47, 53, 25, 64, 41], "learning_rate": 0.009030433537782873, "batch_size": 209, "loss": 0.0014907535212114454}, {"layer_params": [38, 25], "learning_rate": 0.006238671530833926, "batch_size": 326, "loss": 0.002563995837699622}, {"layer_params": [53, 30, 57, 35, 46], "learning_rate": 0.0007177304967925977, "batch_size": 273, "loss": 0.0040305449394509195}, {"layer_params": [44, 28, 37], "learning_rate": 0.009993532873864445, "batch_size": 100, "loss": 0.003408406510716304}, {"layer_params": [43, 44], "learning_rate": 0.009027037048528194, "batch_size": 48, "loss": 0.0034025277802720664}, {"layer_params": [53, 64, 28], "learning_rate": 0.006055409321839561, "batch_size": 52, "loss": 0.00291995873558335}, {"layer_params": [32, 61, 33, 33, 22], "learning_rate": 0.0015599110704062028, "batch_size": 462, "loss": 0.002106622859137133}, {"layer_params": [59, 61, 28], "learning_rate": 0.008606770058116268, "batch_size": 402, "loss": 0.0015419374767225236}, {"layer_params": [56, 41, 58], "learning_rate": 0.0027503755003896644, "batch_size": 226, "loss": 0.002180631390074268}, {"layer_params": [56, 32, 22, 39, 39], "learning_rate": 0.007222457267171274, "batch_size": 200, "loss": 0.0024950035312213004}, {"layer_params": [42, 64, 57, 55, 35], "learning_rate": 0.00529283899182847, "batch_size": 171, "loss": 0.0010889895528089254}, {"layer_params": [24, 51], "learning_rate": 0.002789054429734198, "batch_size": 36, "loss": 0.005135429685469717}, {"layer_params": [53, 50], "learning_rate": 0.00286583182878454, "batch_size": 49, "loss": 0.002420930771622807}, {"layer_params": [39, 60], "learning_rate": 0.003908487473917175, "batch_size": 176, "loss": 0.0015502151811961084}, {"layer_params": [27, 53, 41], "learning_rate": 0.0021405718969195716, "batch_size": 403, "loss": 0.001724161384627223}, {"layer_params": [24, 26, 32, 53], "learning_rate": 0.004498658240616303, "batch_size": 312, "loss": 0.0028222900838591157}, {"layer_params": [35, 64, 64, 42, 56], "learning_rate": 0.0074756922530530255, "batch_size": 268, "loss": 0.0008683068631216884}, {"layer_params": [44, 50, 54], "learning_rate": 0.0007269770391212159, "batch_size": 370, "loss": 0.003505618912167847}, {"layer_params": [17, 51], "learning_rate": 0.005625873312671943, "batch_size": 75, "loss": 0.0042288480000570415}, {"layer_params": [50, 16], "learning_rate": 0.005201777342816576, "batch_size": 164, "loss": 0.004112199791707099}, {"layer_params": [42, 38, 17, 46, 61], "learning_rate": 0.009196559189273711, "batch_size": 479, "loss": 0.0013803494942840188}, {"layer_params": [44, 19, 27, 64, 25], "learning_rate": 0.0030942662132627577, "batch_size": 216, "loss": 0.003010075364727527}, {"layer_params": [21, 34, 47, 53, 16], "learning_rate": 0.00942872465993417, "batch_size": 66, "loss": 0.0040081988065503536}, {"layer_params": [47, 41, 43, 63], "learning_rate": 0.0031864096161654744, "batch_size": 282, "loss": 0.001704609610605985}, {"layer_params": [39, 16, 26, 17, 50], "learning_rate": 0.005144403496640408, "batch_size": 139, "loss": 0.0035934421885758638}, {"layer_params": [39, 56, 49, 22, 34], "learning_rate": 0.00090618055801985, "batch_size": 176, "loss": 0.0034683681931346657}, {"layer_params": [32, 56, 34, 38, 39], "learning_rate": 0.003909097713453648, "batch_size": 144, "loss": 0.002105337280081585}, {"layer_params": [46, 27, 54, 46, 21], "learning_rate": 0.0031395994757409226, "batch_size": 63, "loss": 0.003388316093478352}, {"layer_params": [18, 64, 20, 54], "learning_rate": 0.007217656730516823, "batch_size": 116, "loss": 0.00323737925151363}, {"layer_params": [34, 46], "learning_rate": 0.0003590583231065271, "batch_size": 136, "loss": 0.008501546075567603}, {"layer_params": [50, 56, 49], "learning_rate": 0.001477666857909196, "batch_size": 142, "loss": 0.002130000307224691}, {"layer_params": [54, 47, 31, 46, 36], "learning_rate": 0.0016014018215651097, "batch_size": 189, "loss": 0.002080462807789445}, {"layer_params": [33, 21, 28, 57], "learning_rate": 0.0005243141459375278, "batch_size": 455, "loss": 0.005446707140654325}, {"layer_params": [32, 20, 61], "learning_rate": 0.00749640076115254, "batch_size": 396, "loss": 0.0026238292129710317}, {"layer_params": [58, 47, 45, 42], "learning_rate": 0.004841639073479884, "batch_size": 392, "loss": 0.000834094132296741}, {"layer_params": [18, 16, 19], "learning_rate": 0.0023767377631361097, "batch_size": 200, "loss": 0.006710964892990887}, {"layer_params": [49, 55, 22, 63], "learning_rate": 0.0036387954357213694, "batch_size": 219, "loss": 0.0018869701714720577}, {"layer_params": [38, 29, 62], "learning_rate": 0.0031847339866216493, "batch_size": 431, "loss": 0.0021146126196254045}, {"layer_params": [49, 46, 18], "learning_rate": 0.007358828133269345, "batch_size": 226, "loss": 0.0014678027434274555}, {"layer_params": [53, 28, 48, 61], "learning_rate": 0.002689721045598677, "batch_size": 149, "loss": 0.0027729412051849065}, {"layer_params": [37, 42, 35], "learning_rate": 0.005112570580713603, "batch_size": 264, "loss": 0.0016788258322048932}, {"layer_params": [24, 55, 55, 21], "learning_rate": 0.0010384703576639372, "batch_size": 42, "loss": 0.007089592074044049}, {"layer_params": [27, 49, 60, 49], "learning_rate": 0.009675939521677099, "batch_size": 284, "loss": 0.001869195793988183}, {"layer_params": [63, 60, 52], "learning_rate": 0.005917112449621804, "batch_size": 362, "loss": 0.0013937751716002823}, {"layer_params": [54, 54, 46, 36], "learning_rate": 0.009635496540155584, "batch_size": 460, "loss": 0.001310335216112435}, {"layer_params": [18, 21, 37, 58], "learning_rate": 0.0031914339669800737, "batch_size": 470, "loss": 0.0021199290012009443}, {"layer_params": [28, 64], "learning_rate": 0.0095286521596898, "batch_size": 445, "loss": 0.0027472336473874748}, {"layer_params": [63, 32, 30, 42, 63], "learning_rate": 0.005286671706204557, "batch_size": 100, "loss": 0.0033532827091403306}, {"layer_params": [25, 22], "learning_rate": 0.001507139621536598, "batch_size": 498, "loss": 0.005855981097556651}, {"layer_params": [60, 58, 51], "learning_rate": 0.009801258736805186, "batch_size": 331, "loss": 0.0012158314179396257}, {"layer_params": [28, 52, 62, 43, 28], "learning_rate": 0.002685770986678426, "batch_size": 345, "loss": 0.0016393623780459165}, {"layer_params": [31, 46, 55], "learning_rate": 0.007833292307541635, "batch_size": 511, "loss": 0.001073293200461194}, {"layer_params": [59, 35, 20, 20, 21], "learning_rate": 0.006102373544120307, "batch_size": 201, "loss": 0.0017349372140597551}, {"layer_params": [38, 55, 63, 24], "learning_rate": 0.001878593411843682, "batch_size": 25, "loss": 0.006389066118281335}, {"layer_params": [48, 32, 62, 30, 21], "learning_rate": 0.0046635082886110615, "batch_size": 323, "loss": 0.001125613782205619}, {"layer_params": [47, 31], "learning_rate": 0.003271791458702956, "batch_size": 447, "loss": 0.0022158605826552956}, {"layer_params": [25, 60, 57, 33], "learning_rate": 0.007296729802771642, "batch_size": 141, "loss": 0.0020877123961690813}, {"layer_params": [42, 25], "learning_rate": 0.008798108592563988, "batch_size": 264, "loss": 0.0045442110975272955}, {"layer_params": [16, 26, 54], "learning_rate": 0.006033388322453274, "batch_size": 353, "loss": 0.003087719196919352}, {"layer_params": [20, 20, 43, 53], "learning_rate": 0.008462612295777203, "batch_size": 152, "loss": 0.003025619360851124}, {"layer_params": [48, 33, 26, 48], "learning_rate": 0.0025304152759514065, "batch_size": 142, "loss": 0.003187466796953231}, {"layer_params": [62, 30], "learning_rate": 0.007885360291580904, "batch_size": 347, "loss": 0.0016561409551650286}, {"layer_params": [33, 64, 25, 58, 22], "learning_rate": 0.007626669223348007, "batch_size": 470, "loss": 0.0014000824675895274}, {"layer_params": [21, 64, 47, 28], "learning_rate": 0.00551621557952889, "batch_size": 394, "loss": 0.0022801275458186865}, {"layer_params": [22, 30, 16], "learning_rate": 0.0068720241177195746, "batch_size": 143, "loss": 0.004082962942775339}, {"layer_params": [50, 24, 39, 29], "learning_rate": 0.009005355616748131, "batch_size": 121, "loss": 0.0015745227818842978}, {"layer_params": [29, 17, 24, 33], "learning_rate": 0.0029375658043683766, "batch_size": 466, "loss": 0.002510620199609548}, {"layer_params": [45, 22, 34, 23], "learning_rate": 0.0015845778160420022, "batch_size": 512, "loss": 0.003947278414852917}, {"layer_params": [40, 50, 35, 19, 43], "learning_rate": 0.0005256694504630687, "batch_size": 88, "loss": 0.006974680465646088}, {"layer_params": [27, 44, 19, 41, 34], "learning_rate": 0.005947383926748727, "batch_size": 328, "loss": 0.0020770358957815913}, {"layer_params": [27, 27], "learning_rate": 0.006055223957684106, "batch_size": 252, "loss": 0.0042282126168720425}, {"layer_params": [64, 19, 39, 58, 44], "learning_rate": 0.0006292746418796873, "batch_size": 159, "loss": 0.00423389324452728}, {"layer_params": [25, 52, 53, 46], "learning_rate": 0.009957957984061001, "batch_size": 302, "loss": 0.001311379168764688}, {"layer_params": [57, 36, 27, 39, 25], "learning_rate": 0.004747510106443205, "batch_size": 149, "loss": 0.00205928435199894}, {"layer_params": [17, 31, 29, 43, 61], "learning_rate": 0.0019497602428719116, "batch_size": 492, "loss": 0.0026834019483067094}, {"layer_params": [57, 33, 20], "learning_rate": 0.0027866216648669137, "batch_size": 343, "loss": 0.003022359993774444}, {"layer_params": [48, 47, 16, 34], "learning_rate": 0.006255756539522272, "batch_size": 340, "loss": 0.0011952595767797903}, {"layer_params": [25, 26, 55, 18, 18], "learning_rate": 0.005267890260833409, "batch_size": 113, "loss": 0.004069864586926997}, {"layer_params": [35, 47, 42, 22, 28], "learning_rate": 0.006724184537698191, "batch_size": 336, "loss": 0.0011562366696307436}, {"layer_params": [28, 35], "learning_rate": 0.000416524179913135, "batch_size": 336, "loss": 0.008048271969892084}, {"layer_params": [64, 32, 55, 23, 50], "learning_rate": 0.003463731406678358, "batch_size": 245, "loss": 0.002174741259077564}, {"layer_params": [39, 27, 49, 46], "learning_rate": 0.008710240092787293, "batch_size": 268, "loss": 0.001468315206002444}, {"layer_params": [19, 49, 17, 42], "learning_rate": 0.005476799279334492, "batch_size": 318, "loss": 0.0020159076456911862}, {"layer_params": [37, 28, 17, 19, 17], "learning_rate": 0.007392442458951193, "batch_size": 227, "loss": 0.00184618795174174}, {"layer_params": [22, 29, 19, 59], "learning_rate": 0.005523254877934608, "batch_size": 338, "loss": 0.0052855751523748044}, {"layer_params": [30, 22, 17, 16], "learning_rate": 0.009386899258926253, "batch_size": 218, "loss": 0.002709879344329238}, {"layer_params": [27, 37, 58, 57, 18], "learning_rate": 0.00409528602936207, "batch_size": 350, "loss": 0.002745184621307999}, {"layer_params": [17, 32], "learning_rate": 0.00426039465693563, "batch_size": 511, "loss": 0.004803081382997334}, {"layer_params": [45, 53, 42], "learning_rate": 0.0046840829308959255, "batch_size": 492, "loss": 0.0011991994583513588}, {"layer_params": [21, 23, 40], "learning_rate": 0.009656516639008236, "batch_size": 64, "loss": 0.004891007312107831}, {"layer_params": [49, 31, 26], "learning_rate": 0.009538864078005938, "batch_size": 364, "loss": 0.0014118258468806743}, {"layer_params": [48, 52, 49, 56, 23], "learning_rate": 0.001005678688898697, "batch_size": 222, "loss": 0.00204006016952917}, {"layer_params": [29, 25, 42, 33, 39], "learning_rate": 0.002224989253409873, "batch_size": 358, "loss": 0.002446059894282371}, {"layer_params": [31, 25, 20, 21], "learning_rate": 0.0012377419453559896, "batch_size": 108, "loss": 0.007011735043488443}, {"layer_params": [39, 25, 39, 59], "learning_rate": 0.006751344397958157, "batch_size": 292, "loss": 0.002140037817880511}, {"layer_params": [29, 60, 46, 46, 30], "learning_rate": 0.0032066680897544007, "batch_size": 505, "loss": 0.001253193678567186}, {"layer_params": [61, 55, 18, 61, 38], "learning_rate": 0.002730067298537146, "batch_size": 360, "loss": 0.001349014857551083}, {"layer_params": [58, 48, 43], "learning_rate": 0.002578904025437082, "batch_size": 96, "loss": 0.002035565415862948}, {"layer_params": [28, 22, 21], "learning_rate": 1.559664926128235e-05, "batch_size": 504, "loss": 0.2539209859073162}, {"layer_params": [55, 16, 58, 53], "learning_rate": 0.007681309364902159, "batch_size": 408, "loss": 0.0018981302564498037}, {"layer_params": [57, 53], "learning_rate": 0.005841496581462399, "batch_size": 266, "loss": 0.0011370478878961875}, {"layer_params": [35, 33], "learning_rate": 0.0003014667985455511, "batch_size": 486, "loss": 0.007432264229282737}, {"layer_params": [21, 16], "learning_rate": 0.0030629607464551438, "batch_size": 323, "loss": 0.006035306267440319}, {"layer_params": [36, 59], "learning_rate": 0.0022693608123345367, "batch_size": 420, "loss": 0.002574262872803956}, {"layer_params": [64, 57, 20], "learning_rate": 0.004250234613677481, "batch_size": 205, "loss": 0.002540752029744908}, {"layer_params": [42, 36], "learning_rate": 0.005613546195239115, "batch_size": 484, "loss": 0.001999601980205625}, {"layer_params": [50, 27, 49], "learning_rate": 0.009902920189274736, "batch_size": 262, "loss": 0.002583511385601014}, {"layer_params": [16, 41, 45, 43, 63], "learning_rate": 0.0003422750824988827, "batch_size": 258, "loss": 0.00763088617939502}, {"layer_params": [29, 35, 53, 31, 29], "learning_rate": 0.0032657606653071504, "batch_size": 215, "loss": 0.002405038553988561}, {"layer_params": [60, 34, 64], "learning_rate": 0.0008066473815182154, "batch_size": 381, "loss": 0.002997073079459369}, {"layer_params": [34, 63], "learning_rate": 0.009955527082981327, "batch_size": 45, "loss": 0.00451996655203402}, {"layer_params": [30, 38], "learning_rate": 0.009045527653986155, "batch_size": 512, "loss": 0.002107691027922556}, {"layer_params": [55, 22, 59, 23], "learning_rate": 0.0024951391705231563, "batch_size": 281, "loss": 0.0023936931451316924}, {"layer_params": [54, 43, 59, 22, 34], "learning_rate": 0.0031665367849008394, "batch_size": 296, "loss": 0.0010550334147410468}, {"layer_params": [55, 46, 43, 53, 18], "learning_rate": 0.0016861328571383838, "batch_size": 79, "loss": 0.004785900977440178}, {"layer_params": [58, 19, 40], "learning_rate": 0.0023859917435206475, "batch_size": 152, "loss": 0.003706668331287801}, {"layer_params": [31, 63, 22], "learning_rate": 0.008008149409722784, "batch_size": 334, "loss": 0.0012369162926916034}, {"layer_params": [58, 58, 47], "learning_rate": 0.008696738236981244, "batch_size": 475, "loss": 0.0008157887536799535}, {"layer_params": [40, 36, 42, 50], "learning_rate": 0.007904221132061523, "batch_size": 439, "loss": 0.0016891640448011458}, {"layer_params": [34, 60, 46, 25], "learning_rate": 0.009431009367770537, "batch_size": 274, "loss": 0.001680389812681824}, {"layer_params": [38, 20, 49, 36], "learning_rate": 0.0033458969113145972, "batch_size": 439, "loss": 0.0022215390345081687}, {"layer_params": [41, 32], "learning_rate": 0.00934573762503734, "batch_size": 490, "loss": 0.0017967208789195865}, {"layer_params": [59, 64], "learning_rate": 0.007882004658616581, "batch_size": 396, "loss": 0.0016418086842168124}, {"layer_params": [26, 58, 28], "learning_rate": 0.005826389395653708, "batch_size": 258, "loss": 0.0023272159334737806}, {"layer_params": [24, 45, 34, 50], "learning_rate": 0.009014469917131776, "batch_size": 454, "loss": 0.0013570244226139038}, {"layer_params": [41, 19, 23], "learning_rate": 0.004358155813862688, "batch_size": 89, "loss": 0.002700866275699809}, {"layer_params": [41, 36, 23, 34, 48], "learning_rate": 0.0031318974929246124, "batch_size": 495, "loss": 0.0013030277844518422}, {"layer_params": [48, 51], "learning_rate": 0.008710334775425543, "batch_size": 302, "loss": 0.001992721074493602}, {"layer_params": [34, 34, 37, 50, 63], "learning_rate": 0.0036595713697080267, "batch_size": 409, "loss": 0.0012098667240934447}, {"layer_params": [23, 31, 25], "learning_rate": 0.0059013260127204715, "batch_size": 237, "loss": 0.002861437813844532}, {"layer_params": [60, 42, 60], "learning_rate": 0.0038788281519162755, "batch_size": 19, "loss": 0.0049928760260809215}, {"layer_params": [20, 25], "learning_rate": 0.007702720008137763, "batch_size": 443, "loss": 0.002727728937752545}, {"layer_params": [37, 64], "learning_rate": 0.0028375759264085264, "batch_size": 144, "loss": 0.0022389911348000167}, {"layer_params": [55, 64, 45], "learning_rate": 0.004907023064536912, "batch_size": 101, "loss": 0.0020950237568467854}, {"layer_params": [59, 50, 50, 55, 56], "learning_rate": 0.003627257163582298, "batch_size": 210, "loss": 0.0022566191526129844}, {"layer_params": [22, 35, 36, 64], "learning_rate": 0.0024913348226719657, "batch_size": 492, "loss": 0.0021861677116248755}, {"layer_params": [20, 57, 28, 34], "learning_rate": 0.0016285599146210906, "batch_size": 129, "loss": 0.006212858147919178}, {"layer_params": [27, 39, 44], "learning_rate": 0.0010843309335695221, "batch_size": 185, "loss": 0.004708222022745758}, {"layer_params": [60, 59, 42], "learning_rate": 0.0003428382959417133, "batch_size": 144, "loss": 0.00685460155364126}, {"layer_params": [19, 64, 40, 45, 28], "learning_rate": 0.0016250037846886989, "batch_size": 450, "loss": 0.0028761104121804238}, {"layer_params": [54, 60, 57, 63, 17], "learning_rate": 0.0005460128141882375, "batch_size": 103, "loss": 0.004212528958451003}, {"layer_params": [26, 22, 58], "learning_rate": 0.006065597325512188, "batch_size": 407, "loss": 0.0022360299609135836}, {"layer_params": [52, 39, 26], "learning_rate": 0.006953354832032055, "batch_size": 324, "loss": 0.000653115252207499}, {"layer_params": [21, 43, 63, 56], "learning_rate": 0.00716724032561452, "batch_size": 425, "loss": 0.0011588771204696967}, {"layer_params": [45, 33], "learning_rate": 0.0011708346544533667, "batch_size": 308, "loss": 0.0030986415990628302}, {"layer_params": [31, 47, 61], "learning_rate": 0.0013278286537211804, "batch_size": 441, "loss": 0.0024298525671474637}, {"layer_params": [39, 58, 64], "learning_rate": 0.002668500054946547, "batch_size": 352, "loss": 0.0010712814144790172}, {"layer_params": [21, 38, 51], "learning_rate": 0.00900058822894606, "batch_size": 101, "loss": 0.0027248895808588713}, {"layer_params": [38, 30, 34, 49], "learning_rate": 0.006108808351576935, "batch_size": 86, "loss": 0.002855104107875377}, {"layer_params": [53, 62, 29, 37], "learning_rate": 0.0050621625201081495, "batch_size": 195, "loss": 0.0011121082078898326}, {"layer_params": [42, 57, 27, 26], "learning_rate": 0.008872193214852372, "batch_size": 207, "loss": 0.001965672703227028}, {"layer_params": [31, 25, 33, 37], "learning_rate": 0.00815066249734335, "batch_size": 321, "loss": 0.001603328922064975}, {"layer_params": [56, 43, 54, 27, 35], "learning_rate": 0.002381719472549027, "batch_size": 172, "loss": 0.0017577397159766405}, {"layer_params": [53, 36, 47], "learning_rate": 0.0016801470621590868, "batch_size": 378, "loss": 0.0016890000039711595}, {"layer_params": [50, 54, 21, 64], "learning_rate": 0.006884744986670248, "batch_size": 487, "loss": 0.0008999325870536267}, {"layer_params": [57, 20, 28], "learning_rate": 0.0009682517910066865, "batch_size": 388, "loss": 0.0045361277577467265}, {"layer_params": [23, 33, 57], "learning_rate": 0.008962254146795091, "batch_size": 90, "loss": 0.004368223124183715}, {"layer_params": [35, 52, 32, 58, 16], "learning_rate": 0.002258451331951554, "batch_size": 427, "loss": 0.0018555310973897576}, {"layer_params": [49, 58, 32, 50], "learning_rate": 0.004554203570227621, "batch_size": 273, "loss": 0.0007836997287813574}, {"layer_params": [52, 17, 53], "learning_rate": 0.008179701033040712, "batch_size": 397, "loss": 0.0014921135525219143}, {"layer_params": [38, 16, 51, 54], "learning_rate": 0.005172645115434934, "batch_size": 176, "loss": 0.0025953025615308434}, {"layer_params": [27, 56], "learning_rate": 0.0023368684600281516, "batch_size": 408, "loss": 0.003712672581896186}, {"layer_params": [53, 27, 32, 45], "learning_rate": 0.006336940802374214, "batch_size": 348, "loss": 0.0017544256476685405}, {"layer_params": [49, 60, 61], "learning_rate": 0.007840447100626388, "batch_size": 186, "loss": 0.0016673604561947286}, {"layer_params": [54, 30, 52], "learning_rate": 0.006819086621600106, "batch_size": 289, "loss": 0.0022025075496640055}, {"layer_params": [48, 36, 62, 45, 16], "learning_rate": 0.002835517797736296, "batch_size": 381, "loss": 0.0025723042478784917}, {"layer_params": [31, 41, 35], "learning_rate": 0.0062814112611248914, "batch_size": 117, "loss": 0.0036437592934817076}, {"layer_params": [36, 45, 24], "learning_rate": 0.00573552599923903, "batch_size": 392, "loss": 0.0021298518881667406}, {"layer_params": [17, 32, 52, 46], "learning_rate": 0.007474508812232092, "batch_size": 162, "loss": 0.0032000923063606026}, {"layer_params": [39, 62, 43], "learning_rate": 0.0032510996618357857, "batch_size": 191, "loss": 0.001713707564631477}, {"layer_params": [51, 48, 37], "learning_rate": 0.0008174732183910051, "batch_size": 444, "loss": 0.002590100208763033}, {"layer_params": [45, 47], "learning_rate": 0.00046038525064569995, "batch_size": 34, "loss": 0.008511923518963158}, {"layer_params": [32, 45, 44], "learning_rate": 0.0006536808600071203, "batch_size": 500, "loss": 0.003803631004411727}, {"layer_params": [61, 59, 59, 31, 38], "learning_rate": 0.00443035926387522, "batch_size": 205, "loss": 0.0013402580056572333}, {"layer_params": [31, 38, 31, 22], "learning_rate": 0.0018471423386919833, "batch_size": 458, "loss": 0.0021199203142896294}, {"layer_params": [47, 22, 29, 18], "learning_rate": 0.007094725050411946, "batch_size": 251, "loss": 0.0024081621295772493}, {"layer_params": [22, 37, 64], "learning_rate": 0.007081077996508224, "batch_size": 301, "loss": 0.002196540387813002}, {"layer_params": [62, 59, 64], "learning_rate": 0.0026552651529029134, "batch_size": 272, "loss": 0.0017055235523730516}, {"layer_params": [30, 30, 17, 39], "learning_rate": 0.0003939547598096652, "batch_size": 311, "loss": 0.006678738230839372}, {"layer_params": [46, 38], "learning_rate": 0.003949642077906228, "batch_size": 109, "loss": 0.0028337710280902685}, {"layer_params": [34, 52, 62, 51, 44], "learning_rate": 0.004326936387784931, "batch_size": 427, "loss": 0.0010446713480632753}, {"layer_params": [43, 18], "learning_rate": 0.004365554865463991, "batch_size": 430, "loss": 0.0037164551112800837}, {"layer_params": [30, 40, 41], "learning_rate": 0.006685528371319714, "batch_size": 480, "loss": 0.0013266250980086625}, {"layer_params": [38, 58, 45], "learning_rate": 0.005087752656560052, "batch_size": 130, "loss": 0.0030159927089698614}, {"layer_params": [44, 56], "learning_rate": 0.007393935524044257, "batch_size": 476, "loss": 0.0011610190686769783}, {"layer_params": [42, 28], "learning_rate": 0.007201297766528356, "batch_size": 42, "loss": 0.004926010046619922}, {"layer_params": [22, 47, 44], "learning_rate": 0.0004625233822929207, "batch_size": 18, "loss": 0.010509261472616344}, {"layer_params": [57, 55, 59, 60, 47], "learning_rate": 0.0022120522998845824, "batch_size": 448, "loss": 0.0011542406032094732}, {"layer_params": [38, 50], "learning_rate": 0.005418117631386088, "batch_size": 413, "loss": 0.0023415896750520913}, {"layer_params": [52, 22, 38], "learning_rate": 0.004989668914356317, "batch_size": 327, "loss": 0.0022188684437423945}, {"layer_params": [33, 34, 16, 26, 64], "learning_rate": 0.006687556732396471, "batch_size": 103, "loss": 0.003142101778648794}, {"layer_params": [63, 23, 18, 35, 47], "learning_rate": 0.00566462075131079, "batch_size": 202, "loss": 0.0016792859963607042}, {"layer_params": [26, 26, 17], "learning_rate": 0.0024765159730222356, "batch_size": 169, "loss": 0.005325553002767265}, {"layer_params": [28, 47, 27, 61, 52], "learning_rate": 0.006643325249953121, "batch_size": 332, "loss": 0.0017840481270104647}, {"layer_params": [64, 33, 53], "learning_rate": 0.009922460003579584, "batch_size": 360, "loss": 0.0013515757117420436}, {"layer_params": [21, 19], "learning_rate": 0.006361214082179636, "batch_size": 232, "loss": 0.0070009970292449}, {"layer_params": [20, 48, 45, 22, 45], "learning_rate": 0.008459878578426274, "batch_size": 323, "loss": 0.0029496477264910935}, {"layer_params": [59, 35, 37, 17], "learning_rate": 0.004809714598841856, "batch_size": 213, "loss": 0.0017802842555101962}, {"layer_params": [52, 27], "learning_rate": 0.00961318239069049, "batch_size": 87, "loss": 0.0022467587771825494}, {"layer_params": [22, 18, 58], "learning_rate": 0.00695751540198061, "batch_size": 291, "loss": 0.0021412538550794123}, {"layer_params": [59, 49, 57, 23, 61], "learning_rate": 0.000776082309857047, "batch_size": 258, "loss": 0.0028604607610031962}, {"layer_params": [59, 30], "learning_rate": 0.007478133651818822, "batch_size": 281, "loss": 0.0032691457658074797}, {"layer_params": [48, 62, 34, 37], "learning_rate": 0.006503387311510189, "batch_size": 110, "loss": 0.0018843668070621788}, {"layer_params": [16, 58], "learning_rate": 0.0038465789378506593, "batch_size": 43, "loss": 0.006953016503248363}, {"layer_params": [36, 41], "learning_rate": 0.007076904354921419, "batch_size": 280, "loss": 0.0029563074745237827}, {"layer_params": [37, 30, 35], "learning_rate": 0.0009266369473285917, "batch_size": 151, "loss": 0.0060918593080714345}, {"layer_params": [64, 29, 31, 22], "learning_rate": 0.002580314721466557, "batch_size": 493, "loss": 0.0023112187208607794}, {"layer_params": [28, 16, 38, 41], "learning_rate": 0.0002933226703978517, "batch_size": 18, "loss": 0.027469453029334547}, {"layer_params": [34, 49, 27, 18, 45], "learning_rate": 0.006089629124629466, "batch_size": 166, "loss": 0.0029193746333476154}, {"layer_params": [46, 41], "learning_rate": 0.005447982565795817, "batch_size": 78, "loss": 0.002279984134947881}, {"layer_params": [23, 54, 33, 43, 29], "learning_rate": 0.007405474934348945, "batch_size": 42, "loss": 0.005643295657355338}, {"layer_params": [47, 39, 40, 27, 54], "learning_rate": 0.0038864544388552175, "batch_size": 396, "loss": 0.001563511707354337}, {"layer_params": [29, 47, 58, 33, 47], "learning_rate": 0.002593648338130611, "batch_size": 394, "loss": 0.0015719782176893205}, {"layer_params": [61, 44, 25, 57], "learning_rate": 0.00703678934301323, "batch_size": 497, "loss": 0.0011833292385563254}, {"layer_params": [17, 55], "learning_rate": 0.00596826997336904, "batch_size": 140, "loss": 0.003338492058683187}, {"layer_params": [18, 48, 56, 43, 64], "learning_rate": 0.003252511032478651, "batch_size": 320, "loss": 0.0016792323533445597}, {"layer_params": [37, 52, 41, 63], "learning_rate": 0.004974713943912639, "batch_size": 510, "loss": 0.0013682414614595473}, {"layer_params": [41, 52, 38, 47, 40], "learning_rate": 0.007869056692071824, "batch_size": 175, "loss": 0.0013287304755067453}, {"layer_params": [56, 41], "learning_rate": 0.00964199124885935, "batch_size": 451, "loss": 0.001547182467766106}, {"layer_params": [44, 21, 46], "learning_rate": 0.00328281357431411, "batch_size": 370, "loss": 0.0032424515672028064}, {"layer_params": [29, 42, 59, 64], "learning_rate": 0.0071395304316338665, "batch_size": 383, "loss": 0.0010659989475971087}, {"layer_params": [56, 63, 47], "learning_rate": 0.00306063483313504, "batch_size": 61, "loss": 0.002486394072184339}, {"layer_params": [60, 63], "learning_rate": 0.0015146695909907008, "batch_size": 396, "loss": 0.002507825163193047}, {"layer_params": [37, 19, 23], "learning_rate": 0.0006072927982405461, "batch_size": 192, "loss": 0.007238343222998083}, {"layer_params": [34, 56, 23, 61, 29], "learning_rate": 0.008192227490882035, "batch_size": 477, "loss": 0.0014263569319155067}, {"layer_params": [27, 55, 57, 32, 49], "learning_rate": 0.009279789813896452, "batch_size": 321, "loss": 0.0018107792746741324}, {"layer_params": [26, 20, 24, 20], "learning_rate": 0.008024673301233343, "batch_size": 388, "loss": 0.0031115520955063403}, {"layer_params": [42, 51, 39], "learning_rate": 0.0014971582785254286, "batch_size": 21, "loss": 0.008346751669887454}, {"layer_params": [36, 58, 25, 58], "learning_rate": 0.0031230231445699723, "batch_size": 132, "loss": 0.0027096869866363705}, {"layer_params": [51, 41, 38, 43], "learning_rate": 0.005616451767116959, "batch_size": 107, "loss": 0.0022461692010983824}, {"layer_params": [45, 18, 27, 17], "learning_rate": 0.009109040861083644, "batch_size": 45, "loss": 0.004979397417046129}, {"layer_params": [34, 48, 54, 24, 61], "learning_rate": 0.00997460517403392, "batch_size": 365, "loss": 0.001529799122363329}, {"layer_params": [19, 55, 46], "learning_rate": 0.0018489627736825367, "batch_size": 439, "loss": 0.002192762459162623}, {"layer_params": [58, 33, 42, 34, 45], "learning_rate": 0.008183444338251349, "batch_size": 509, "loss": 0.0019096928567159921}, {"layer_params": [54, 50, 31, 51], "learning_rate": 0.006928946361022356, "batch_size": 159, "loss": 0.0015132158051710575}, {"layer_params": [16, 18, 46, 26], "learning_rate": 0.006794632857627579, "batch_size": 425, "loss": 0.003083572823088616}, {"layer_params": [18, 47, 20, 30], "learning_rate": 0.005086068233827522, "batch_size": 371, "loss": 0.002470031261909753}, {"layer_params": [55, 55, 18, 28, 37], "learning_rate": 0.00998753457272545, "batch_size": 415, "loss": 0.0012675640790257602}, {"layer_params": [49, 54, 47, 21, 53], "learning_rate": 0.0075280691488277445, "batch_size": 448, "loss": 0.0010252397012664005}, {"layer_params": [17, 49, 47], "learning_rate": 0.008938595424357583, "batch_size": 156, "loss": 0.0027838272950612007}, {"layer_params": [36, 51, 25, 35], "learning_rate": 0.0029206088287318612, "batch_size": 385, "loss": 0.0019188275176566093}, {"layer_params": [18, 39, 54, 62], "learning_rate": 0.005992304853018871, "batch_size": 407, "loss": 0.0020174593513365836}, {"layer_params": [17, 25, 35, 27], "learning_rate": 0.007595144418303168, "batch_size": 176, "loss": 0.003496324666775763}, {"layer_params": [46, 50, 33, 58], "learning_rate": 0.007849032058894229, "batch_size": 342, "loss": 0.0008910336712142453}, {"layer_params": [50, 25, 60], "learning_rate": 0.00451449031762069, "batch_size": 462, "loss": 0.0022174783784430475}, {"layer_params": [32, 16, 37, 25], "learning_rate": 0.007192036282262518, "batch_size": 84, "loss": 0.005589755408000201}, {"layer_params": [31, 46, 61], "learning_rate": 0.006804267174061248, "batch_size": 74, "loss": 0.003200875447364524}, {"layer_params": [22, 45], "learning_rate": 0.0007020648409190085, "batch_size": 102, "loss": 0.00808026321232319}, {"layer_params": [37, 29], "learning_rate": 0.005034850860994915, "batch_size": 215, "loss": 0.00230124079156667}, {"layer_params": [37, 30, 61, 32, 34], "learning_rate": 0.009016211213167383, "batch_size": 368, "loss": 0.0016130883817095309}, {"layer_params": [58, 61, 19, 16], "learning_rate": 0.0058660767642470715, "batch_size": 365, "loss": 0.0013483640237245708}, {"layer_params": [32, 27], "learning_rate": 0.009453588479778128, "batch_size": 193, "loss": 0.002812888086773455}, {"layer_params": [48, 61, 53], "learning_rate": 0.004678324320450445, "batch_size": 319, "loss": 0.0015435678290668874}, {"layer_params": [38, 62], "learning_rate": 0.009883156628387537, "batch_size": 51, "loss": 0.0033841154677793383}, {"layer_params": [33, 41, 42, 28, 54], "learning_rate": 0.0029391491819897066, "batch_size": 414, "loss": 0.001617845888249576}, {"layer_params": [59, 56, 33, 49], "learning_rate": 0.00680166453805632, "batch_size": 71, "loss": 0.003219879111275077}, {"layer_params": [53, 18, 58, 24], "learning_rate": 0.007582440862420674, "batch_size": 17, "loss": 0.009116740205790848}, {"layer_params": [16, 43, 17, 47, 32], "learning_rate": 0.009144283244573509, "batch_size": 358, "loss": 0.002619806968141347}, {"layer_params": [42, 28, 24, 56, 43], "learning_rate": 0.005100058550773672, "batch_size": 76, "loss": 0.002974662984488532}, {"layer_params": [47, 33, 22, 64], "learning_rate": 0.006518153574148449, "batch_size": 214, "loss": 0.002172601039055735}, {"layer_params": [24, 31, 51, 33, 29], "learning_rate": 0.0009957093572337526, "batch_size": 213, "loss": 0.004999264918733388}, {"layer_params": [54, 62, 26, 53], "learning_rate": 0.007538793986567004, "batch_size": 237, "loss": 0.0017328325018752366}, {"layer_params": [52, 28, 60, 20, 42], "learning_rate": 0.009170098954600778, "batch_size": 227, "loss": 0.0017945089389104396}, {"layer_params": [52, 47, 58, 35], "learning_rate": 0.009176210524726102, "batch_size": 113, "loss": 0.0015872058214154094}, {"layer_params": [49, 29, 52, 57], "learning_rate": 0.0033632498681682994, "batch_size": 223, "loss": 0.001356798677588813}, {"layer_params": [31, 44, 55, 57], "learning_rate": 0.007197164292925486, "batch_size": 38, "loss": 0.005186961581930518}, {"layer_params": [38, 56, 51], "learning_rate": 0.002990180250367473, "batch_size": 248, "loss": 0.0013857403001748024}, {"layer_params": [29, 28, 32, 53, 42], "learning_rate": 0.007508293504560615, "batch_size": 314, "loss": 0.00308125879149884}, {"layer_params": [59, 59, 55, 58], "learning_rate": 0.0020256204370060218, "batch_size": 397, "loss": 0.0012211421254323795}, {"layer_params": [18, 62], "learning_rate": 0.007802730566784829, "batch_size": 421, "loss": 0.0024817763082683087}, {"layer_params": [24, 48, 58, 25, 62], "learning_rate": 0.009214484073693437, "batch_size": 478, "loss": 0.0012922697025351227}, {"layer_params": [25, 36], "learning_rate": 0.003129357133343626, "batch_size": 168, "loss": 0.0034288480691611768}, {"layer_params": [58, 35, 48, 51, 34], "learning_rate": 0.003457223127264326, "batch_size": 183, "loss": 0.0021089252608362586}, {"layer_params": [40, 57, 53, 63, 51], "learning_rate": 0.0010728442041934025, "batch_size": 74, "loss": 0.0038022044487297534}, {"layer_params": [50, 25, 40, 62, 44], "learning_rate": 0.009437782971813774, "batch_size": 338, "loss": 0.0035821231827139854}, {"layer_params": [20, 63, 42], "learning_rate": 0.0034815270912230078, "batch_size": 436, "loss": 0.002473472743295133}, {"layer_params": [52, 40, 61], "learning_rate": 0.0007057697648050498, "batch_size": 218, "loss": 0.004605971635319292}, {"layer_params": [63, 33, 43, 17, 46], "learning_rate": 0.0009397415250176698, "batch_size": 264, "loss": 0.0024365870258770883}, {"layer_params": [53, 29, 19], "learning_rate": 0.003184944659416148, "batch_size": 297, "loss": 0.001389148860471323}, {"layer_params": [60, 45, 36], "learning_rate": 0.007473008768268379, "batch_size": 396, "loss": 0.002022987494710833}, {"layer_params": [64, 50], "learning_rate": 0.005209413819641632, "batch_size": 424, "loss": 0.0023636639874894173}, {"layer_params": [17, 21, 35], "learning_rate": 0.003058318391737961, "batch_size": 290, "loss": 0.0039554548123851415}, {"layer_params": [45, 34], "learning_rate": 0.002313865134453653, "batch_size": 190, "loss": 0.0025752680574078115}, {"layer_params": [40, 28, 63], "learning_rate": 0.008340702215885865, "batch_size": 429, "loss": 0.0013476900290697812}, {"layer_params": [35, 26], "learning_rate": 0.0049497143172946255, "batch_size": 225, "loss": 0.0026211907574906945}, {"layer_params": [54, 62, 17, 60, 38], "learning_rate": 0.0067491006527600084, "batch_size": 348, "loss": 0.0013094221136998386}, {"layer_params": [58, 25, 21], "learning_rate": 0.008242251730379128, "batch_size": 440, "loss": 0.0027198769827373325}, {"layer_params": [49, 20], "learning_rate": 0.00824653546773955, "batch_size": 182, "loss": 0.002367882131366059}, {"layer_params": [42, 45, 32, 41, 47], "learning_rate": 0.0036102450273503475, "batch_size": 227, "loss": 0.0017271420336328446}, {"layer_params": [17, 35, 64], "learning_rate": 0.00214545674500693, "batch_size": 449, "loss": 0.002534460842143744}, {"layer_params": [39, 50], "learning_rate": 0.00521492048265395, "batch_size": 123, "loss": 0.002745494629489258}, {"layer_params": [45, 23], "learning_rate": 0.006380827972328917, "batch_size": 402, "loss": 0.002433082840871066}, {"layer_params": [46, 39, 45], "learning_rate": 0.0003196321299565886, "batch_size": 231, "loss": 0.007174479165114462}, {"layer_params": [54, 19, 25], "learning_rate": 0.008190002573034292, "batch_size": 140, "loss": 0.0032584825553931295}, {"layer_params": [46, 58, 38, 17, 16], "learning_rate": 0.009626588728151406, "batch_size": 412, "loss": 0.0008720795618137344}, {"layer_params": [59, 20, 28], "learning_rate": 0.0007391034897505074, "batch_size": 180, "loss": 0.005764735974371433}, {"layer_params": [30, 46, 42], "learning_rate": 0.0009765880049071103, "batch_size": 234, "loss": 0.0038283204031176864}, {"layer_params": [56, 55, 32], "learning_rate": 0.00031046556941308553, "batch_size": 288, "loss": 0.005893004979006946}, {"layer_params": [64, 52], "learning_rate": 0.004708044050070154, "batch_size": 261, "loss": 0.0020912483788561075}, {"layer_params": [60, 42, 37, 18, 44], "learning_rate": 0.0035669197699741916, "batch_size": 383, "loss": 0.0011689442582428456}, {"layer_params": [32, 52, 16], "learning_rate": 0.0062390809290439, "batch_size": 18, "loss": 0.008126781422179192}, {"layer_params": [64, 37], "learning_rate": 0.004148694946027355, "batch_size": 61, "loss": 0.0037987380870617925}, {"layer_params": [35, 49, 61], "learning_rate": 0.006069256447266544, "batch_size": 45, "loss": 0.004007886919425801}, {"layer_params": [26, 51, 22, 22], "learning_rate": 0.008455836406916214, "batch_size": 429, "loss": 0.0025354685401543977}, {"layer_params": [64, 54, 39, 40, 20], "learning_rate": 0.00022075803942334438, "batch_size": 290, "loss": 0.006632224982604384}, {"layer_params": [45, 64], "learning_rate": 0.005897788270603745, "batch_size": 280, "loss": 0.0014631824940443039}, {"layer_params": [33, 20, 55, 27], "learning_rate": 0.007021875160612449, "batch_size": 281, "loss": 0.0028425446269102397}, {"layer_params": [41, 48], "learning_rate": 0.0006002959215339723, "batch_size": 479, "loss": 0.005771965240128339}, {"layer_params": [26, 64, 16], "learning_rate": 0.0018605712846660478, "batch_size": 67, "loss": 0.006026109822560102}, {"layer_params": [36, 28, 34], "learning_rate": 0.009549636336942929, "batch_size": 252, "loss": 0.0012535305658821017}, {"layer_params": [27, 20], "learning_rate": 0.0013815756403052699, "batch_size": 243, "loss": 0.005916872015222907}, {"layer_params": [48, 20], "learning_rate": 0.002900835374270925, "batch_size": 356, "loss": 0.002066885964013636}, {"layer_params": [16, 60, 36, 59, 52], "learning_rate": 0.007700657026389103, "batch_size": 479, "loss": 0.0021826518431771547}, {"layer_params": [37, 39, 40, 52, 41], "learning_rate": 0.000744317399971221, "batch_size": 84, "loss": 0.00521117185940966}, {"layer_params": [60, 38], "learning_rate": 0.000248550750023252, "batch_size": 469, "loss": 0.00806889297440648}, {"layer_params": [45, 47, 53, 33, 62], "learning_rate": 0.00815300953029783, "batch_size": 319, "loss": 0.00197631475282833}, {"layer_params": [41, 27], "learning_rate": 0.0013589130470771375, "batch_size": 275, "loss": 0.00480054829036817}, {"layer_params": [21, 18], "learning_rate": 0.0036175528834087984, "batch_size": 151, "loss": 0.0035545953642576933}, {"layer_params": [51, 34, 47, 23], "learning_rate": 0.005724066324282905, "batch_size": 490, "loss": 0.0008678114996291697}, {"layer_params": [24, 36], "learning_rate": 0.002221768491183808, "batch_size": 507, "loss": 0.0036743092793039976}, {"layer_params": [32, 18, 43, 20], "learning_rate": 0.005924729183409732, "batch_size": 34, "loss": 0.005716547293122858}, {"layer_params": [63, 52, 50, 40], "learning_rate": 0.0019220997878596948, "batch_size": 76, "loss": 0.002733520081965253}, {"layer_params": [41, 32, 26, 24, 33], "learning_rate": 0.001345815881500888, "batch_size": 396, "loss": 0.002907857506070286}, {"layer_params": [24, 39, 55], "learning_rate": 0.0033107483858884046, "batch_size": 81, "loss": 0.0038800189876928926}, {"layer_params": [51, 37, 56], "learning_rate": 0.009167506948450381, "batch_size": 170, "loss": 0.003595103383995593}, {"layer_params": [62, 17, 39], "learning_rate": 0.0014249784038811212, "batch_size": 58, "loss": 0.005272218701429665}, {"layer_params": [49, 60], "learning_rate": 0.004073299943639402, "batch_size": 440, "loss": 0.0015547108533792197}, {"layer_params": [34, 43, 35, 49, 63], "learning_rate": 0.0072250665087936, "batch_size": 331, "loss": 0.0013764155970420688}, {"layer_params": [17, 54, 53], "learning_rate": 0.006428494073615863, "batch_size": 23, "loss": 0.007954480755142868}, {"layer_params": [51, 43], "learning_rate": 0.0052461854637689915, "batch_size": 306, "loss": 0.0012958303582854568}, {"layer_params": [31, 64], "learning_rate": 0.006235236547740662, "batch_size": 485, "loss": 0.0013577333057764917}, {"layer_params": [51, 39, 59, 46], "learning_rate": 0.008317979665294394, "batch_size": 54, "loss": 0.0029483933886513113}, {"layer_params": [30, 46, 44, 39], "learning_rate": 0.00938460979671051, "batch_size": 374, "loss": 0.0016572554153390228}, {"layer_params": [59, 22, 62], "learning_rate": 0.0008905259631910427, "batch_size": 509, "loss": 0.00400461268145591}, {"layer_params": [22, 59, 55, 35, 40], "learning_rate": 0.0044202820646325166, "batch_size": 331, "loss": 0.0024906900548376143}, {"layer_params": [64, 25], "learning_rate": 0.0011441054752929928, "batch_size": 297, "loss": 0.005708668916486204}, {"layer_params": [35, 28, 36], "learning_rate": 0.008934999085790136, "batch_size": 430, "loss": 0.002595151250716299}, {"layer_params": [34, 60, 28, 44], "learning_rate": 0.003477422119782448, "batch_size": 433, "loss": 0.002109425551025197}, {"layer_params": [54, 31, 58], "learning_rate": 0.003327888007815135, "batch_size": 334, "loss": 0.0019033368688542397}, {"layer_params": [19, 17, 45], "learning_rate": 0.009704745036141816, "batch_size": 248, "loss": 0.0017385522299446165}, {"layer_params": [19, 24, 18, 16, 64], "learning_rate": 0.0015052797084250354, "batch_size": 259, "loss": 0.005380499600432813}, {"layer_params": [54, 26, 61, 52, 38], "learning_rate": 0.00612327022020992, "batch_size": 66, "loss": 0.0027428097417578103}, {"layer_params": [25, 48, 36, 28], "learning_rate": 0.0002570765622561521, "batch_size": 76, "loss": 0.008709110990166665}, {"layer_params": [33, 58], "learning_rate": 0.0020860907906673077, "batch_size": 79, "loss": 0.005874692783690989}, {"layer_params": [16, 23, 20, 17], "learning_rate": 0.009243223332690094, "batch_size": 212, "loss": 0.005202771506737917}, {"layer_params": [33, 46, 60, 27, 22], "learning_rate": 0.004939206459548504, "batch_size": 82, "loss": 0.0030200779589358716}, {"layer_params": [35, 23, 53, 45], "learning_rate": 0.009288346342120843, "batch_size": 428, "loss": 0.001390590969240293}, {"layer_params": [54, 29, 51, 39, 39], "learning_rate": 0.0007594389206194909, "batch_size": 406, "loss": 0.002926853992976248}, {"layer_params": [37, 34, 32], "learning_rate": 0.0010501168701899063, "batch_size": 77, "loss": 0.005322291860356927}, {"layer_params": [61, 18], "learning_rate": 0.005284955767365661, "batch_size": 265, "loss": 0.003478840219322592}, {"layer_params": [60, 51, 18, 37], "learning_rate": 0.005851885407720519, "batch_size": 247, "loss": 0.0007918189966585487}, {"layer_params": [28, 59, 18], "learning_rate": 0.0002751919680664975, "batch_size": 84, "loss": 0.008632909003645182}, {"layer_params": [50, 16, 38], "learning_rate": 0.004523098050111909, "batch_size": 21, "loss": 0.006400920681189745}, {"layer_params": [17, 39, 20, 46], "learning_rate": 0.005686540499796486, "batch_size": 435, "loss": 0.002602335261180997}, {"layer_params": [29, 37, 63], "learning_rate": 0.007031146469719954, "batch_size": 117, "loss": 0.0021762519993353633}, {"layer_params": [59, 30, 36], "learning_rate": 0.007152202334643683, "batch_size": 264, "loss": 0.0011493865976808593}, {"layer_params": [24, 37, 52], "learning_rate": 0.005142561549488702, "batch_size": 378, "loss": 0.0029372792295180262}, {"layer_params": [46, 29], "learning_rate": 0.0028480091790200677, "batch_size": 27, "loss": 0.006207403163425624}, {"layer_params": [29, 28, 52, 29], "learning_rate": 0.006636439849354343, "batch_size": 415, "loss": 0.001586564575554803}, {"layer_params": [40, 49, 26], "learning_rate": 0.007982303878351188, "batch_size": 29, "loss": 0.0053772054717410355}, {"layer_params": [32, 16], "learning_rate": 0.004635071205079839, "batch_size": 75, "loss": 0.00676910066511482}, {"layer_params": [41, 58, 36], "learning_rate": 0.00944531927072696, "batch_size": 137, "loss": 0.002096811360679567}, {"layer_params": [62, 59, 39, 53, 18], "learning_rate": 0.0009310664733629938, "batch_size": 19, "loss": 0.008058889235835523}, {"layer_params": [50, 50, 17, 33], "learning_rate": 0.006154285560247405, "batch_size": 495, "loss": 0.0019207630818709731}, {"layer_params": [36, 28, 49, 30], "learning_rate": 0.0075127996745487065, "batch_size": 383, "loss": 0.00187555049196817}, {"layer_params": [43, 38, 18], "learning_rate": 0.004260729693765979, "batch_size": 48, "loss": 0.0035107325902208686}, {"layer_params": [40, 57, 60, 51, 26], "learning_rate": 0.0027809428013029647, "batch_size": 466, "loss": 0.0015241156273987145}, {"layer_params": [59, 19, 52, 33], "learning_rate": 0.004959784007719583, "batch_size": 233, "loss": 0.0020058218378107995}, {"layer_params": [61, 45, 60, 35, 41], "learning_rate": 0.0036876569202730965, "batch_size": 497, "loss": 0.001120802871300839}, {"layer_params": [39, 36, 24, 32, 16], "learning_rate": 0.0034328114028360115, "batch_size": 306, "loss": 0.0017602577991783618}, {"layer_params": [23, 33], "learning_rate": 0.008261690224476738, "batch_size": 191, "loss": 0.0027724881656467915}, {"layer_params": [58, 53], "learning_rate": 0.0044094482348483064, "batch_size": 350, "loss": 0.0019333724351599812}, {"layer_params": [57, 45, 49, 27], "learning_rate": 0.002223558751520413, "batch_size": 215, "loss": 0.001553259827196598}, {"layer_params": [39, 54, 36, 16], "learning_rate": 0.007361420253117414, "batch_size": 325, "loss": 0.0015347576863132418}, {"layer_params": [39, 49, 37], "learning_rate": 0.00296098492275123, "batch_size": 65, "loss": 0.0031725705310236664}, {"layer_params": [48, 35, 23, 59], "learning_rate": 0.007934379722554851, "batch_size": 287, "loss": 0.0009888337709708138}, {"layer_params": [33, 60, 45, 32, 38], "learning_rate": 0.007982090437423437, "batch_size": 414, "loss": 0.0010497208265587688}, {"layer_params": [59, 19], "learning_rate": 0.00010792320006273744, "batch_size": 491, "loss": 0.026745483335107564}, {"layer_params": [33, 52, 16, 29, 34], "learning_rate": 0.005012399308904898, "batch_size": 96, "loss": 0.0034296801243908705}, {"layer_params": [27, 60], "learning_rate": 0.00571313092940032, "batch_size": 464, "loss": 0.0022161949379369615}, {"layer_params": [29, 18, 45, 56, 25], "learning_rate": 0.00035079849953081947, "batch_size": 159, "loss": 0.00808226949069649}, {"layer_params": [38, 34, 25, 29, 51], "learning_rate": 0.00847118354363288, "batch_size": 490, "loss": 0.0022648336936254053}, {"layer_params": [22, 48, 23, 36, 49], "learning_rate": 0.00407317139785847, "batch_size": 389, "loss": 0.001971184071153402}, {"layer_params": [39, 32, 29, 20, 22], "learning_rate": 0.004852269315759849, "batch_size": 319, "loss": 0.0012977493304060772}, {"layer_params": [21, 57], "learning_rate": 0.009963937557953936, "batch_size": 447, "loss": 0.001947685342747718}, {"layer_params": [38, 34, 60, 33], "learning_rate": 0.007561952623669594, "batch_size": 464, "loss": 0.0015942689089570195}, {"layer_params": [62, 49, 60, 16], "learning_rate": 0.001825862048144084, "batch_size": 337, "loss": 0.0015873225044924766}, {"layer_params": [44, 64, 32, 47], "learning_rate": 0.003326285015871249, "batch_size": 302, "loss": 0.0009683612547814846}, {"layer_params": [37, 33, 34], "learning_rate": 0.0014366011333028655, "batch_size": 507, "loss": 0.0031102120433934032}, {"layer_params": [29, 30, 18, 55, 28], "learning_rate": 0.008734406602130323, "batch_size": 216, "loss": 0.002520549112232402}, {"layer_params": [43, 19, 48], "learning_rate": 0.00759555089439964, "batch_size": 56, "loss": 0.004109234823845327}, {"layer_params": [32, 27, 55, 53, 22], "learning_rate": 0.006975182349895492, "batch_size": 512, "loss": 0.001251577044604346}, {"layer_params": [46, 23, 62, 41], "learning_rate": 0.0013695826724267638, "batch_size": 130, "loss": 0.00429553771391511}, {"layer_params": [41, 46, 27, 35, 24], "learning_rate": 0.008924798345370424, "batch_size": 382, "loss": 0.0010081571276532486}, {"layer_params": [51, 54], "learning_rate": 0.0004083264094577836, "batch_size": 105, "loss": 0.00681908714119345}, {"layer_params": [58, 43], "learning_rate": 0.007369228400731846, "batch_size": 304, "loss": 0.0018586400733329356}, {"layer_params": [32, 34, 29, 19], "learning_rate": 0.0025016814588640223, "batch_size": 194, "loss": 0.0024795471131801605}, {"layer_params": [64, 17, 31], "learning_rate": 0.003227681268409469, "batch_size": 397, "loss": 0.0027464812947437167}, {"layer_params": [26, 47], "learning_rate": 0.007221469815936446, "batch_size": 314, "loss": 0.0020630805601831526}, {"layer_params": [29, 32, 42, 59, 42], "learning_rate": 0.006833775259979036, "batch_size": 102, "loss": 0.004209077418781817}, {"layer_params": [21, 31], "learning_rate": 0.0034675676585427893, "batch_size": 492, "loss": 0.0036471959855407477}, {"layer_params": [23, 52, 43, 26], "learning_rate": 0.004326721019704691, "batch_size": 181, "loss": 0.003257023936603218}, {"layer_params": [56, 48, 53, 62], "learning_rate": 0.006911514795691116, "batch_size": 97, "loss": 0.0023234240536112337}, {"layer_params": [63, 61], "learning_rate": 0.001952030882997482, "batch_size": 207, "loss": 0.0017225063929799944}, {"layer_params": [64, 54, 59], "learning_rate": 0.009564218455627934, "batch_size": 282, "loss": 0.0007089203095529228}, {"layer_params": [64, 56], "learning_rate": 0.009451079609411836, "batch_size": 409, "loss": 0.0007854045275598764}, {"layer_params": [34, 26, 64, 33], "learning_rate": 0.0048228783950749, "batch_size": 225, "loss": 0.0014197373623028398}, {"layer_params": [37, 32, 24, 21], "learning_rate": 0.006327358985445896, "batch_size": 364, "loss": 0.0015822547930292785}, {"layer_params": [29, 37, 45, 46, 55], "learning_rate": 0.007006462935691604, "batch_size": 220, "loss": 0.0027042591699864716}, {"layer_params": [21, 64, 60], "learning_rate": 0.0008402680705605747, "batch_size": 145, "loss": 0.003951912943739444}, {"layer_params": [59, 43, 57], "learning_rate": 0.005941290035221758, "batch_size": 459, "loss": 0.001931639389367774}, {"layer_params": [57, 38], "learning_rate": 0.00827393502442679, "batch_size": 303, "loss": 0.0011987220944138244}, {"layer_params": [16, 41, 33, 50], "learning_rate": 0.004050713469307636, "batch_size": 219, "loss": 0.003853945601731539}, {"layer_params": [48, 38, 46], "learning_rate": 0.0020230959230212848, "batch_size": 255, "loss": 0.002205673799617216}, {"layer_params": [40, 47, 20, 31], "learning_rate": 0.0035134397240033253, "batch_size": 267, "loss": 0.00177471294417046}, {"layer_params": [54, 31, 17], "learning_rate": 0.008734008006411258, "batch_size": 279, "loss": 0.0015781832113862038}, {"layer_params": [31, 54, 25, 39, 32], "learning_rate": 0.009604367027551549, "batch_size": 361, "loss": 0.0028933114581741392}, {"layer_params": [55, 27, 52, 64], "learning_rate": 0.004988396070774819, "batch_size": 458, "loss": 0.0015053161792457103}, {"layer_params": [30, 61, 25, 42], "learning_rate": 0.003579249745547022, "batch_size": 38, "loss": 0.004028224683133885}, {"layer_params": [26, 29, 38, 35, 26], "learning_rate": 0.008104952872529497, "batch_size": 490, "loss": 0.0023432669893372806}, {"layer_params": [17, 37, 57], "learning_rate": 0.006993121746013038, "batch_size": 468, "loss": 0.0016418946976773441}, {"layer_params": [54, 51, 32, 43, 55], "learning_rate": 0.0068307089531845595, "batch_size": 392, "loss": 0.0013022899301722646}, {"layer_params": [26, 59, 16, 46], "learning_rate": 0.0039205888541639375, "batch_size": 473, "loss": 0.001440223673125729}, {"layer_params": [63, 17, 61, 38, 63], "learning_rate": 0.008659074933577952, "batch_size": 268, "loss": 0.002447129877982661}, {"layer_params": [56, 49, 61, 64], "learning_rate": 0.008135067302409238, "batch_size": 389, "loss": 0.0012104739056667314}, {"layer_params": [60, 58, 57], "learning_rate": 0.008941426189644958, "batch_size": 469, "loss": 0.0007304056984139606}, {"layer_params": [52, 49, 23], "learning_rate": 0.0047392922936456685, "batch_size": 218, "loss": 0.0012735955230891705}, {"layer_params": [49, 54, 40, 48, 39], "learning_rate": 0.006713034356341446, "batch_size": 46, "loss": 0.00413814990548417}, {"layer_params": [40, 33, 17], "learning_rate": 0.005155090193458885, "batch_size": 504, "loss": 0.002001119607593864}, {"layer_params": [23, 50, 61], "learning_rate": 0.007741162351028579, "batch_size": 115, "loss": 0.002826937502250075}, {"layer_params": [37, 24], "learning_rate": 0.0060709938418784856, "batch_size": 97, "loss": 0.004774573044851422}, {"layer_params": [62, 25, 17], "learning_rate": 0.006271846142411499, "batch_size": 404, "loss": 0.0014984147518407554}, {"layer_params": [28, 54], "learning_rate": 0.006803257981816252, "batch_size": 184, "loss": 0.0024171123129781338}, {"layer_params": [46, 24], "learning_rate": 0.004829065026068796, "batch_size": 445, "loss": 0.002109483781969175}, {"layer_params": [27, 41], "learning_rate": 0.004643068815670976, "batch_size": 32, "loss": 0.006335357497446239}, {"layer_params": [27, 27, 49, 41, 16], "learning_rate": 0.002876930450866905, "batch_size": 89, "loss": 0.003078241052571684}, {"layer_params": [38, 64], "learning_rate": 0.001213132906245226, "batch_size": 508, "loss": 0.0031256866967305542}, {"layer_params": [24, 25, 57, 46, 62], "learning_rate": 0.00833818237154705, "batch_size": 391, "loss": 0.0022261005092877894}, {"layer_params": [16, 34, 18, 52], "learning_rate": 0.00944914546316382, "batch_size": 389, "loss": 0.0029837358044460414}, {"layer_params": [18, 29, 21, 51, 38], "learning_rate": 0.002826956173634383, "batch_size": 413, "loss": 0.0023778971808496863}, {"layer_params": [20, 64, 33, 23], "learning_rate": 0.00499706123482875, "batch_size": 259, "loss": 0.002896343821194023}, {"layer_params": [60, 20, 55, 40], "learning_rate": 0.005848300582066488, "batch_size": 179, "loss": 0.0021005098114255816}, {"layer_params": [56, 54], "learning_rate": 0.00773572286934695, "batch_size": 379, "loss": 0.0017951556143816561}, {"layer_params": [59, 34], "learning_rate": 0.0029468355996569435, "batch_size": 130, "loss": 0.0021003584389109164}, {"layer_params": [46, 34, 48, 55], "learning_rate": 0.008007940646833515, "batch_size": 263, "loss": 0.0019861459452658894}, {"layer_params": [49, 19, 16, 52, 44], "learning_rate": 0.00040992745259082125, "batch_size": 38, "loss": 0.00748712687054649}, {"layer_params": [55, 57, 37, 45, 62], "learning_rate": 0.007675030658078832, "batch_size": 241, "loss": 0.001577744553796947}, {"layer_params": [54, 32, 23], "learning_rate": 0.009398287151008756, "batch_size": 90, "loss": 0.0023924617271404713}, {"layer_params": [51, 34, 60], "learning_rate": 0.005501444561373854, "batch_size": 323, "loss": 0.0017800371418707072}, {"layer_params": [33, 36, 43, 19], "learning_rate": 0.008319600770619042, "batch_size": 301, "loss": 0.0029497106536291538}, {"layer_params": [54, 52, 43], "learning_rate": 0.00980607570209976, "batch_size": 220, "loss": 0.0017369948828127235}, {"layer_params": [37, 56, 51, 51, 29], "learning_rate": 0.004892093922537469, "batch_size": 409, "loss": 0.0011528061766875907}, {"layer_params": [23, 42, 55, 60, 60], "learning_rate": 0.00990900705923186, "batch_size": 433, "loss": 0.0014400288928300142}, {"layer_params": [28, 42, 49, 48, 29], "learning_rate": 0.002671784953662513, "batch_size": 222, "loss": 0.002524146088398993}, {"layer_params": [56, 39, 58, 57], "learning_rate": 0.0023224900145378817, "batch_size": 133, "loss": 0.0021338557614944877}, {"layer_params": [27, 63], "learning_rate": 0.0005887512626644809, "batch_size": 299, "loss": 0.007979716579429806}, {"layer_params": [60, 55], "learning_rate": 0.005057110733153914, "batch_size": 456, "loss": 0.0013540867366828024}, {"layer_params": [40, 46, 62, 61, 26], "learning_rate": 0.0014421632559548714, "batch_size": 109, "loss": 0.00462703792611137}, {"layer_params": [34, 64, 38, 20], "learning_rate": 0.008234731936875834, "batch_size": 243, "loss": 0.001799796047853306}, {"layer_params": [47, 45, 31, 28], "learning_rate": 0.009573392584076227, "batch_size": 332, "loss": 0.001510009600315243}, {"layer_params": [59, 49, 58, 35], "learning_rate": 0.004262231914908958, "batch_size": 65, "loss": 0.0025190435885451734}, {"layer_params": [52, 36, 36, 55, 48], "learning_rate": 0.004488580125525771, "batch_size": 349, "loss": 0.001469868728891015}, {"layer_params": [35, 48, 64, 43], "learning_rate": 0.009716669456810064, "batch_size": 386, "loss": 0.001192396859987639}, {"layer_params": [48, 25, 57, 50], "learning_rate": 0.008562448053885625, "batch_size": 479, "loss": 0.0019246567436493932}, {"layer_params": [64, 52, 25, 60], "learning_rate": 0.006520682041085113, "batch_size": 377, "loss": 0.0012870192260015757}, {"layer_params": [26, 62], "learning_rate": 0.00931872487375501, "batch_size": 506, "loss": 0.0017081117769703268}, {"layer_params": [21, 28, 54], "learning_rate": 0.005295486819544744, "batch_size": 462, "loss": 0.0022902923030778764}, {"layer_params": [26, 33, 53], "learning_rate": 0.00012367687036437042, "batch_size": 32, "loss": 0.026450260365381836}, {"layer_params": [38, 37, 21, 50, 28], "learning_rate": 0.0069311250177413325, "batch_size": 87, "loss": 0.0038175802794285117}, {"layer_params": [31, 56, 32, 45], "learning_rate": 0.007699980579003009, "batch_size": 457, "loss": 0.0017405480472370983}, {"layer_params": [43, 52], "learning_rate": 0.007990109749640604, "batch_size": 394, "loss": 0.0012757720879744737}, {"layer_params": [55, 26, 37, 34], "learning_rate": 0.009216276000742131, "batch_size": 293, "loss": 0.0014799692726228386}, {"layer_params": [37, 64, 42, 30, 56], "learning_rate": 0.004660950655869718, "batch_size": 390, "loss": 0.0015716493432410062}, {"layer_params": [56, 45], "learning_rate": 0.004151800956184223, "batch_size": 258, "loss": 0.0020709825470112265}, {"layer_params": [61, 37, 37, 34, 44], "learning_rate": 0.00500987855402891, "batch_size": 66, "loss": 0.0029711460100952537}, {"layer_params": [51, 41, 64], "learning_rate": 0.006001200454088646, "batch_size": 355, "loss": 0.0016763137106318028}, {"layer_params": [34, 58, 52, 50, 30], "learning_rate": 0.007251281542053769, "batch_size": 264, "loss": 0.001393990385113284}, {"layer_params": [62, 27, 60, 16, 41], "learning_rate": 0.0044771959267832055, "batch_size": 509, "loss": 0.0008642889448674396}, {"layer_params": [36, 31, 22], "learning_rate": 0.009471106440561866, "batch_size": 115, "loss": 0.0028048061521258206}, {"layer_params": [22, 20, 23], "learning_rate": 0.005647153033986571, "batch_size": 75, "loss": 0.007327213394455611}, {"layer_params": [60, 21, 44, 29, 18], "learning_rate": 0.0049811697610842205, "batch_size": 373, "loss": 0.002066368627129123}, {"layer_params": [18, 35], "learning_rate": 0.009624803959964123, "batch_size": 483, "loss": 0.0028355312324129045}, {"layer_params": [36, 60, 47, 21, 37], "learning_rate": 0.005130040829151215, "batch_size": 127, "loss": 0.0016781717725098133}, {"layer_params": [36, 49], "learning_rate": 0.0020294411054140476, "batch_size": 312, "loss": 0.003576050675474107}, {"layer_params": [42, 51, 31], "learning_rate": 0.006727859210027569, "batch_size": 460, "loss": 0.001286726458929479}, {"layer_params": [47, 26, 54, 30], "learning_rate": 0.004760317963248364, "batch_size": 481, "loss": 0.0014312755689024925}, {"layer_params": [59, 22, 37, 37, 56], "learning_rate": 0.0021731194420858725, "batch_size": 321, "loss": 0.001748301750048995}, {"layer_params": [36, 53, 34, 34], "learning_rate": 0.006095980461801184, "batch_size": 150, "loss": 0.0019310458807740361}, {"layer_params": [22, 47], "learning_rate": 0.0005716098028023477, "batch_size": 491, "loss": 0.006887207748368382}, {"layer_params": [44, 21], "learning_rate": 9.200402996383698e-05, "batch_size": 320, "loss": 0.02750292284414172}, {"layer_params": [59, 52, 36, 45], "learning_rate": 0.005293199897733314, "batch_size": 334, "loss": 0.001039767840411514}, {"layer_params": [53, 27, 19, 57], "learning_rate": 0.00935326229545421, "batch_size": 106, "loss": 0.0029315407713875175}, {"layer_params": [49, 25, 19, 50], "learning_rate": 0.006902030813753082, "batch_size": 79, "loss": 0.0024671275122091175}, {"layer_params": [22, 25], "learning_rate": 0.0005608401013921267, "batch_size": 424, "loss": 0.008364551821723581}, {"layer_params": [61, 38], "learning_rate": 0.008289539106234556, "batch_size": 120, "loss": 0.001928162716794759}, {"layer_params": [38, 41], "learning_rate": 0.0038144920414581373, "batch_size": 368, "loss": 0.0014166322886012494}, {"layer_params": [46, 48, 56], "learning_rate": 0.008750267650548697, "batch_size": 205, "loss": 0.0018822653032839298}, {"layer_params": [37, 62], "learning_rate": 0.004962304726437474, "batch_size": 73, "loss": 0.003331811868119985}, {"layer_params": [16, 53, 46, 56, 45], "learning_rate": 0.005491148128751195, "batch_size": 345, "loss": 0.0024771475442685186}, {"layer_params": [51, 26], "learning_rate": 0.0013020039837928336, "batch_size": 140, "loss": 0.0054000887228176}, {"layer_params": [25, 55, 26, 39], "learning_rate": 0.00516674939718408, "batch_size": 442, "loss": 0.0008335561398416757}, {"layer_params": [57, 23], "learning_rate": 0.007608247213954225, "batch_size": 24, "loss": 0.005504455058835447}, {"layer_params": [24, 30], "learning_rate": 0.006720010459170127, "batch_size": 138, "loss": 0.003913456075824797}, {"layer_params": [28, 50, 35], "learning_rate": 0.00996336779541727, "batch_size": 63, "loss": 0.0037763690273277463}, {"layer_params": [32, 64], "learning_rate": 0.008497512793440454, "batch_size": 235, "loss": 0.0020424679084680973}, {"layer_params": [60, 23, 16], "learning_rate": 0.002307359617986531, "batch_size": 329, "loss": 0.002342365398071706}, {"layer_params": [37, 58], "learning_rate": 0.0086882603828898, "batch_size": 395, "loss": 0.001111687698867172}, {"layer_params": [53, 30, 38], "learning_rate": 0.0013652044066196354, "batch_size": 489, "loss": 0.0024913028511218726}, {"layer_params": [29, 21], "learning_rate": 0.0023402763519393952, "batch_size": 198, "loss": 0.004453367916867137}, {"layer_params": [58, 27, 54], "learning_rate": 0.008490797292626945, "batch_size": 488, "loss": 0.0007355926622403786}, {"layer_params": [43, 48, 56, 26, 32], "learning_rate": 0.00908998944484246, "batch_size": 228, "loss": 0.0013315544446231798}, {"layer_params": [35, 61], "learning_rate": 0.007717349708290221, "batch_size": 185, "loss": 0.00233326040324755}, {"layer_params": [44, 19, 33, 32, 36], "learning_rate": 0.008347682316842034, "batch_size": 68, "loss": 0.0037694849376566707}, {"layer_params": [45, 44, 37, 57], "learning_rate": 0.009978421267149486, "batch_size": 444, "loss": 0.0016267974977381527}, {"layer_params": [35, 37, 45, 37], "learning_rate": 0.006072565696026583, "batch_size": 23, "loss": 0.006677628433099016}, {"layer_params": [20, 22, 30, 40, 55], "learning_rate": 0.005158134292634595, "batch_size": 23, "loss": 0.008414367730729282}, {"layer_params": [41, 61, 61, 51], "learning_rate": 0.008605241352907534, "batch_size": 112, "loss": 0.001969092634972185}, {"layer_params": [54, 26, 63, 44], "learning_rate": 6.77313324258595e-05, "batch_size": 466, "loss": 0.019462704099714755}, {"layer_params": [39, 31, 38, 38], "learning_rate": 0.004415226663584587, "batch_size": 255, "loss": 0.0019938907364849003}, {"layer_params": [32, 27], "learning_rate": 0.0006387301837802153, "batch_size": 122, "loss": 0.00747014423366636}, {"layer_params": [64, 18], "learning_rate": 0.005083982095465628, "batch_size": 291, "loss": 0.002349434980424121}, {"layer_params": [50, 54, 40, 58, 17], "learning_rate": 0.007314624618958676, "batch_size": 67, "loss": 0.0023901829298119993}, {"layer_params": [58, 21, 22, 35], "learning_rate": 0.007056303339630351, "batch_size": 226, "loss": 0.00108366840693634}, {"layer_params": [36, 31, 34, 44], "learning_rate": 0.009337225585503012, "batch_size": 322, "loss": 0.002404990956420079}, {"layer_params": [57, 29, 61, 57, 49], "learning_rate": 0.0029186753142382165, "batch_size": 339, "loss": 0.0013313108711736276}, {"layer_params": [63, 64, 41], "learning_rate": 0.0070395477042649885, "batch_size": 437, "loss": 0.0011187751876423136}, {"layer_params": [33, 52], "learning_rate": 0.0060699516803941755, "batch_size": 216, "loss": 0.002907388680614531}, {"layer_params": [63, 52, 49, 48, 26], "learning_rate": 0.0015572391877295795, "batch_size": 264, "loss": 0.0017395980015862734}, {"layer_params": [28, 42, 46, 18, 22], "learning_rate": 0.009715093662992636, "batch_size": 468, "loss": 0.0022051203367300333}, {"layer_params": [62, 33, 54], "learning_rate": 0.0005432809717027491, "batch_size": 69, "loss": 0.005672043804079294}, {"layer_params": [57, 17, 22, 22, 34], "learning_rate": 0.005814153822081488, "batch_size": 504, "loss": 0.0025325215654447676}, {"layer_params": [29, 21, 58], "learning_rate": 0.0043692510515463915, "batch_size": 172, "loss": 0.002573910653591156}, {"layer_params": [26, 34, 29, 57], "learning_rate": 0.006495889521383887, "batch_size": 468, "loss": 0.0017549954634159804}, {"layer_params": [57, 39, 36], "learning_rate": 0.0006692786741191277, "batch_size": 182, "loss": 0.004157271410804242}, {"layer_params": [45, 38, 62, 57, 50], "learning_rate": 0.005871957624130991, "batch_size": 332, "loss": 0.0013511935365386307}, {"layer_params": [32, 25, 28], "learning_rate": 0.005971992834925552, "batch_size": 350, "loss": 0.0028570280526764693}, {"layer_params": [63, 50, 29, 52], "learning_rate": 0.0039452173877854955, "batch_size": 333, "loss": 0.0010545884509338065}, {"layer_params": [57, 35, 61], "learning_rate": 0.007858906657277768, "batch_size": 471, "loss": 0.0008299253403674811}, {"layer_params": [40, 42], "learning_rate": 0.006096659942081325, "batch_size": 93, "loss": 0.002054705665213987}, {"layer_params": [56, 17, 32, 53, 34], "learning_rate": 0.0024144955780724944, "batch_size": 234, "loss": 0.0024371310661081224}, {"layer_params": [42, 35, 18, 29], "learning_rate": 0.0017911608150183887, "batch_size": 440, "loss": 0.0023808258469216526}, {"layer_params": [37, 21], "learning_rate": 0.003960327361005921, "batch_size": 225, "loss": 0.0048440461256541315}, {"layer_params": [21, 49, 37, 45, 37], "learning_rate": 0.006655800498000499, "batch_size": 50, "loss": 0.00557680289959535}, {"layer_params": [47, 24, 43], "learning_rate": 0.002336873505770895, "batch_size": 224, "loss": 0.003244892451912165}, {"layer_params": [19, 24, 58], "learning_rate": 0.0012361220259863655, "batch_size": 57, "loss": 0.006635920929256827}, {"layer_params": [26, 51], "learning_rate": 0.009312382044942074, "batch_size": 177, "loss": 0.002346805512206629}, {"layer_params": [16, 21, 62], "learning_rate": 0.008988582995933758, "batch_size": 458, "loss": 0.003817836174275726}, {"layer_params": [43, 60, 29, 61], "learning_rate": 0.002366466129000649, "batch_size": 475, "loss": 0.0019070905714761465}, {"layer_params": [37, 60, 40, 23], "learning_rate": 0.0034199429664922153, "batch_size": 287, "loss": 0.0017264540353789926}, {"layer_params": [44, 34, 29, 47, 59], "learning_rate": 0.0029987729659408666, "batch_size": 422, "loss": 0.0018008931772783398}, {"layer_params": [18, 62, 22, 30], "learning_rate": 0.00506598303102194, "batch_size": 95, "loss": 0.004028615730348974}, {"layer_params": [53, 52, 38, 48], "learning_rate": 0.009465815887175207, "batch_size": 249, "loss": 0.0010922498698346316}, {"layer_params": [60, 45], "learning_rate": 0.007669417227197074, "batch_size": 386, "loss": 0.0009840981574961915}, {"layer_params": [57, 23], "learning_rate": 0.0019317497212356983, "batch_size": 371, "loss": 0.0021432835329324006}, {"layer_params": [31, 37, 30], "learning_rate": 0.003716801820140571, "batch_size": 456, "loss": 0.002171979600097984}, {"layer_params": [26, 55, 16], "learning_rate": 0.005933546808028655, "batch_size": 346, "loss": 0.0019244039186742156}, {"layer_params": [57, 16], "learning_rate": 0.002839174254367601, "batch_size": 90, "loss": 0.004339709740597755}, {"layer_params": [23, 39, 55, 38, 17], "learning_rate": 0.007956442115407409, "batch_size": 314, "loss": 0.0024455895891878753}, {"layer_params": [64, 31], "learning_rate": 0.0065955771282793065, "batch_size": 144, "loss": 0.002937896342482418}, {"layer_params": [37, 35, 24, 62], "learning_rate": 0.0005998166299463958, "batch_size": 322, "loss": 0.004248140105046332}, {"layer_params": [63, 45], "learning_rate": 0.009722092455577336, "batch_size": 151, "loss": 0.00106191013881471}, {"layer_params": [64, 54], "learning_rate": 0.009469860812280816, "batch_size": 30, "loss": 0.0032491103024221957}, {"layer_params": [50, 49, 61], "learning_rate": 0.0012438223646900801, "batch_size": 149, "loss": 0.003511142118368298}, {"layer_params": [53, 45, 64], "learning_rate": 0.0019004424746660478, "batch_size": 270, "loss": 0.0015591005596797913}, {"layer_params": [36, 48], "learning_rate": 0.0060953253953837695, "batch_size": 452, "loss": 0.0022543001372832805}, {"layer_params": [35, 55, 54], "learning_rate": 0.009924388733881635, "batch_size": 127, "loss": 0.0018498081457801164}, {"layer_params": [35, 56, 19], "learning_rate": 0.008246063597590853, "batch_size": 482, "loss": 0.001159296507248655}, {"layer_params": [50, 55], "learning_rate": 0.005227825941817714, "batch_size": 59, "loss": 0.0031938296486623587}, {"layer_params": [34, 17, 34, 22, 25], "learning_rate": 0.00866309773310334, "batch_size": 457, "loss": 0.0027526340470649304}, {"layer_params": [25, 19, 62, 22], "learning_rate": 0.004495453018723486, "batch_size": 113, "loss": 0.005367906123865396}, {"layer_params": [44, 53], "learning_rate": 0.0010802069797681553, "batch_size": 229, "loss": 0.004307680383790285}, {"layer_params": [31, 41, 64, 56, 63], "learning_rate": 0.006366914834755088, "batch_size": 446, "loss": 0.0008161830832250416}, {"layer_params": [20, 59, 59, 64], "learning_rate": 0.006174221701572223, "batch_size": 503, "loss": 0.001252593596582301}, {"layer_params": [20, 16, 25], "learning_rate": 0.0003569614679347266, "batch_size": 157, "loss": 0.01032601285725832}, {"layer_params": [63, 56], "learning_rate": 0.00955660588710992, "batch_size": 49, "loss": 0.0027527944010216744}, {"layer_params": [44, 63, 41], "learning_rate": 0.007326073581674474, "batch_size": 169, "loss": 0.0015150006220210344}, {"layer_params": [30, 19, 21, 46], "learning_rate": 0.006047242431749212, "batch_size": 41, "loss": 0.005695015494711697}, {"layer_params": [22, 64, 59, 33], "learning_rate": 0.006965304769497039, "batch_size": 337, "loss": 0.002045799258630723}, {"layer_params": [21, 43], "learning_rate": 0.007678508186844094, "batch_size": 69, "loss": 0.005544570137280971}, {"layer_params": [60, 56, 43, 53, 30], "learning_rate": 0.00022934225519303546, "batch_size": 161, "loss": 0.006490389532409609}, {"layer_params": [17, 36], "learning_rate": 0.004268549762248636, "batch_size": 194, "loss": 0.002920553290750831}, {"layer_params": [22, 53], "learning_rate": 0.005628499360212377, "batch_size": 462, "loss": 0.0016879797796718777}, {"layer_params": [22, 46, 53], "learning_rate": 0.009957601743054436, "batch_size": 96, "loss": 0.0037065972853451965}, {"layer_params": [38, 35, 16], "learning_rate": 0.008890763030952238, "batch_size": 471, "loss": 0.0017205776704940945}, {"layer_params": [36, 51, 25, 28], "learning_rate": 0.0006434141986803562, "batch_size": 58, "loss": 0.00761802848894149}, {"layer_params": [44, 48, 40, 42], "learning_rate": 0.005711795476977819, "batch_size": 483, "loss": 0.0008495368534931913}, {"layer_params": [57, 51, 25, 58, 56], "learning_rate": 0.0012029724185099917, "batch_size": 345, "loss": 0.0020802889566402883}, {"layer_params": [39, 62, 34], "learning_rate": 0.004833229662424379, "batch_size": 62, "loss": 0.003415584738831967}, {"layer_params": [28, 58, 60, 56, 23], "learning_rate": 0.006446467427192131, "batch_size": 160, "loss": 0.001438560193637386}, {"layer_params": [35, 58, 51, 31], "learning_rate": 0.004360565386832039, "batch_size": 356, "loss": 0.0018796714604832232}, {"layer_params": [44, 29, 55, 44, 59], "learning_rate": 0.007911579942423844, "batch_size": 357, "loss": 0.0017483558400999755}, {"layer_params": [24, 23], "learning_rate": 0.0031837299909016855, "batch_size": 238, "loss": 0.004392706430517137}, {"layer_params": [55, 37, 22, 61, 46], "learning_rate": 0.006245990893214177, "batch_size": 216, "loss": 0.0012664706073701381}, {"layer_params": [36, 56, 36, 33, 43], "learning_rate": 0.0014284879442105858, "batch_size": 48, "loss": 0.0052179756225086745}, {"layer_params": [43, 64, 31], "learning_rate": 0.009810103388469516, "batch_size": 133, "loss": 0.0022460542852059005}, {"layer_params": [20, 32, 61], "learning_rate": 0.0022822536440326303, "batch_size": 61, "loss": 0.006166374150197953}, {"layer_params": [46, 28], "learning_rate": 0.006913972201327507, "batch_size": 347, "loss": 0.0014015163213480263}, {"layer_params": [49, 30, 39, 26, 61], "learning_rate": 0.007660967587380201, "batch_size": 292, "loss": 0.0016820492350962013}, {"layer_params": [50, 40], "learning_rate": 0.00799977837570922, "batch_size": 91, "loss": 0.002424531027209014}, {"layer_params": [46, 52, 49, 63], "learning_rate": 0.006673450823947038, "batch_size": 408, "loss": 0.0010526781366206705}, {"layer_params": [51, 26, 36, 19], "learning_rate": 0.0058778122994026195, "batch_size": 52, "loss": 0.004368960396386683}, {"layer_params": [40, 26, 24, 58], "learning_rate": 0.0064211516871641346, "batch_size": 495, "loss": 0.001350702594500035}, {"layer_params": [50, 36, 51, 37], "learning_rate": 0.0025670590722340625, "batch_size": 319, "loss": 0.002387817333219573}, {"layer_params": [40, 54], "learning_rate": 0.009944223175269416, "batch_size": 117, "loss": 0.002497674513142556}, {"layer_params": [44, 32, 38, 53], "learning_rate": 0.006169403002538643, "batch_size": 148, "loss": 0.002190085514448583}, {"layer_params": [30, 20, 36], "learning_rate": 0.0008259506777223203, "batch_size": 280, "loss": 0.007459796080365777}, {"layer_params": [24, 45], "learning_rate": 0.008915633628999216, "batch_size": 180, "loss": 0.002636511381715536}, {"layer_params": [49, 26, 20], "learning_rate": 0.007089920178456223, "batch_size": 26, "loss": 0.004402312893653289}, {"layer_params": [53, 17], "learning_rate": 0.0009551548356813505, "batch_size": 191, "loss": 0.005872902600094676}, {"layer_params": [53, 45, 54], "learning_rate": 0.008211663728211215, "batch_size": 30, "loss": 0.004835098423063755}, {"layer_params": [64, 26, 53], "learning_rate": 0.009664229390715044, "batch_size": 257, "loss": 0.0022803899145219476}, {"layer_params": [29, 55, 18], "learning_rate": 0.0024447028591531605, "batch_size": 417, "loss": 0.0014831917162518948}, {"layer_params": [27, 23, 54, 57], "learning_rate": 0.009437277434818852, "batch_size": 341, "loss": 0.0021999844489619135}, {"layer_params": [56, 62, 54, 16], "learning_rate": 0.003914762138548824, "batch_size": 231, "loss": 0.00232903225813061}, {"layer_params": [22, 35, 41, 53], "learning_rate": 0.005738640265684601, "batch_size": 172, "loss": 0.0026353233586996795}, {"layer_params": [42, 21, 24, 41, 37], "learning_rate": 0.0023121213722791514, "batch_size": 488, "loss": 0.0021930354612413796}, {"layer_params": [56, 23, 19], "learning_rate": 0.006193349053291909, "batch_size": 290, "loss": 0.0021797854895703496}, {"layer_params": [50, 20, 21, 29], "learning_rate": 0.005910571218211652, "batch_size": 86, "loss": 0.0028219225723296404}, {"layer_params": [29, 46, 44, 59], "learning_rate": 0.00469664251037478, "batch_size": 271, "loss": 0.001708053145557642}, {"layer_params": [17, 19], "learning_rate": 0.002322030507748836, "batch_size": 86, "loss": 0.008231633678078651}, {"layer_params": [19, 64], "learning_rate": 0.002269205470419889, "batch_size": 350, "loss": 0.003912484655156732}, {"layer_params": [30, 34, 35, 59, 20], "learning_rate": 0.004774378571165041, "batch_size": 420, "loss": 0.001198121956549585}, {"layer_params": [16, 63, 36, 51], "learning_rate": 0.002397508841367377, "batch_size": 464, "loss": 0.0029832835169509055}, {"layer_params": [23, 60, 37, 24], "learning_rate": 0.003830721512181104, "batch_size": 135, "loss": 0.0038567262422293425}, {"layer_params": [38, 16, 55], "learning_rate": 0.00030294008479844043, "batch_size": 494, "loss": 0.00667384325992316}, {"layer_params": [18, 51, 45, 47], "learning_rate": 0.004680009529390114, "batch_size": 276, "loss": 0.0020172063517384232}, {"layer_params": [48, 23, 28, 51, 50], "learning_rate": 0.00713158509283992, "batch_size": 350, "loss": 0.0019428658985998482}, {"layer_params": [24, 18, 56, 52], "learning_rate": 0.0076477762146972515, "batch_size": 245, "loss": 0.001941567776957527}, {"layer_params": [59, 35, 34, 54, 54], "learning_rate": 0.00787287076261252, "batch_size": 164, "loss": 0.0014010722388047726}, {"layer_params": [32, 41, 19, 55], "learning_rate": 0.009172311476765635, "batch_size": 408, "loss": 0.0013419872522354127}, {"layer_params": [46, 51, 35, 49], "learning_rate": 0.0021295873011299028, "batch_size": 231, "loss": 0.0019235932570882141}, {"layer_params": [58, 29, 30, 38, 20], "learning_rate": 0.008291757790335464, "batch_size": 239, "loss": 0.002410730217816308}, {"layer_params": [23, 25, 27], "learning_rate": 0.007689814996913954, "batch_size": 493, "loss": 0.0021586427744477985}, {"layer_params": [22, 42, 55, 59], "learning_rate": 0.007832013824412915, "batch_size": 280, "loss": 0.002283849025843665}, {"layer_params": [56, 19, 23, 34, 22], "learning_rate": 0.00820698892773985, "batch_size": 337, "loss": 0.002482930184341967}, {"layer_params": [60, 25, 16], "learning_rate": 0.008697564900549617, "batch_size": 473, "loss": 0.001942113694967702}, {"layer_params": [47, 41, 20], "learning_rate": 0.004492839640840639, "batch_size": 229, "loss": 0.003709932486526668}, {"layer_params": [57, 56, 54], "learning_rate": 0.00787944615984551, "batch_size": 82, "loss": 0.0022331829369068145}, {"layer_params": [41, 28, 33, 50], "learning_rate": 0.00036694277935615067, "batch_size": 184, "loss": 0.00702988619916141}, {"layer_params": [58, 41, 58, 57, 25], "learning_rate": 0.002293409539040395, "batch_size": 320, "loss": 0.0014248647191561759}, {"layer_params": [45, 50], "learning_rate": 0.001758919162150301, "batch_size": 489, "loss": 0.0019060871400870382}, {"layer_params": [30, 56], "learning_rate": 0.0014647786378742316, "batch_size": 454, "loss": 0.0040177787840366365}, {"layer_params": [37, 25, 53, 36], "learning_rate": 0.008450899676713376, "batch_size": 32, "loss": 0.005660021340008825}, {"layer_params": [54, 63, 37], "learning_rate": 0.0010909692662300025, "batch_size": 414, "loss": 0.0016755789809394627}, {"layer_params": [30, 26], "learning_rate": 0.00023985719967854356, "batch_size": 436, "loss": 0.014790000226348639}, {"layer_params": [52, 44, 59], "learning_rate": 0.003254189817762711, "batch_size": 342, "loss": 0.0015211304416880012}, {"layer_params": [19, 32, 51], "learning_rate": 0.001515094756312331, "batch_size": 358, "loss": 0.00337665130617097}, {"layer_params": [50, 40, 34], "learning_rate": 0.005379744238762011, "batch_size": 71, "loss": 0.0030029081786051392}, {"layer_params": [60, 40, 33, 55, 59], "learning_rate": 0.004695920243395899, "batch_size": 423, "loss": 0.0008969776297453791}, {"layer_params": [23, 22, 43, 48, 52], "learning_rate": 0.00394245527403891, "batch_size": 91, "loss": 0.0036788173951208592}, {"layer_params": [19, 59, 54, 18, 37], "learning_rate": 0.007734981858775961, "batch_size": 330, "loss": 0.0018618680373765528}, {"layer_params": [16, 46, 55, 63, 27], "learning_rate": 0.008429145022831284, "batch_size": 32, "loss": 0.007757000220008195}, {"layer_params": [20, 59, 44, 22], "learning_rate": 0.0034976261698642925, "batch_size": 434, "loss": 0.0013025297655258328}, {"layer_params": [28, 16, 54, 26, 50], "learning_rate": 0.008260831402250996, "batch_size": 390, "loss": 0.0023800608178135008}, {"layer_params": [37, 37, 38, 42, 39], "learning_rate": 0.0058584686843045864, "batch_size": 433, "loss": 0.0008476349030388519}, {"layer_params": [16, 40, 28, 40], "learning_rate": 0.008279443441598235, "batch_size": 170, "loss": 0.0038524056551977994}, {"layer_params": [31, 24], "learning_rate": 0.00797480789519564, "batch_size": 20, "loss": 0.007626331374049187}, {"layer_params": [31, 47, 53, 57], "learning_rate": 0.00835217768763843, "batch_size": 464, "loss": 0.001166278409655206}, {"layer_params": [52, 44, 44, 35], "learning_rate": 0.002029288192970123, "batch_size": 19, "loss": 0.007137137807440012}, {"layer_params": [27, 31], "learning_rate": 0.0006573461874199019, "batch_size": 266, "loss": 0.007956074778921901}, {"layer_params": [56, 62, 54], "learning_rate": 0.0032132080454379984, "batch_size": 188, "loss": 0.0014619211724493653}, {"layer_params": [62, 36, 48, 24, 29], "learning_rate": 0.004530625488535303, "batch_size": 89, "loss": 0.0023133156751282513}, {"layer_params": [17, 25, 21, 38, 47], "learning_rate": 0.006361504539394795, "batch_size": 329, "loss": 0.003067932641133666}, {"layer_params": [29, 31], "learning_rate": 0.009655182665543906, "batch_size": 52, "loss": 0.005527723256964236}, {"layer_params": [29, 50], "learning_rate": 0.0025612407357301103, "batch_size": 89, "loss": 0.006058964829426259}, {"layer_params": [48, 51], "learning_rate": 0.001434627172353029, "batch_size": 117, "loss": 0.003997746622189879}, {"layer_params": [19, 16], "learning_rate": 0.005451536568733241, "batch_size": 98, "loss": 0.005475433843676001}, {"layer_params": [57, 39, 62, 51], "learning_rate": 0.0071557065324573494, "batch_size": 214, "loss": 0.001165359314181842}, {"layer_params": [60, 30, 28], "learning_rate": 0.007011635020714428, "batch_size": 30, "loss": 0.005731289100367576}, {"layer_params": [16, 48], "learning_rate": 0.009483508067254207, "batch_size": 242, "loss": 0.0036653842870146038}, {"layer_params": [29, 48], "learning_rate": 0.0016344407758683626, "batch_size": 172, "loss": 0.0066422133706510065}, {"layer_params": [41, 25], "learning_rate": 0.004467710270385625, "batch_size": 505, "loss": 0.0013816122489515692}, {"layer_params": [59, 27], "learning_rate": 0.009496004302759141, "batch_size": 453, "loss": 0.0011440150009002536}, {"layer_params": [44, 54], "learning_rate": 0.0011175491584254598, "batch_size": 145, "loss": 0.003942316973116249}, {"layer_params": [53, 44, 17, 58, 33], "learning_rate": 0.006688617929651433, "batch_size": 259, "loss": 0.0017064109304919838}, {"layer_params": [60, 48], "learning_rate": 0.005689020646474439, "batch_size": 447, "loss": 0.0016723985911812633}, {"layer_params": [38, 34, 55], "learning_rate": 0.009591851546410847, "batch_size": 71, "loss": 0.003236971927108243}, {"layer_params": [58, 28, 21], "learning_rate": 0.006655025752534264, "batch_size": 199, "loss": 0.002383273422019556}, {"layer_params": [16, 64], "learning_rate": 0.0017014054583527794, "batch_size": 357, "loss": 0.004740458442829549}, {"layer_params": [32, 30, 22, 24], "learning_rate": 0.009556303262356992, "batch_size": 372, "loss": 0.0015773388044908643}, {"layer_params": [52, 39, 42], "learning_rate": 0.0011553537313635793, "batch_size": 377, "loss": 0.002332061534980312}, {"layer_params": [39, 56, 22], "learning_rate": 0.0079545304509422, "batch_size": 152, "loss": 0.002414684008108452}, {"layer_params": [56, 63], "learning_rate": 0.004059535791589725, "batch_size": 398, "loss": 0.0011656831606524066}, {"layer_params": [60, 22], "learning_rate": 0.005473549572207492, "batch_size": 438, "loss": 0.00224446058855392}, {"layer_params": [62, 21, 18, 38, 62], "learning_rate": 0.005378776586341998, "batch_size": 446, "loss": 0.001719098798930645}, {"layer_params": [55, 39, 31], "learning_rate": 0.003996097923262305, "batch_size": 417, "loss": 0.0013240314612630755}, {"layer_params": [56, 63, 42], "learning_rate": 0.0024505800244318697, "batch_size": 175, "loss": 0.0020666527526918797}, {"layer_params": [16, 34, 31], "learning_rate": 0.0012800645990793573, "batch_size": 384, "loss": 0.004491774062626064}, {"layer_params": [63, 32, 19, 55, 27], "learning_rate": 0.008050412353420232, "batch_size": 350, "loss": 0.0012880107405362651}, {"layer_params": [36, 61, 59, 16], "learning_rate": 0.008224554468793072, "batch_size": 501, "loss": 0.0011221478844527155}, {"layer_params": [45, 42, 55, 29, 42], "learning_rate": 0.005379788517465103, "batch_size": 51, "loss": 0.0031650188902858645}, {"layer_params": [49, 62, 53, 24], "learning_rate": 0.00555920044516067, "batch_size": 117, "loss": 0.0015063324430957437}, {"layer_params": [16, 31, 42, 18], "learning_rate": 0.008260800924516323, "batch_size": 61, "loss": 0.00523138023680076}, {"layer_params": [44, 37], "learning_rate": 0.0022056216898762747, "batch_size": 450, "loss": 0.0023249640630092472}, {"layer_params": [64, 54, 39], "learning_rate": 0.004337271374331514, "batch_size": 122, "loss": 0.001813476188108325}, {"layer_params": [52, 16, 32, 45, 44], "learning_rate": 0.006741740887128024, "batch_size": 225, "loss": 0.0018728446762543171}, {"layer_params": [33, 27, 51, 45], "learning_rate": 0.007418863178274821, "batch_size": 351, "loss": 0.001782882440602407}, {"layer_params": [59, 24, 54, 28, 64], "learning_rate": 0.0025686326694312474, "batch_size": 299, "loss": 0.0020541577460244298}, {"layer_params": [50, 55, 63, 25, 55], "learning_rate": 0.0011776174710896195, "batch_size": 147, "loss": 0.0024478189030196517}, {"layer_params": [49, 51], "learning_rate": 0.006182051949520735, "batch_size": 203, "loss": 0.0025162967504002154}, {"layer_params": [57, 37], "learning_rate": 0.006614549524885829, "batch_size": 125, "loss": 0.0013753881555749103}, {"layer_params": [61, 49, 55, 37, 47], "learning_rate": 0.0075559302339104914, "batch_size": 445, "loss": 0.0008600902650505304}, {"layer_params": [52, 52], "learning_rate": 0.006602278901840782, "batch_size": 161, "loss": 0.0014183050976134836}, {"layer_params": [16, 24, 55, 29], "learning_rate": 0.004319030991552559, "batch_size": 495, "loss": 0.003556384923867881}, {"layer_params": [32, 27, 27, 58, 56], "learning_rate": 0.0011718819831304315, "batch_size": 172, "loss": 0.003782495658379048}, {"layer_params": [40, 50], "learning_rate": 0.0014971380378502337, "batch_size": 286, "loss": 0.0024597383569926025}, {"layer_params": [27, 63, 37, 52, 49], "learning_rate": 0.009852892339366549, "batch_size": 17, "loss": 0.008214553717989475}, {"layer_params": [18, 22, 31], "learning_rate": 0.003974384907560187, "batch_size": 36, "loss": 0.007922874726355077}, {"layer_params": [31, 63], "learning_rate": 0.008573119159860376, "batch_size": 64, "loss": 0.0026513707241974773}, {"layer_params": [59, 18, 61], "learning_rate": 0.00201941798345172, "batch_size": 288, "loss": 0.0017915332864504308}, {"layer_params": [41, 35, 46, 49, 41], "learning_rate": 0.0024583056562557017, "batch_size": 175, "loss": 0.002192429844290018}, {"layer_params": [19, 23, 43, 56, 37], "learning_rate": 0.002008234134696761, "batch_size": 392, "loss": 0.004282125844620168}, {"layer_params": [26, 62, 17, 58], "learning_rate": 0.005983380916765511, "batch_size": 369, "loss": 0.0016567095217760652}, {"layer_params": [48, 58, 39], "learning_rate": 0.0038501553212309018, "batch_size": 168, "loss": 0.0025963618396781384}, {"layer_params": [20, 25, 25, 44, 48], "learning_rate": 0.0066491186711425095, "batch_size": 277, "loss": 0.0035091505874879658}, {"layer_params": [26, 52], "learning_rate": 0.004600419180874083, "batch_size": 477, "loss": 0.0031291004386730494}, {"layer_params": [45, 47], "learning_rate": 0.006211940820471571, "batch_size": 293, "loss": 0.0015264136390760541}, {"layer_params": [17, 31], "learning_rate": 0.009688005001434945, "batch_size": 366, "loss": 0.003995174893643707}, {"layer_params": [41, 31, 54, 57, 49], "learning_rate": 0.008347942515147897, "batch_size": 202, "loss": 0.002078718701377511}, {"layer_params": [31, 58, 51, 46], "learning_rate": 0.0007451264029067308, "batch_size": 499, "loss": 0.00324728635372594}, {"layer_params": [38, 62, 62, 26], "learning_rate": 0.005178662299307794, "batch_size": 295, "loss": 0.001423997519304976}, {"layer_params": [56, 27, 41, 28], "learning_rate": 0.0019194390058969322, "batch_size": 415, "loss": 0.0021708400174975397}, {"layer_params": [31, 46, 63, 17], "learning_rate": 0.009761411740345038, "batch_size": 48, "loss": 0.005337384291924536}, {"layer_params": [58, 38, 53, 39, 52], "learning_rate": 0.008287910739726782, "batch_size": 470, "loss": 0.0013750127202365548}, {"layer_params": [30, 23, 37, 51, 20], "learning_rate": 0.00418530009792413, "batch_size": 39, "loss": 0.005291842552833259}, {"layer_params": [40, 56, 46, 46, 32], "learning_rate": 0.005379725566662989, "batch_size": 201, "loss": 0.000881741571938619}, {"layer_params": [34, 50, 45, 52, 60], "learning_rate": 0.0028009244632467385, "batch_size": 176, "loss": 0.002085477099753916}, {"layer_params": [27, 44, 17, 28], "learning_rate": 0.0054242368417293085, "batch_size": 126, "loss": 0.0031202310509979726}, {"layer_params": [19, 45, 59], "learning_rate": 0.0011451471915161521, "batch_size": 116, "loss": 0.00513663784833625}, {"layer_params": [60, 30, 28, 45, 21], "learning_rate": 0.008257888312343595, "batch_size": 396, "loss": 0.0007911261322442443}, {"layer_params": [59, 29, 19, 55], "learning_rate": 0.0003370301509532924, "batch_size": 129, "loss": 0.006302280062809587}, {"layer_params": [27, 23, 26, 26, 50], "learning_rate": 0.001271750848501284, "batch_size": 167, "loss": 0.004717142290901393}, {"layer_params": [54, 46, 51], "learning_rate": 0.005778623900397921, "batch_size": 133, "loss": 0.0019141270162072032}, {"layer_params": [64, 30], "learning_rate": 0.008602242635854114, "batch_size": 131, "loss": 0.0019328968587797135}, {"layer_params": [31, 29, 41], "learning_rate": 0.0024215413226735113, "batch_size": 362, "loss": 0.0029128032852895557}, {"layer_params": [27, 22, 54], "learning_rate": 0.005807439290674269, "batch_size": 413, "loss": 0.0026694706501439215}, {"layer_params": [38, 44, 46, 32], "learning_rate": 0.0034409764065604542, "batch_size": 92, "loss": 0.0037744740536436437}, {"layer_params": [60, 29, 52], "learning_rate": 0.0008541841995051463, "batch_size": 292, "loss": 0.0031746713910251858}, {"layer_params": [20, 28, 30, 39], "learning_rate": 0.007334184034250863, "batch_size": 482, "loss": 0.0025647683790884913}, {"layer_params": [56, 49], "learning_rate": 0.00784685223579324, "batch_size": 313, "loss": 0.002207934884354472}, {"layer_params": [48, 41, 32, 44], "learning_rate": 0.008426469929006766, "batch_size": 125, "loss": 0.001604342659120448}, {"layer_params": [40, 51, 16, 49], "learning_rate": 0.007275871276507531, "batch_size": 161, "loss": 0.0017583497182931751}, {"layer_params": [45, 47, 43, 55], "learning_rate": 0.00703181332849706, "batch_size": 363, "loss": 0.0012703815585700794}, {"layer_params": [51, 36, 50, 55], "learning_rate": 0.003887719143259514, "batch_size": 103, "loss": 0.0023640702024567872}, {"layer_params": [19, 21], "learning_rate": 0.005588211777517314, "batch_size": 284, "loss": 0.004344481092412025}, {"layer_params": [40, 61, 48, 50, 40], "learning_rate": 0.006076188922773057, "batch_size": 467, "loss": 0.001192023255280219}, {"layer_params": [26, 20, 41, 40, 40], "learning_rate": 0.004542488338576168, "batch_size": 85, "loss": 0.003243503323756158}, {"layer_params": [38, 23, 29, 51], "learning_rate": 0.0029153675982717467, "batch_size": 143, "loss": 0.0030066072288900615}, {"layer_params": [62, 35, 61, 42, 32], "learning_rate": 0.00553758686548365, "batch_size": 299, "loss": 0.0016700400947593152}, {"layer_params": [64, 48], "learning_rate": 0.0028925992791021303, "batch_size": 339, "loss": 0.0016686733765527606}, {"layer_params": [25, 23, 40], "learning_rate": 0.00871368893422742, "batch_size": 482, "loss": 0.0021011925605125725}, {"layer_params": [23, 39, 18], "learning_rate": 0.006941387570573493, "batch_size": 287, "loss": 0.005604132702574134}, {"layer_params": [29, 21, 37], "learning_rate": 0.009366625011988398, "batch_size": 149, "loss": 0.0031081182602792977}, {"layer_params": [63, 40, 42], "learning_rate": 0.00437273668623224, "batch_size": 421, "loss": 0.001638508605537936}, {"layer_params": [57, 56], "learning_rate": 0.0036456869048625434, "batch_size": 126, "loss": 0.0036253294348716734}, {"layer_params": [49, 54, 42, 54, 43], "learning_rate": 0.008307833176454359, "batch_size": 63, "loss": 0.0029741656745318323}, {"layer_params": [24, 25], "learning_rate": 0.006392958742576533, "batch_size": 361, "loss": 0.004581545502878726}, {"layer_params": [53, 63, 31, 55, 35], "learning_rate": 0.00280499361437615, "batch_size": 471, "loss": 0.0015555428573861719}, {"layer_params": [20, 33, 26], "learning_rate": 0.00149146883617175, "batch_size": 382, "loss": 0.003998408829793334}, {"layer_params": [64, 37, 45, 26], "learning_rate": 0.0062063503897268595, "batch_size": 500, "loss": 0.0008719853626098484}, {"layer_params": [19, 35, 56], "learning_rate": 0.002266042473115536, "batch_size": 85, "loss": 0.0036924337991513312}, {"layer_params": [42, 46, 35, 18], "learning_rate": 0.005473913835499566, "batch_size": 120, "loss": 0.00200431143399328}, {"layer_params": [31, 49, 40, 55, 51], "learning_rate": 0.003028876841790779, "batch_size": 116, "loss": 0.0030394337908364833}, {"layer_params": [46, 34, 47, 64, 21], "learning_rate": 0.008392118944141503, "batch_size": 20, "loss": 0.00744491032557562}, {"layer_params": [46, 39, 64, 39, 53], "learning_rate": 0.005716315591294817, "batch_size": 48, "loss": 0.004170821928419173}, {"layer_params": [38, 32], "learning_rate": 0.0032823839018049287, "batch_size": 396, "loss": 0.002232640176080167}, {"layer_params": [51, 28], "learning_rate": 0.006325907840002083, "batch_size": 294, "loss": 0.0019247881427872926}, {"layer_params": [28, 17, 63], "learning_rate": 0.006518466526194581, "batch_size": 52, "loss": 0.005579560573678464}, {"layer_params": [62, 45], "learning_rate": 0.00038881846456445795, "batch_size": 511, "loss": 0.006297667208127677}, {"layer_params": [40, 27, 40, 50], "learning_rate": 0.0065122012154385685, "batch_size": 56, "loss": 0.004185977126471698}, {"layer_params": [34, 39, 64, 57], "learning_rate": 0.0010879662010020198, "batch_size": 362, "loss": 0.002301994690205902}, {"layer_params": [37, 16, 28, 20, 44], "learning_rate": 0.009478547613627831, "batch_size": 103, "loss": 0.003717031301930547}, {"layer_params": [18, 24, 44, 37], "learning_rate": 0.005295497999624992, "batch_size": 207, "loss": 0.0038968440098688007}, {"layer_params": [35, 46, 16, 26, 21], "learning_rate": 0.0012317626804476025, "batch_size": 455, "loss": 0.0030080776661634443}, {"layer_params": [53, 54, 40, 38, 19], "learning_rate": 0.002052710619219177, "batch_size": 325, "loss": 0.0021189421764574944}, {"layer_params": [61, 42], "learning_rate": 0.006948793361986712, "batch_size": 128, "loss": 0.0023338477418292313}, {"layer_params": [17, 42, 60], "learning_rate": 0.004002701388290972, "batch_size": 482, "loss": 0.0027730188728310166}, {"layer_params": [25, 46], "learning_rate": 0.009650769443904583, "batch_size": 386, "loss": 0.0028353955806232987}, {"layer_params": [33, 61, 29, 54, 36], "learning_rate": 0.006454135949338238, "batch_size": 134, "loss": 0.002209124503424391}, {"layer_params": [28, 37, 59, 16], "learning_rate": 0.00265639764766204, "batch_size": 452, "loss": 0.0016837434039916844}, {"layer_params": [61, 46, 22, 40], "learning_rate": 0.008173156361735111, "batch_size": 376, "loss": 0.001180741980788298}, {"layer_params": [29, 44, 52], "learning_rate": 0.007609560542995952, "batch_size": 474, "loss": 0.0018182093009818346}, {"layer_params": [35, 38], "learning_rate": 0.0033489179930288092, "batch_size": 197, "loss": 0.0035118540516123177}, {"layer_params": [46, 30, 61, 44], "learning_rate": 0.009888936788697735, "batch_size": 96, "loss": 0.0039164358377456665}, {"layer_params": [52, 41], "learning_rate": 0.006954218760798749, "batch_size": 99, "loss": 0.0023630069347564133}, {"layer_params": [32, 50], "learning_rate": 0.00039977142105879476, "batch_size": 66, "loss": 0.008991111293435097}, {"layer_params": [44, 46], "learning_rate": 0.008347517570059226, "batch_size": 463, "loss": 0.0026651055144611747}, {"layer_params": [58, 39, 36, 34, 30], "learning_rate": 0.007953025315500583, "batch_size": 219, "loss": 0.0016709331783931703}, {"layer_params": [22, 25], "learning_rate": 0.0012267551760688743, "batch_size": 75, "loss": 0.007294393703341484}, {"layer_params": [28, 51, 43, 30], "learning_rate": 0.0011516952871138705, "batch_size": 495, "loss": 0.002473224871791899}, {"layer_params": [33, 51, 57], "learning_rate": 0.004661097907859517, "batch_size": 295, "loss": 0.0027103877766057848}, {"layer_params": [34, 30, 22, 48], "learning_rate": 0.006296950476896416, "batch_size": 262, "loss": 0.002484197202138603}, {"layer_params": [62, 21, 53], "learning_rate": 0.0007754694552030543, "batch_size": 163, "loss": 0.003568405306432396}, {"layer_params": [53, 53, 43, 53], "learning_rate": 7.242807151132169e-05, "batch_size": 361, "loss": 0.009614702127873898}, {"layer_params": [47, 37], "learning_rate": 0.006379817500894175, "batch_size": 203, "loss": 0.0018091054353863}, {"layer_params": [44, 33], "learning_rate": 0.0018282381572346587, "batch_size": 469, "loss": 0.00295064756879583}, {"layer_params": [60, 24], "learning_rate": 0.0069934311389664204, "batch_size": 474, "loss": 0.0015294269309379161}, {"layer_params": [49, 26], "learning_rate": 0.007363617490975266, "batch_size": 27, "loss": 0.005449176700785756}, {"layer_params": [50, 59, 16, 54], "learning_rate": 0.005390525563383606, "batch_size": 258, "loss": 0.002254061409039423}, {"layer_params": [31, 36, 48], "learning_rate": 0.004381077816878626, "batch_size": 309, "loss": 0.0022957485588267447}, {"layer_params": [24, 40, 28, 62], "learning_rate": 0.00949170829499023, "batch_size": 154, "loss": 0.0017845772625878454}, {"layer_params": [51, 56, 53], "learning_rate": 0.0031325341377123877, "batch_size": 392, "loss": 0.0012940435588825493}, {"layer_params": [31, 25, 17, 32], "learning_rate": 0.009727197271536878, "batch_size": 388, "loss": 0.002691333910916001}, {"layer_params": [58, 44, 28, 19, 49], "learning_rate": 0.007483882445596257, "batch_size": 427, "loss": 0.001355872006388381}, {"layer_params": [30, 28, 20, 35], "learning_rate": 0.003276259148559253, "batch_size": 506, "loss": 0.002265989346196875}, {"layer_params": [29, 59, 24], "learning_rate": 0.005969813600284733, "batch_size": 144, "loss": 0.0030018973350524904}, {"layer_params": [46, 31], "learning_rate": 0.006323705704644191, "batch_size": 118, "loss": 0.0047437874553725124}, {"layer_params": [59, 28, 32], "learning_rate": 0.0022978557867310003, "batch_size": 219, "loss": 0.0027975740982219576}, {"layer_params": [41, 33, 45, 30], "learning_rate": 0.00814210782600249, "batch_size": 280, "loss": 0.001862417528172955}, {"layer_params": [53, 18, 37, 46], "learning_rate": 0.00462191309774447, "batch_size": 129, "loss": 0.0021409096382558348}, {"layer_params": [54, 42, 31, 20, 43], "learning_rate": 0.004554293569647603, "batch_size": 226, "loss": 0.002623589993454516}, {"layer_params": [22, 57, 46], "learning_rate": 0.007889217662105296, "batch_size": 262, "loss": 0.0025890805933158844}, {"layer_params": [61, 49, 19], "learning_rate": 0.007979928919687159, "batch_size": 351, "loss": 0.0019999656919389964}, {"layer_params": [53, 53, 25], "learning_rate": 0.006255135111042329, "batch_size": 304, "loss": 0.0008550683769863099}, {"layer_params": [35, 25], "learning_rate": 0.009589211097401074, "batch_size": 239, "loss": 0.001384198128944263}, {"layer_params": [56, 56], "learning_rate": 0.009011071903997818, "batch_size": 162, "loss": 0.0014923403318971395}, {"layer_params": [47, 50], "learning_rate": 0.009913170492019006, "batch_size": 74, "loss": 0.002710791619028896}, {"layer_params": [22, 64, 28, 61], "learning_rate": 0.009948897801361123, "batch_size": 134, "loss": 0.002876845217542723}, {"layer_params": [16, 61], "learning_rate": 0.005957727226765956, "batch_size": 149, "loss": 0.0030428493861109017}, {"layer_params": [59, 43, 23], "learning_rate": 0.004433509492810331, "batch_size": 200, "loss": 0.003777287129778415}, {"layer_params": [28, 60, 24, 57], "learning_rate": 0.009041114144664079, "batch_size": 246, "loss": 0.001832057237625122}, {"layer_params": [26, 57, 63], "learning_rate": 0.009937685759043774, "batch_size": 473, "loss": 0.0015526869613677263}, {"layer_params": [57, 19], "learning_rate": 0.005227872118652984, "batch_size": 214, "loss": 0.003883600230328739}, {"layer_params": [31, 31, 42, 39, 46], "learning_rate": 0.0033217998835215557, "batch_size": 189, "loss": 0.0023684571974445135}, {"layer_params": [39, 36, 17, 28, 64], "learning_rate": 0.0021162156377534875, "batch_size": 461, "loss": 0.002504579904489219}, {"layer_params": [20, 34, 24, 34], "learning_rate": 0.008617759152508368, "batch_size": 444, "loss": 0.0020742373878601937}, {"layer_params": [24, 31, 34], "learning_rate": 0.0051500892094570394, "batch_size": 18, "loss": 0.009082896336913109}, {"layer_params": [28, 52, 29], "learning_rate": 0.0019521318427861147, "batch_size": 426, "loss": 0.002922129975631833}, {"layer_params": [30, 30, 62], "learning_rate": 0.007151611034546787, "batch_size": 113, "loss": 0.0036520203878171744}, {"layer_params": [32, 32], "learning_rate": 0.007502604578686711, "batch_size": 56, "loss": 0.004079830711707473}, {"layer_params": [24, 64], "learning_rate": 0.007818549519453299, "batch_size": 211, "loss": 0.0037054151901975275}, {"layer_params": [58, 48, 60, 37], "learning_rate": 0.003814200272980494, "batch_size": 185, "loss": 0.001282070341403596}, {"layer_params": [43, 60, 59, 47], "learning_rate": 0.007617905437967691, "batch_size": 266, "loss": 0.0018110046803485602}, {"layer_params": [54, 17, 17], "learning_rate": 0.005878368360195198, "batch_size": 507, "loss": 0.002246812282828614}, {"layer_params": [55, 60, 16], "learning_rate": 0.004475337405506067, "batch_size": 409, "loss": 0.0015180876152589918}, {"layer_params": [59, 60, 26, 47], "learning_rate": 0.004455503874764803, "batch_size": 118, "loss": 0.0016812926915008575}, {"layer_params": [62, 44, 54, 20], "learning_rate": 0.0016423169158526854, "batch_size": 154, "loss": 0.0033286994020454586}, {"layer_params": [38, 43, 36], "learning_rate": 0.001659356200661409, "batch_size": 132, "loss": 0.004348363778553903}, {"layer_params": [49, 48, 29, 21], "learning_rate": 0.007145566543633731, "batch_size": 383, "loss": 0.0011181797907920555}, {"layer_params": [47, 51], "learning_rate": 0.004435221708618333, "batch_size": 398, "loss": 0.0021455620334018023}, {"layer_params": [64, 59], "learning_rate": 0.002605190554582873, "batch_size": 335, "loss": 0.002162509742192924}, {"layer_params": [27, 48, 37, 36, 33], "learning_rate": 0.005905615222914794, "batch_size": 261, "loss": 0.0016810375696513801}, {"layer_params": [32, 30, 48, 63, 61], "learning_rate": 0.001235924542901644, "batch_size": 94, "loss": 0.003979991704691202}, {"layer_params": [49, 59, 20], "learning_rate": 0.007800599819634403, "batch_size": 182, "loss": 0.0020509630732703952}, {"layer_params": [22, 29, 44, 22, 53], "learning_rate": 0.00044904146645551415, "batch_size": 500, "loss": 0.007322911839000881}, {"layer_params": [20, 29, 27, 44, 57], "learning_rate": 0.0021287119421693913, "batch_size": 484, "loss": 0.0026374423410743474}, {"layer_params": [60, 45, 42, 18, 40], "learning_rate": 0.0038936339510960414, "batch_size": 473, "loss": 0.0013073427334893495}, {"layer_params": [54, 33, 44], "learning_rate": 0.0018518038186285442, "batch_size": 41, "loss": 0.0043437118409201505}, {"layer_params": [45, 45, 58, 42], "learning_rate": 0.006145070707164816, "batch_size": 266, "loss": 0.001217334767570719}, {"layer_params": [44, 34, 17, 19], "learning_rate": 0.007426904403761781, "batch_size": 195, "loss": 0.0021322590950876475}, {"layer_params": [31, 20], "learning_rate": 0.0014812272054810435, "batch_size": 264, "loss": 0.005194414220750332}, {"layer_params": [53, 19], "learning_rate": 0.003965635612466214, "batch_size": 355, "loss": 0.001900250855833292}, {"layer_params": [18, 28, 46, 56], "learning_rate": 0.007768519404550885, "batch_size": 279, "loss": 0.002325553938280791}, {"layer_params": [63, 19, 20], "learning_rate": 0.0019008355443239401, "batch_size": 63, "loss": 0.005397530852351337}, {"layer_params": [38, 61], "learning_rate": 0.009488165961462916, "batch_size": 287, "loss": 0.001771421703742817}, {"layer_params": [28, 48, 16, 33, 54], "learning_rate": 0.0031455164961589135, "batch_size": 404, "loss": 0.0019867310230620204}, {"layer_params": [42, 42, 52, 37, 51], "learning_rate": 0.006074182044555886, "batch_size": 417, "loss": 0.001454613506793976}, {"layer_params": [31, 23], "learning_rate": 0.0010001210061213281, "batch_size": 273, "loss": 0.006227281582541763}, {"layer_params": [60, 28, 23, 41, 48], "learning_rate": 0.0008479680635861544, "batch_size": 270, "loss": 0.0043799932091496884}, {"layer_params": [29, 27], "learning_rate": 0.002287030112068335, "batch_size": 27, "loss": 0.0071504072565585376}, {"layer_params": [25, 29], "learning_rate": 0.0041320889057758605, "batch_size": 225, "loss": 0.0038619616837240757}, {"layer_params": [38, 43, 39, 29, 21], "learning_rate": 0.009133880015073453, "batch_size": 229, "loss": 0.0013864625949645416}, {"layer_params": [44, 30, 22, 55], "learning_rate": 0.00801193810518763, "batch_size": 97, "loss": 0.002471072382759303}, {"layer_params": [49, 64, 34], "learning_rate": 0.0007430977099923897, "batch_size": 57, "loss": 0.005400462674442679}, {"layer_params": [35, 47, 30, 41], "learning_rate": 0.00824901742095933, "batch_size": 406, "loss": 0.0012978799309348687}, {"layer_params": [32, 18, 59, 21], "learning_rate": 0.00561665388859637, "batch_size": 408, "loss": 0.002587810531258583}, {"layer_params": [38, 57, 37, 60], "learning_rate": 0.003956055653650121, "batch_size": 277, "loss": 0.0022931660676840694}, {"layer_params": [56, 23, 50, 18], "learning_rate": 0.0055125204287679915, "batch_size": 478, "loss": 0.001864666270557791}, {"layer_params": [48, 22, 46], "learning_rate": 0.004034088388964365, "batch_size": 479, "loss": 0.002041121309157461}, {"layer_params": [16, 26, 25, 17, 50], "learning_rate": 0.00028218476612755836, "batch_size": 241, "loss": 0.01108644953928888}, {"layer_params": [16, 60, 54], "learning_rate": 0.006174015593834469, "batch_size": 228, "loss": 0.003122800139244646}, {"layer_params": [42, 53, 16], "learning_rate": 0.0003299513657796928, "batch_size": 77, "loss": 0.008040808504447342}, {"layer_params": [44, 27, 31], "learning_rate": 0.00021101440670132134, "batch_size": 465, "loss": 0.009800510019995273}, {"layer_params": [41, 18], "learning_rate": 0.00644121760217222, "batch_size": 186, "loss": 0.0031984424334950746}, {"layer_params": [54, 44, 36, 32, 44], "learning_rate": 0.007744813198356473, "batch_size": 89, "loss": 0.002971217320300639}, {"layer_params": [62, 34, 59, 22, 18], "learning_rate": 0.0010919713650742538, "batch_size": 454, "loss": 0.0024484720663167535}, {"layer_params": [22, 22, 54, 52], "learning_rate": 0.005680963750789658, "batch_size": 487, "loss": 0.0032871334929950534}, {"layer_params": [63, 42], "learning_rate": 0.0047000082658372406, "batch_size": 190, "loss": 0.0023433957144152373}, {"layer_params": [44, 36, 43, 44], "learning_rate": 0.00018982590709691082, "batch_size": 334, "loss": 0.007447829926386476}, {"layer_params": [32, 19, 25, 23], "learning_rate": 0.0034602724185375877, "batch_size": 245, "loss": 0.0017635243863333018}, {"layer_params": [54, 58], "learning_rate": 0.003653894268967964, "batch_size": 448, "loss": 0.0014844849775545298}, {"layer_params": [45, 55], "learning_rate": 0.00443352348973812, "batch_size": 361, "loss": 0.0020826962997671215}, {"layer_params": [28, 42], "learning_rate": 0.003999341124412668, "batch_size": 357, "loss": 0.0038801538571715355}, {"layer_params": [39, 40], "learning_rate": 0.008814862004035534, "batch_size": 20, "loss": 0.006769170367624611}, {"layer_params": [59, 43, 53], "learning_rate": 0.006288764105174955, "batch_size": 390, "loss": 0.0012716535769868643}, {"layer_params": [35, 26], "learning_rate": 0.006188901832079963, "batch_size": 495, "loss": 0.0024615710275247694}, {"layer_params": [38, 21, 26], "learning_rate": 0.008370028305628042, "batch_size": 436, "loss": 0.0014579315017908812}, {"layer_params": [25, 19, 61, 47, 61], "learning_rate": 0.005905368108825711, "batch_size": 442, "loss": 0.0033683752082288264}, {"layer_params": [20, 40, 46, 45, 22], "learning_rate": 0.004444061733691294, "batch_size": 58, "loss": 0.0037371241091750562}, {"layer_params": [36, 63, 24], "learning_rate": 0.006696335754047448, "batch_size": 347, "loss": 0.0017751868173945696}, {"layer_params": [37, 25, 26, 32, 63], "learning_rate": 0.003118153489801901, "batch_size": 127, "loss": 0.003956115043256432}, {"layer_params": [61, 41], "learning_rate": 0.0041380787587483115, "batch_size": 221, "loss": 0.0025301011209376157}, {"layer_params": [22, 62], "learning_rate": 0.0014197936654712399, "batch_size": 343, "loss": 0.0044987554615363474}, {"layer_params": [56, 18, 26], "learning_rate": 0.006035886942991755, "batch_size": 229, "loss": 0.003239651806652546}, {"layer_params": [56, 26, 60, 33], "learning_rate": 0.0038763211014097793, "batch_size": 460, "loss": 0.0016780965740326793}, {"layer_params": [45, 24, 18, 59, 20], "learning_rate": 0.006089454882951637, "batch_size": 220, "loss": 0.004483919620979577}, {"layer_params": [36, 24, 24, 20, 50], "learning_rate": 0.0006376453650422664, "batch_size": 394, "loss": 0.005259052547626197}, {"layer_params": [44, 54, 40, 16], "learning_rate": 0.004513798591890517, "batch_size": 220, "loss": 0.0014308065827935935}, {"layer_params": [52, 53, 48, 44], "learning_rate": 0.008136391197491405, "batch_size": 337, "loss": 0.0016063936380669474}, {"layer_params": [34, 17, 31, 18], "learning_rate": 0.005634911160883252, "batch_size": 85, "loss": 0.004072595026809722}, {"layer_params": [23, 55, 54, 39, 37], "learning_rate": 0.0013896040458856928, "batch_size": 230, "loss": 0.006274249954149127}, {"layer_params": [32, 19, 35, 38, 49], "learning_rate": 0.009567479071412234, "batch_size": 31, "loss": 0.007664218880236149}, {"layer_params": [42, 39], "learning_rate": 0.009653319055526513, "batch_size": 223, "loss": 0.0014081524003995583}, {"layer_params": [56, 19, 48, 62, 54], "learning_rate": 0.0058105683782160265, "batch_size": 467, "loss": 0.002036195801338181}, {"layer_params": [38, 47, 44, 37], "learning_rate": 0.0034450267071819206, "batch_size": 145, "loss": 0.003643380384892225}, {"layer_params": [27, 52, 20, 16], "learning_rate": 0.008861239630557592, "batch_size": 227, "loss": 0.0016811863682232797}, {"layer_params": [35, 45, 53, 37], "learning_rate": 0.003641793755136967, "batch_size": 158, "loss": 0.001484618519898504}, {"layer_params": [30, 60], "learning_rate": 0.0011464547008095015, "batch_size": 281, "loss": 0.004935737629421055}, {"layer_params": [40, 31], "learning_rate": 0.007904386963817595, "batch_size": 99, "loss": 0.004028861003462225}, {"layer_params": [32, 23, 35], "learning_rate": 0.00859668774878155, "batch_size": 371, "loss": 0.002779236438218504}, {"layer_params": [52, 61, 53, 31, 17], "learning_rate": 0.009938263000554061, "batch_size": 426, "loss": 0.0010878366947872564}, {"layer_params": [45, 51, 39], "learning_rate": 0.004609491437921252, "batch_size": 80, "loss": 0.0023553611035458744}, {"layer_params": [45, 57, 58, 19, 31], "learning_rate": 0.000301290843677336, "batch_size": 302, "loss": 0.006967994938604533}, {"layer_params": [54, 31, 60, 36], "learning_rate": 0.005669356933909236, "batch_size": 101, "loss": 0.0024138670309912414}, {"layer_params": [58, 22, 51], "learning_rate": 0.0015663814864641924, "batch_size": 351, "loss": 0.001973338156240061}, {"layer_params": [60, 43], "learning_rate": 0.00508945164401325, "batch_size": 45, "loss": 0.0033953687793109566}, {"layer_params": [18, 20, 40], "learning_rate": 0.0012099684503207512, "batch_size": 85, "loss": 0.008365822918713094}, {"layer_params": [20, 64, 32, 55, 37], "learning_rate": 0.003097178546729051, "batch_size": 166, "loss": 0.0037909450265578926}, {"layer_params": [61, 36, 35, 50, 27], "learning_rate": 0.005175094802875263, "batch_size": 319, "loss": 0.0019151305023115128}, {"layer_params": [60, 42], "learning_rate": 0.0008394691698860435, "batch_size": 220, "loss": 0.003473018389195204}, {"layer_params": [20, 60, 60, 24], "learning_rate": 0.009764267648788067, "batch_size": 323, "loss": 0.0015807791240513324}, {"layer_params": [42, 23, 28], "learning_rate": 0.009738784460398258, "batch_size": 246, "loss": 0.0019965568510815503}, {"layer_params": [59, 34, 53, 56], "learning_rate": 0.001735610005410223, "batch_size": 329, "loss": 0.0018343621143139899}, {"layer_params": [52, 26, 45, 54], "learning_rate": 0.006303321539479776, "batch_size": 360, "loss": 0.0017094922007527202}, {"layer_params": [49, 25, 53, 60, 63], "learning_rate": 0.0018569623257461022, "batch_size": 421, "loss": 0.0017209711554460228}, {"layer_params": [47, 34, 44], "learning_rate": 0.006335899284712411, "batch_size": 72, "loss": 0.0024904477910604327}, {"layer_params": [19, 64, 21], "learning_rate": 0.002562822357523834, "batch_size": 213, "loss": 0.004139782588463276}, {"layer_params": [54, 52, 29, 40], "learning_rate": 0.006775895253841288, "batch_size": 431, "loss": 0.0008227489975979552}, {"layer_params": [43, 57, 16, 52], "learning_rate": 0.005107507434606469, "batch_size": 177, "loss": 0.0015093874093145131}, {"layer_params": [33, 43, 60, 34], "learning_rate": 0.009816970440292868, "batch_size": 167, "loss": 0.0009870293363928794}, {"layer_params": [29, 30, 51, 37], "learning_rate": 0.0018978486212673964, "batch_size": 416, "loss": 0.002945081116631627}, {"layer_params": [34, 27, 30, 33, 43], "learning_rate": 0.0008396479676340517, "batch_size": 248, "loss": 0.003548460283782333}, {"layer_params": [41, 23, 47, 19, 17], "learning_rate": 0.007541441062828952, "batch_size": 299, "loss": 0.0021539552975445987}, {"layer_params": [57, 35], "learning_rate": 0.007899059441261144, "batch_size": 178, "loss": 0.0015199987334199249}, {"layer_params": [37, 38], "learning_rate": 0.0042948474169864454, "batch_size": 171, "loss": 0.0030772811500355602}, {"layer_params": [55, 18, 26, 59, 55], "learning_rate": 0.004867012690905071, "batch_size": 384, "loss": 0.002655896982178092}, {"layer_params": [31, 52, 23, 27, 16], "learning_rate": 0.009952163003001002, "batch_size": 194, "loss": 0.0022047977207694204}, {"layer_params": [32, 46], "learning_rate": 0.003988659580803793, "batch_size": 279, "loss": 0.002005685049807653}, {"layer_params": [16, 56, 20, 53], "learning_rate": 0.000209565053936901, "batch_size": 498, "loss": 0.007940842281095683}, {"layer_params": [57, 59, 64, 38], "learning_rate": 0.003728143942610555, "batch_size": 463, "loss": 0.0009311312722275033}, {"layer_params": [52, 17], "learning_rate": 0.00515054457186492, "batch_size": 239, "loss": 0.0036196580063551664}, {"layer_params": [60, 60, 36, 48, 63], "learning_rate": 0.005972739215826196, "batch_size": 105, "loss": 0.0022987363731954247}, {"layer_params": [64, 61, 26], "learning_rate": 0.009652529125568306, "batch_size": 210, "loss": 0.001963572329841554}, {"layer_params": [50, 46, 38, 26, 34], "learning_rate": 0.0021260819093267373, "batch_size": 449, "loss": 0.00148959958110936}, {"layer_params": [43, 40, 21, 51], "learning_rate": 0.006247368380802232, "batch_size": 30, "loss": 0.0054667342640459535}, {"layer_params": [16, 21, 24, 55], "learning_rate": 0.0016455228464156474, "batch_size": 329, "loss": 0.004883400429971516}, {"layer_params": [30, 27, 20, 29, 21], "learning_rate": 0.0001348938531117416, "batch_size": 85, "loss": 0.014126013088971377}, {"layer_params": [23, 20, 61, 58], "learning_rate": 0.0013686336339782386, "batch_size": 456, "loss": 0.003069483665749431}, {"layer_params": [63, 30, 37], "learning_rate": 0.001361227904578723, "batch_size": 345, "loss": 0.002984873915556818}, {"layer_params": [50, 61], "learning_rate": 0.003798452258576987, "batch_size": 205, "loss": 0.0020516849984414877}, {"layer_params": [42, 38, 30, 44, 58], "learning_rate": 0.0018045260017762032, "batch_size": 108, "loss": 0.00376440406544134}, {"layer_params": [58, 57, 40, 26], "learning_rate": 0.002109022028225793, "batch_size": 398, "loss": 0.001114430685993284}, {"layer_params": [22, 59, 41, 17, 58], "learning_rate": 0.0013723476170460927, "batch_size": 440, "loss": 0.0026602803519926964}, {"layer_params": [45, 63, 58], "learning_rate": 0.0007590028145950884, "batch_size": 427, "loss": 0.0028874142607674003}, {"layer_params": [37, 24, 54, 27], "learning_rate": 0.00436188355903871, "batch_size": 407, "loss": 0.00211650675162673}, {"layer_params": [29, 32, 25], "learning_rate": 0.0028248637808163056, "batch_size": 50, "loss": 0.0074622704088687895}, {"layer_params": [42, 25, 28], "learning_rate": 0.0049246260915434695, "batch_size": 417, "loss": 0.0014624394045677036}, {"layer_params": [55, 50, 49, 17], "learning_rate": 0.00960453341267764, "batch_size": 418, "loss": 0.000843827452044934}, {"layer_params": [36, 43, 33], "learning_rate": 0.002174288277596249, "batch_size": 21, "loss": 0.006882444149814546}, {"layer_params": [34, 32], "learning_rate": 0.005326996201366394, "batch_size": 290, "loss": 0.002090033646672964}, {"layer_params": [44, 55, 39], "learning_rate": 0.0027175927807031887, "batch_size": 352, "loss": 0.0015515856386628002}, {"layer_params": [19, 52, 46], "learning_rate": 0.009565952502460045, "batch_size": 241, "loss": 0.0017917246115393937}, {"layer_params": [22, 23, 19, 47], "learning_rate": 0.0030228708848722627, "batch_size": 479, "loss": 0.002701302468776703}, {"layer_params": [62, 55], "learning_rate": 0.006220365487908931, "batch_size": 464, "loss": 0.0007942192378686741}, {"layer_params": [23, 53, 60, 39, 64], "learning_rate": 0.0010200858457165018, "batch_size": 447, "loss": 0.0025633434904739263}, {"layer_params": [43, 23, 59, 58], "learning_rate": 0.007143532401696725, "batch_size": 236, "loss": 0.002036782751092687}, {"layer_params": [17, 51, 54, 44], "learning_rate": 0.008575981364920068, "batch_size": 153, "loss": 0.002708978976588696}, {"layer_params": [39, 54, 51, 40], "learning_rate": 0.00546416115616165, "batch_size": 141, "loss": 0.0019134414987638593}, {"layer_params": [47, 19, 50], "learning_rate": 0.007682572778180729, "batch_size": 318, "loss": 0.0014933914190623909}, {"layer_params": [56, 58], "learning_rate": 0.007972626382826233, "batch_size": 475, "loss": 0.001235673720948398}, {"layer_params": [52, 42], "learning_rate": 0.0023786219141898658, "batch_size": 277, "loss": 0.002461471111746505}, {"layer_params": [38, 53, 20, 33, 24], "learning_rate": 0.005248268586230088, "batch_size": 119, "loss": 0.0020868776692077517}, {"layer_params": [49, 56, 46, 51], "learning_rate": 0.0015577549720829009, "batch_size": 144, "loss": 0.0021964296407531946}, {"layer_params": [49, 55, 52, 20], "learning_rate": 0.00956392399481294, "batch_size": 347, "loss": 0.0008779807662358508}, {"layer_params": [31, 45, 56, 23, 25], "learning_rate": 0.0013287170672260612, "batch_size": 72, "loss": 0.004682939562480897}, {"layer_params": [55, 47], "learning_rate": 0.003392375992674005, "batch_size": 79, "loss": 0.0034349826187826693}, {"layer_params": [24, 19, 53, 56, 19], "learning_rate": 0.002007711334720205, "batch_size": 69, "loss": 0.00507834622869268}, {"layer_params": [32, 29], "learning_rate": 0.007418517138691486, "batch_size": 485, "loss": 0.0024204332125373185}, {"layer_params": [45, 27], "learning_rate": 0.004427937984150385, "batch_size": 36, "loss": 0.005674236048944295}, {"layer_params": [59, 39], "learning_rate": 0.007453178682063822, "batch_size": 504, "loss": 0.0010281198337906972}, {"layer_params": [49, 38], "learning_rate": 0.008729008920423378, "batch_size": 234, "loss": 0.0027945761557202787}, {"layer_params": [44, 61, 28], "learning_rate": 0.007203528702244106, "batch_size": 185, "loss": 0.0018388019548729062}, {"layer_params": [42, 56, 21], "learning_rate": 0.005821271041823028, "batch_size": 345, "loss": 0.00117417570669204}, {"layer_params": [28, 38, 39, 51, 62], "learning_rate": 0.008295603846174601, "batch_size": 385, "loss": 0.002025637385668233}, {"layer_params": [43, 22, 31], "learning_rate": 0.005363277413738167, "batch_size": 49, "loss": 0.004941279498161748}, {"layer_params": [52, 52, 55, 57], "learning_rate": 0.0024040763525958377, "batch_size": 323, "loss": 0.0014544749294873327}, {"layer_params": [24, 40], "learning_rate": 0.008027690726284705, "batch_size": 355, "loss": 0.00213438420672901}, {"layer_params": [48, 54, 61, 21], "learning_rate": 0.00863350507223869, "batch_size": 20, "loss": 0.00688580226385966}, {"layer_params": [16, 59, 61, 52, 39], "learning_rate": 0.004876087020404414, "batch_size": 156, "loss": 0.002771443239180371}, {"layer_params": [27, 55, 19], "learning_rate": 0.0020979474776412444, "batch_size": 146, "loss": 0.0031658311071805657}, {"layer_params": [55, 50], "learning_rate": 0.005316777728701283, "batch_size": 130, "loss": 0.003031077114865184}, {"layer_params": [30, 27], "learning_rate": 0.002183085160105846, "batch_size": 332, "loss": 0.006061466597020626}, {"layer_params": [29, 23, 64, 47, 17], "learning_rate": 0.00467630596059979, "batch_size": 46, "loss": 0.004027237377595156}, {"layer_params": [33, 30], "learning_rate": 0.00722387457004328, "batch_size": 157, "loss": 0.00443317003082484}, {"layer_params": [21, 64], "learning_rate": 0.0031666917382991698, "batch_size": 335, "loss": 0.002418358859140426}, {"layer_params": [58, 60], "learning_rate": 0.003151641237950402, "batch_size": 464, "loss": 0.0014164591568987816}, {"layer_params": [31, 60, 61, 31, 43], "learning_rate": 0.004470794099539832, "batch_size": 505, "loss": 0.002485652579925954}, {"layer_params": [51, 50], "learning_rate": 0.002468263286435659, "batch_size": 111, "loss": 0.002316724015399814}, {"layer_params": [18, 63], "learning_rate": 0.0008738152421894194, "batch_size": 441, "loss": 0.005334542761556804}, {"layer_params": [54, 53, 16, 46, 17], "learning_rate": 0.00952650236058219, "batch_size": 245, "loss": 0.0018646306486334652}, {"layer_params": [23, 52, 19, 32], "learning_rate": 0.005139776781628289, "batch_size": 335, "loss": 0.002085720559116453}, {"layer_params": [54, 35, 60, 23, 34], "learning_rate": 0.002040393244715951, "batch_size": 331, "loss": 0.002207473637536168}, {"layer_params": [34, 63, 26, 39, 44], "learning_rate": 0.009876927029897228, "batch_size": 98, "loss": 0.00242558290832676}, {"layer_params": [27, 19, 33], "learning_rate": 0.004430601750190611, "batch_size": 342, "loss": 0.00203957203659229}, {"layer_params": [50, 22, 20], "learning_rate": 0.002141395783211071, "batch_size": 439, "loss": 0.002173343294998631}, {"layer_params": [48, 62, 57], "learning_rate": 0.0067345931738195626, "batch_size": 188, "loss": 0.0014254183135926724}, {"layer_params": [37, 58], "learning_rate": 0.006151037035432403, "batch_size": 200, "loss": 0.0017321338853798806}, {"layer_params": [51, 42, 21, 23, 55], "learning_rate": 0.007781929906787477, "batch_size": 165, "loss": 0.001800275295972824}, {"layer_params": [20, 16], "learning_rate": 0.004327431862315557, "batch_size": 421, "loss": 0.004465493080206215}, {"layer_params": [61, 51, 43, 16], "learning_rate": 0.0018724057762451573, "batch_size": 192, "loss": 0.0016418063559103758}, {"layer_params": [62, 58], "learning_rate": 0.009950838962931197, "batch_size": 501, "loss": 0.0008036686235573143}, {"layer_params": [64, 28, 54, 25, 30], "learning_rate": 0.0025656836699707824, "batch_size": 125, "loss": 0.002534470803802833}, {"layer_params": [48, 43, 64], "learning_rate": 0.002621463767047127, "batch_size": 294, "loss": 0.0013748009025584906}, {"layer_params": [44, 17], "learning_rate": 0.002923492316928942, "batch_size": 83, "loss": 0.0054906970099546015}, {"layer_params": [31, 36, 27], "learning_rate": 0.00896076125143809, "batch_size": 32, "loss": 0.006342602162621915}, {"layer_params": [32, 45, 48, 21], "learning_rate": 0.003391171288816098, "batch_size": 236, "loss": 0.0016019226796925067}, {"layer_params": [16, 18, 37, 40], "learning_rate": 0.008724124745796211, "batch_size": 84, "loss": 0.0053138967626728114}, {"layer_params": [25, 55], "learning_rate": 0.00930121622500354, "batch_size": 326, "loss": 0.0018506665364839137}, {"layer_params": [27, 38, 62, 38], "learning_rate": 0.0074338171282945205, "batch_size": 144, "loss": 0.0025729627953842284}, {"layer_params": [63, 21, 22], "learning_rate": 0.00813333704033817, "batch_size": 39, "loss": 0.002791416111867875}, {"layer_params": [26, 24, 45, 62], "learning_rate": 0.0016945962164618, "batch_size": 67, "loss": 0.005676983722951263}, {"layer_params": [54, 16, 60, 59, 36], "learning_rate": 0.0028017230607631895, "batch_size": 136, "loss": 0.0033821245818398894}, {"layer_params": [23, 41, 53], "learning_rate": 0.0025280046695032215, "batch_size": 270, "loss": 0.003956822252366692}, {"layer_params": [31, 33, 48], "learning_rate": 0.003298300907583453, "batch_size": 465, "loss": 0.001960230882978067}, {"layer_params": [50, 58, 18], "learning_rate": 0.0017454937524771798, "batch_size": 497, "loss": 0.0023453530704136936}, {"layer_params": [21, 47], "learning_rate": 0.004316332057902853, "batch_size": 34, "loss": 0.006260488289408386}, {"layer_params": [40, 39, 44], "learning_rate": 0.004419278364800716, "batch_size": 51, "loss": 0.004262247160077095}, {"layer_params": [37, 47, 18, 30], "learning_rate": 0.008218381917960543, "batch_size": 43, "loss": 0.004828205585945398}, {"layer_params": [52, 33, 37, 32], "learning_rate": 0.0009725198417402134, "batch_size": 116, "loss": 0.005157584759872407}, {"layer_params": [30, 31, 62], "learning_rate": 0.008237181909986364, "batch_size": 310, "loss": 0.002042067850707099}, {"layer_params": [45, 56, 25, 29], "learning_rate": 0.0033532156654080543, "batch_size": 317, "loss": 0.001976241315715015}, {"layer_params": [25, 53, 45, 33], "learning_rate": 0.007090084789605665, "batch_size": 245, "loss": 0.002025706439744681}, {"layer_params": [16, 51, 29, 44, 61], "learning_rate": 0.003855038717993983, "batch_size": 309, "loss": 0.0022241695434786378}, {"layer_params": [20, 33], "learning_rate": 0.0021784676399959975, "batch_size": 476, "loss": 0.006385096511803567}, {"layer_params": [19, 43], "learning_rate": 0.0021449651014230505, "batch_size": 394, "loss": 0.003389087768737227}, {"layer_params": [63, 21, 44, 43, 54], "learning_rate": 0.0029100259865159715, "batch_size": 349, "loss": 0.00240914000896737}, {"layer_params": [61, 24, 43, 40, 59], "learning_rate": 0.002337052238584603, "batch_size": 504, "loss": 0.0013782416272442788}, {"layer_params": [26, 25, 29, 62, 21], "learning_rate": 0.0036089304687663575, "batch_size": 443, "loss": 0.002484512578230351}, {"layer_params": [44, 20, 32, 59], "learning_rate": 0.0062156988710129245, "batch_size": 456, "loss": 0.002271269835764542}, {"layer_params": [41, 42, 57, 33], "learning_rate": 0.0013614498950058412, "batch_size": 78, "loss": 0.0034551229444332423}, {"layer_params": [49, 62, 39], "learning_rate": 0.005379126771813303, "batch_size": 74, "loss": 0.002344939992763102}, {"layer_params": [31, 36, 20, 63], "learning_rate": 0.007202177498175207, "batch_size": 425, "loss": 0.002536106344778091}, {"layer_params": [45, 25, 19], "learning_rate": 0.00022726316199382082, "batch_size": 358, "loss": 0.0075001491559669375}, {"layer_params": [53, 37, 47, 58, 51], "learning_rate": 0.009724806038332567, "batch_size": 51, "loss": 0.004447168405167758}, {"layer_params": [38, 31, 60], "learning_rate": 0.00013255742452521663, "batch_size": 479, "loss": 0.012241246039047837}, {"layer_params": [18, 18, 24, 31], "learning_rate": 0.0017344409519653985, "batch_size": 108, "loss": 0.006698732785880565}, {"layer_params": [44, 43, 22, 57, 22], "learning_rate": 0.0018659368769415269, "batch_size": 389, "loss": 0.0018919445038773118}, {"layer_params": [40, 25, 39, 35], "learning_rate": 0.006678838891021511, "batch_size": 453, "loss": 0.0024274839740246533}, {"layer_params": [34, 51, 38, 57], "learning_rate": 0.007524442210572659, "batch_size": 214, "loss": 0.0017923956469167023}, {"layer_params": [25, 54, 34, 28, 46], "learning_rate": 0.008483735495489593, "batch_size": 434, "loss": 0.0015123976417817176}, {"layer_params": [19, 16, 40, 54], "learning_rate": 0.007598918452839298, "batch_size": 248, "loss": 0.003884207757655531}, {"layer_params": [40, 59], "learning_rate": 0.008457354806502908, "batch_size": 434, "loss": 0.0020734661957249045}, {"layer_params": [26, 59, 20], "learning_rate": 0.006414670526654477, "batch_size": 137, "loss": 0.0019746753957588224}, {"layer_params": [20, 20, 54, 60, 49], "learning_rate": 0.0070016000642309445, "batch_size": 474, "loss": 0.002408390589989722}, {"layer_params": [41, 23, 35], "learning_rate": 0.009023548177635203, "batch_size": 129, "loss": 0.002474555382505059}, {"layer_params": [42, 24, 27], "learning_rate": 0.00021005373503601152, "batch_size": 80, "loss": 0.00974801393225789}, {"layer_params": [34, 32, 42, 42], "learning_rate": 0.004230514213317044, "batch_size": 337, "loss": 0.001435214957455173}, {"layer_params": [30, 62, 60, 25], "learning_rate": 0.004632332251345149, "batch_size": 272, "loss": 0.0011176486138720066}, {"layer_params": [39, 33, 23, 54, 51], "learning_rate": 0.0061879941950573215, "batch_size": 203, "loss": 0.002017698501003906}, {"layer_params": [42, 20, 32], "learning_rate": 0.0013604705248082595, "batch_size": 313, "loss": 0.003148998240940273}, {"layer_params": [64, 43, 51], "learning_rate": 0.007980658316417552, "batch_size": 355, "loss": 0.0011373703851131722}, {"layer_params": [50, 50, 51], "learning_rate": 0.006337517944297987, "batch_size": 173, "loss": 0.0023166174662765117}, {"layer_params": [62, 21], "learning_rate": 0.005094947668904403, "batch_size": 332, "loss": 0.0034032479696907104}, {"layer_params": [50, 45, 61, 53], "learning_rate": 0.0003759448309153454, "batch_size": 413, "loss": 0.003736802090425044}, {"layer_params": [50, 34, 33, 23, 26], "learning_rate": 0.007581614555502073, "batch_size": 317, "loss": 0.001880304121877998}, {"layer_params": [25, 33, 39, 19, 39], "learning_rate": 0.005012169519054709, "batch_size": 436, "loss": 0.001988564177881926}, {"layer_params": [52, 30, 63, 44, 48], "learning_rate": 0.006359466102242225, "batch_size": 129, "loss": 0.0013400355825433509}, {"layer_params": [64, 41, 44], "learning_rate": 0.00019853671005612075, "batch_size": 31, "loss": 0.010752455908805131}, {"layer_params": [19, 47, 51], "learning_rate": 0.004217519866063467, "batch_size": 487, "loss": 0.0018558331741951406}, {"layer_params": [38, 17], "learning_rate": 0.00208041842302764, "batch_size": 271, "loss": 0.003478242631535977}, {"layer_params": [47, 47, 28, 26, 21], "learning_rate": 0.005685419015388805, "batch_size": 319, "loss": 0.0011576521518873052}, {"layer_params": [34, 36, 30, 62, 61], "learning_rate": 0.007631163386702816, "batch_size": 32, "loss": 0.004625476050423458}, {"layer_params": [53, 29, 20, 60, 25], "learning_rate": 0.0044912250796346875, "batch_size": 161, "loss": 0.0021590667846612633}, {"layer_params": [53, 45, 16, 44, 62], "learning_rate": 0.0005771910428729448, "batch_size": 235, "loss": 0.004370442321524024}, {"layer_params": [62, 48, 55, 17, 54], "learning_rate": 0.007839552428774972, "batch_size": 97, "loss": 0.0017630953062325715}, {"layer_params": [31, 51, 29], "learning_rate": 0.005998393701450661, "batch_size": 511, "loss": 0.0015971711114980281}, {"layer_params": [61, 63, 26, 28], "learning_rate": 0.002400133636065158, "batch_size": 332, "loss": 0.0016935303306672722}, {"layer_params": [45, 63, 42], "learning_rate": 0.006150604394755283, "batch_size": 509, "loss": 0.0010896663775201887}, {"layer_params": [45, 51, 25, 51, 33], "learning_rate": 0.006429105839001929, "batch_size": 262, "loss": 0.0010678049322450534}, {"layer_params": [30, 47], "learning_rate": 0.00970200685788651, "batch_size": 120, "loss": 0.003060976004926488}, {"layer_params": [21, 60, 44, 31], "learning_rate": 0.009300231846126453, "batch_size": 93, "loss": 0.0035187466698698698}, {"layer_params": [33, 25, 34, 33, 49], "learning_rate": 0.009410047915052929, "batch_size": 416, "loss": 0.001882338309660554}, {"layer_params": [56, 64, 56, 42], "learning_rate": 0.00920576672352605, "batch_size": 351, "loss": 0.000961225459468551}, {"layer_params": [48, 45, 61, 19, 53], "learning_rate": 0.00015022055684075006, "batch_size": 22, "loss": 0.026534281708300113}, {"layer_params": [43, 48, 27, 53, 52], "learning_rate": 0.0007714819182827574, "batch_size": 279, "loss": 0.002583710504695773}, {"layer_params": [17, 47, 58, 19, 25], "learning_rate": 0.002896883268022761, "batch_size": 301, "loss": 0.0031151173310354353}, {"layer_params": [38, 60, 28], "learning_rate": 0.002042217387042436, "batch_size": 185, "loss": 0.002109679585555568}, {"layer_params": [33, 35, 33, 39, 58], "learning_rate": 0.002669109864463695, "batch_size": 423, "loss": 0.001440251556923613}, {"layer_params": [50, 52, 57, 26, 39], "learning_rate": 0.008075759547956439, "batch_size": 449, "loss": 0.0006354579387698322}, {"layer_params": [51, 23, 50], "learning_rate": 0.0018755080448851194, "batch_size": 93, "loss": 0.004177526086568833}, {"layer_params": [63, 30], "learning_rate": 0.0032207201046416715, "batch_size": 137, "loss": 0.0029659854946658014}, {"layer_params": [63, 41, 62, 56], "learning_rate": 0.008874162530142074, "batch_size": 293, "loss": 0.0011839138972572982}, {"layer_params": [37, 40, 30], "learning_rate": 0.008420204320112297, "batch_size": 396, "loss": 0.0015349377377424389}, {"layer_params": [23, 44], "learning_rate": 0.008113957203865175, "batch_size": 468, "loss": 0.002235746057704091}, {"layer_params": [38, 16, 41, 19], "learning_rate": 0.008597760134170325, "batch_size": 175, "loss": 0.0035918525280430914}, {"layer_params": [48, 59], "learning_rate": 0.007462078954176798, "batch_size": 423, "loss": 0.0011732105363626033}, {"layer_params": [62, 49, 42, 40], "learning_rate": 0.004571080298916294, "batch_size": 487, "loss": 0.0006563287577591836}, {"layer_params": [26, 19], "learning_rate": 0.0024109392428489757, "batch_size": 77, "loss": 0.007441944205202162}, {"layer_params": [35, 27], "learning_rate": 0.009752843239470408, "batch_size": 393, "loss": 0.0030946347466669975}, {"layer_params": [42, 19, 54], "learning_rate": 0.004211657163806531, "batch_size": 396, "loss": 0.0020370139926671983}, {"layer_params": [52, 34, 58], "learning_rate": 0.007734333916381898, "batch_size": 200, "loss": 0.0022643524955492465}, {"layer_params": [33, 17, 25], "learning_rate": 0.009185657880078135, "batch_size": 471, "loss": 0.0026052540133241564}, {"layer_params": [20, 60, 22, 45, 32], "learning_rate": 0.003397828243810789, "batch_size": 412, "loss": 0.0018469260726124048}, {"layer_params": [26, 25, 34], "learning_rate": 0.00396456648714586, "batch_size": 297, "loss": 0.0024956627399660646}, {"layer_params": [56, 23, 31], "learning_rate": 0.009275558049869981, "batch_size": 364, "loss": 0.0012919271568534896}, {"layer_params": [52, 58, 32, 50, 39], "learning_rate": 0.006639700131699105, "batch_size": 500, "loss": 0.0011039405968040227}, {"layer_params": [52, 38], "learning_rate": 0.0009915865028352296, "batch_size": 408, "loss": 0.003555173103231937}, {"layer_params": [54, 31, 63, 16], "learning_rate": 0.002124750963304781, "batch_size": 504, "loss": 0.001594989753793925}, {"layer_params": [35, 47, 59, 60], "learning_rate": 0.0012870591541383717, "batch_size": 168, "loss": 0.0029851096915081143}, {"layer_params": [59, 52, 46, 51], "learning_rate": 0.002386274011853954, "batch_size": 235, "loss": 0.0013513335457537323}, {"layer_params": [24, 48, 42, 53], "learning_rate": 0.005880436695142846, "batch_size": 458, "loss": 0.0013698716158978641}, {"layer_params": [21, 60], "learning_rate": 0.005041875323303554, "batch_size": 183, "loss": 0.002483859519707039}, {"layer_params": [28, 42, 53, 20], "learning_rate": 0.005603499615864015, "batch_size": 115, "loss": 0.002656819847179577}, {"layer_params": [54, 54, 24, 33], "learning_rate": 0.006240660450384666, "batch_size": 279, "loss": 0.0019643743941560386}, {"layer_params": [53, 48], "learning_rate": 0.008199848724592283, "batch_size": 279, "loss": 0.0011162635259097443}, {"layer_params": [28, 61, 19], "learning_rate": 0.007619583813950233, "batch_size": 337, "loss": 0.0014058038161601871}, {"layer_params": [37, 46], "learning_rate": 0.006692698690703161, "batch_size": 344, "loss": 0.001814021912869066}, {"layer_params": [56, 57], "learning_rate": 0.006604975063841445, "batch_size": 122, "loss": 0.0023147681297268716}, {"layer_params": [54, 51, 47], "learning_rate": 0.007494085698856272, "batch_size": 359, "loss": 0.0011928071605507285}, {"layer_params": [42, 25, 46], "learning_rate": 0.00020070266381477382, "batch_size": 281, "loss": 0.009079666482284665}, {"layer_params": [40, 33], "learning_rate": 0.002992269031194405, "batch_size": 426, "loss": 0.0019992823572829365}, {"layer_params": [16, 50, 16, 55, 49], "learning_rate": 0.004385740386325628, "batch_size": 215, "loss": 0.0039953118818812075}, {"layer_params": [17, 44, 46, 44, 51], "learning_rate": 0.00994850135104697, "batch_size": 490, "loss": 0.002470646174624562}, {"layer_params": [53, 26], "learning_rate": 0.009458533337256271, "batch_size": 127, "loss": 0.003448455024044961}, {"layer_params": [38, 52, 26, 35, 16], "learning_rate": 0.002526637089460611, "batch_size": 438, "loss": 0.0017386805510614068}, {"layer_params": [57, 24, 43, 24], "learning_rate": 0.00591834019788716, "batch_size": 403, "loss": 0.002040796137880534}, {"layer_params": [23, 37, 37], "learning_rate": 0.0012727018858645148, "batch_size": 474, "loss": 0.003116322085261345}, {"layer_params": [55, 35], "learning_rate": 0.001525179518755118, "batch_size": 254, "loss": 0.002301431258674711}, {"layer_params": [24, 34], "learning_rate": 0.0005183776063539505, "batch_size": 60, "loss": 0.010020301081240177}, {"layer_params": [28, 54], "learning_rate": 0.005792348592681353, "batch_size": 186, "loss": 0.0013885188661515713}, {"layer_params": [25, 51], "learning_rate": 0.0065431497384434165, "batch_size": 48, "loss": 0.007657580906525254}, {"layer_params": [17, 28, 16, 25, 36], "learning_rate": 0.0012962918813034623, "batch_size": 48, "loss": 0.007882474567741155}, {"layer_params": [17, 24, 49, 19], "learning_rate": 0.007921898491544862, "batch_size": 460, "loss": 0.003337705680169165}, {"layer_params": [48, 62, 26, 57, 23], "learning_rate": 0.007174239338237411, "batch_size": 205, "loss": 0.001473756751511246}, {"layer_params": [54, 54, 63, 32], "learning_rate": 0.0017956268162020645, "batch_size": 164, "loss": 0.0020391185465268792}, {"layer_params": [44, 38, 20, 60], "learning_rate": 0.001797851551608299, "batch_size": 123, "loss": 0.0027176059281919154}, {"layer_params": [17, 59], "learning_rate": 0.009774931429580538, "batch_size": 449, "loss": 0.00318871327675879}, {"layer_params": [35, 52, 57], "learning_rate": 0.0066309538950142825, "batch_size": 397, "loss": 0.0014489755791146307}, {"layer_params": [52, 19], "learning_rate": 0.008182777460472072, "batch_size": 369, "loss": 0.0019181295053567738}, {"layer_params": [21, 53, 30, 43], "learning_rate": 0.0015830832862297113, "batch_size": 486, "loss": 0.0027450120355933904}, {"layer_params": [30, 61], "learning_rate": 0.0007590967847771553, "batch_size": 203, "loss": 0.0047111273324117065}, {"layer_params": [33, 40, 27, 18, 28], "learning_rate": 0.0030890942863152243, "batch_size": 209, "loss": 0.0028662198688834905}, {"layer_params": [51, 50], "learning_rate": 0.008017402091407158, "batch_size": 256, "loss": 0.0013879297557286919}, {"layer_params": [24, 56, 56], "learning_rate": 0.002287375180862263, "batch_size": 232, "loss": 0.002447204685304314}, {"layer_params": [56, 21], "learning_rate": 0.0010406131482275612, "batch_size": 459, "loss": 0.0024068920616991817}, {"layer_params": [55, 61, 33, 19, 49], "learning_rate": 0.007222695569295376, "batch_size": 184, "loss": 0.001255485129659064}, {"layer_params": [62, 52], "learning_rate": 0.0008788121040444339, "batch_size": 496, "loss": 0.00322499934816733}, {"layer_params": [28, 28], "learning_rate": 0.0065761266234996545, "batch_size": 201, "loss": 0.0024102731922175736}, {"layer_params": [63, 45, 39, 51, 59], "learning_rate": 0.007584092245893834, "batch_size": 231, "loss": 0.0010392536484869197}, {"layer_params": [45, 25, 58, 23, 40], "learning_rate": 0.0054450978413259936, "batch_size": 438, "loss": 0.0010538829915458336}, {"layer_params": [50, 59], "learning_rate": 0.0035575144864691418, "batch_size": 24, "loss": 0.004714327857363969}, {"layer_params": [25, 38], "learning_rate": 0.002609959373052866, "batch_size": 192, "loss": 0.0028480630274862052}, {"layer_params": [32, 57, 48, 32], "learning_rate": 0.005297905001742335, "batch_size": 316, "loss": 0.0014031743304803968}, {"layer_params": [58, 37, 45], "learning_rate": 0.008308596423321922, "batch_size": 192, "loss": 0.0018952865584287793}, {"layer_params": [60, 54, 58, 31], "learning_rate": 0.005215110533631696, "batch_size": 132, "loss": 0.0018352326448075474}, {"layer_params": [43, 54, 45, 26, 33], "learning_rate": 0.002079599422895677, "batch_size": 279, "loss": 0.0017323472478892655}, {"layer_params": [37, 50, 38], "learning_rate": 0.008696591905222735, "batch_size": 180, "loss": 0.0016622933617327362}, {"layer_params": [46, 16, 24, 23, 35], "learning_rate": 0.002889504030675206, "batch_size": 124, "loss": 0.002999290833249688}, {"layer_params": [22, 17, 31, 51], "learning_rate": 0.0041915123553362315, "batch_size": 413, "loss": 0.003435817623976618}, {"layer_params": [36, 55], "learning_rate": 0.0015584535809481327, "batch_size": 139, "loss": 0.003071664134040475}, {"layer_params": [25, 61, 37, 38, 46], "learning_rate": 0.0019422069773076033, "batch_size": 497, "loss": 0.0021271540911402555}, {"layer_params": [34, 34, 64], "learning_rate": 0.0012007064872025391, "batch_size": 454, "loss": 0.0028611819399520753}, {"layer_params": [55, 58, 16, 18], "learning_rate": 0.007959555427900115, "batch_size": 271, "loss": 0.001112058344297111}, {"layer_params": [18, 61, 26, 23], "learning_rate": 0.0003670985783614264, "batch_size": 160, "loss": 0.008408522573299706}, {"layer_params": [32, 31], "learning_rate": 0.004654769946569761, "batch_size": 456, "loss": 0.0019071948423516004}, {"layer_params": [51, 32, 22], "learning_rate": 0.0049114552299568195, "batch_size": 309, "loss": 0.0016542522155214101}, {"layer_params": [59, 41, 53, 24], "learning_rate": 0.008603091338591497, "batch_size": 418, "loss": 0.0008402388013200834}, {"layer_params": [19, 43], "learning_rate": 0.0003148222430746368, "batch_size": 50, "loss": 0.01847984259016812}, {"layer_params": [29, 33, 51], "learning_rate": 0.003317743322146215, "batch_size": 183, "loss": 0.0028389581642113628}, {"layer_params": [57, 21, 41, 33], "learning_rate": 0.003771025717103687, "batch_size": 48, "loss": 0.003948630183003843}, {"layer_params": [45, 41, 46, 57], "learning_rate": 0.009458473189514566, "batch_size": 333, "loss": 0.0018437432509381324}, {"layer_params": [57, 21, 49, 33, 51], "learning_rate": 0.0009366847292748219, "batch_size": 42, "loss": 0.00661282061599195}, {"layer_params": [64, 38], "learning_rate": 0.006485338829245789, "batch_size": 392, "loss": 0.001864932180615142}, {"layer_params": [33, 29, 45], "learning_rate": 0.006647216653655452, "batch_size": 127, "loss": 0.0022411368368193507}, {"layer_params": [26, 55, 39], "learning_rate": 0.0018260494871910912, "batch_size": 459, "loss": 0.0019045612670015545}, {"layer_params": [49, 30], "learning_rate": 0.0012964937563640535, "batch_size": 26, "loss": 0.007619263445958495}, {"layer_params": [33, 22, 27, 51, 38], "learning_rate": 0.008489196953437604, "batch_size": 368, "loss": 0.0018862113403156399}, {"layer_params": [40, 38, 38, 17, 26], "learning_rate": 0.00670804095907257, "batch_size": 40, "loss": 0.005274661988951265}, {"layer_params": [44, 18, 54], "learning_rate": 0.007390514907663945, "batch_size": 344, "loss": 0.003053746598307043}, {"layer_params": [21, 58], "learning_rate": 0.0010912138034490733, "batch_size": 209, "loss": 0.006985992463305593}, {"layer_params": [30, 58, 44], "learning_rate": 0.002270722779530689, "batch_size": 420, "loss": 0.0017622692440636455}, {"layer_params": [61, 28, 28, 55], "learning_rate": 0.005039422815224333, "batch_size": 177, "loss": 0.00117059180396609}, {"layer_params": [61, 46], "learning_rate": 0.009980711508190337, "batch_size": 360, "loss": 0.001233983444981277}, {"layer_params": [27, 51, 31], "learning_rate": 0.00010688449473247867, "batch_size": 287, "loss": 0.012974937036633492}, {"layer_params": [36, 64], "learning_rate": 0.009160251639771456, "batch_size": 242, "loss": 0.0022978259332012384}, {"layer_params": [22, 37, 53, 27, 57], "learning_rate": 0.009825460129461405, "batch_size": 232, "loss": 0.0033974833064712583}, {"layer_params": [42, 61, 51, 32, 49], "learning_rate": 0.005362615376441835, "batch_size": 442, "loss": 0.001358978160424158}, {"layer_params": [64, 62, 21], "learning_rate": 0.00998573168051822, "batch_size": 54, "loss": 0.0027161899930797516}, {"layer_params": [30, 59, 34], "learning_rate": 0.005495870607666446, "batch_size": 269, "loss": 0.0015191366244107485}, {"layer_params": [64, 57, 20, 22], "learning_rate": 0.00581087276635842, "batch_size": 482, "loss": 0.0008732015185523778}, {"layer_params": [40, 31, 63], "learning_rate": 0.006794202906774754, "batch_size": 364, "loss": 0.0012439136707689613}, {"layer_params": [60, 61, 36, 59], "learning_rate": 0.00805605133649178, "batch_size": 63, "loss": 0.0028644857078325005}, {"layer_params": [21, 53], "learning_rate": 0.005504363000168845, "batch_size": 48, "loss": 0.006214986359700561}, {"layer_params": [52, 58, 39, 49], "learning_rate": 0.007852962922874697, "batch_size": 139, "loss": 0.0022270617610774934}, {"layer_params": [23, 42, 27], "learning_rate": 0.006036154605841058, "batch_size": 306, "loss": 0.00258228289661929}, {"layer_params": [47, 21], "learning_rate": 0.008689534482487373, "batch_size": 223, "loss": 0.001999045420670882}, {"layer_params": [53, 37], "learning_rate": 0.0014184251808383541, "batch_size": 285, "loss": 0.0035911878012120724}, {"layer_params": [53, 19, 61, 60, 29], "learning_rate": 0.0003584710184706812, "batch_size": 117, "loss": 0.006658037905581295}, {"layer_params": [21, 23], "learning_rate": 0.009288941009767715, "batch_size": 87, "loss": 0.006629204852506518}, {"layer_params": [53, 48, 22, 38], "learning_rate": 0.0043178575473085574, "batch_size": 375, "loss": 0.0014677448582369834}, {"layer_params": [59, 44], "learning_rate": 0.002566888321947575, "batch_size": 329, "loss": 0.0020367539976723493}, {"layer_params": [61, 39, 53, 40], "learning_rate": 0.004963017900509499, "batch_size": 430, "loss": 0.0008242605323903262}, {"layer_params": [39, 21, 42], "learning_rate": 0.004839613051545072, "batch_size": 426, "loss": 0.0023177229869179427}, {"layer_params": [23, 44], "learning_rate": 0.0077471977505757655, "batch_size": 140, "loss": 0.003042090421076864}, {"layer_params": [23, 43, 21, 25], "learning_rate": 0.0012721739687750226, "batch_size": 399, "loss": 0.0038010429963469504}, {"layer_params": [50, 43], "learning_rate": 0.003631045110640514, "batch_size": 387, "loss": 0.002044716764939949}, {"layer_params": [22, 22, 50, 27], "learning_rate": 0.007990692279238668, "batch_size": 500, "loss": 0.0026004868093878033}, {"layer_params": [41, 57], "learning_rate": 7.989023417923806e-05, "batch_size": 371, "loss": 0.02052559668198228}, {"layer_params": [52, 31, 30, 31], "learning_rate": 0.003921464705975487, "batch_size": 289, "loss": 0.0020295968244317918}, {"layer_params": [17, 42, 54, 60], "learning_rate": 0.004485695762096816, "batch_size": 116, "loss": 0.003534871449228376}, {"layer_params": [42, 37, 18], "learning_rate": 0.00813545124360666, "batch_size": 421, "loss": 0.0014243829390034079}, {"layer_params": [16, 23, 50, 53, 55], "learning_rate": 0.0028506885698998227, "batch_size": 382, "loss": 0.0038817108934745192}, {"layer_params": [57, 49, 42, 55, 58], "learning_rate": 0.009357988395813753, "batch_size": 137, "loss": 0.0018544344033580274}, {"layer_params": [47, 60, 63], "learning_rate": 0.00948418446498197, "batch_size": 293, "loss": 0.0010237859474727883}, {"layer_params": [36, 64, 45, 23, 49], "learning_rate": 0.00020149662021435867, "batch_size": 282, "loss": 0.007864201595075428}, {"layer_params": [56, 24, 32, 40, 53], "learning_rate": 0.009688851159823349, "batch_size": 418, "loss": 0.0025780154624953865}, {"layer_params": [21, 46, 54], "learning_rate": 0.00903461694536841, "batch_size": 233, "loss": 0.002663886498194188}, {"layer_params": [31, 18, 64], "learning_rate": 0.0014366868993110067, "batch_size": 270, "loss": 0.003752606373745948}, {"layer_params": [35, 42], "learning_rate": 0.008362998522851366, "batch_size": 352, "loss": 0.002849786630831659}, {"layer_params": [38, 20, 32, 59], "learning_rate": 0.002332154095619951, "batch_size": 485, "loss": 0.002503689806908369}, {"layer_params": [54, 49, 40, 46, 19], "learning_rate": 0.00045594989206909273, "batch_size": 198, "loss": 0.005877100410871207}, {"layer_params": [45, 20, 46, 25, 35], "learning_rate": 0.00807192294143284, "batch_size": 43, "loss": 0.006086409806739539}, {"layer_params": [30, 50, 52], "learning_rate": 0.006623577929324672, "batch_size": 281, "loss": 0.001401183222187683}, {"layer_params": [39, 62], "learning_rate": 0.001032790380263978, "batch_size": 201, "loss": 0.00397525672102347}, {"layer_params": [36, 24], "learning_rate": 0.008759532552689984, "batch_size": 433, "loss": 0.003202482424676418}, {"layer_params": [23, 52], "learning_rate": 0.00953177563261175, "batch_size": 316, "loss": 0.0023372975655365736}, {"layer_params": [60, 40, 21], "learning_rate": 0.005984381349267794, "batch_size": 481, "loss": 0.0024623956019058824}, {"layer_params": [40, 58, 40], "learning_rate": 0.001617247670005511, "batch_size": 335, "loss": 0.0017930939397774637}, {"layer_params": [62, 17, 27, 33], "learning_rate": 0.007638081639674671, "batch_size": 42, "loss": 0.006059858601074666}, {"layer_params": [40, 53, 44], "learning_rate": 0.002891137221758215, "batch_size": 458, "loss": 0.0015556998504325749}, {"layer_params": [36, 33, 22, 53], "learning_rate": 0.0035597517189202023, "batch_size": 354, "loss": 0.0018879516574088484}, {"layer_params": [57, 43, 62, 17, 35], "learning_rate": 0.0028619287371171405, "batch_size": 481, "loss": 0.0010672625992447138}, {"layer_params": [43, 58, 38, 57], "learning_rate": 0.0035456844400768846, "batch_size": 373, "loss": 0.0015581650950480253}, {"layer_params": [60, 36, 39, 35, 55], "learning_rate": 0.009494350029226894, "batch_size": 325, "loss": 0.002891146580222994}, {"layer_params": [44, 30], "learning_rate": 0.0007512555796435569, "batch_size": 270, "loss": 0.006078847902826965}, {"layer_params": [55, 50, 21, 29, 47], "learning_rate": 0.0006167458787304119, "batch_size": 328, "loss": 0.005813057282939554}, {"layer_params": [38, 30, 40, 62], "learning_rate": 0.005397944416132432, "batch_size": 28, "loss": 0.004719506049295888}, {"layer_params": [29, 61, 16, 32, 38], "learning_rate": 0.009400582088861869, "batch_size": 79, "loss": 0.002337487058248371}, {"layer_params": [44, 40, 58, 42, 21], "learning_rate": 0.0009512884910225706, "batch_size": 239, "loss": 0.0025368744763545692}, {"layer_params": [49, 55], "learning_rate": 0.007887609950163556, "batch_size": 205, "loss": 0.0016279483295511454}, {"layer_params": [31, 30, 41], "learning_rate": 0.006559353213144382, "batch_size": 326, "loss": 0.0016184813366271556}, {"layer_params": [42, 34, 38, 26], "learning_rate": 4.7883877247880236e-05, "batch_size": 230, "loss": 0.03778381187468767}, {"layer_params": [49, 22], "learning_rate": 0.004249280872476402, "batch_size": 510, "loss": 0.001871071282075718}, {"layer_params": [44, 24, 21, 16], "learning_rate": 0.002779876507515936, "batch_size": 36, "loss": 0.006967924288474024}, {"layer_params": [45, 52], "learning_rate": 0.00036661226402925044, "batch_size": 127, "loss": 0.007603251277469098}, {"layer_params": [25, 24, 31, 49], "learning_rate": 0.009729305467429354, "batch_size": 276, "loss": 0.0023277616419363767}, {"layer_params": [61, 30], "learning_rate": 0.004546602317052245, "batch_size": 467, "loss": 0.00287305208388716}, {"layer_params": [52, 51, 29, 40, 51], "learning_rate": 0.006999721447677519, "batch_size": 451, "loss": 0.0011990998964756727}, {"layer_params": [47, 43, 22], "learning_rate": 0.001427077025754807, "batch_size": 380, "loss": 0.0037940561259165407}, {"layer_params": [55, 49, 41, 51, 37], "learning_rate": 0.0003656912064674977, "batch_size": 403, "loss": 0.005390737159177661}, {"layer_params": [48, 60], "learning_rate": 0.0010802130914622362, "batch_size": 131, "loss": 0.004423900449182838}, {"layer_params": [31, 23, 34, 40, 43], "learning_rate": 0.00931082227413273, "batch_size": 407, "loss": 0.002818708757404238}, {"layer_params": [38, 42, 63], "learning_rate": 0.002452066747396434, "batch_size": 37, "loss": 0.005760725440923125}, {"layer_params": [18, 41, 55], "learning_rate": 0.00032834915072773365, "batch_size": 462, "loss": 0.008392110513523222}, {"layer_params": [59, 40, 36], "learning_rate": 0.00569568111091975, "batch_size": 460, "loss": 0.001443926077336073}, {"layer_params": [28, 61, 22], "learning_rate": 0.008849638887890228, "batch_size": 499, "loss": 0.0017865787702612578}, {"layer_params": [55, 30, 43], "learning_rate": 0.0071708956205715655, "batch_size": 444, "loss": 0.0027989221597090365}, {"layer_params": [40, 32, 27, 31, 47], "learning_rate": 0.0015536646213216822, "batch_size": 496, "loss": 0.002637183484621346}, {"layer_params": [45, 32, 37, 37], "learning_rate": 0.005919144153105586, "batch_size": 77, "loss": 0.004817859784234315}, {"layer_params": [52, 52, 46, 59], "learning_rate": 0.0058138187668630706, "batch_size": 398, "loss": 0.0008219653979176655}, {"layer_params": [16, 21, 17, 51, 39], "learning_rate": 0.005620868433519138, "batch_size": 119, "loss": 0.005192270155530423}, {"layer_params": [22, 31, 21, 57, 57], "learning_rate": 0.0012149677677147888, "batch_size": 234, "loss": 0.004445616120938212}, {"layer_params": [56, 59], "learning_rate": 0.002116046302061507, "batch_size": 216, "loss": 0.0016815217479597777}, {"layer_params": [39, 16, 24], "learning_rate": 0.006019483821256688, "batch_size": 275, "loss": 0.002559464199002832}, {"layer_params": [16, 61, 41], "learning_rate": 0.007805838935965264, "batch_size": 451, "loss": 0.0022537457779981196}, {"layer_params": [17, 24], "learning_rate": 0.0012257451018171442, "batch_size": 319, "loss": 0.008102479884400963}, {"layer_params": [60, 45, 23, 23, 35], "learning_rate": 0.004436985548765036, "batch_size": 441, "loss": 0.0012515785591676832}, {"layer_params": [51, 35, 19], "learning_rate": 0.006821178845152126, "batch_size": 498, "loss": 0.0022269474703352898}, {"layer_params": [40, 31, 32], "learning_rate": 0.005683611662048838, "batch_size": 493, "loss": 0.001598345838719979}, {"layer_params": [64, 51], "learning_rate": 0.0009144988396468277, "batch_size": 492, "loss": 0.002665322138927877}, {"layer_params": [49, 49, 46, 32], "learning_rate": 0.004742178457953701, "batch_size": 350, "loss": 0.0014278879389166832}, {"layer_params": [47, 38, 43, 41, 60], "learning_rate": 0.004884210454124757, "batch_size": 184, "loss": 0.00340061591938138}, {"layer_params": [54, 51, 41, 17, 26], "learning_rate": 0.0081352753122255, "batch_size": 244, "loss": 0.001580258545000106}, {"layer_params": [37, 59, 39], "learning_rate": 0.005688016996499304, "batch_size": 174, "loss": 0.0017919746425468475}, {"layer_params": [58, 63], "learning_rate": 0.0042250201629910325, "batch_size": 371, "loss": 0.001630315964575857}, {"layer_params": [35, 59], "learning_rate": 0.004562793739242873, "batch_size": 170, "loss": 0.0018514668650459498}, {"layer_params": [39, 36], "learning_rate": 0.009442366969440166, "batch_size": 49, "loss": 0.003363954764790833}, {"layer_params": [56, 47, 59, 58], "learning_rate": 0.008414565343385031, "batch_size": 168, "loss": 0.001916346070356667}, {"layer_params": [58, 49, 28, 45], "learning_rate": 3.4649104082905644e-05, "batch_size": 232, "loss": 0.03657706405967474}, {"layer_params": [49, 58, 55, 60, 57], "learning_rate": 0.006680422701883052, "batch_size": 62, "loss": 0.0028092769731301813}, {"layer_params": [16, 23, 29], "learning_rate": 0.001226287629721271, "batch_size": 440, "loss": 0.00640295930672437}, {"layer_params": [27, 19], "learning_rate": 0.0018725422973553721, "batch_size": 97, "loss": 0.005881454646587372}, {"layer_params": [16, 28], "learning_rate": 0.0030508360538050823, "batch_size": 410, "loss": 0.004215197549201548}, {"layer_params": [26, 29], "learning_rate": 0.0047714325941991004, "batch_size": 436, "loss": 0.0020937932131346315}, {"layer_params": [22, 21, 47], "learning_rate": 0.007728210370242021, "batch_size": 476, "loss": 0.0026542654982768}, {"layer_params": [62, 41], "learning_rate": 0.007735007068942806, "batch_size": 334, "loss": 0.0017490722553338855}, {"layer_params": [43, 51, 26, 21], "learning_rate": 0.006061923639170703, "batch_size": 436, "loss": 0.0009709957358427346}, {"layer_params": [34, 21, 40], "learning_rate": 0.002729465471800953, "batch_size": 443, "loss": 0.0012302663503214717}, {"layer_params": [53, 62, 35, 44], "learning_rate": 0.004762027946670685, "batch_size": 188, "loss": 0.0012421002564951778}, {"layer_params": [20, 61, 41, 57, 42], "learning_rate": 0.00933250329805673, "batch_size": 130, "loss": 0.0018146239907946438}, {"layer_params": [55, 50, 27, 26], "learning_rate": 0.0018379716590324728, "batch_size": 398, "loss": 0.001574923259904608}, {"layer_params": [55, 41, 60], "learning_rate": 0.007941492191295117, "batch_size": 308, "loss": 0.0007767870597308502}, {"layer_params": [64, 44, 52, 49], "learning_rate": 0.0063220327367046626, "batch_size": 145, "loss": 0.0016153437772300095}, {"layer_params": [60, 31], "learning_rate": 0.008744132416973778, "batch_size": 364, "loss": 0.001957915883976966}, {"layer_params": [46, 41], "learning_rate": 0.001232591747068318, "batch_size": 508, "loss": 0.003400557399727404}, {"layer_params": [38, 26, 33, 38, 46], "learning_rate": 0.00542228818882245, "batch_size": 342, "loss": 0.0017229441436938941}, {"layer_params": [60, 47, 35], "learning_rate": 0.00036150280573745997, "batch_size": 121, "loss": 0.007031794735230506}, {"layer_params": [27, 40, 35], "learning_rate": 0.001780052150803501, "batch_size": 20, "loss": 0.006805206914432347}, {"layer_params": [50, 16, 23, 30], "learning_rate": 0.005801312130905381, "batch_size": 78, "loss": 0.004360610621515662}, {"layer_params": [25, 32], "learning_rate": 0.009611914301954618, "batch_size": 55, "loss": 0.006877325733657926}, {"layer_params": [17, 17, 21, 54], "learning_rate": 0.009188625044971794, "batch_size": 476, "loss": 0.0029719632328487934}, {"layer_params": [41, 39, 64, 32, 27], "learning_rate": 0.008001318076702303, "batch_size": 157, "loss": 0.001579027861589566}, {"layer_params": [51, 51, 39, 18], "learning_rate": 0.002600538869569081, "batch_size": 379, "loss": 0.0011307168327039107}, {"layer_params": [36, 34, 27], "learning_rate": 0.004903365212104258, "batch_size": 454, "loss": 0.0022261722688563168}, {"layer_params": [40, 25, 46], "learning_rate": 0.003509152195178765, "batch_size": 216, "loss": 0.002982623274438083}, {"layer_params": [30, 28, 34], "learning_rate": 0.008783149829993635, "batch_size": 324, "loss": 0.0019420628785155713}, {"layer_params": [32, 36, 37, 59, 57], "learning_rate": 0.005453641083011336, "batch_size": 503, "loss": 0.0017711778497323395}, {"layer_params": [21, 38, 59, 32, 46], "learning_rate": 0.002058144680870417, "batch_size": 143, "loss": 0.0029722354607656597}, {"layer_params": [53, 46, 60, 32, 56], "learning_rate": 0.0015982731633347803, "batch_size": 106, "loss": 0.0024124323553405703}, {"layer_params": [55, 54, 31, 53], "learning_rate": 0.009401160227119154, "batch_size": 185, "loss": 0.0016764399164821953}, {"layer_params": [48, 31, 62], "learning_rate": 0.000489139364052681, "batch_size": 195, "loss": 0.00569802365731448}, {"layer_params": [58, 25, 33, 55, 38], "learning_rate": 0.004391644415816066, "batch_size": 298, "loss": 0.0021858178346883506}, {"layer_params": [52, 57], "learning_rate": 0.00028420638158939394, "batch_size": 253, "loss": 0.0068979289289563895}, {"layer_params": [61, 20, 62], "learning_rate": 0.005145581676429346, "batch_size": 467, "loss": 0.0007847052748547867}, {"layer_params": [33, 34, 57, 41, 32], "learning_rate": 0.004910002145351584, "batch_size": 210, "loss": 0.002247067110147327}, {"layer_params": [59, 63], "learning_rate": 0.00833145147125554, "batch_size": 450, "loss": 0.001120293938438408}, {"layer_params": [56, 44, 58, 62], "learning_rate": 0.005092592980963271, "batch_size": 363, "loss": 0.0011991531448438764}, {"layer_params": [27, 19, 38, 39], "learning_rate": 0.009595240658692581, "batch_size": 309, "loss": 0.0028679662244394423}, {"layer_params": [50, 16], "learning_rate": 0.001421170794024769, "batch_size": 307, "loss": 0.004258194726426154}, {"layer_params": [29, 64], "learning_rate": 0.005009479603563805, "batch_size": 363, "loss": 0.0026592619507573544}, {"layer_params": [17, 53, 24, 26], "learning_rate": 0.005867964660876526, "batch_size": 476, "loss": 0.0021312552760355177}, {"layer_params": [22, 45], "learning_rate": 0.006131988338807154, "batch_size": 278, "loss": 0.002365614623995498}, {"layer_params": [53, 24, 50], "learning_rate": 0.0048106011854074536, "batch_size": 284, "loss": 0.00235357980709523}, {"layer_params": [49, 58, 48, 40], "learning_rate": 0.00822164073562124, "batch_size": 439, "loss": 0.0010774509806651621}, {"layer_params": [16, 32, 18], "learning_rate": 0.009319798778854756, "batch_size": 284, "loss": 0.0039885560376569625}, {"layer_params": [40, 17], "learning_rate": 0.009784455321510685, "batch_size": 177, "loss": 0.004861723736394197}, {"layer_params": [30, 45, 22, 22], "learning_rate": 0.00772342389183334, "batch_size": 67, "loss": 0.004867929618339986}, {"layer_params": [31, 43, 25, 23], "learning_rate": 0.003931838768971439, "batch_size": 378, "loss": 0.0020494985778350384}, {"layer_params": [34, 38], "learning_rate": 0.009563931627845438, "batch_size": 31, "loss": 0.006088998623890802}, {"layer_params": [25, 40, 50], "learning_rate": 0.0022901092419436195, "batch_size": 443, "loss": 0.0027137211291119456}, {"layer_params": [24, 18, 45], "learning_rate": 0.005341833715687893, "batch_size": 454, "loss": 0.004760836162604392}, {"layer_params": [48, 58, 46], "learning_rate": 0.009932358580851, "batch_size": 31, "loss": 0.004360349832568318}, {"layer_params": [32, 50], "learning_rate": 0.003692442472755871, "batch_size": 182, "loss": 0.0032872933219186963}, {"layer_params": [41, 43, 28], "learning_rate": 0.0064662316627778155, "batch_size": 177, "loss": 0.0017628184100612998}, {"layer_params": [26, 36], "learning_rate": 0.005327631592452504, "batch_size": 271, "loss": 0.002641140162013471}, {"layer_params": [35, 20, 36, 18], "learning_rate": 0.0050314568140551325, "batch_size": 89, "loss": 0.0036981504736468196}, {"layer_params": [23, 53, 48], "learning_rate": 0.0059499574623867344, "batch_size": 281, "loss": 0.001688432936789468}, {"layer_params": [44, 42], "learning_rate": 0.007011199443772886, "batch_size": 343, "loss": 0.0017524233274161815}, {"layer_params": [54, 22], "learning_rate": 0.005899195434102594, "batch_size": 182, "loss": 0.002409914485178888}, {"layer_params": [18, 58, 40], "learning_rate": 0.008223097105722098, "batch_size": 240, "loss": 0.0013357360323425383}, {"layer_params": [49, 18, 46, 27, 47], "learning_rate": 0.0035165595807910813, "batch_size": 291, "loss": 0.0017577986849937588}, {"layer_params": [51, 47, 44, 34, 32], "learning_rate": 0.003042205089959688, "batch_size": 270, "loss": 0.0014900907536502927}, {"layer_params": [17, 51, 44, 64, 55], "learning_rate": 0.009076182980159758, "batch_size": 152, "loss": 0.0024863953643944115}, {"layer_params": [51, 26, 52], "learning_rate": 0.005898996098316197, "batch_size": 335, "loss": 0.002869594895746559}, {"layer_params": [35, 40, 56, 54], "learning_rate": 0.0015083414101782747, "batch_size": 478, "loss": 0.00206305603380315}, {"layer_params": [60, 26, 22, 35, 47], "learning_rate": 0.009285891375008681, "batch_size": 133, "loss": 0.0018175811716355384}, {"layer_params": [37, 22, 18, 27], "learning_rate": 0.005563009912648873, "batch_size": 242, "loss": 0.003481007197406143}, {"layer_params": [51, 51, 34, 56], "learning_rate": 0.005758084054770117, "batch_size": 374, "loss": 0.0015922418015543371}, {"layer_params": [33, 17, 44], "learning_rate": 0.008403963232783378, "batch_size": 245, "loss": 0.001936000508721918}, {"layer_params": [25, 20, 23], "learning_rate": 0.002937389641079802, "batch_size": 46, "loss": 0.00803551884368062}, {"layer_params": [17, 25, 18, 25, 39], "learning_rate": 0.0032180778341406426, "batch_size": 291, "loss": 0.003200564356520772}, {"layer_params": [43, 43, 37, 55], "learning_rate": 0.0029853363796174216, "batch_size": 392, "loss": 0.0016705601860303432}, {"layer_params": [26, 42, 56], "learning_rate": 0.0018752143362065648, "batch_size": 407, "loss": 0.0020183612732216716}, {"layer_params": [21, 58], "learning_rate": 0.006015216625925182, "batch_size": 109, "loss": 0.0026472614752128722}, {"layer_params": [40, 32], "learning_rate": 0.009312760298801495, "batch_size": 94, "loss": 0.002869288926012814}, {"layer_params": [44, 63], "learning_rate": 0.009058161689751935, "batch_size": 411, "loss": 0.001706595574505627}, {"layer_params": [38, 61, 35, 30], "learning_rate": 0.0025128696722369207, "batch_size": 176, "loss": 0.002190561074530706}, {"layer_params": [50, 54], "learning_rate": 0.0008202312981424996, "batch_size": 179, "loss": 0.004862046153284609}, {"layer_params": [33, 31, 54], "learning_rate": 0.004050964554041455, "batch_size": 214, "loss": 0.002737888146657497}, {"layer_params": [33, 26, 52], "learning_rate": 0.0015020557242925111, "batch_size": 90, "loss": 0.005614792373962701}, {"layer_params": [61, 62, 56], "learning_rate": 0.0027146050025592533, "batch_size": 149, "loss": 0.001387342200614512}, {"layer_params": [22, 32, 49, 28, 48], "learning_rate": 0.009725233434808933, "batch_size": 272, "loss": 0.0026078252529259773}, {"layer_params": [60, 19, 21, 59], "learning_rate": 0.006376241164963378, "batch_size": 433, "loss": 0.0019227627397049218}, {"layer_params": [54, 63], "learning_rate": 0.004513770260200902, "batch_size": 376, "loss": 0.0016063358460087329}, {"layer_params": [54, 49, 29], "learning_rate": 0.0019561488622923547, "batch_size": 258, "loss": 0.0016043812956195325}, {"layer_params": [59, 21, 61], "learning_rate": 0.003574242041758908, "batch_size": 248, "loss": 0.002399472773540765}, {"layer_params": [33, 20, 35], "learning_rate": 0.007747774235370906, "batch_size": 325, "loss": 0.002224164166254923}, {"layer_params": [46, 49, 38], "learning_rate": 0.0004997554394161936, "batch_size": 396, "loss": 0.004160511263180524}, {"layer_params": [54, 25], "learning_rate": 0.0021332725956597813, "batch_size": 381, "loss": 0.002887980139348656}, {"layer_params": [34, 53, 31], "learning_rate": 0.004626220441242461, "batch_size": 418, "loss": 0.001589035065844655}, {"layer_params": [38, 17, 32, 57, 45], "learning_rate": 0.001624617603540535, "batch_size": 235, "loss": 0.0037643525283783674}, {"layer_params": [22, 39, 45, 46, 43], "learning_rate": 0.00529654739450597, "batch_size": 105, "loss": 0.004313406189903617}, {"layer_params": [54, 64, 18, 55, 39], "learning_rate": 0.0034808543636711117, "batch_size": 71, "loss": 0.0020472174254246057}, {"layer_params": [35, 64, 22], "learning_rate": 0.005029083485711389, "batch_size": 377, "loss": 0.0010865197033854202}, {"layer_params": [59, 23, 20, 64], "learning_rate": 0.0037012453258348224, "batch_size": 221, "loss": 0.0020820377755444495}, {"layer_params": [64, 18], "learning_rate": 0.0034578415387119363, "batch_size": 186, "loss": 0.005101317432709038}, {"layer_params": [56, 20, 53, 38, 55], "learning_rate": 0.001780273363226221, "batch_size": 346, "loss": 0.002329237050144002}, {"layer_params": [55, 54, 38, 18, 47], "learning_rate": 0.003073079655809022, "batch_size": 278, "loss": 0.0009530647768406197}, {"layer_params": [19, 33, 29], "learning_rate": 0.008721354598235462, "batch_size": 231, "loss": 0.0028682661708444358}, {"layer_params": [45, 36], "learning_rate": 0.001985997616037758, "batch_size": 317, "loss": 0.0025295463553629814}, {"layer_params": [47, 25, 38], "learning_rate": 0.008596106190176898, "batch_size": 258, "loss": 0.0019860751344822347}, {"layer_params": [40, 50, 37, 54, 28], "learning_rate": 0.008644296550876781, "batch_size": 485, "loss": 0.0010928966413484885}, {"layer_params": [33, 38, 44], "learning_rate": 0.006418408463368232, "batch_size": 421, "loss": 0.0014658051042351873}, {"layer_params": [54, 48, 63, 39], "learning_rate": 0.008767131515893398, "batch_size": 485, "loss": 0.0017255166929680853}, {"layer_params": [32, 56, 45, 17], "learning_rate": 0.009013659370224199, "batch_size": 377, "loss": 0.0019379564770497383}, {"layer_params": [32, 21], "learning_rate": 0.0031637023238283266, "batch_size": 90, "loss": 0.004072208032011986}, {"layer_params": [31, 39], "learning_rate": 0.003980422912730337, "batch_size": 170, "loss": 0.003852494035381824}, {"layer_params": [60, 44, 48, 20, 42], "learning_rate": 0.007641248251696704, "batch_size": 325, "loss": 0.001415529039222747}, {"layer_params": [46, 40, 44, 64, 25], "learning_rate": 0.006159163646966552, "batch_size": 195, "loss": 0.001748393945163116}, {"layer_params": [58, 26, 38, 33], "learning_rate": 0.006663050034096296, "batch_size": 87, "loss": 0.0024631346901878713}, {"layer_params": [63, 21, 25, 54, 16], "learning_rate": 0.009868768870112524, "batch_size": 48, "loss": 0.005005555090028793}, {"layer_params": [58, 27, 21, 58, 39], "learning_rate": 0.0014204484080955044, "batch_size": 450, "loss": 0.0019274026667699218}, {"layer_params": [51, 56, 47], "learning_rate": 0.00884648877411658, "batch_size": 484, "loss": 0.000645663429168053}, {"layer_params": [22, 29, 63, 61], "learning_rate": 0.009770629146395544, "batch_size": 375, "loss": 0.00203787250444293}, {"layer_params": [49, 54, 45, 31], "learning_rate": 0.006514477757493302, "batch_size": 223, "loss": 0.0016610290051903575}, {"layer_params": [36, 62, 20], "learning_rate": 0.00014633359653418155, "batch_size": 262, "loss": 0.007910937862470746}, {"layer_params": [16, 25, 63, 55], "learning_rate": 0.005999055297201296, "batch_size": 202, "loss": 0.0035626722709275783}, {"layer_params": [25, 22, 30, 35], "learning_rate": 0.003890286425510938, "batch_size": 469, "loss": 0.0032665827334858477}, {"layer_params": [38, 23], "learning_rate": 0.0003463586045326078, "batch_size": 284, "loss": 0.008616303680464626}, {"layer_params": [39, 40], "learning_rate": 0.002165510623869639, "batch_size": 487, "loss": 0.0027551543759182094}, {"layer_params": [46, 19], "learning_rate": 0.0009605284947074835, "batch_size": 248, "loss": 0.006974554024636746}, {"layer_params": [63, 50, 18, 51, 35], "learning_rate": 0.004609926225407435, "batch_size": 357, "loss": 0.0011714614363154397}, {"layer_params": [39, 16, 21], "learning_rate": 0.00259847401953056, "batch_size": 126, "loss": 0.002203344595618546}, {"layer_params": [27, 36, 49, 61], "learning_rate": 0.006107892660744016, "batch_size": 322, "loss": 0.002494634008035064}, {"layer_params": [59, 45, 43, 33], "learning_rate": 0.0020644410276266806, "batch_size": 384, "loss": 0.001527146038133651}, {"layer_params": [34, 39, 58], "learning_rate": 0.005383517128152992, "batch_size": 261, "loss": 0.0012847307854099198}, {"layer_params": [26, 32, 29, 39, 39], "learning_rate": 0.007579744478124882, "batch_size": 62, "loss": 0.00559885821538046}, {"layer_params": [19, 59, 64], "learning_rate": 0.004732392976991923, "batch_size": 254, "loss": 0.0029455283284187317}, {"layer_params": [36, 57, 51, 21], "learning_rate": 0.0038031682688171296, "batch_size": 206, "loss": 0.001572383705060929}, {"layer_params": [43, 32], "learning_rate": 0.001805912668028428, "batch_size": 237, "loss": 0.0025658828136511146}, {"layer_params": [25, 20], "learning_rate": 0.009759712024736803, "batch_size": 344, "loss": 0.0034616706660017373}, {"layer_params": [29, 32], "learning_rate": 0.0010525196778365454, "batch_size": 434, "loss": 0.0056152100209146735}, {"layer_params": [49, 20, 16], "learning_rate": 0.002503004833804271, "batch_size": 48, "loss": 0.005415686341002583}, {"layer_params": [37, 38, 28, 57, 39], "learning_rate": 0.004419685037905509, "batch_size": 106, "loss": 0.0033440895029343666}, {"layer_params": [54, 19, 24, 20], "learning_rate": 0.007632510252689678, "batch_size": 250, "loss": 0.0021632923174183818}, {"layer_params": [46, 32], "learning_rate": 0.006187819877981291, "batch_size": 146, "loss": 0.002068984820507467}, {"layer_params": [16, 47, 56, 17], "learning_rate": 0.0027822015081774695, "batch_size": 446, "loss": 0.0025374316074885427}, {"layer_params": [62, 34], "learning_rate": 0.0041178398383010005, "batch_size": 318, "loss": 0.0019338185142260046}, {"layer_params": [44, 38, 43, 40], "learning_rate": 0.0036831002337859636, "batch_size": 340, "loss": 0.0017339958250522614}, {"layer_params": [61, 32, 21, 51], "learning_rate": 0.0011961846905638497, "batch_size": 292, "loss": 0.004672615015879273}, {"layer_params": [47, 34], "learning_rate": 0.008958873008319629, "batch_size": 455, "loss": 0.002539789753500372}, {"layer_params": [48, 42, 22, 54], "learning_rate": 0.00970914141886073, "batch_size": 156, "loss": 0.0018035022052936256}, {"layer_params": [45, 40, 39], "learning_rate": 0.007425181963859242, "batch_size": 223, "loss": 0.0018826466938480736}, {"layer_params": [59, 26, 36, 18, 47], "learning_rate": 0.0013041459432127983, "batch_size": 437, "loss": 0.002479173177853227}, {"layer_params": [40, 52, 34, 28, 60], "learning_rate": 0.008151633586474546, "batch_size": 381, "loss": 0.0011031936254585163}, {"layer_params": [63, 23, 41, 50], "learning_rate": 0.0074012287991562994, "batch_size": 455, "loss": 0.0010802488931221889}, {"layer_params": [24, 27, 39, 57, 38], "learning_rate": 0.00565305203878889, "batch_size": 497, "loss": 0.0014733278070343657}, {"layer_params": [38, 24, 48], "learning_rate": 0.004485721438082277, "batch_size": 470, "loss": 0.0022775618941523134}, {"layer_params": [21, 37], "learning_rate": 0.008759113057879402, "batch_size": 430, "loss": 0.001638952308567241}, {"layer_params": [31, 59, 16, 56], "learning_rate": 0.0008070685076957934, "batch_size": 34, "loss": 0.006760651902295649}, {"layer_params": [56, 32, 35], "learning_rate": 0.008264023432468856, "batch_size": 115, "loss": 0.002826613994548097}, {"layer_params": [45, 52, 23, 38], "learning_rate": 0.004610364488120344, "batch_size": 326, "loss": 0.001282845747191459}, {"layer_params": [59, 17, 26, 42, 51], "learning_rate": 0.0034148531641202055, "batch_size": 331, "loss": 0.001992031013360247}, {"layer_params": [59, 55, 37, 45], "learning_rate": 0.007593704011736994, "batch_size": 140, "loss": 0.0014969928201753646}, {"layer_params": [30, 64, 30], "learning_rate": 0.004380771161203085, "batch_size": 440, "loss": 0.0016468794259708376}, {"layer_params": [46, 25], "learning_rate": 0.001968632469161667, "batch_size": 32, "loss": 0.0068859249632805585}, {"layer_params": [53, 22, 33], "learning_rate": 0.0021798291916464156, "batch_size": 272, "loss": 0.0021731035865377637}, {"layer_params": [29, 36, 24, 45, 25], "learning_rate": 0.002936995105220847, "batch_size": 284, "loss": 0.0017783394234720618}, {"layer_params": [50, 31, 45], "learning_rate": 0.007427991041867248, "batch_size": 245, "loss": 0.00279801185708493}, {"layer_params": [42, 46, 35, 36, 31], "learning_rate": 0.00487595543565457, "batch_size": 461, "loss": 0.001276706064818427}, {"layer_params": [59, 44, 48, 37], "learning_rate": 0.005494576387010242, "batch_size": 485, "loss": 0.000555423340993002}, {"layer_params": [59, 31, 26, 54, 17], "learning_rate": 0.0023931991097373463, "batch_size": 221, "loss": 0.0024578520166687666}, {"layer_params": [61, 38, 46], "learning_rate": 0.009721656617039541, "batch_size": 32, "loss": 0.004848451521247625}, {"layer_params": [44, 28, 50], "learning_rate": 0.005090437574445285, "batch_size": 285, "loss": 0.0018089277495164425}, {"layer_params": [29, 51, 47, 35, 53], "learning_rate": 0.003132354252462975, "batch_size": 176, "loss": 0.002180729424580932}, {"layer_params": [54, 42, 45, 43, 53], "learning_rate": 0.006329838553977093, "batch_size": 133, "loss": 0.0017753571516368539}, {"layer_params": [53, 51, 25, 38], "learning_rate": 0.004239137463214687, "batch_size": 361, "loss": 0.0015652169228997082}, {"layer_params": [53, 25, 46, 16], "learning_rate": 0.00699081765813348, "batch_size": 381, "loss": 0.0017338404769543557}, {"layer_params": [36, 34, 26, 55], "learning_rate": 0.0027649059012010008, "batch_size": 266, "loss": 0.0024146109994035215}, {"layer_params": [31, 55], "learning_rate": 0.0008466618605563965, "batch_size": 279, "loss": 0.0060622194455936555}, {"layer_params": [46, 22, 31], "learning_rate": 0.007246121824279279, "batch_size": 463, "loss": 0.0018771717930212617}, {"layer_params": [46, 17, 43], "learning_rate": 0.0005968148598600665, "batch_size": 447, "loss": 0.006305555249564349}, {"layer_params": [19, 23, 43], "learning_rate": 0.004150327704542852, "batch_size": 259, "loss": 0.005079865269362926}, {"layer_params": [39, 61, 42, 52, 56], "learning_rate": 0.009588570062694264, "batch_size": 395, "loss": 0.001159775237319991}, {"layer_params": [43, 62, 25], "learning_rate": 0.005248974580162407, "batch_size": 452, "loss": 0.0012414321769028901}, {"layer_params": [16, 53, 18, 49], "learning_rate": 0.007152915255511745, "batch_size": 35, "loss": 0.007205536074470728}, {"layer_params": [42, 51, 50, 16], "learning_rate": 0.006105855460122481, "batch_size": 145, "loss": 0.00181382991024293}, {"layer_params": [40, 54, 53, 44], "learning_rate": 0.002322458401980421, "batch_size": 375, "loss": 0.0015458185761235655}, {"layer_params": [22, 19, 32], "learning_rate": 7.342214412478821e-05, "batch_size": 117, "loss": 0.03633750641718507}, {"layer_params": [60, 31, 59], "learning_rate": 0.00853659981436044, "batch_size": 183, "loss": 0.0012413026043213904}, {"layer_params": [35, 39, 25, 24], "learning_rate": 0.0009870490545614405, "batch_size": 209, "loss": 0.003567521928343922}, {"layer_params": [56, 29, 61, 40, 32], "learning_rate": 0.008889593670480853, "batch_size": 504, "loss": 0.0018584310973528773}, {"layer_params": [61, 46, 49], "learning_rate": 0.006437607218813586, "batch_size": 76, "loss": 0.002947697420604527}, {"layer_params": [58, 63, 46, 29, 44], "learning_rate": 0.002436228899177268, "batch_size": 384, "loss": 0.00115041344310157}, {"layer_params": [36, 55, 51], "learning_rate": 0.00816387002478434, "batch_size": 59, "loss": 0.003130118109984323}, {"layer_params": [54, 30, 20, 26], "learning_rate": 0.0009196916207230604, "batch_size": 353, "loss": 0.004228780847042799}, {"layer_params": [18, 59, 36], "learning_rate": 0.0025326744175988903, "batch_size": 174, "loss": 0.0031570377969183027}, {"layer_params": [50, 34, 44], "learning_rate": 0.00936611931680668, "batch_size": 81, "loss": 0.002936983034014702}, {"layer_params": [21, 58], "learning_rate": 0.00869838568261106, "batch_size": 84, "loss": 0.0033994071884080766}, {"layer_params": [59, 49, 43], "learning_rate": 0.003156133223246877, "batch_size": 203, "loss": 0.0012989611132070422}, {"layer_params": [40, 48, 44, 62, 35], "learning_rate": 0.007958188909724275, "batch_size": 234, "loss": 0.002204234884120524}, {"layer_params": [59, 35], "learning_rate": 0.003541052462283302, "batch_size": 256, "loss": 0.0017965338251087815}, {"layer_params": [33, 17, 23, 63, 16], "learning_rate": 0.007038009834230353, "batch_size": 191, "loss": 0.0035611581639386713}, {"layer_params": [23, 30, 35, 54], "learning_rate": 0.008544402160652742, "batch_size": 268, "loss": 0.003163085328415036}, {"layer_params": [18, 59, 58, 57, 64], "learning_rate": 0.00018923412660017266, "batch_size": 212, "loss": 0.007480150144547224}, {"layer_params": [63, 28], "learning_rate": 0.0032066193524773455, "batch_size": 166, "loss": 0.003043875542934984}, {"layer_params": [42, 53, 62, 39, 53], "learning_rate": 0.002725234980190305, "batch_size": 26, "loss": 0.006338064295705408}, {"layer_params": [24, 28], "learning_rate": 0.009862378938572995, "batch_size": 78, "loss": 0.004817068029660731}, {"layer_params": [59, 24, 30, 44, 47], "learning_rate": 1.5178780409529879e-05, "batch_size": 98, "loss": 0.046046359464526176}, {"layer_params": [29, 40, 37, 24, 16], "learning_rate": 0.0002967780207487013, "batch_size": 288, "loss": 0.0074941215151920915}, {"layer_params": [27, 21, 50], "learning_rate": 0.004717220898268244, "batch_size": 166, "loss": 0.003899963083676994}, {"layer_params": [22, 32], "learning_rate": 0.008420938179606291, "batch_size": 132, "loss": 0.004533985978923738}, {"layer_params": [45, 24, 57, 36, 50], "learning_rate": 0.0003497080411238755, "batch_size": 76, "loss": 0.007947047036141157}, {"layer_params": [55, 44, 59], "learning_rate": 0.006244878279262851, "batch_size": 171, "loss": 0.0013114981126273052}, {"layer_params": [61, 52, 28, 39], "learning_rate": 0.0026590570974432725, "batch_size": 25, "loss": 0.005621315857861191}, {"layer_params": [58, 57, 18, 42, 36], "learning_rate": 0.009434815840573285, "batch_size": 65, "loss": 0.0024153640726581214}, {"layer_params": [32, 46, 22, 24, 40], "learning_rate": 0.005735855865992389, "batch_size": 455, "loss": 0.0010086391097866}, {"layer_params": [23, 57, 62, 42, 41], "learning_rate": 0.0006992371027256064, "batch_size": 214, "loss": 0.005035816750023514}, {"layer_params": [49, 19], "learning_rate": 0.004482207631226468, "batch_size": 298, "loss": 0.0035943408776074647}, {"layer_params": [47, 51], "learning_rate": 0.005541197184640948, "batch_size": 465, "loss": 0.0013659090816508979}, {"layer_params": [52, 52, 46, 29, 47], "learning_rate": 0.008985989685428913, "batch_size": 334, "loss": 0.001366965975612402}, {"layer_params": [24, 37], "learning_rate": 0.006305281643987983, "batch_size": 401, "loss": 0.0026597232464700936}, {"layer_params": [48, 21, 49], "learning_rate": 0.006977613557914486, "batch_size": 280, "loss": 0.0017093846155330538}, {"layer_params": [62, 58, 48], "learning_rate": 0.00527038712172449, "batch_size": 464, "loss": 0.00101192356669344}, {"layer_params": [62, 37, 31, 61, 54], "learning_rate": 0.00916531174860177, "batch_size": 91, "loss": 0.0023781565146055073}, {"layer_params": [37, 59, 30], "learning_rate": 0.0006830026274407215, "batch_size": 166, "loss": 0.004214312571566552}, {"layer_params": [30, 48], "learning_rate": 0.005476490362964348, "batch_size": 283, "loss": 0.0027146861352957785}, {"layer_params": [29, 21, 35, 54], "learning_rate": 0.007432094728007264, "batch_size": 154, "loss": 0.003357550816144794}, {"layer_params": [64, 37], "learning_rate": 0.0050436428427572825, "batch_size": 393, "loss": 0.001833673994988203}, {"layer_params": [46, 17], "learning_rate": 0.006077945475350294, "batch_size": 386, "loss": 0.0023838484776206315}, {"layer_params": [55, 16, 38, 33, 19], "learning_rate": 0.005489379309508748, "batch_size": 303, "loss": 0.0026556576602160932}, {"layer_params": [51, 27, 47, 30], "learning_rate": 0.00254210665272199, "batch_size": 476, "loss": 0.0019764448003843425}, {"layer_params": [61, 44, 36], "learning_rate": 0.0016889321615880199, "batch_size": 221, "loss": 0.003100212237332016}, {"layer_params": [47, 16, 47, 53, 32], "learning_rate": 0.0029605675240587195, "batch_size": 401, "loss": 0.0018032729299739003}, {"layer_params": [26, 57, 38], "learning_rate": 0.003907684220655472, "batch_size": 74, "loss": 0.004746810281649232}, {"layer_params": [27, 62, 29, 30, 57], "learning_rate": 0.008998216449386622, "batch_size": 224, "loss": 0.0016798069118522108}, {"layer_params": [39, 39], "learning_rate": 0.00407972604818534, "batch_size": 406, "loss": 0.0031539090001024305}, {"layer_params": [32, 35, 44, 30, 48], "learning_rate": 0.0007458306786804863, "batch_size": 471, "loss": 0.004231961432378739}, {"layer_params": [50, 58, 20, 23], "learning_rate": 0.008898963709022581, "batch_size": 192, "loss": 0.001529115114826709}, {"layer_params": [59, 17, 26, 57, 46], "learning_rate": 0.008612680392065171, "batch_size": 81, "loss": 0.005375183280557394}, {"layer_params": [58, 25, 52], "learning_rate": 0.0070580839645720435, "batch_size": 366, "loss": 0.0010294850019272417}, {"layer_params": [41, 34, 32], "learning_rate": 0.0019748574671373384, "batch_size": 488, "loss": 0.0020537852228153498}, {"layer_params": [52, 17], "learning_rate": 0.007756382573483877, "batch_size": 432, "loss": 0.0032042009569704533}, {"layer_params": [61, 51, 34, 26], "learning_rate": 0.004116476530709695, "batch_size": 122, "loss": 0.0018413039215374738}, {"layer_params": [62, 30, 47, 35, 51], "learning_rate": 0.009297089323123725, "batch_size": 469, "loss": 0.001157645261264406}, {"layer_params": [46, 58, 64], "learning_rate": 0.0027214052896571417, "batch_size": 18, "loss": 0.0062056159973144535}, {"layer_params": [43, 49, 54], "learning_rate": 0.0020283176161062905, "batch_size": 264, "loss": 0.0024324528814759104}, {"layer_params": [57, 49, 26, 46, 41], "learning_rate": 0.0027246276098007774, "batch_size": 431, "loss": 0.0016634386091027408}, {"layer_params": [37, 42, 22, 38], "learning_rate": 0.005511968081857783, "batch_size": 32, "loss": 0.005133267131168395}, {"layer_params": [31, 38, 21], "learning_rate": 0.0034985105939257634, "batch_size": 472, "loss": 0.0024484321381896736}, {"layer_params": [59, 23, 55], "learning_rate": 0.005942487382789054, "batch_size": 413, "loss": 0.0021674753550905736}, {"layer_params": [48, 50, 47, 31], "learning_rate": 0.009825182027836155, "batch_size": 16, "loss": 0.008360586625058205}, {"layer_params": [49, 49, 28, 31], "learning_rate": 0.00942097626356861, "batch_size": 51, "loss": 0.004028924050508067}, {"layer_params": [22, 44], "learning_rate": 0.0064087421322038185, "batch_size": 113, "loss": 0.003139770880807191}, {"layer_params": [53, 23], "learning_rate": 0.008133923508429784, "batch_size": 268, "loss": 0.0030192798376083374}, {"layer_params": [16, 32, 25, 64, 63], "learning_rate": 0.009446419640870434, "batch_size": 360, "loss": 0.002769018532708287}, {"layer_params": [37, 26, 17], "learning_rate": 0.00942872016743771, "batch_size": 81, "loss": 0.004003268391825259}, {"layer_params": [55, 61], "learning_rate": 0.0097566524600131, "batch_size": 33, "loss": 0.005459364529233426}, {"layer_params": [47, 23], "learning_rate": 0.003039212379390983, "batch_size": 253, "loss": 0.0030580862704664468}, {"layer_params": [60, 33, 23, 22], "learning_rate": 0.000756129240900733, "batch_size": 440, "loss": 0.0034875027439557017}, {"layer_params": [35, 43, 30], "learning_rate": 0.008567791186136228, "batch_size": 147, "loss": 0.002943641021847725}, {"layer_params": [38, 61, 40], "learning_rate": 0.003143577635393087, "batch_size": 214, "loss": 0.001432639880804345}, {"layer_params": [32, 44, 60, 33, 42], "learning_rate": 0.009282594128447673, "batch_size": 506, "loss": 0.001289331872249022}, {"layer_params": [27, 19, 54, 43], "learning_rate": 0.001193523559661477, "batch_size": 60, "loss": 0.007237844150513411}, {"layer_params": [46, 23, 27, 34], "learning_rate": 0.009368142057734766, "batch_size": 431, "loss": 0.0008473492303164676}, {"layer_params": [35, 29, 48], "learning_rate": 0.002369266923435544, "batch_size": 442, "loss": 0.002691259509883821}, {"layer_params": [49, 37, 28], "learning_rate": 0.001179833973640337, "batch_size": 170, "loss": 0.005559222844894975}, {"layer_params": [21, 41], "learning_rate": 0.006822165767829832, "batch_size": 353, "loss": 0.0022134017606731506}, {"layer_params": [47, 60, 43, 53, 53], "learning_rate": 0.007484148403609082, "batch_size": 340, "loss": 0.00095307863492053}, {"layer_params": [19, 42, 31, 34], "learning_rate": 0.00797242239165998, "batch_size": 321, "loss": 0.003180885559413582}, {"layer_params": [51, 19, 18, 59, 55], "learning_rate": 0.007612623283628592, "batch_size": 119, "loss": 0.0038330868585035203}, {"layer_params": [30, 29, 49], "learning_rate": 0.0014567167200690923, "batch_size": 466, "loss": 0.0032661483623087407}, {"layer_params": [57, 34, 63, 34], "learning_rate": 0.005416679303236866, "batch_size": 471, "loss": 0.0008393755368888378}, {"layer_params": [34, 48], "learning_rate": 0.0077158174705201565, "batch_size": 282, "loss": 0.002458738702116534}, {"layer_params": [52, 38, 56], "learning_rate": 0.005816726963534699, "batch_size": 127, "loss": 0.00233580983011052}, {"layer_params": [60, 60], "learning_rate": 0.0010729814431895699, "batch_size": 490, "loss": 0.002667522309347987}, {"layer_params": [41, 54, 26, 55, 24], "learning_rate": 0.008549227278027384, "batch_size": 194, "loss": 0.0014791774924378842}, {"layer_params": [60, 57], "learning_rate": 0.0037019677275585377, "batch_size": 381, "loss": 0.0014802486798726022}, {"layer_params": [28, 25, 50], "learning_rate": 0.007039179049939864, "batch_size": 94, "loss": 0.0048208569409325715}, {"layer_params": [47, 19], "learning_rate": 0.009960322653153405, "batch_size": 82, "loss": 0.002806674066232517}, {"layer_params": [33, 36, 16, 20], "learning_rate": 0.0028863138844630897, "batch_size": 444, "loss": 0.002615819850470871}, {"layer_params": [31, 30, 30], "learning_rate": 0.007691787520534811, "batch_size": 351, "loss": 0.002490318858763203}, {"layer_params": [50, 47, 31, 17, 55], "learning_rate": 0.007576261585492807, "batch_size": 341, "loss": 0.0014569080073852092}, {"layer_params": [25, 42, 51, 53, 36], "learning_rate": 0.0023266661394104773, "batch_size": 155, "loss": 0.0028780110843945293}, {"layer_params": [39, 59, 45, 21, 36], "learning_rate": 0.0019517364491319338, "batch_size": 244, "loss": 0.0021024251298513265}, {"layer_params": [30, 52, 26], "learning_rate": 0.0025271091017504584, "batch_size": 23, "loss": 0.006949192548636347}, {"layer_params": [16, 47, 34], "learning_rate": 0.006661598257265713, "batch_size": 123, "loss": 0.004890464069321751}, {"layer_params": [44, 33, 52], "learning_rate": 0.00480346803532914, "batch_size": 62, "loss": 0.0034370758198201657}, {"layer_params": [50, 18, 33, 34, 45], "learning_rate": 0.0006435757663005293, "batch_size": 131, "loss": 0.006568987667560577}, {"layer_params": [22, 53], "learning_rate": 0.009915513429813574, "batch_size": 371, "loss": 0.002472211258718744}, {"layer_params": [42, 41, 60, 47], "learning_rate": 0.0033787608336491304, "batch_size": 47, "loss": 0.005082312123849988}, {"layer_params": [60, 21, 61, 53, 30], "learning_rate": 0.006884709750761008, "batch_size": 242, "loss": 0.0021281763433944434}, {"layer_params": [60, 26], "learning_rate": 0.005426196001371327, "batch_size": 188, "loss": 0.00256504220655188}, {"layer_params": [21, 16, 35, 16, 44], "learning_rate": 0.004632058408137453, "batch_size": 283, "loss": 0.004766678106971085}, {"layer_params": [26, 64, 28], "learning_rate": 0.007316479404348183, "batch_size": 99, "loss": 0.0034938623220659793}, {"layer_params": [53, 60, 45, 53, 39], "learning_rate": 0.008316187254969657, "batch_size": 416, "loss": 0.0014841357036493718}, {"layer_params": [60, 21], "learning_rate": 0.005807722398689386, "batch_size": 141, "loss": 0.0021972483932040632}, {"layer_params": [61, 34, 30, 25, 48], "learning_rate": 0.00985218239916749, "batch_size": 32, "loss": 0.005215285837184638}, {"layer_params": [43, 54], "learning_rate": 0.0024443599049041543, "batch_size": 437, "loss": 0.0016675943473819642}, {"layer_params": [33, 38, 19, 58, 18], "learning_rate": 0.0013114341748580354, "batch_size": 307, "loss": 0.0025303246872499584}, {"layer_params": [44, 38, 49, 30], "learning_rate": 0.005481402867040447, "batch_size": 48, "loss": 0.005933368511032313}, {"layer_params": [53, 30, 42, 20, 18], "learning_rate": 0.007255274987720101, "batch_size": 420, "loss": 0.002402922547189519}, {"layer_params": [54, 24], "learning_rate": 0.00604706627242895, "batch_size": 209, "loss": 0.0021679384680464864}, {"layer_params": [57, 22, 58, 59, 55], "learning_rate": 0.0008726173062507769, "batch_size": 44, "loss": 0.0063928610784932975}, {"layer_params": [22, 43, 55, 31, 33], "learning_rate": 0.0009575496003400476, "batch_size": 393, "loss": 0.0022236303542740644}, {"layer_params": [34, 46, 18, 39], "learning_rate": 0.002252349486400453, "batch_size": 303, "loss": 0.003338973727077246}, {"layer_params": [57, 35, 48], "learning_rate": 0.007849396514035437, "batch_size": 379, "loss": 0.0010525710962247102}, {"layer_params": [56, 30, 41, 41, 48], "learning_rate": 0.00560256576145197, "batch_size": 446, "loss": 0.0016860438708681614}, {"layer_params": [58, 45, 40, 46], "learning_rate": 0.009997583385090865, "batch_size": 97, "loss": 0.002070940331323072}, {"layer_params": [36, 50, 51, 28, 59], "learning_rate": 0.0028209364165191065, "batch_size": 360, "loss": 0.001169078480452299}, {"layer_params": [49, 47, 45], "learning_rate": 0.004720340769543713, "batch_size": 24, "loss": 0.004723862591199577}, {"layer_params": [31, 23, 63, 31, 58], "learning_rate": 0.007038746003869692, "batch_size": 453, "loss": 0.0010620909987483175}, {"layer_params": [60, 44, 54, 58], "learning_rate": 0.0010743629199634292, "batch_size": 76, "loss": 0.003924745635595172}, {"layer_params": [62, 63, 19, 48, 51], "learning_rate": 0.0009732101043482424, "batch_size": 258, "loss": 0.0023250977462157606}, {"layer_params": [47, 30], "learning_rate": 0.0013553654947748874, "batch_size": 122, "loss": 0.005748707670718432}, {"layer_params": [28, 52], "learning_rate": 0.0027157430398488257, "batch_size": 168, "loss": 0.004087967230007052}, {"layer_params": [63, 39, 25, 38, 16], "learning_rate": 0.0032480831956365887, "batch_size": 135, "loss": 0.0016537572629749776}, {"layer_params": [56, 47, 31, 31, 22], "learning_rate": 0.005104694670282915, "batch_size": 180, "loss": 0.0013161900028353557}, {"layer_params": [50, 31, 35, 24, 64], "learning_rate": 0.008641284203877025, "batch_size": 152, "loss": 0.0027601562009658665}, {"layer_params": [29, 34], "learning_rate": 0.007673954864432084, "batch_size": 401, "loss": 0.00198100964887999}, {"layer_params": [42, 39], "learning_rate": 0.004118167607367451, "batch_size": 162, "loss": 0.002135028666816652}, {"layer_params": [38, 36, 58, 33, 46], "learning_rate": 0.00610755754738099, "batch_size": 346, "loss": 0.001210978311719373}, {"layer_params": [56, 60, 20, 39, 23], "learning_rate": 0.0012836110733618592, "batch_size": 460, "loss": 0.001836008575046435}, {"layer_params": [39, 31], "learning_rate": 0.0037606291512571987, "batch_size": 256, "loss": 0.0016990177682600915}, {"layer_params": [41, 59, 29, 37, 19], "learning_rate": 0.006734391544411574, "batch_size": 392, "loss": 0.001081249804701656}, {"layer_params": [42, 33, 25, 41], "learning_rate": 0.003377732732866021, "batch_size": 309, "loss": 0.0018427873135078699}, {"layer_params": [49, 23, 32, 42], "learning_rate": 0.0008760125074571454, "batch_size": 472, "loss": 0.0025648642820306124}, {"layer_params": [60, 34], "learning_rate": 0.00033913992870313964, "batch_size": 413, "loss": 0.006607773452997207}, {"layer_params": [40, 41, 33, 17, 18], "learning_rate": 0.001409707557296731, "batch_size": 264, "loss": 0.0023742151097394526}, {"layer_params": [49, 22, 54, 20, 37], "learning_rate": 0.008162910858019613, "batch_size": 59, "loss": 0.005785110490396619}, {"layer_params": [25, 20, 20], "learning_rate": 0.009426123505487716, "batch_size": 314, "loss": 0.0027901944820769133}, {"layer_params": [46, 28, 42], "learning_rate": 0.009738891664644356, "batch_size": 320, "loss": 0.002415370251983404}, {"layer_params": [48, 55, 32], "learning_rate": 0.006455009271656355, "batch_size": 72, "loss": 0.002728783405618742}, {"layer_params": [48, 38], "learning_rate": 0.0029949406589267935, "batch_size": 124, "loss": 0.0038337636133655905}, {"layer_params": [29, 43, 51, 32, 61], "learning_rate": 0.005698715585733627, "batch_size": 34, "loss": 0.007870719591155649}, {"layer_params": [26, 60], "learning_rate": 0.001650170646823901, "batch_size": 81, "loss": 0.004948219961952418}, {"layer_params": [43, 21, 23, 36, 32], "learning_rate": 0.007964574444531894, "batch_size": 453, "loss": 0.00230524969403632}, {"layer_params": [29, 36, 36, 37], "learning_rate": 0.006292622636624889, "batch_size": 435, "loss": 0.0022205966361798345}, {"layer_params": [39, 58, 53, 19], "learning_rate": 0.004656145486322255, "batch_size": 410, "loss": 0.0023437600233592094}, {"layer_params": [63, 56, 22, 56], "learning_rate": 0.0008291543809465228, "batch_size": 316, "loss": 0.0024078892660327257}, {"layer_params": [22, 56, 45, 54, 29], "learning_rate": 0.0012079027461233975, "batch_size": 381, "loss": 0.0017939592024777086}, {"layer_params": [60, 64, 28], "learning_rate": 0.007901128150961095, "batch_size": 238, "loss": 0.0009752539999317378}, {"layer_params": [46, 49], "learning_rate": 0.003391534643217583, "batch_size": 297, "loss": 0.0017732451646588743}, {"layer_params": [44, 35, 50, 44, 45], "learning_rate": 0.008873661627901834, "batch_size": 418, "loss": 0.0014743292797356844}, {"layer_params": [29, 51, 62, 29, 53], "learning_rate": 0.004393896599764642, "batch_size": 379, "loss": 0.0011689073627348988}, {"layer_params": [58, 59, 64, 37, 26], "learning_rate": 0.005230468445685773, "batch_size": 106, "loss": 0.0015367762884125114}, {"layer_params": [60, 40], "learning_rate": 0.004712458120249093, "batch_size": 208, "loss": 0.0023102594283409415}, {"layer_params": [41, 55, 57, 28, 44], "learning_rate": 0.005017901805886518, "batch_size": 452, "loss": 0.0009070355724543333}, {"layer_params": [30, 19, 50, 24, 48], "learning_rate": 0.0016310642654146414, "batch_size": 147, "loss": 0.005047273354139179}, {"layer_params": [29, 53, 60], "learning_rate": 0.0012197747859185525, "batch_size": 185, "loss": 0.0033303613401949404}, {"layer_params": [56, 31, 26, 48, 34], "learning_rate": 0.005055169225736876, "batch_size": 329, "loss": 0.0020341227017343045}, {"layer_params": [24, 37, 40, 47, 25], "learning_rate": 0.0064742167491436305, "batch_size": 474, "loss": 0.0020040084596257657}, {"layer_params": [40, 32], "learning_rate": 0.005826446528478406, "batch_size": 247, "loss": 0.0024809134914539756}, {"layer_params": [63, 56, 53, 47], "learning_rate": 0.008520150888047697, "batch_size": 40, "loss": 0.003689495995640755}, {"layer_params": [54, 49, 56, 31, 17], "learning_rate": 0.0031393265215045874, "batch_size": 299, "loss": 0.0025492055201902985}, {"layer_params": [59, 59, 39, 29], "learning_rate": 0.008028158887663351, "batch_size": 207, "loss": 0.0013450189295690508}, {"layer_params": [44, 61, 31, 47, 32], "learning_rate": 0.0020402969289555714, "batch_size": 337, "loss": 0.001455407802714035}, {"layer_params": [54, 48, 29, 39], "learning_rate": 0.005507298925641975, "batch_size": 372, "loss": 0.0014813154621515423}, {"layer_params": [23, 34, 35], "learning_rate": 0.0038923683494683876, "batch_size": 216, "loss": 0.0033767259470187127}, {"layer_params": [64, 23], "learning_rate": 0.009079187941055642, "batch_size": 379, "loss": 0.0017102075775619597}, {"layer_params": [56, 29, 23, 20, 28], "learning_rate": 0.001215086923692739, "batch_size": 364, "loss": 0.004445845824666322}, {"layer_params": [41, 60, 51], "learning_rate": 0.009256910669892036, "batch_size": 418, "loss": 0.001481581152183935}, {"layer_params": [49, 63, 44, 35], "learning_rate": 0.0015418118640144628, "batch_size": 194, "loss": 0.0017874629981815815}, {"layer_params": [40, 29], "learning_rate": 0.0002844162933851438, "batch_size": 505, "loss": 0.008259639283642173}, {"layer_params": [50, 45, 16, 53], "learning_rate": 0.004690360330171315, "batch_size": 209, "loss": 0.0027197272691410037}, {"layer_params": [63, 56, 49], "learning_rate": 0.0021407806116893083, "batch_size": 391, "loss": 0.0011462399578886107}, {"layer_params": [50, 53, 43, 26], "learning_rate": 0.0055180741061447575, "batch_size": 301, "loss": 0.0009869192057522015}, {"layer_params": [39, 41, 17, 36, 46], "learning_rate": 0.0024912432053162637, "batch_size": 109, "loss": 0.0023942724172957243}, {"layer_params": [31, 61, 18], "learning_rate": 0.0025302053645586795, "batch_size": 340, "loss": 0.002465440679807216}, {"layer_params": [29, 27], "learning_rate": 0.0019451908584351592, "batch_size": 504, "loss": 0.004263757655862719}, {"layer_params": [60, 30], "learning_rate": 0.0034382368638927346, "batch_size": 249, "loss": 0.0037445833650417626}, {"layer_params": [61, 45, 58, 64], "learning_rate": 0.006116487601253916, "batch_size": 87, "loss": 0.0017412849457468836}, {"layer_params": [63, 40, 51, 61, 17], "learning_rate": 0.0010051784021581137, "batch_size": 63, "loss": 0.0051593407872132955}, {"layer_params": [18, 27, 24, 48], "learning_rate": 0.004007573960973907, "batch_size": 502, "loss": 0.0032079949672333898}, {"layer_params": [36, 36, 27, 42], "learning_rate": 0.002482896347832228, "batch_size": 192, "loss": 0.002048406567191705}, {"layer_params": [22, 41], "learning_rate": 0.007044614275733639, "batch_size": 407, "loss": 0.0031123169464990497}, {"layer_params": [51, 41, 35, 40], "learning_rate": 0.004475781121125279, "batch_size": 292, "loss": 0.0019585049885790795}, {"layer_params": [31, 56], "learning_rate": 0.004531616515734538, "batch_size": 240, "loss": 0.002056943231727928}, {"layer_params": [54, 17, 47], "learning_rate": 0.004605948944790901, "batch_size": 175, "loss": 0.001700802679406479}, {"layer_params": [22, 32, 58, 39], "learning_rate": 0.00553705461681124, "batch_size": 486, "loss": 0.0015367940277792513}, {"layer_params": [30, 61, 45, 34], "learning_rate": 0.0029111547946285557, "batch_size": 294, "loss": 0.0016642969462554902}, {"layer_params": [20, 38, 40, 51, 64], "learning_rate": 0.007181980381093132, "batch_size": 448, "loss": 0.001331132875639014}, {"layer_params": [43, 26, 18, 44], "learning_rate": 0.000556800799266203, "batch_size": 318, "loss": 0.00572810375597328}, {"layer_params": [29, 52, 39, 36], "learning_rate": 0.006789636064627245, "batch_size": 234, "loss": 0.0018220135965384542}, {"layer_params": [21, 61, 23, 36, 19], "learning_rate": 0.009278602810607647, "batch_size": 231, "loss": 0.002957106940448284}, {"layer_params": [48, 23], "learning_rate": 0.001713866145966324, "batch_size": 201, "loss": 0.004345408447552473}, {"layer_params": [21, 44], "learning_rate": 0.009277766974067831, "batch_size": 128, "loss": 0.0033893928956240417}, {"layer_params": [18, 48, 50], "learning_rate": 0.000498997605440235, "batch_size": 330, "loss": 0.006469911704771221}, {"layer_params": [32, 61, 25], "learning_rate": 1.4742847225228116e-05, "batch_size": 270, "loss": 0.07022884022444487}, {"layer_params": [42, 32, 35, 55, 53], "learning_rate": 0.004343573042755809, "batch_size": 293, "loss": 0.001704920899355784}, {"layer_params": [63, 31, 27], "learning_rate": 0.006180910585240258, "batch_size": 60, "loss": 0.0037668632518034427}, {"layer_params": [35, 27, 61], "learning_rate": 0.001193447796104812, "batch_size": 88, "loss": 0.00531587129458785}, {"layer_params": [17, 52, 29], "learning_rate": 0.0006769726553984011, "batch_size": 471, "loss": 0.006983566600829363}, {"layer_params": [40, 39, 16, 59, 63], "learning_rate": 0.007131407375008479, "batch_size": 119, "loss": 0.0019778444070834666}, {"layer_params": [36, 33, 40, 28, 64], "learning_rate": 0.00691827812057153, "batch_size": 412, "loss": 0.00200616579502821}, {"layer_params": [27, 56, 34, 35], "learning_rate": 0.006794367328970107, "batch_size": 374, "loss": 0.0019363379443529992}, {"layer_params": [63, 26, 62], "learning_rate": 0.0054314815002192264, "batch_size": 217, "loss": 0.0009696889499900863}, {"layer_params": [19, 34, 18, 43], "learning_rate": 0.0009508220239971667, "batch_size": 200, "loss": 0.0052107214950956405}, {"layer_params": [64, 41, 29, 47], "learning_rate": 0.0014326252046216934, "batch_size": 367, "loss": 0.0021880194859113544}, {"layer_params": [27, 49, 58, 61, 19], "learning_rate": 0.0015687592513633658, "batch_size": 447, "loss": 0.002061686988454312}, {"layer_params": [43, 58], "learning_rate": 0.009271207221204277, "batch_size": 56, "loss": 0.003912739544175565}, {"layer_params": [56, 19], "learning_rate": 0.007309436296728825, "batch_size": 361, "loss": 0.0025352382380515338}, {"layer_params": [55, 17, 56, 36, 49], "learning_rate": 0.009454444133205224, "batch_size": 372, "loss": 0.003345631998963654}, {"layer_params": [22, 52], "learning_rate": 0.0020185598444137725, "batch_size": 483, "loss": 0.0038477418292313815}, {"layer_params": [31, 20], "learning_rate": 0.0036247292241651705, "batch_size": 127, "loss": 0.0042224665335379545}, {"layer_params": [55, 36], "learning_rate": 0.007729245275983705, "batch_size": 137, "loss": 0.0017051462433300912}, {"layer_params": [39, 49, 21, 31, 62], "learning_rate": 0.00994089503522714, "batch_size": 161, "loss": 0.0016828952915966511}, {"layer_params": [34, 62, 32, 18, 61], "learning_rate": 0.009677704823551434, "batch_size": 352, "loss": 0.0016933394875377416}, {"layer_params": [34, 33, 40, 35, 28], "learning_rate": 6.938045363568032e-05, "batch_size": 329, "loss": 0.033815669883042576}, {"layer_params": [21, 45, 35, 17], "learning_rate": 0.008312701896182656, "batch_size": 374, "loss": 0.00239343827823177}, {"layer_params": [49, 59, 20, 38, 22], "learning_rate": 0.005627907984369571, "batch_size": 510, "loss": 0.0006302894972031936}, {"layer_params": [40, 55, 22, 45, 64], "learning_rate": 0.002412049140917342, "batch_size": 282, "loss": 0.0017140445113182068}, {"layer_params": [57, 60, 21, 48, 39], "learning_rate": 0.009301509072168892, "batch_size": 396, "loss": 0.0010519007925176994}, {"layer_params": [54, 18, 50, 35], "learning_rate": 0.0026599694116888665, "batch_size": 326, "loss": 0.0023425046843476593}, {"layer_params": [46, 48, 32], "learning_rate": 0.002585463585206391, "batch_size": 32, "loss": 0.005317003673408181}, {"layer_params": [28, 53, 55], "learning_rate": 0.0020218655415100285, "batch_size": 338, "loss": 0.0024409996659960596}, {"layer_params": [19, 24], "learning_rate": 0.00657932792438499, "batch_size": 251, "loss": 0.005322932587005198}, {"layer_params": [44, 63], "learning_rate": 0.002685364914946779, "batch_size": 488, "loss": 0.0023109064029995354}, {"layer_params": [21, 36, 55, 64], "learning_rate": 0.0030855514903874023, "batch_size": 253, "loss": 0.0035868990956805648}, {"layer_params": [54, 31, 45], "learning_rate": 0.0005357941469023545, "batch_size": 30, "loss": 0.007534224570263177}, {"layer_params": [35, 61, 64, 47], "learning_rate": 0.0020638106711921246, "batch_size": 197, "loss": 0.0013185536762466655}, {"layer_params": [34, 31], "learning_rate": 0.0010051786548888593, "batch_size": 233, "loss": 0.006355976643972099}, {"layer_params": [20, 26, 51], "learning_rate": 0.009075745719299089, "batch_size": 351, "loss": 0.0037666673003695903}, {"layer_params": [50, 63, 24, 40], "learning_rate": 0.00946844016644245, "batch_size": 307, "loss": 0.0014734152075834572}, {"layer_params": [42, 16, 60, 43, 63], "learning_rate": 0.0002027529569063094, "batch_size": 165, "loss": 0.009201227095909417}, {"layer_params": [42, 55], "learning_rate": 0.005472200237988219, "batch_size": 438, "loss": 0.0016174143366515636}, {"layer_params": [52, 51, 61, 33, 28], "learning_rate": 0.006770732162360713, "batch_size": 116, "loss": 0.0017620784312020988}, {"layer_params": [39, 64], "learning_rate": 0.0016934326524657194, "batch_size": 128, "loss": 0.002748859866987914}, {"layer_params": [30, 33, 44, 63, 22], "learning_rate": 0.009881750719774351, "batch_size": 483, "loss": 0.0020481147663667797}, {"layer_params": [39, 24, 53, 22, 38], "learning_rate": 0.008323925528412228, "batch_size": 132, "loss": 0.0028687950083985925}, {"layer_params": [30, 34, 50, 62, 56], "learning_rate": 0.005910387802491973, "batch_size": 180, "loss": 0.0016829336271621286}, {"layer_params": [52, 51], "learning_rate": 0.004651009576153936, "batch_size": 511, "loss": 0.0011811700864927843}, {"layer_params": [58, 19, 49, 35, 43], "learning_rate": 0.0037700211320873516, "batch_size": 478, "loss": 0.0014781563391443341}, {"layer_params": [62, 16, 46, 24], "learning_rate": 0.003489650711840715, "batch_size": 371, "loss": 0.0019897097744978965}, {"layer_params": [23, 45, 17, 56], "learning_rate": 0.005834272038198983, "batch_size": 398, "loss": 0.002063360373722389}, {"layer_params": [16, 28], "learning_rate": 0.0014318747866616975, "batch_size": 499, "loss": 0.006775240739807486}, {"layer_params": [34, 33, 54], "learning_rate": 0.006658253567273348, "batch_size": 388, "loss": 0.0009859888325445354}, {"layer_params": [34, 57, 37, 63, 36], "learning_rate": 0.004074322899571974, "batch_size": 391, "loss": 0.0015747269080020488}, {"layer_params": [41, 19], "learning_rate": 0.0058639265384986825, "batch_size": 58, "loss": 0.0050852093007415534}, {"layer_params": [37, 31, 17, 33, 47], "learning_rate": 0.005449798515166647, "batch_size": 450, "loss": 0.0020450286811683326}, {"layer_params": [49, 35], "learning_rate": 0.008592783554681894, "batch_size": 144, "loss": 0.002790723666548729}, {"layer_params": [36, 31], "learning_rate": 0.004035753084120673, "batch_size": 83, "loss": 0.004762607119046152}, {"layer_params": [48, 42, 62], "learning_rate": 0.009540292490826734, "batch_size": 342, "loss": 0.0013930331874871626}, {"layer_params": [54, 22, 34, 35, 32], "learning_rate": 0.008056844127052945, "batch_size": 392, "loss": 0.0020769418717827646}, {"layer_params": [63, 23, 59], "learning_rate": 0.0043928496925655985, "batch_size": 109, "loss": 0.0023441644688136877}, {"layer_params": [38, 21, 16], "learning_rate": 0.004746255496147531, "batch_size": 126, "loss": 0.004762798806186765}, {"layer_params": [61, 32, 40], "learning_rate": 0.007571727031453416, "batch_size": 362, "loss": 0.0017358691163826734}, {"layer_params": [28, 46, 40], "learning_rate": 0.0039053108207460995, "batch_size": 234, "loss": 0.001264738656464033}, {"layer_params": [59, 19], "learning_rate": 0.0010902316412451844, "batch_size": 108, "loss": 0.005926588694564998}, {"layer_params": [19, 49, 48, 18, 56], "learning_rate": 0.0015879425367121293, "batch_size": 347, "loss": 0.0026664747879840433}, {"layer_params": [35, 60, 21, 24, 41], "learning_rate": 0.008745987345936658, "batch_size": 464, "loss": 0.0011194828944280743}, {"layer_params": [30, 21], "learning_rate": 0.0004397678158499435, "batch_size": 308, "loss": 0.008437474234960973}, {"layer_params": [34, 48, 60, 22, 30], "learning_rate": 0.004895450361842243, "batch_size": 371, "loss": 0.001958402582677081}, {"layer_params": [51, 58], "learning_rate": 0.0031315743710738607, "batch_size": 258, "loss": 0.0015681833343114703}, {"layer_params": [26, 38, 54, 48, 20], "learning_rate": 0.00900643125068337, "batch_size": 258, "loss": 0.002488282109843567}, {"layer_params": [35, 37, 19], "learning_rate": 0.004483236941182955, "batch_size": 93, "loss": 0.003323741697240621}, {"layer_params": [43, 35, 29, 64, 49], "learning_rate": 0.006274254305084812, "batch_size": 327, "loss": 0.0012228957581100985}, {"layer_params": [30, 47, 39, 48], "learning_rate": 0.005605177652098524, "batch_size": 216, "loss": 0.002077072524698451}, {"layer_params": [45, 57, 56], "learning_rate": 0.004611447983721859, "batch_size": 98, "loss": 0.0022404401004314425}, {"layer_params": [49, 47, 63], "learning_rate": 0.0022068548008173454, "batch_size": 490, "loss": 0.0014037241612095386}, {"layer_params": [25, 21, 27, 36, 35], "learning_rate": 0.007685754727696471, "batch_size": 19, "loss": 0.008233352950774132}, {"layer_params": [18, 62, 59], "learning_rate": 0.0013403296879170514, "batch_size": 320, "loss": 0.0031424298021011056}, {"layer_params": [20, 53, 56], "learning_rate": 0.0015499620957656135, "batch_size": 68, "loss": 0.006254662410356104}, {"layer_params": [18, 47, 24, 39, 21], "learning_rate": 0.007836931888424421, "batch_size": 466, "loss": 0.0022990680707152935}, {"layer_params": [63, 39, 56, 55], "learning_rate": 0.009755088379504723, "batch_size": 272, "loss": 0.0010381234512897208}, {"layer_params": [36, 64, 62, 55], "learning_rate": 0.0020557383157343723, "batch_size": 225, "loss": 0.0018784453172702342}, {"layer_params": [63, 41, 63], "learning_rate": 0.002315541561660443, "batch_size": 65, "loss": 0.0030337286123540254}, {"layer_params": [33, 25, 18], "learning_rate": 0.003266231019283782, "batch_size": 433, "loss": 0.0017555313103366644}, {"layer_params": [28, 54, 53, 40, 42], "learning_rate": 0.001996976706287034, "batch_size": 364, "loss": 0.0018727363285142929}, {"layer_params": [50, 60, 56, 62], "learning_rate": 0.006490730538471751, "batch_size": 313, "loss": 0.0008983418758725748}, {"layer_params": [21, 17], "learning_rate": 0.002422618858351524, "batch_size": 263, "loss": 0.006375327138230204}, {"layer_params": [23, 21, 34, 28], "learning_rate": 0.006750962300312612, "batch_size": 223, "loss": 0.002721177083440125}, {"layer_params": [47, 56], "learning_rate": 0.0008688799319093593, "batch_size": 31, "loss": 0.007689424399286509}, {"layer_params": [22, 29, 48], "learning_rate": 0.00354623388141609, "batch_size": 40, "loss": 0.004282392151653766}, {"layer_params": [56, 23], "learning_rate": 0.008534113544041322, "batch_size": 481, "loss": 0.0018747236614581198}, {"layer_params": [40, 42, 41], "learning_rate": 0.009082246892363642, "batch_size": 279, "loss": 0.0024535042990464716}, {"layer_params": [64, 32, 28, 26], "learning_rate": 0.006727425773929986, "batch_size": 356, "loss": 0.0023056392336729915}, {"layer_params": [43, 24, 31], "learning_rate": 0.0008415987745207296, "batch_size": 225, "loss": 0.0065469138789922}, {"layer_params": [46, 19, 32], "learning_rate": 0.008553639820058084, "batch_size": 448, "loss": 0.001988328086445108}, {"layer_params": [21, 28, 41, 24, 62], "learning_rate": 0.007812645183732057, "batch_size": 100, "loss": 0.004053949159570038}, {"layer_params": [46, 39, 52], "learning_rate": 0.008976102018609159, "batch_size": 419, "loss": 0.0009573895600624383}, {"layer_params": [40, 23, 26, 39, 61], "learning_rate": 0.0024876146656586857, "batch_size": 431, "loss": 0.0020678064250387253}, {"layer_params": [48, 28, 17, 52, 51], "learning_rate": 0.005463375638267984, "batch_size": 458, "loss": 0.00113948886631988}, {"layer_params": [62, 58, 54, 32], "learning_rate": 0.008297572400378563, "batch_size": 446, "loss": 0.0006160083273425699}, {"layer_params": [53, 25, 55, 55, 48], "learning_rate": 0.0032029296916222627, "batch_size": 256, "loss": 0.0017174285475630314}, {"layer_params": [64, 55, 59, 27], "learning_rate": 0.00517235868416797, "batch_size": 339, "loss": 0.0008325774397235364}, {"layer_params": [36, 35, 59, 22, 17], "learning_rate": 0.0005284361140760043, "batch_size": 123, "loss": 0.00796159602701664}, {"layer_params": [54, 41, 41], "learning_rate": 0.006631558577269429, "batch_size": 193, "loss": 0.0021944573312066497}, {"layer_params": [50, 53, 33], "learning_rate": 0.0012736262006440146, "batch_size": 150, "loss": 0.0030831735697574914}, {"layer_params": [64, 23, 38], "learning_rate": 0.0003559967487032655, "batch_size": 462, "loss": 0.0056712775398045775}, {"layer_params": [42, 25, 45, 62], "learning_rate": 0.005155491097653278, "batch_size": 31, "loss": 0.005400869916193187}, {"layer_params": [61, 35, 31], "learning_rate": 0.007849329973829795, "batch_size": 206, "loss": 0.0009221462183631957}, {"layer_params": [24, 29], "learning_rate": 0.0009195698155481189, "batch_size": 202, "loss": 0.006066131847910583}, {"layer_params": [47, 37], "learning_rate": 0.007447566300714915, "batch_size": 287, "loss": 0.0015397408790886402}, {"layer_params": [35, 62, 41, 28, 18], "learning_rate": 0.002183819049827307, "batch_size": 336, "loss": 0.0020400282728951424}, {"layer_params": [43, 58, 16], "learning_rate": 0.005254301919621933, "batch_size": 323, "loss": 0.0017941413598600775}, {"layer_params": [19, 30, 64, 16], "learning_rate": 0.0035909675598581603, "batch_size": 53, "loss": 0.005249285302124917}, {"layer_params": [27, 61, 48, 37], "learning_rate": 0.0054196774140945975, "batch_size": 325, "loss": 0.0013338549865875393}, {"layer_params": [39, 24], "learning_rate": 0.001238450799979029, "batch_size": 283, "loss": 0.00491779500618577}, {"layer_params": [52, 47, 25, 33, 50], "learning_rate": 0.0014359481442095911, "batch_size": 483, "loss": 0.0017808370525017382}, {"layer_params": [18, 25, 57], "learning_rate": 0.009731837709336484, "batch_size": 306, "loss": 0.0031933356286026537}, {"layer_params": [32, 39, 22, 25, 38], "learning_rate": 0.007346260626294204, "batch_size": 161, "loss": 0.0022846038197167217}, {"layer_params": [59, 63, 55, 60, 36], "learning_rate": 0.006583574982682208, "batch_size": 202, "loss": 0.0014812296745367348}, {"layer_params": [29, 52, 52], "learning_rate": 0.004680818160225771, "batch_size": 233, "loss": 0.0024929119774606077}, {"layer_params": [20, 64, 25, 23], "learning_rate": 0.003777067202558812, "batch_size": 80, "loss": 0.003560371610801667}, {"layer_params": [16, 52, 48, 62], "learning_rate": 0.006665594505853188, "batch_size": 207, "loss": 0.0024424323823768646}, {"layer_params": [55, 61, 59, 40], "learning_rate": 0.0023480350814255517, "batch_size": 288, "loss": 0.002158977586077526}, {"layer_params": [48, 32, 34], "learning_rate": 0.00034454060961380107, "batch_size": 110, "loss": 0.007362521030008793}, {"layer_params": [45, 53, 57, 25], "learning_rate": 0.0033672024412345226, "batch_size": 174, "loss": 0.0018554478243459015}, {"layer_params": [55, 22, 18, 52], "learning_rate": 0.00409970474253608, "batch_size": 320, "loss": 0.002193328645080328}, {"layer_params": [57, 61, 38, 38, 63], "learning_rate": 0.009536477483263793, "batch_size": 207, "loss": 0.0011393585166661069}, {"layer_params": [38, 45, 21, 48], "learning_rate": 0.007734971265336749, "batch_size": 308, "loss": 0.0012650459492579104}, {"layer_params": [51, 40, 39, 39], "learning_rate": 0.005440349437798054, "batch_size": 155, "loss": 0.0018862997903488577}, {"layer_params": [50, 51, 34, 19, 35], "learning_rate": 0.009785300160898762, "batch_size": 108, "loss": 0.0024574485851917415}, {"layer_params": [38, 22], "learning_rate": 0.004790283745329153, "batch_size": 74, "loss": 0.005134168430231512}, {"layer_params": [35, 27, 52], "learning_rate": 0.009361741706340614, "batch_size": 455, "loss": 0.0011291537916986272}, {"layer_params": [63, 54, 21, 61, 59], "learning_rate": 0.009955623674357999, "batch_size": 321, "loss": 0.0015902130876202136}, {"layer_params": [27, 19, 35], "learning_rate": 0.0034515374133468296, "batch_size": 359, "loss": 0.002515237641055137}, {"layer_params": [31, 38, 50], "learning_rate": 0.004618535728544835, "batch_size": 43, "loss": 0.0045571481110528115}, {"layer_params": [20, 54, 31, 57], "learning_rate": 0.0003436270576618547, "batch_size": 196, "loss": 0.007732954113744199}, {"layer_params": [18, 51], "learning_rate": 0.006615464563238217, "batch_size": 481, "loss": 0.0016843786253593863}, {"layer_params": [38, 37, 16], "learning_rate": 0.002627298221790826, "batch_size": 249, "loss": 0.002767767815385014}, {"layer_params": [61, 44, 22, 20], "learning_rate": 0.003332603149814193, "batch_size": 488, "loss": 0.0014915249741170556}, {"layer_params": [17, 55, 19], "learning_rate": 0.0011345443162993744, "batch_size": 305, "loss": 0.003947273546364158}, {"layer_params": [46, 46, 44, 57, 48], "learning_rate": 0.0053828997497875, "batch_size": 231, "loss": 0.0017914095357991755}, {"layer_params": [30, 57], "learning_rate": 0.005954120955644352, "batch_size": 208, "loss": 0.0028835053206421437}, {"layer_params": [16, 52, 25, 59], "learning_rate": 0.007898263125305428, "batch_size": 454, "loss": 0.001936886153416708}, {"layer_params": [19, 64, 48, 47], "learning_rate": 0.00568934579061487, "batch_size": 150, "loss": 0.0019634522579144685}, {"layer_params": [35, 41], "learning_rate": 0.003319981484309445, "batch_size": 291, "loss": 0.0028465922712348404}, {"layer_params": [19, 56, 25, 25, 60], "learning_rate": 0.003827749717536269, "batch_size": 144, "loss": 0.0026732554822228847}, {"layer_params": [38, 42, 44], "learning_rate": 0.007885821787162075, "batch_size": 49, "loss": 0.004087843280285597}, {"layer_params": [33, 40, 28, 60, 25], "learning_rate": 0.00865540709554811, "batch_size": 407, "loss": 0.0018042147997766732}, {"layer_params": [58, 43, 26, 37], "learning_rate": 0.008203965266884543, "batch_size": 81, "loss": 0.002369010424008593}, {"layer_params": [21, 36, 39], "learning_rate": 0.0008881998904673517, "batch_size": 110, "loss": 0.006254719751887024}, {"layer_params": [48, 20, 33, 36], "learning_rate": 0.005743092791548696, "batch_size": 149, "loss": 0.0022502649086527525}, {"layer_params": [60, 42], "learning_rate": 0.009237988175102494, "batch_size": 355, "loss": 0.001400319632375613}, {"layer_params": [47, 55], "learning_rate": 0.008010545078286791, "batch_size": 260, "loss": 0.0020817787281703203}, {"layer_params": [22, 43, 38, 31, 58], "learning_rate": 0.005883833290948178, "batch_size": 280, "loss": 0.003084525887388736}, {"layer_params": [47, 34, 63, 51], "learning_rate": 0.0065097869742198455, "batch_size": 414, "loss": 0.0009614333941135555}, {"layer_params": [28, 30, 28, 47, 54], "learning_rate": 0.004343284839280083, "batch_size": 196, "loss": 0.0025454593414906412}, {"layer_params": [57, 63], "learning_rate": 0.008792578305566848, "batch_size": 370, "loss": 0.002029951689764857}, {"layer_params": [60, 22, 28, 22, 47], "learning_rate": 0.004373881984323314, "batch_size": 257, "loss": 0.002211451737675816}, {"layer_params": [21, 47, 52, 37], "learning_rate": 0.0072527566153241935, "batch_size": 437, "loss": 0.0017156716424506157}, {"layer_params": [62, 17, 52, 54, 41], "learning_rate": 0.0039895965987892775, "batch_size": 311, "loss": 0.0012582516169641167}, {"layer_params": [32, 16, 57], "learning_rate": 0.004163103981081154, "batch_size": 73, "loss": 0.004333690358325839}, {"layer_params": [33, 33, 48, 43], "learning_rate": 0.001468853549953568, "batch_size": 361, "loss": 0.0019148235523607582}, {"layer_params": [51, 53], "learning_rate": 0.0013977010841782415, "batch_size": 441, "loss": 0.0030476881540380417}, {"layer_params": [48, 37, 64, 27], "learning_rate": 0.004463342436172132, "batch_size": 161, "loss": 0.0026507989037781953}, {"layer_params": [60, 28], "learning_rate": 0.0011754409824079198, "batch_size": 358, "loss": 0.002985424851067364}, {"layer_params": [49, 49], "learning_rate": 0.008597059695564218, "batch_size": 294, "loss": 0.002726083032321185}, {"layer_params": [37, 23, 58, 35, 57], "learning_rate": 0.005480317979678155, "batch_size": 70, "loss": 0.004902601591311395}, {"layer_params": [16, 21, 23, 48], "learning_rate": 0.001917031697468906, "batch_size": 100, "loss": 0.00795258307363838}, {"layer_params": [23, 60], "learning_rate": 0.005486067022003248, "batch_size": 417, "loss": 0.003371447892859578}, {"layer_params": [34, 28, 20], "learning_rate": 0.0044038663559572925, "batch_size": 313, "loss": 0.0030278070899657904}, {"layer_params": [16, 58, 22], "learning_rate": 0.0023764012416915173, "batch_size": 484, "loss": 0.003243382894434035}, {"layer_params": [51, 52, 19, 34, 41], "learning_rate": 0.008130242855451175, "batch_size": 361, "loss": 0.0018584245292004198}, {"layer_params": [56, 57, 54], "learning_rate": 0.003818701958166999, "batch_size": 479, "loss": 0.0007843185437377543}, {"layer_params": [23, 52, 50], "learning_rate": 0.006123119095717644, "batch_size": 503, "loss": 0.0014840698835905642}, {"layer_params": [40, 64, 26], "learning_rate": 5.640176292947442e-05, "batch_size": 197, "loss": 0.030653768330812455}, {"layer_params": [28, 58, 23], "learning_rate": 0.003304136473531038, "batch_size": 404, "loss": 0.0023976642719935625}, {"layer_params": [45, 26, 45], "learning_rate": 0.0008241428878167228, "batch_size": 240, "loss": 0.0038348294724710285}, {"layer_params": [41, 33, 60], "learning_rate": 0.008295346041228533, "batch_size": 213, "loss": 0.0018440816726069897}, {"layer_params": [55, 28, 32], "learning_rate": 0.0003533537315904832, "batch_size": 142, "loss": 0.00667970516718924}, {"layer_params": [17, 40], "learning_rate": 0.007429789614220076, "batch_size": 398, "loss": 0.0032339406665414573}, {"layer_params": [21, 64, 44, 26], "learning_rate": 0.0010597537693290996, "batch_size": 472, "loss": 0.0029343862156383693}, {"layer_params": [50, 64], "learning_rate": 0.005307399105801828, "batch_size": 56, "loss": 0.0024006270326208325}, {"layer_params": [37, 22, 57, 56, 16], "learning_rate": 0.008101777775893078, "batch_size": 274, "loss": 0.0024657160544302313}, {"layer_params": [42, 22], "learning_rate": 0.00437409211259096, "batch_size": 306, "loss": 0.004205060184467584}, {"layer_params": [32, 25, 33], "learning_rate": 0.0003018765557453148, "batch_size": 264, "loss": 0.007552196141332388}, {"layer_params": [60, 60, 36, 40, 51], "learning_rate": 0.0037510450996544598, "batch_size": 201, "loss": 0.001103227853309363}, {"layer_params": [43, 22], "learning_rate": 0.00422329758260642, "batch_size": 399, "loss": 0.0036102015455253423}, {"layer_params": [23, 56], "learning_rate": 0.008333414099483072, "batch_size": 53, "loss": 0.003167022143024951}, {"layer_params": [35, 41, 26, 33], "learning_rate": 0.004067688819107671, "batch_size": 96, "loss": 0.00291514549870044}, {"layer_params": [22, 36, 50, 30, 49], "learning_rate": 0.002922287385713595, "batch_size": 204, "loss": 0.003825227259658277}, {"layer_params": [57, 21, 52, 25, 58], "learning_rate": 0.009296618967547497, "batch_size": 434, "loss": 0.0014696059422567487}, {"layer_params": [20, 23, 23, 56, 17], "learning_rate": 0.005560261459226713, "batch_size": 429, "loss": 0.004572661651764065}, {"layer_params": [38, 42, 34, 42, 47], "learning_rate": 0.00696409996315031, "batch_size": 400, "loss": 0.0011588635155931116}, {"layer_params": [35, 36], "learning_rate": 0.006166239308767364, "batch_size": 153, "loss": 0.002020493147429079}, {"layer_params": [24, 63], "learning_rate": 0.0033970063982911953, "batch_size": 320, "loss": 0.0034489516098983584}, {"layer_params": [46, 39, 57, 36, 48], "learning_rate": 0.004602417048350873, "batch_size": 403, "loss": 0.001542847363743931}, {"layer_params": [21, 50], "learning_rate": 0.0031332646120250727, "batch_size": 273, "loss": 0.002863334575667977}, {"layer_params": [21, 61, 48], "learning_rate": 0.0028597428750374754, "batch_size": 165, "loss": 0.0032643338851630686}, {"layer_params": [30, 55, 57, 19, 39], "learning_rate": 0.0012128386934070518, "batch_size": 349, "loss": 0.0025394592666998506}, {"layer_params": [44, 31, 16, 30], "learning_rate": 0.004442749116712179, "batch_size": 430, "loss": 0.002538258346030489}, {"layer_params": [56, 26, 32, 36, 58], "learning_rate": 0.005559664931274437, "batch_size": 323, "loss": 0.0019503976369742305}, {"layer_params": [24, 55, 43, 30], "learning_rate": 0.009212288466921072, "batch_size": 52, "loss": 0.004674784145317972}, {"layer_params": [35, 56, 28, 42], "learning_rate": 0.007860742622544877, "batch_size": 501, "loss": 0.001550414414377883}, {"layer_params": [28, 48, 17, 35, 50], "learning_rate": 0.0041010377133432795, "batch_size": 107, "loss": 0.002847164024133235}, {"layer_params": [37, 24, 43, 32], "learning_rate": 0.0008001986855162146, "batch_size": 318, "loss": 0.005171418590471148}, {"layer_params": [22, 44, 34, 37], "learning_rate": 0.001223964736725148, "batch_size": 80, "loss": 0.007713802256621421}, {"layer_params": [47, 47], "learning_rate": 0.0011498165459958931, "batch_size": 244, "loss": 0.0034209551149979233}, {"layer_params": [29, 17], "learning_rate": 0.0007040964974421718, "batch_size": 435, "loss": 0.00641811503097415}, {"layer_params": [61, 26, 31, 50, 57], "learning_rate": 0.006587813170379425, "batch_size": 281, "loss": 0.002401090378407389}, {"layer_params": [41, 25, 41, 22], "learning_rate": 0.005215616204041702, "batch_size": 243, "loss": 0.002510196567745879}, {"layer_params": [38, 42, 49], "learning_rate": 0.006305067133249315, "batch_size": 230, "loss": 0.0018561893596779554}, {"layer_params": [34, 54, 46, 20, 51], "learning_rate": 0.002080229870389869, "batch_size": 425, "loss": 0.001607250003144145}, {"layer_params": [60, 59, 18], "learning_rate": 0.007206471065565709, "batch_size": 232, "loss": 0.001120442075189203}, {"layer_params": [32, 44, 24, 19, 36], "learning_rate": 0.0010261975550073157, "batch_size": 246, "loss": 0.003920191221404821}, {"layer_params": [63, 60, 41], "learning_rate": 0.005403500896712043, "batch_size": 494, "loss": 0.0008346336294198409}, {"layer_params": [27, 26, 31], "learning_rate": 0.009950789711803293, "batch_size": 500, "loss": 0.0019566151488106696}, {"layer_params": [61, 19, 38, 55, 50], "learning_rate": 0.007503491590360461, "batch_size": 251, "loss": 0.0015835671406239271}, {"layer_params": [55, 61, 61], "learning_rate": 0.008245661644379879, "batch_size": 328, "loss": 0.001156302323215641}, {"layer_params": [51, 30, 54, 20], "learning_rate": 0.0009790564797348795, "batch_size": 106, "loss": 0.005621180231682957}, {"layer_params": [35, 39, 34, 28], "learning_rate": 0.0017065019895021578, "batch_size": 474, "loss": 0.0025769365043379366}, {"layer_params": [27, 36, 29, 40], "learning_rate": 0.0012718291935323945, "batch_size": 37, "loss": 0.006841855836100876}, {"layer_params": [18, 48, 25, 48], "learning_rate": 0.002816264685587221, "batch_size": 67, "loss": 0.004465770639944822}, {"layer_params": [43, 27, 20, 43, 46], "learning_rate": 0.009543528590265514, "batch_size": 419, "loss": 0.0021590492548421024}, {"layer_params": [21, 43, 41, 61, 54], "learning_rate": 0.00042914922644501577, "batch_size": 365, "loss": 0.005754763097502291}, {"layer_params": [35, 22, 42, 25], "learning_rate": 0.0005615332116867571, "batch_size": 137, "loss": 0.007647521565668285}, {"layer_params": [44, 21, 44], "learning_rate": 0.002043092700064471, "batch_size": 451, "loss": 0.0018464363471139222}, {"layer_params": [36, 43, 40, 17, 17], "learning_rate": 0.0032295089642541117, "batch_size": 31, "loss": 0.005099610162433237}, {"layer_params": [50, 36, 50, 31], "learning_rate": 0.004403423547524123, "batch_size": 229, "loss": 0.0014323626016266645}, {"layer_params": [18, 41, 28, 41, 35], "learning_rate": 0.0023959836094499362, "batch_size": 364, "loss": 0.002240910700056702}, {"layer_params": [55, 56, 33], "learning_rate": 0.007467567919489942, "batch_size": 119, "loss": 0.00127492047380656}, {"layer_params": [46, 58, 31, 36], "learning_rate": 0.007179231044598807, "batch_size": 497, "loss": 0.0010015067248605191}, {"layer_params": [39, 37], "learning_rate": 0.006525399005869998, "batch_size": 281, "loss": 0.002400420734193176}, {"layer_params": [19, 36, 17], "learning_rate": 0.002469430634567978, "batch_size": 353, "loss": 0.00392845573136583}, {"layer_params": [54, 48, 41, 34], "learning_rate": 0.0026391354452998555, "batch_size": 81, "loss": 0.002821584288030863}, {"layer_params": [23, 52, 57], "learning_rate": 0.002671523812698959, "batch_size": 187, "loss": 0.0022309765534009787}, {"layer_params": [29, 34, 29, 45], "learning_rate": 0.009768654462496367, "batch_size": 282, "loss": 0.00256628533010371}, {"layer_params": [47, 59, 24, 51], "learning_rate": 0.007465434321896072, "batch_size": 60, "loss": 0.002534760837443173}, {"layer_params": [37, 63, 22, 61], "learning_rate": 0.0013057291233442947, "batch_size": 217, "loss": 0.0024081685522105547}, {"layer_params": [61, 35, 64], "learning_rate": 0.006820920921220294, "batch_size": 365, "loss": 0.0007329678314272315}, {"layer_params": [43, 24, 38, 18, 47], "learning_rate": 0.005672631693768738, "batch_size": 462, "loss": 0.0018996025901287794}, {"layer_params": [36, 46, 41], "learning_rate": 0.0033863944257081675, "batch_size": 312, "loss": 0.0008814681821968407}, {"layer_params": [22, 62], "learning_rate": 0.0030509611093910804, "batch_size": 170, "loss": 0.002825867070350796}, {"layer_params": [26, 19, 63], "learning_rate": 0.003956521970259239, "batch_size": 387, "loss": 0.0039044219581410287}, {"layer_params": [33, 32, 18], "learning_rate": 0.007888322400983262, "batch_size": 252, "loss": 0.0025190543534699826}, {"layer_params": [53, 17, 36, 18], "learning_rate": 0.0029207619656660497, "batch_size": 250, "loss": 0.0032490002550184726}, {"layer_params": [62, 27, 30, 43], "learning_rate": 0.0016510039191412885, "batch_size": 493, "loss": 0.0019554759038146585}, {"layer_params": [49, 34, 22, 21], "learning_rate": 0.00833669993307263, "batch_size": 230, "loss": 0.0016067896247841417}, {"layer_params": [62, 30, 41], "learning_rate": 0.0034440653698163755, "batch_size": 462, "loss": 0.00214155591558665}, {"layer_params": [34, 54], "learning_rate": 0.003103419842089087, "batch_size": 349, "loss": 0.0018847631418611854}, {"layer_params": [45, 36, 62], "learning_rate": 0.005129957745384798, "batch_size": 354, "loss": 0.001853096386184916}, {"layer_params": [40, 49, 39, 26], "learning_rate": 0.00523215145420995, "batch_size": 112, "loss": 0.003422044930048287}, {"layer_params": [48, 49, 50], "learning_rate": 8.170123099784975e-05, "batch_size": 456, "loss": 0.027104688696563243}, {"layer_params": [33, 47, 61, 60], "learning_rate": 0.008840725794969436, "batch_size": 285, "loss": 0.0019548953394405546}, {"layer_params": [36, 36, 46, 58, 48], "learning_rate": 0.0030164703715393057, "batch_size": 315, "loss": 0.001903371171792969}, {"layer_params": [61, 55, 60, 26, 17], "learning_rate": 0.001787602249319171, "batch_size": 255, "loss": 0.0013694834068883211}, {"layer_params": [45, 33], "learning_rate": 0.0020124558332843363, "batch_size": 108, "loss": 0.005076855367515236}, {"layer_params": [33, 27, 32, 57, 57], "learning_rate": 0.0042879244383721, "batch_size": 58, "loss": 0.00401996512664482}, {"layer_params": [34, 20], "learning_rate": 0.00990055005341153, "batch_size": 402, "loss": 0.004657188581768423}, {"layer_params": [64, 35], "learning_rate": 0.006587693388481424, "batch_size": 324, "loss": 0.0017408851499203593}, {"layer_params": [43, 59, 40, 51, 57], "learning_rate": 0.001271411598991889, "batch_size": 72, "loss": 0.004131526674609631}, {"layer_params": [26, 38, 35], "learning_rate": 0.006886063522325844, "batch_size": 147, "loss": 0.003721905832644552}, {"layer_params": [18, 64, 61], "learning_rate": 0.0013220453362631985, "batch_size": 374, "loss": 0.0024133527441881596}, {"layer_params": [60, 27, 61, 16], "learning_rate": 0.001222279408017605, "batch_size": 88, "loss": 0.005041450853459537}, {"layer_params": [64, 38, 64, 17, 23], "learning_rate": 0.00017554418133245618, "batch_size": 463, "loss": 0.0059091677097603676}, {"layer_params": [43, 45], "learning_rate": 0.0002288960117501438, "batch_size": 423, "loss": 0.00866823122370988}, {"layer_params": [21, 58, 61], "learning_rate": 0.006935700990604343, "batch_size": 22, "loss": 0.007476797585841268}, {"layer_params": [37, 43, 26], "learning_rate": 0.009850037301421744, "batch_size": 317, "loss": 0.0018956547521520406}, {"layer_params": [36, 32], "learning_rate": 0.0014383882993088508, "batch_size": 32, "loss": 0.007603851333260536}, {"layer_params": [54, 61], "learning_rate": 0.008896327992188317, "batch_size": 444, "loss": 0.002071207796689123}, {"layer_params": [42, 25], "learning_rate": 0.008248593691268676, "batch_size": 413, "loss": 0.0015450830606278032}, {"layer_params": [22, 20, 37, 57], "learning_rate": 0.002779492025428113, "batch_size": 127, "loss": 0.004666942006442696}, {"layer_params": [34, 20, 30], "learning_rate": 0.008975494074451043, "batch_size": 96, "loss": 0.004270298583433032}, {"layer_params": [47, 22], "learning_rate": 0.006495754235767882, "batch_size": 49, "loss": 0.0035638124914839863}, {"layer_params": [60, 35, 58, 23], "learning_rate": 0.007936137948397065, "batch_size": 387, "loss": 0.0016653680137824268}, {"layer_params": [46, 16], "learning_rate": 0.005595492132299107, "batch_size": 250, "loss": 0.002206063639605418}, {"layer_params": [60, 21, 20, 17], "learning_rate": 0.009351685363857548, "batch_size": 135, "loss": 0.0020026409975253045}, {"layer_params": [64, 25, 56], "learning_rate": 0.005638833151852366, "batch_size": 278, "loss": 0.0014793451316654682}, {"layer_params": [30, 54, 27, 52], "learning_rate": 0.007918742625714811, "batch_size": 120, "loss": 0.002889098923187703}, {"layer_params": [38, 62, 54, 26], "learning_rate": 0.009638351688133017, "batch_size": 409, "loss": 0.0007633352873381228}, {"layer_params": [25, 46, 20, 36], "learning_rate": 0.003980148144457356, "batch_size": 475, "loss": 0.002982509990688413}, {"layer_params": [26, 33, 62], "learning_rate": 0.007828648578122401, "batch_size": 41, "loss": 0.004240199585910887}, {"layer_params": [34, 28, 27, 45, 21], "learning_rate": 0.008938741623027373, "batch_size": 497, "loss": 0.0018515738181304187}, {"layer_params": [38, 49], "learning_rate": 0.002341230753479291, "batch_size": 121, "loss": 0.0028920554730575533}, {"layer_params": [39, 34, 56, 37, 40], "learning_rate": 0.001723309690212862, "batch_size": 111, "loss": 0.004635424506850541}, {"layer_params": [39, 38, 40, 22, 19], "learning_rate": 0.006274844713651135, "batch_size": 361, "loss": 0.001549562431173399}, {"layer_params": [58, 61, 54, 20], "learning_rate": 0.005863205329864534, "batch_size": 200, "loss": 0.0014681569242384284}, {"layer_params": [33, 38], "learning_rate": 0.0017707880491679604, "batch_size": 300, "loss": 0.00336247346829623}, {"layer_params": [44, 33, 61], "learning_rate": 0.0071113076153380824, "batch_size": 25, "loss": 0.006392041158396751}, {"layer_params": [52, 54, 38, 21], "learning_rate": 0.0003024602117760426, "batch_size": 333, "loss": 0.00655277029145509}, {"layer_params": [33, 57, 17, 40], "learning_rate": 0.004298330928488147, "batch_size": 205, "loss": 0.0020062535000033676}, {"layer_params": [25, 42, 64], "learning_rate": 0.0038535894697654606, "batch_size": 337, "loss": 0.002807626575231552}, {"layer_params": [35, 63, 17, 34, 55], "learning_rate": 0.0031699436933551083, "batch_size": 102, "loss": 0.004258298284839839}, {"layer_params": [45, 28, 34, 26], "learning_rate": 0.004793798533982093, "batch_size": 226, "loss": 0.0019555424281861634}, {"layer_params": [52, 30, 34, 28, 22], "learning_rate": 0.0036560670638959266, "batch_size": 56, "loss": 0.004930434965062886}, {"layer_params": [54, 58], "learning_rate": 0.008098056194902517, "batch_size": 155, "loss": 0.0012276984559139237}, {"layer_params": [19, 36, 40, 36, 40], "learning_rate": 0.0003337704445331206, "batch_size": 134, "loss": 0.007957498622126878}, {"layer_params": [52, 57, 23], "learning_rate": 0.0095232868292298, "batch_size": 399, "loss": 0.0015342233970295639}, {"layer_params": [34, 35, 21, 26, 26], "learning_rate": 0.003658379711721862, "batch_size": 383, "loss": 0.002146454257890582}, {"layer_params": [35, 53, 30, 20], "learning_rate": 0.006818978903206968, "batch_size": 399, "loss": 0.0019890169834252446}, {"layer_params": [30, 38], "learning_rate": 0.0034954832310987523, "batch_size": 105, "loss": 0.003210388335864991}, {"layer_params": [59, 43, 45, 36, 19], "learning_rate": 0.006508421365818508, "batch_size": 497, "loss": 0.0018177350366022438}, {"layer_params": [37, 31, 63], "learning_rate": 0.000304419401826233, "batch_size": 512, "loss": 0.0060755963763222095}, {"layer_params": [48, 20], "learning_rate": 0.0024827581019082117, "batch_size": 402, "loss": 0.004082984696142375}, {"layer_params": [44, 46, 41], "learning_rate": 0.0037580418695577797, "batch_size": 289, "loss": 0.001341036690864712}, {"layer_params": [60, 42, 53, 52], "learning_rate": 0.0004129843130625646, "batch_size": 92, "loss": 0.00582454988732934}, {"layer_params": [27, 17, 28], "learning_rate": 0.00039934825081020366, "batch_size": 255, "loss": 0.008342962409369648}, {"layer_params": [35, 36], "learning_rate": 9.759794500774715e-05, "batch_size": 197, "loss": 0.029511663131415844}, {"layer_params": [23, 35, 25, 26, 63], "learning_rate": 0.004924257973608813, "batch_size": 338, "loss": 0.002631398793309927}, {"layer_params": [17, 64, 58, 20, 41], "learning_rate": 0.001658359509145155, "batch_size": 106, "loss": 0.004777681645937264}, {"layer_params": [46, 17], "learning_rate": 0.0074201707831387164, "batch_size": 19, "loss": 0.007356916284188628}, {"layer_params": [32, 31], "learning_rate": 0.0008527914252153072, "batch_size": 112, "loss": 0.0072635691286996006}, {"layer_params": [16, 61, 45, 55, 34], "learning_rate": 0.006780394360922087, "batch_size": 30, "loss": 0.007185251764021814}, {"layer_params": [29, 44, 50, 40, 32], "learning_rate": 0.009722324979795489, "batch_size": 454, "loss": 0.0016969454812351614}, {"layer_params": [16, 54, 38, 18, 47], "learning_rate": 0.005344101789054494, "batch_size": 18, "loss": 0.006743515010457486}, {"layer_params": [43, 54, 54, 22, 38], "learning_rate": 0.0028862612545861636, "batch_size": 101, "loss": 0.002647341979900375}, {"layer_params": [34, 42, 47], "learning_rate": 0.002287745419110857, "batch_size": 264, "loss": 0.0018756094924174248}, {"layer_params": [58, 49, 16], "learning_rate": 0.0007795100906152565, "batch_size": 388, "loss": 0.00379244398791343}, {"layer_params": [55, 22, 38, 45], "learning_rate": 0.009684396168691321, "batch_size": 334, "loss": 0.0017351256334222852}, {"layer_params": [61, 25], "learning_rate": 0.00016005725193466095, "batch_size": 395, "loss": 0.013730967119336128}, {"layer_params": [62, 25, 22, 39, 28], "learning_rate": 0.005565716134888961, "batch_size": 19, "loss": 0.007304835533723235}, {"layer_params": [20, 44, 33], "learning_rate": 0.008839780404353162, "batch_size": 373, "loss": 0.0017239181732293218}, {"layer_params": [60, 35, 28, 56, 44], "learning_rate": 0.00664613066292733, "batch_size": 454, "loss": 0.001185453372891061}, {"layer_params": [46, 36, 21], "learning_rate": 0.004712857743211199, "batch_size": 74, "loss": 0.003539298626128584}, {"layer_params": [51, 21], "learning_rate": 0.0065852460330858035, "batch_size": 199, "loss": 0.002465894204797223}, {"layer_params": [27, 52, 61], "learning_rate": 0.005428972425758044, "batch_size": 229, "loss": 0.001721720858477056}, {"layer_params": [52, 53, 51, 17], "learning_rate": 0.0033840235795954015, "batch_size": 71, "loss": 0.004083552833180875}, {"layer_params": [49, 48, 35, 62, 47], "learning_rate": 0.006793974054696089, "batch_size": 500, "loss": 0.000945991903427057}, {"layer_params": [20, 24, 25, 31, 34], "learning_rate": 0.0002906152710219295, "batch_size": 155, "loss": 0.008683662423864006}, {"layer_params": [29, 46, 31], "learning_rate": 0.001562312208337472, "batch_size": 130, "loss": 0.005433179654646665}, {"layer_params": [16, 19, 51, 42], "learning_rate": 0.001215607449241937, "batch_size": 277, "loss": 0.004744082416873425}, {"layer_params": [51, 55, 28, 34], "learning_rate": 0.007607003798372831, "batch_size": 342, "loss": 0.001014879391877912}, {"layer_params": [63, 32, 33, 24], "learning_rate": 0.0028196207339315172, "batch_size": 310, "loss": 0.0016627368645276874}, {"layer_params": [44, 22, 43, 45, 54], "learning_rate": 0.0026544196145210992, "batch_size": 95, "loss": 0.0027754379343241454}, {"layer_params": [46, 43, 58, 59, 17], "learning_rate": 0.002556180853269935, "batch_size": 219, "loss": 0.001947065310087055}, {"layer_params": [39, 16, 51, 43], "learning_rate": 0.008335354612856142, "batch_size": 317, "loss": 0.0035201764362864196}, {"layer_params": [46, 31, 31, 30], "learning_rate": 0.00963917377294037, "batch_size": 197, "loss": 0.0016897210886236281}, {"layer_params": [55, 19, 31, 45, 45], "learning_rate": 0.004016438944583623, "batch_size": 380, "loss": 0.0014437252213247121}, {"layer_params": [23, 57, 27], "learning_rate": 0.00027900365739007846, "batch_size": 245, "loss": 0.007006776118651033}, {"layer_params": [19, 40, 54, 25, 59], "learning_rate": 0.009664068671769464, "batch_size": 383, "loss": 0.002950451646465808}, {"layer_params": [54, 20], "learning_rate": 0.0017610708952316683, "batch_size": 464, "loss": 0.0028185368259437383}, {"layer_params": [38, 26, 40, 36, 49], "learning_rate": 0.005310471765731951, "batch_size": 406, "loss": 0.0021280187892261894}, {"layer_params": [36, 49], "learning_rate": 0.0019327770669284332, "batch_size": 302, "loss": 0.0029158904985524714}, {"layer_params": [40, 39, 64, 58, 45], "learning_rate": 0.0007727907507692023, "batch_size": 194, "loss": 0.0035965927853249015}, {"layer_params": [17, 16, 20, 37, 50], "learning_rate": 0.0012266593388281025, "batch_size": 148, "loss": 0.0066582241840660574}, {"layer_params": [21, 22, 58], "learning_rate": 0.00047235440823500854, "batch_size": 137, "loss": 0.008352447235956788}, {"layer_params": [22, 27], "learning_rate": 0.006282409961713821, "batch_size": 200, "loss": 0.00523274109698832}, {"layer_params": [54, 33, 18, 34], "learning_rate": 0.004567759549621516, "batch_size": 44, "loss": 0.00451462731929496}, {"layer_params": [44, 56, 46], "learning_rate": 0.009299948372227564, "batch_size": 139, "loss": 0.0014912836696021258}, {"layer_params": [63, 18, 37], "learning_rate": 0.005621537233526867, "batch_size": 410, "loss": 0.0017592587508261203}, {"layer_params": [57, 32, 22, 31], "learning_rate": 0.008935755323551602, "batch_size": 100, "loss": 0.003259598081931472}, {"layer_params": [17, 22, 23, 26], "learning_rate": 0.0031149152108031625, "batch_size": 280, "loss": 0.003476738128811121}, {"layer_params": [38, 42], "learning_rate": 0.005841233510373377, "batch_size": 317, "loss": 0.0036814404651522637}, {"layer_params": [52, 26], "learning_rate": 0.009980462497322517, "batch_size": 188, "loss": 0.0028732790565118194}, {"layer_params": [62, 34, 35], "learning_rate": 0.00957820975252728, "batch_size": 498, "loss": 0.0009144569974159822}, {"layer_params": [31, 36, 63, 38, 19], "learning_rate": 0.004992437810223497, "batch_size": 27, "loss": 0.008512518254574388}, {"layer_params": [43, 52], "learning_rate": 0.0020816435608935467, "batch_size": 279, "loss": 0.0027087842277251184}, {"layer_params": [28, 23, 17, 23], "learning_rate": 0.006693221021939118, "batch_size": 91, "loss": 0.0025140827405266465}, {"layer_params": [42, 42, 54, 31], "learning_rate": 0.0012390427497586903, "batch_size": 335, "loss": 0.002322897178819403}, {"layer_params": [58, 42], "learning_rate": 0.00453335984483365, "batch_size": 505, "loss": 0.0015461112163029612}, {"layer_params": [37, 46, 41, 27, 56], "learning_rate": 0.008285147767748741, "batch_size": 208, "loss": 0.0018848149420227856}, {"layer_params": [37, 33, 17, 47, 58], "learning_rate": 0.0005452594923403036, "batch_size": 128, "loss": 0.0057241536770015955}, {"layer_params": [62, 36, 23, 42], "learning_rate": 0.0023032646183056256, "batch_size": 38, "loss": 0.005595592767931521}, {"layer_params": [19, 19, 16, 38], "learning_rate": 0.008488702674025884, "batch_size": 337, "loss": 0.005614698766730725}, {"layer_params": [53, 58, 43, 60, 61], "learning_rate": 0.0013645481197013469, "batch_size": 122, "loss": 0.00217196230427362}, {"layer_params": [63, 45, 28, 44, 46], "learning_rate": 0.0074127439887920745, "batch_size": 18, "loss": 0.0072479161201044915}, {"layer_params": [41, 46, 29], "learning_rate": 0.004877211072925573, "batch_size": 166, "loss": 0.00205560258589685}, {"layer_params": [62, 62], "learning_rate": 0.002065567133697681, "batch_size": 18, "loss": 0.0067285719374194745}, {"layer_params": [55, 23, 43, 61, 35], "learning_rate": 0.0024319684816678936, "batch_size": 350, "loss": 0.0035898316791281104}, {"layer_params": [50, 16, 18, 34], "learning_rate": 0.00467403364449717, "batch_size": 426, "loss": 0.0037418768648058176}, {"layer_params": [46, 53], "learning_rate": 0.007659454922695747, "batch_size": 72, "loss": 0.0027867359761148693}, {"layer_params": [54, 40, 35, 43], "learning_rate": 0.008925436360752855, "batch_size": 446, "loss": 0.0011487049679271876}, {"layer_params": [59, 32, 25], "learning_rate": 0.009289149349890771, "batch_size": 383, "loss": 0.000793672518339008}, {"layer_params": [45, 46], "learning_rate": 0.009414450924853988, "batch_size": 306, "loss": 0.0023812703974545003}, {"layer_params": [22, 21, 36], "learning_rate": 0.004610864650645, "batch_size": 441, "loss": 0.003981743471231311}, {"layer_params": [33, 32, 46], "learning_rate": 0.00395971169262885, "batch_size": 403, "loss": 0.0017439155746251345}, {"layer_params": [40, 46], "learning_rate": 0.003537594480316022, "batch_size": 307, "loss": 0.002100688919890672}, {"layer_params": [40, 23, 43, 25, 18], "learning_rate": 0.002372254538965979, "batch_size": 158, "loss": 0.00404210694367066}, {"layer_params": [39, 22, 27, 42, 18], "learning_rate": 0.0024209157745479666, "batch_size": 495, "loss": 0.0015593980776611716}, {"layer_params": [62, 52], "learning_rate": 0.009732653860699204, "batch_size": 506, "loss": 0.0018629070045426488}, {"layer_params": [61, 52], "learning_rate": 0.003120659779398455, "batch_size": 158, "loss": 0.0038040836434811353}, {"layer_params": [63, 45], "learning_rate": 0.008785836264033836, "batch_size": 20, "loss": 0.007392331599257887}, {"layer_params": [22, 24, 47], "learning_rate": 0.009987032764528959, "batch_size": 124, "loss": 0.002825430965749547}, {"layer_params": [56, 24], "learning_rate": 0.005013387884385607, "batch_size": 469, "loss": 0.001195884744520299}, {"layer_params": [41, 60, 64, 29, 23], "learning_rate": 0.0028728761965171913, "batch_size": 183, "loss": 0.0016154298570472748}, {"layer_params": [26, 36, 60, 30, 21], "learning_rate": 0.00817931806589369, "batch_size": 410, "loss": 0.0024176490143872796}, {"layer_params": [54, 49], "learning_rate": 0.0026385697813170075, "batch_size": 265, "loss": 0.0020327197830192745}, {"layer_params": [23, 54, 44, 31, 38], "learning_rate": 0.0019716403639616726, "batch_size": 411, "loss": 0.002744099602568895}, {"layer_params": [57, 62], "learning_rate": 0.006825745846782579, "batch_size": 490, "loss": 0.0008562556427204981}, {"layer_params": [41, 17, 56, 23, 37], "learning_rate": 0.00596498390382802, "batch_size": 203, "loss": 0.0033491416345350442}, {"layer_params": [21, 22, 60, 40, 20], "learning_rate": 0.00048269617050738313, "batch_size": 325, "loss": 0.006845053806900978}, {"layer_params": [45, 20, 29, 28, 26], "learning_rate": 0.005223078943348182, "batch_size": 209, "loss": 0.00335424876306206}, {"layer_params": [40, 22, 21, 35, 16], "learning_rate": 0.008984414302127063, "batch_size": 321, "loss": 0.0015580468683037906}, {"layer_params": [46, 27, 19, 53], "learning_rate": 0.004994357371822364, "batch_size": 228, "loss": 0.0013447834132239223}, {"layer_params": [46, 40], "learning_rate": 0.0024535685228980536, "batch_size": 350, "loss": 0.0027074072021059693}, {"layer_params": [42, 56, 54, 56, 59], "learning_rate": 0.0032069741478312694, "batch_size": 96, "loss": 0.002994545104447752}, {"layer_params": [41, 29, 34, 56], "learning_rate": 0.007870776106249746, "batch_size": 108, "loss": 0.0028051315050106494}, {"layer_params": [17, 37, 22, 22], "learning_rate": 0.005250827536254991, "batch_size": 184, "loss": 0.003912816594820469}, {"layer_params": [17, 51], "learning_rate": 0.002633131098089891, "batch_size": 145, "loss": 0.005255702799186111}, {"layer_params": [38, 23, 29, 30], "learning_rate": 0.0018189740473300877, "batch_size": 167, "loss": 0.004009028787259013}, {"layer_params": [59, 55, 34], "learning_rate": 0.005032692795156293, "batch_size": 332, "loss": 0.0015734243020415306}, {"layer_params": [45, 35], "learning_rate": 0.006596292117909237, "batch_size": 490, "loss": 0.00104463706840761}, {"layer_params": [52, 21], "learning_rate": 0.0035839092373236795, "batch_size": 447, "loss": 0.0020993232855107636}, {"layer_params": [48, 50, 16], "learning_rate": 0.005210204045181664, "batch_size": 473, "loss": 0.0018150052556302398}, {"layer_params": [35, 26, 19], "learning_rate": 0.0012470589511335514, "batch_size": 70, "loss": 0.006102423300035298}, {"layer_params": [52, 36, 16, 41, 26], "learning_rate": 0.0050014575731341555, "batch_size": 107, "loss": 0.0024521418882068246}, {"layer_params": [34, 56, 58, 41], "learning_rate": 0.005972880556479684, "batch_size": 129, "loss": 0.0018998895096592604}, {"layer_params": [47, 17, 23, 26, 43], "learning_rate": 0.008181827919782902, "batch_size": 223, "loss": 0.004424472509417683}, {"layer_params": [26, 27], "learning_rate": 0.00573264658612839, "batch_size": 130, "loss": 0.0034304032963700594}, {"layer_params": [48, 34, 38, 35], "learning_rate": 0.005719362274846715, "batch_size": 405, "loss": 0.0012144297047052533}, {"layer_params": [41, 39, 39, 23], "learning_rate": 0.008075051370169808, "batch_size": 443, "loss": 0.001399531775387004}, {"layer_params": [39, 61, 27, 44], "learning_rate": 0.009333607908290647, "batch_size": 117, "loss": 0.004187318729236722}, {"layer_params": [50, 57, 17, 42], "learning_rate": 0.009896821614092206, "batch_size": 301, "loss": 0.001056025010184385}, {"layer_params": [32, 42, 16, 21, 56], "learning_rate": 0.008338127203981815, "batch_size": 259, "loss": 0.0017705624259542673}, {"layer_params": [30, 25, 17, 61], "learning_rate": 0.0059703815780415585, "batch_size": 139, "loss": 0.0030710888421162964}, {"layer_params": [45, 56], "learning_rate": 0.002673654377926883, "batch_size": 359, "loss": 0.0021224003983661534}, {"layer_params": [45, 64, 54], "learning_rate": 0.004742135431511362, "batch_size": 66, "loss": 0.002671733256429434}, {"layer_params": [30, 20, 57], "learning_rate": 0.0088605485434695, "batch_size": 27, "loss": 0.006807747962884605}, {"layer_params": [24, 24, 18, 32, 47], "learning_rate": 0.004175002844440963, "batch_size": 36, "loss": 0.006553108561784029}, {"layer_params": [46, 16, 22, 62], "learning_rate": 0.006286959512603881, "batch_size": 97, "loss": 0.004201281080022454}, {"layer_params": [46, 55, 44], "learning_rate": 0.0014145473317556036, "batch_size": 469, "loss": 0.001623041220009327}, {"layer_params": [46, 32, 23, 36], "learning_rate": 0.009690945117965788, "batch_size": 361, "loss": 0.0011918196512851864}, {"layer_params": [25, 20, 24], "learning_rate": 0.008033855744617477, "batch_size": 288, "loss": 0.0030944984639063476}, {"layer_params": [62, 28, 34], "learning_rate": 0.00660282721400864, "batch_size": 265, "loss": 0.000993452940019779}, {"layer_params": [19, 44, 41, 52, 40], "learning_rate": 0.00857308467686286, "batch_size": 223, "loss": 0.0019318123173434286}, {"layer_params": [22, 52, 31], "learning_rate": 0.004469929877370451, "batch_size": 432, "loss": 0.002791780233383179}, {"layer_params": [49, 26, 28], "learning_rate": 0.0015089723564842168, "batch_size": 145, "loss": 0.003232589499093592}, {"layer_params": [37, 52, 20], "learning_rate": 0.0018441918766905038, "batch_size": 80, "loss": 0.0034480773122049866}, {"layer_params": [27, 35, 52], "learning_rate": 0.003604569909249267, "batch_size": 346, "loss": 0.001741544979158789}, {"layer_params": [50, 32, 47], "learning_rate": 0.0041737733906643355, "batch_size": 210, "loss": 0.0010395553900161758}, {"layer_params": [49, 27], "learning_rate": 0.005616207419959257, "batch_size": 477, "loss": 0.001780416052788496}, {"layer_params": [43, 33, 46], "learning_rate": 0.006403364644451863, "batch_size": 195, "loss": 0.0018016770633403213}, {"layer_params": [51, 53, 29, 49, 29], "learning_rate": 0.00861663165617281, "batch_size": 114, "loss": 0.001872192396549508}, {"layer_params": [45, 63, 55, 31, 31], "learning_rate": 0.0010988636452137581, "batch_size": 391, "loss": 0.0016828576801344753}, {"layer_params": [42, 59, 49], "learning_rate": 0.007298829372974305, "batch_size": 199, "loss": 0.001312963154632598}, {"layer_params": [61, 21], "learning_rate": 0.0051993904779987455, "batch_size": 107, "loss": 0.0031201841263100503}, {"layer_params": [56, 49], "learning_rate": 0.008502916806535596, "batch_size": 302, "loss": 0.00246093136142008}, {"layer_params": [33, 42, 25, 39], "learning_rate": 0.0006299322446258817, "batch_size": 261, "loss": 0.006250386745668948}, {"layer_params": [58, 19, 20, 42], "learning_rate": 0.004780899185737946, "batch_size": 374, "loss": 0.0018574832659214735}, {"layer_params": [20, 49], "learning_rate": 0.006087215864482249, "batch_size": 190, "loss": 0.002867267361143604}, {"layer_params": [35, 32], "learning_rate": 0.0013087388072990764, "batch_size": 162, "loss": 0.005298569083679467}, {"layer_params": [64, 32, 34, 32, 51], "learning_rate": 0.004041435376460005, "batch_size": 243, "loss": 0.001665652320953086}, {"layer_params": [58, 25], "learning_rate": 0.0014572862871273181, "batch_size": 426, "loss": 0.0025956046138890087}, {"layer_params": [48, 28, 38, 26, 28], "learning_rate": 0.003569154110898324, "batch_size": 159, "loss": 0.0021397918090224266}, {"layer_params": [41, 38, 33], "learning_rate": 0.001910885777096589, "batch_size": 116, "loss": 0.0025984457496088}, {"layer_params": [33, 26, 62, 36, 33], "learning_rate": 0.00421170417759106, "batch_size": 48, "loss": 0.005651041078381241}, {"layer_params": [45, 19, 29, 41], "learning_rate": 0.005896251467082263, "batch_size": 141, "loss": 0.0022922990401275456}, {"layer_params": [21, 40, 18, 57], "learning_rate": 0.001617517263094593, "batch_size": 131, "loss": 0.003781711948104203}, {"layer_params": [63, 57, 37, 24, 42], "learning_rate": 0.005277478422627439, "batch_size": 428, "loss": 0.0013845235155895352}, {"layer_params": [45, 25], "learning_rate": 0.0072603138263595355, "batch_size": 52, "loss": 0.003021121323108673}, {"layer_params": [43, 33, 39, 20, 49], "learning_rate": 0.0043856521294741175, "batch_size": 71, "loss": 0.0030355566705111414}, {"layer_params": [55, 38, 55, 30, 21], "learning_rate": 0.006394933705245283, "batch_size": 52, "loss": 0.005272337638307363}, {"layer_params": [53, 24], "learning_rate": 0.00743139849392379, "batch_size": 225, "loss": 0.00251162227592431}, {"layer_params": [33, 47], "learning_rate": 0.007494189683814302, "batch_size": 332, "loss": 0.002702553765848279}, {"layer_params": [17, 18], "learning_rate": 0.007087775185793329, "batch_size": 221, "loss": 0.004406806924380362}, {"layer_params": [61, 31, 18, 46, 50], "learning_rate": 0.004214909240993293, "batch_size": 350, "loss": 0.001686036178143695}, {"layer_params": [26, 19, 25, 37, 45], "learning_rate": 0.0006558520522965513, "batch_size": 19, "loss": 0.00889971957076341}, {"layer_params": [45, 45], "learning_rate": 0.008668443476559358, "batch_size": 170, "loss": 0.001229221451212652}, {"layer_params": [20, 43], "learning_rate": 0.009225244429110024, "batch_size": 286, "loss": 0.005742629966698587}, {"layer_params": [58, 50, 57], "learning_rate": 0.005746113882368147, "batch_size": 343, "loss": 0.0013094502239255235}, {"layer_params": [61, 20, 45, 57, 38], "learning_rate": 0.0005684062224833945, "batch_size": 258, "loss": 0.003792607639916241}, {"layer_params": [23, 56, 64, 59], "learning_rate": 0.00345708126313678, "batch_size": 167, "loss": 0.0020315853459760545}, {"layer_params": [56, 22, 25, 33], "learning_rate": 0.003452631205763545, "batch_size": 414, "loss": 0.0025569643382914366}, {"layer_params": [62, 44, 41], "learning_rate": 0.004972316060327772, "batch_size": 270, "loss": 0.001622417961480096}, {"layer_params": [50, 22], "learning_rate": 0.0030328346031158323, "batch_size": 392, "loss": 0.0013838222192134708}, {"layer_params": [29, 18], "learning_rate": 0.0026499051547693555, "batch_size": 57, "loss": 0.00666802731808275}, {"layer_params": [60, 35], "learning_rate": 0.009793930110557665, "batch_size": 336, "loss": 0.0011662398086627946}, {"layer_params": [63, 24, 37], "learning_rate": 0.007939193418712062, "batch_size": 34, "loss": 0.004278630210319534}, {"layer_params": [30, 26, 35, 24, 30], "learning_rate": 0.00886006132368156, "batch_size": 145, "loss": 0.005076483199372888}, {"layer_params": [38, 58, 29, 28], "learning_rate": 0.0012224004922939677, "batch_size": 422, "loss": 0.0028570503252558412}, {"layer_params": [62, 54], "learning_rate": 0.00934085479089859, "batch_size": 119, "loss": 0.0018579887272790075}, {"layer_params": [60, 62, 18, 20, 36], "learning_rate": 0.007068997529660874, "batch_size": 137, "loss": 0.00162391125690192}, {"layer_params": [43, 57, 45, 16], "learning_rate": 0.006717453907531462, "batch_size": 329, "loss": 0.0011707268131431192}, {"layer_params": [57, 42, 31, 59], "learning_rate": 0.00085355450850877, "batch_size": 129, "loss": 0.0032162782293744386}, {"layer_params": [21, 51, 43, 24, 62], "learning_rate": 0.007642290856576059, "batch_size": 86, "loss": 0.004143944564275443}, {"layer_params": [34, 43], "learning_rate": 0.004427822748378819, "batch_size": 330, "loss": 0.001486582582583651}, {"layer_params": [60, 38, 28, 17], "learning_rate": 0.003321026550983177, "batch_size": 160, "loss": 0.0015608098020311444}, {"layer_params": [44, 51], "learning_rate": 0.004852170311194511, "batch_size": 46, "loss": 0.0032799518934916705}, {"layer_params": [21, 26, 44], "learning_rate": 0.0035957606673986315, "batch_size": 146, "loss": 0.0036682155379094182}, {"layer_params": [27, 22, 42, 22, 32], "learning_rate": 0.009065058954635203, "batch_size": 222, "loss": 0.0024558518966659904}, {"layer_params": [54, 44, 42], "learning_rate": 0.0012960223087303078, "batch_size": 282, "loss": 0.00288882979657501}, {"layer_params": [49, 64, 17], "learning_rate": 0.003779686598026786, "batch_size": 421, "loss": 0.000997275723493658}, {"layer_params": [25, 38], "learning_rate": 0.008602455043007818, "batch_size": 168, "loss": 0.0021507340425159782}, {"layer_params": [37, 29, 20], "learning_rate": 0.008345849275947653, "batch_size": 352, "loss": 0.002364238006994128}, {"layer_params": [31, 32, 62, 64, 36], "learning_rate": 0.0007486176481446668, "batch_size": 511, "loss": 0.0036349669145420193}, {"layer_params": [35, 61, 18], "learning_rate": 0.009280927744884019, "batch_size": 273, "loss": 0.0024703374365344644}, {"layer_params": [58, 38, 51], "learning_rate": 0.009033357487847267, "batch_size": 57, "loss": 0.0034764802642166612}, {"layer_params": [50, 34], "learning_rate": 0.0056369264497737655, "batch_size": 95, "loss": 0.0025305190903600304}, {"layer_params": [37, 49, 16], "learning_rate": 0.002829907520981682, "batch_size": 438, "loss": 0.0016250956687144935}, {"layer_params": [37, 60], "learning_rate": 0.005236229130925007, "batch_size": 250, "loss": 0.0019314767746254802}, {"layer_params": [18, 38], "learning_rate": 0.00039480316339643315, "batch_size": 304, "loss": 0.009274339689873158}, {"layer_params": [17, 37], "learning_rate": 0.00483202077652732, "batch_size": 406, "loss": 0.005231608632020652}, {"layer_params": [51, 37, 44, 39], "learning_rate": 0.009698895551459053, "batch_size": 52, "loss": 0.003642466516466811}, {"layer_params": [28, 41, 37], "learning_rate": 0.006269152247353621, "batch_size": 316, "loss": 0.0022903854947071522}, {"layer_params": [23, 33, 52, 18], "learning_rate": 0.004769693433561007, "batch_size": 29, "loss": 0.006257473630830646}, {"layer_params": [16, 62, 22], "learning_rate": 0.006246573164470147, "batch_size": 228, "loss": 0.003623531155753881}, {"layer_params": [28, 16, 29, 54], "learning_rate": 0.008463582895649566, "batch_size": 472, "loss": 0.0038521962868981064}, {"layer_params": [31, 45], "learning_rate": 0.003411878817278297, "batch_size": 204, "loss": 0.002965894644148648}, {"layer_params": [41, 54, 38, 36], "learning_rate": 0.0004240416941284205, "batch_size": 220, "loss": 0.005843335692770779}, {"layer_params": [27, 62], "learning_rate": 0.0033023197629517254, "batch_size": 100, "loss": 0.0035974728618748484}, {"layer_params": [19, 41], "learning_rate": 0.00305269802880369, "batch_size": 269, "loss": 0.0036355431843549013}, {"layer_params": [16, 20, 42, 42], "learning_rate": 0.0075955057651330956, "batch_size": 172, "loss": 0.003438475299626589}, {"layer_params": [19, 21], "learning_rate": 0.0008402100470392183, "batch_size": 150, "loss": 0.008208570107817649}, {"layer_params": [33, 47, 51, 41], "learning_rate": 0.00796117468563698, "batch_size": 403, "loss": 0.001140396983246319}, {"layer_params": [22, 63, 56, 36, 20], "learning_rate": 0.0027822929666049467, "batch_size": 273, "loss": 0.0023062387062236667}, {"layer_params": [47, 54, 53], "learning_rate": 0.004794698359795425, "batch_size": 309, "loss": 0.0011719957907916979}, {"layer_params": [28, 25, 58, 52, 26], "learning_rate": 0.004136041123156996, "batch_size": 434, "loss": 0.001874697747407481}, {"layer_params": [38, 18], "learning_rate": 0.004507523644233828, "batch_size": 224, "loss": 0.002769825083669275}, {"layer_params": [52, 24, 23, 61], "learning_rate": 0.0022795485499786813, "batch_size": 85, "loss": 0.0035592165356501935}, {"layer_params": [51, 34, 46, 32], "learning_rate": 0.007921636250168465, "batch_size": 363, "loss": 0.001748607011977583}, {"layer_params": [52, 50, 35, 28], "learning_rate": 0.0057010972371017285, "batch_size": 411, "loss": 0.0013840348040685057}, {"layer_params": [42, 31, 27, 51, 19], "learning_rate": 0.005165577396244828, "batch_size": 465, "loss": 0.0009250162210082635}, {"layer_params": [54, 21, 63], "learning_rate": 0.0049060620336918125, "batch_size": 286, "loss": 0.0016337093955371528}, {"layer_params": [47, 41], "learning_rate": 0.006226944337108077, "batch_size": 272, "loss": 0.0015888510586228222}, {"layer_params": [59, 64], "learning_rate": 0.006578530742826508, "batch_size": 117, "loss": 0.0024088521930389108}, {"layer_params": [60, 50, 46, 44], "learning_rate": 0.002817745390674808, "batch_size": 491, "loss": 0.001177033761050552}, {"layer_params": [29, 44], "learning_rate": 0.005117930475010817, "batch_size": 51, "loss": 0.004655832799617201}, {"layer_params": [33, 41, 24, 47, 46], "learning_rate": 0.00983664534251351, "batch_size": 20, "loss": 0.008262960419524462}, {"layer_params": [19, 48], "learning_rate": 0.001435872683278074, "batch_size": 321, "loss": 0.0049176292051561175}, {"layer_params": [60, 37], "learning_rate": 0.0013825399206597306, "batch_size": 498, "loss": 0.0020354368968401103}, {"layer_params": [58, 32, 38], "learning_rate": 0.0032011837089265713, "batch_size": 202, "loss": 0.0018222780001815409}, {"layer_params": [48, 22], "learning_rate": 0.00932592257402837, "batch_size": 414, "loss": 0.001877224020427093}, {"layer_params": [50, 17, 48, 37, 31], "learning_rate": 0.003488861137582664, "batch_size": 391, "loss": 0.002535450519062579}, {"layer_params": [42, 48, 34, 29], "learning_rate": 0.007561190484734859, "batch_size": 100, "loss": 0.002758939751656726}, {"layer_params": [64, 23, 27, 59, 21], "learning_rate": 0.004087124615001139, "batch_size": 85, "loss": 0.004110704693011939}, {"layer_params": [64, 61, 45, 24, 61], "learning_rate": 0.0013790460331484428, "batch_size": 88, "loss": 0.002794992091367021}, {"layer_params": [63, 64], "learning_rate": 0.008869516057756415, "batch_size": 117, "loss": 0.001625103161786683}, {"layer_params": [35, 37, 48, 34], "learning_rate": 0.006747313289536939, "batch_size": 258, "loss": 0.0013430514140054584}, {"layer_params": [63, 62, 25, 63, 45], "learning_rate": 0.006976056476596008, "batch_size": 360, "loss": 0.000755505432607606}, {"layer_params": [26, 55, 17, 43], "learning_rate": 0.0026659812283507094, "batch_size": 367, "loss": 0.002588081273715943}, {"layer_params": [49, 57], "learning_rate": 0.0019638878761001352, "batch_size": 407, "loss": 0.002687331181950867}, {"layer_params": [53, 59, 43, 36], "learning_rate": 0.00040211888697612647, "batch_size": 369, "loss": 0.003869849347975105}, {"layer_params": [46, 56, 43, 45, 20], "learning_rate": 0.0017063566583277667, "batch_size": 470, "loss": 0.002215220998041332}, {"layer_params": [21, 28, 28, 27, 46], "learning_rate": 0.006166534473410281, "batch_size": 437, "loss": 0.002578365565277636}, {"layer_params": [56, 20, 17, 23, 56], "learning_rate": 0.00992041589998262, "batch_size": 426, "loss": 0.0030752469692379237}, {"layer_params": [26, 39, 16, 60, 23], "learning_rate": 0.00011046389863605064, "batch_size": 156, "loss": 0.034215050525963304}, {"layer_params": [63, 29, 47, 33], "learning_rate": 0.008746704253345394, "batch_size": 462, "loss": 0.0011966853321064264}, {"layer_params": [56, 52, 27], "learning_rate": 0.0020047196958307063, "batch_size": 471, "loss": 0.0015634892706293613}, {"layer_params": [38, 37], "learning_rate": 0.005208829209797187, "batch_size": 389, "loss": 0.002891919536050409}, {"layer_params": [27, 31], "learning_rate": 0.005255023708456288, "batch_size": 115, "loss": 0.003594595044851303}, {"layer_params": [63, 44, 33, 20], "learning_rate": 0.001465547170561836, "batch_size": 140, "loss": 0.0021997311851009727}, {"layer_params": [53, 44], "learning_rate": 0.0005702458210001157, "batch_size": 380, "loss": 0.005308783510699868}, {"layer_params": [41, 58, 59, 56, 49], "learning_rate": 0.004766276121575572, "batch_size": 111, "loss": 0.002286316594108939}, {"layer_params": [28, 46, 43], "learning_rate": 0.0014951829826435764, "batch_size": 124, "loss": 0.004057357073761523}, {"layer_params": [60, 33, 29, 22], "learning_rate": 0.005016089444747428, "batch_size": 195, "loss": 0.0015507250226801262}, {"layer_params": [32, 52, 26, 53, 38], "learning_rate": 0.006339915505917512, "batch_size": 70, "loss": 0.0037418994912877678}, {"layer_params": [42, 52], "learning_rate": 0.003403205658404229, "batch_size": 284, "loss": 0.002125616336707026}, {"layer_params": [46, 48, 54, 59, 62], "learning_rate": 0.008504836216490511, "batch_size": 269, "loss": 0.0016438903193920851}, {"layer_params": [22, 21, 64, 36, 46], "learning_rate": 0.009897134347759217, "batch_size": 31, "loss": 0.008402312733232975}, {"layer_params": [34, 64, 28, 44, 25], "learning_rate": 0.00743105626162284, "batch_size": 399, "loss": 0.0011023164191283285}, {"layer_params": [56, 61, 50], "learning_rate": 0.003436403927010404, "batch_size": 417, "loss": 0.001627195783657953}, {"layer_params": [51, 29, 46, 17, 50], "learning_rate": 0.0019625664064402116, "batch_size": 163, "loss": 0.0028750228811986744}, {"layer_params": [38, 50, 26], "learning_rate": 0.00023355122549935525, "batch_size": 388, "loss": 0.006482251528650522}, {"layer_params": [51, 21], "learning_rate": 0.007240766804312198, "batch_size": 249, "loss": 0.0022528054716531186}, {"layer_params": [62, 22], "learning_rate": 0.005298739055363781, "batch_size": 209, "loss": 0.0028497471986338495}, {"layer_params": [38, 34], "learning_rate": 0.008804276042488731, "batch_size": 264, "loss": 0.00236425060313195}, {"layer_params": [35, 43], "learning_rate": 0.007278797812927681, "batch_size": 115, "loss": 0.002159920480335131}, {"layer_params": [24, 54], "learning_rate": 0.0029010562461644377, "batch_size": 147, "loss": 0.0036719114170409737}, {"layer_params": [56, 51, 34], "learning_rate": 0.0005559591492967416, "batch_size": 60, "loss": 0.006106233417522162}, {"layer_params": [55, 19, 46], "learning_rate": 0.002335817014290721, "batch_size": 21, "loss": 0.007594331167638302}, {"layer_params": [27, 33, 37, 31], "learning_rate": 0.009331187082234772, "batch_size": 423, "loss": 0.002203849951038137}, {"layer_params": [54, 50, 37, 25, 37], "learning_rate": 0.0019235476351621278, "batch_size": 95, "loss": 0.0026500671671237795}, {"layer_params": [40, 49, 59, 60, 36], "learning_rate": 0.007555907605602215, "batch_size": 241, "loss": 0.0008088968973606825}, {"layer_params": [63, 46, 31, 20, 48], "learning_rate": 0.009680328781292807, "batch_size": 50, "loss": 0.003614543799776584}, {"layer_params": [38, 46], "learning_rate": 0.007523869420405754, "batch_size": 505, "loss": 0.0018537408532574772}, {"layer_params": [21, 45], "learning_rate": 0.003738355610004359, "batch_size": 121, "loss": 0.0034047764539718627}, {"layer_params": [52, 37], "learning_rate": 9.83380202032941e-05, "batch_size": 149, "loss": 0.025447586216032506}, {"layer_params": [38, 50, 28], "learning_rate": 0.0005923156499505156, "batch_size": 99, "loss": 0.006593514867126941}, {"layer_params": [39, 31], "learning_rate": 0.0053611387337221626, "batch_size": 227, "loss": 0.0028192866034805774}, {"layer_params": [62, 24, 48], "learning_rate": 0.007631467970249387, "batch_size": 118, "loss": 0.0017175738431978972}, {"layer_params": [37, 53, 17, 39], "learning_rate": 0.009707674959024, "batch_size": 407, "loss": 0.0027893002284690737}, {"layer_params": [31, 47, 32, 19], "learning_rate": 0.007267542872621831, "batch_size": 403, "loss": 0.0015462872793432325}, {"layer_params": [34, 29, 49], "learning_rate": 0.005733723938292021, "batch_size": 146, "loss": 0.0026830553589388727}, {"layer_params": [27, 47, 28], "learning_rate": 0.0038033590255702023, "batch_size": 438, "loss": 0.0023378224100451916}, {"layer_params": [54, 64, 62, 33, 16], "learning_rate": 0.009467934369699746, "batch_size": 409, "loss": 0.0018280461826361716}, {"layer_params": [23, 38, 53, 31], "learning_rate": 0.008479860559845197, "batch_size": 295, "loss": 0.0027128767140675338}, {"layer_params": [50, 48, 40, 59, 37], "learning_rate": 0.006352328997501208, "batch_size": 101, "loss": 0.0018437744944822044}, {"layer_params": [44, 53, 63], "learning_rate": 0.0065583197542190864, "batch_size": 29, "loss": 0.0065441565169021484}, {"layer_params": [21, 49, 27, 64, 17], "learning_rate": 0.00381545772683349, "batch_size": 225, "loss": 0.002205797376809642}, {"layer_params": [18, 31, 54, 23, 63], "learning_rate": 0.0016458186586810364, "batch_size": 495, "loss": 0.002770551478024572}, {"layer_params": [27, 31, 20, 56], "learning_rate": 0.004890164530244347, "batch_size": 80, "loss": 0.003261740660527721}, {"layer_params": [19, 16, 34, 52], "learning_rate": 0.00865442109870537, "batch_size": 256, "loss": 0.004314394735265523}, {"layer_params": [57, 20], "learning_rate": 0.00756979163827388, "batch_size": 393, "loss": 0.0017967831902205944}, {"layer_params": [62, 32], "learning_rate": 0.0035400764435055384, "batch_size": 283, "loss": 0.0025695863156579434}, {"layer_params": [36, 53, 63, 36], "learning_rate": 0.005723393355105981, "batch_size": 389, "loss": 0.0009632362343836576}, {"layer_params": [52, 20, 30, 22], "learning_rate": 0.009092030483240124, "batch_size": 191, "loss": 0.0029421682516112923}, {"layer_params": [33, 26, 58, 18, 51], "learning_rate": 0.009438056632733146, "batch_size": 78, "loss": 0.0058634028071537616}, {"layer_params": [57, 55, 46, 28], "learning_rate": 0.009280287502997604, "batch_size": 125, "loss": 0.0024813987128436566}, {"layer_params": [44, 35, 22, 28, 27], "learning_rate": 0.001134276194844761, "batch_size": 305, "loss": 0.0037944044731557367}, {"layer_params": [47, 34, 26, 45], "learning_rate": 0.006233838423494288, "batch_size": 221, "loss": 0.002314323087921366}, {"layer_params": [39, 53], "learning_rate": 0.008890387889971988, "batch_size": 97, "loss": 0.006563856997527182}, {"layer_params": [45, 46, 43], "learning_rate": 0.00021022436109349236, "batch_size": 70, "loss": 0.009293391271494329}, {"layer_params": [16, 19, 44, 34], "learning_rate": 0.003051347042705362, "batch_size": 153, "loss": 0.005796906175091863}, {"layer_params": [36, 29, 54, 17], "learning_rate": 0.007853405112632585, "batch_size": 84, "loss": 0.00319576402194798}, {"layer_params": [18, 46], "learning_rate": 0.009818121340328875, "batch_size": 457, "loss": 0.003053509867750108}, {"layer_params": [48, 61, 48, 45], "learning_rate": 0.008660219475650844, "batch_size": 362, "loss": 0.0010269371088361368}, {"layer_params": [21, 63], "learning_rate": 0.008599034012238663, "batch_size": 139, "loss": 0.0020852221990935505}, {"layer_params": [30, 39, 44], "learning_rate": 0.0034215753565164926, "batch_size": 225, "loss": 0.003060285022947937}, {"layer_params": [53, 46, 24], "learning_rate": 0.008460015448341664, "batch_size": 372, "loss": 0.0007994261430576444}, {"layer_params": [50, 28, 43, 48], "learning_rate": 0.009014708722895027, "batch_size": 468, "loss": 0.0007739042496541515}, {"layer_params": [52, 45], "learning_rate": 0.008543683534973418, "batch_size": 249, "loss": 0.0019879274535924197}, {"layer_params": [56, 18, 37, 38], "learning_rate": 0.0010826157691180233, "batch_size": 502, "loss": 0.003650865787640214}, {"layer_params": [25, 26, 37, 31, 21], "learning_rate": 0.004459224699523266, "batch_size": 402, "loss": 0.0018044340866617858}, {"layer_params": [56, 22, 37], "learning_rate": 0.0031797311421808624, "batch_size": 419, "loss": 0.0013671359955333172}, {"layer_params": [27, 38, 46], "learning_rate": 0.006832901304888171, "batch_size": 64, "loss": 0.003914528607856483}, {"layer_params": [43, 39, 38], "learning_rate": 0.007459253650464808, "batch_size": 459, "loss": 0.0018065181968268007}, {"layer_params": [35, 38, 39], "learning_rate": 0.0064876486370497284, "batch_size": 175, "loss": 0.0026864448538981376}, {"layer_params": [63, 49, 35], "learning_rate": 0.004810679887362457, "batch_size": 454, "loss": 0.0009511633921647445}, {"layer_params": [54, 50], "learning_rate": 0.0007546150813608035, "batch_size": 19, "loss": 0.008669246167410166}, {"layer_params": [48, 55], "learning_rate": 0.005881437665273773, "batch_size": 419, "loss": 0.0010297074727714062}, {"layer_params": [59, 43, 30, 56, 25], "learning_rate": 0.008546822314088497, "batch_size": 309, "loss": 0.0010127701720921323}, {"layer_params": [25, 20], "learning_rate": 0.009165919017636939, "batch_size": 123, "loss": 0.003630338511429727}, {"layer_params": [16, 57], "learning_rate": 0.006970659180961722, "batch_size": 196, "loss": 0.0032775714807212353}, {"layer_params": [32, 54, 47], "learning_rate": 0.002380746428273075, "batch_size": 253, "loss": 0.0022665514482650907}, {"layer_params": [19, 47, 17], "learning_rate": 0.005088722901799526, "batch_size": 139, "loss": 0.002903920386452228}, {"layer_params": [62, 55, 45], "learning_rate": 0.005942757815209167, "batch_size": 449, "loss": 0.001069176007877104}, {"layer_params": [28, 17, 48, 61, 45], "learning_rate": 0.009847612544791903, "batch_size": 392, "loss": 0.003139987087342888}, {"layer_params": [36, 36], "learning_rate": 0.004700419803013764, "batch_size": 336, "loss": 0.0030452231294475496}, {"layer_params": [56, 21, 49], "learning_rate": 0.005372811482382119, "batch_size": 142, "loss": 0.0022237767081242053}, {"layer_params": [18, 60, 40], "learning_rate": 0.007738178360373282, "batch_size": 430, "loss": 0.0024600726028438658}, {"layer_params": [25, 36, 57], "learning_rate": 0.007598603231427405, "batch_size": 108, "loss": 0.004501382736489177}, {"layer_params": [57, 42, 33, 30, 29], "learning_rate": 0.005956942384717504, "batch_size": 404, "loss": 0.0019439438229892402}, {"layer_params": [48, 49], "learning_rate": 0.0002172303384551703, "batch_size": 133, "loss": 0.009916055970825255}, {"layer_params": [56, 17], "learning_rate": 0.003170005944140717, "batch_size": 462, "loss": 0.0034757304354570808}, {"layer_params": [41, 46], "learning_rate": 0.006467685794469552, "batch_size": 428, "loss": 0.0018031189625617116}, {"layer_params": [43, 55, 16, 41], "learning_rate": 0.006151693214020315, "batch_size": 439, "loss": 0.0014467757486272604}, {"layer_params": [26, 36, 27], "learning_rate": 0.0025157713055133056, "batch_size": 206, "loss": 0.0036230106325820088}, {"layer_params": [60, 21, 57, 28], "learning_rate": 0.007497262696299098, "batch_size": 58, "loss": 0.00349377715960145}, {"layer_params": [62, 30, 22, 16, 50], "learning_rate": 0.009290606742692812, "batch_size": 16, "loss": 0.009157717246562242}, {"layer_params": [18, 56, 63, 18], "learning_rate": 0.006886642356238034, "batch_size": 98, "loss": 0.004830533594358712}, {"layer_params": [28, 35, 59, 17], "learning_rate": 0.009660869186448758, "batch_size": 364, "loss": 0.001568181765032932}, {"layer_params": [41, 51], "learning_rate": 0.004426102458326258, "batch_size": 298, "loss": 0.0022445694671478123}, {"layer_params": [19, 42, 19, 34], "learning_rate": 0.0072924645281553305, "batch_size": 77, "loss": 0.00412066146498546}, {"layer_params": [44, 21, 56, 23, 27], "learning_rate": 0.004020807524620687, "batch_size": 396, "loss": 0.0017148168466519565}, {"layer_params": [55, 44, 39], "learning_rate": 0.009557246892357464, "batch_size": 298, "loss": 0.0020264985458925367}, {"layer_params": [30, 17, 42, 60], "learning_rate": 0.005202096945330373, "batch_size": 149, "loss": 0.003647116783540696}, {"layer_params": [30, 38], "learning_rate": 0.0013748477796692064, "batch_size": 493, "loss": 0.004661647789180279}, {"layer_params": [63, 50], "learning_rate": 0.005549688983012145, "batch_size": 327, "loss": 0.0018560891097877175}, {"layer_params": [20, 35, 56, 22], "learning_rate": 0.0027602800261375213, "batch_size": 508, "loss": 0.0018992600170895458}, {"layer_params": [54, 44, 57], "learning_rate": 0.005204844138855076, "batch_size": 244, "loss": 0.0017163223191164435}, {"layer_params": [35, 16], "learning_rate": 0.0018402188920292953, "batch_size": 241, "loss": 0.004061148164328188}, {"layer_params": [22, 51], "learning_rate": 0.00624517695993021, "batch_size": 254, "loss": 0.0024196549213957043}, {"layer_params": [56, 36, 25, 35, 59], "learning_rate": 0.005126823541417774, "batch_size": 493, "loss": 0.0009625094092916697}, {"layer_params": [37, 43, 59, 38, 47], "learning_rate": 0.0055237688359010325, "batch_size": 271, "loss": 0.0010682625061599537}, {"layer_params": [25, 49], "learning_rate": 0.005007395575018411, "batch_size": 364, "loss": 0.0018828392901923507}, {"layer_params": [34, 63, 38, 27, 47], "learning_rate": 0.009683636800075678, "batch_size": 376, "loss": 0.0013948105671443044}, {"layer_params": [39, 51], "learning_rate": 0.008349855754996135, "batch_size": 478, "loss": 0.0017050525546073913}, {"layer_params": [45, 28], "learning_rate": 0.0023935328459399508, "batch_size": 55, "loss": 0.0061013912898488344}, {"layer_params": [30, 31], "learning_rate": 0.00695159613813663, "batch_size": 56, "loss": 0.003335487419972196}, {"layer_params": [41, 17, 49, 58, 42], "learning_rate": 0.0061203441620227015, "batch_size": 248, "loss": 0.002439593564486131}, {"layer_params": [55, 53, 19, 39], "learning_rate": 0.003964614565119065, "batch_size": 367, "loss": 0.0013059819547925145}, {"layer_params": [59, 19, 46, 25, 63], "learning_rate": 0.009468325047526543, "batch_size": 335, "loss": 0.0018359739391598851}, {"layer_params": [57, 48], "learning_rate": 0.0017739028809192177, "batch_size": 73, "loss": 0.0056816158769652245}, {"layer_params": [36, 19], "learning_rate": 0.0018590290646887102, "batch_size": 50, "loss": 0.00723807503003627}, {"layer_params": [45, 38, 30, 35, 33], "learning_rate": 0.008844075936270103, "batch_size": 334, "loss": 0.001619360054610297}, {"layer_params": [36, 56], "learning_rate": 0.0005944439608281016, "batch_size": 421, "loss": 0.0042096549877896905}, {"layer_params": [28, 33, 46], "learning_rate": 0.009899106433623938, "batch_size": 298, "loss": 0.0017740830883849412}, {"layer_params": [56, 58, 46, 42, 22], "learning_rate": 0.001115127903951302, "batch_size": 352, "loss": 0.0014501655427739024}, {"layer_params": [46, 28, 27], "learning_rate": 0.0009362572319638354, "batch_size": 229, "loss": 0.004137783164624125}, {"layer_params": [27, 54, 32], "learning_rate": 0.007647836907219086, "batch_size": 69, "loss": 0.002658207864733413}, {"layer_params": [54, 25, 16, 46], "learning_rate": 0.006047556428687093, "batch_size": 289, "loss": 0.0029168227245099845}, {"layer_params": [37, 31, 28, 28, 17], "learning_rate": 0.006610248393291187, "batch_size": 121, "loss": 0.0021424944419413806}, {"layer_params": [22, 34, 50, 46], "learning_rate": 0.00990979737943821, "batch_size": 323, "loss": 0.0023122098413296045}, {"layer_params": [31, 27, 28, 62, 47], "learning_rate": 0.0017435202490807416, "batch_size": 427, "loss": 0.0024521746241953223}, {"layer_params": [63, 46, 51, 56], "learning_rate": 0.003142910740790824, "batch_size": 144, "loss": 0.0022288079292047767}, {"layer_params": [55, 18, 63, 55], "learning_rate": 0.005397421728448246, "batch_size": 181, "loss": 0.002522981931688264}, {"layer_params": [40, 38], "learning_rate": 0.005958053558083156, "batch_size": 322, "loss": 0.0029503719392232597}, {"layer_params": [51, 46, 35], "learning_rate": 0.007623166168145804, "batch_size": 471, "loss": 0.0009195087145781144}, {"layer_params": [56, 30, 17], "learning_rate": 0.006350164420418958, "batch_size": 47, "loss": 0.0032410649908706547}, {"layer_params": [33, 16, 59], "learning_rate": 0.0024870456948718742, "batch_size": 385, "loss": 0.0029032982303760944}, {"layer_params": [55, 31], "learning_rate": 0.005094971199936179, "batch_size": 363, "loss": 0.0022639937850181015}, {"layer_params": [31, 58, 49, 26, 39], "learning_rate": 0.009192066252404811, "batch_size": 430, "loss": 0.0014418852189555765}, {"layer_params": [39, 58, 22], "learning_rate": 0.0023453727357295126, "batch_size": 96, "loss": 0.0026002743968274442}, {"layer_params": [33, 38, 55], "learning_rate": 0.0069362733355027035, "batch_size": 195, "loss": 0.0019922355830203744}, {"layer_params": [25, 34], "learning_rate": 0.0031441509868275893, "batch_size": 185, "loss": 0.0033220193907618524}, {"layer_params": [58, 16, 53, 64], "learning_rate": 0.005404725887229993, "batch_size": 350, "loss": 0.0008929325325880199}, {"layer_params": [62, 31, 33], "learning_rate": 0.0014709642847539357, "batch_size": 18, "loss": 0.00671897070016712}, {"layer_params": [53, 54, 16], "learning_rate": 0.006298407471858019, "batch_size": 449, "loss": 0.0012772992858663202}, {"layer_params": [23, 19, 32, 62], "learning_rate": 0.006527671057713189, "batch_size": 75, "loss": 0.00488177087623626}, {"layer_params": [41, 17, 62, 55, 29], "learning_rate": 0.002672920864740065, "batch_size": 479, "loss": 0.0018254723481368274}, {"layer_params": [43, 54, 23, 50], "learning_rate": 0.002060518482509136, "batch_size": 91, "loss": 0.0031886120489798488}, {"layer_params": [38, 52, 45, 23], "learning_rate": 0.007131578807588587, "batch_size": 88, "loss": 0.0018719798978418113}, {"layer_params": [51, 37, 41, 27], "learning_rate": 0.0017888804725816813, "batch_size": 74, "loss": 0.0037184942327439783}, {"layer_params": [26, 24, 53], "learning_rate": 0.006343873407365566, "batch_size": 27, "loss": 0.006386357632}, {"layer_params": [33, 16, 29, 63, 57], "learning_rate": 0.006877133387895477, "batch_size": 512, "loss": 0.0024557570356409995}, {"layer_params": [62, 31], "learning_rate": 0.004746811455706056, "batch_size": 58, "loss": 0.003114625628804788}, {"layer_params": [56, 57, 40, 57], "learning_rate": 0.0063507838799875625, "batch_size": 131, "loss": 0.001447455883026123}, {"layer_params": [60, 57, 59, 28], "learning_rate": 0.00524160959375866, "batch_size": 430, "loss": 0.001210839053383097}, {"layer_params": [19, 43, 21, 39, 35], "learning_rate": 0.005323588075545993, "batch_size": 273, "loss": 0.002880296476650983}, {"layer_params": [49, 18], "learning_rate": 0.007010598291274064, "batch_size": 243, "loss": 0.004361577043309808}, {"layer_params": [46, 58, 37], "learning_rate": 0.009785573622904366, "batch_size": 281, "loss": 0.0014579260302707553}, {"layer_params": [34, 33], "learning_rate": 0.006756505916663733, "batch_size": 464, "loss": 0.0021700287074781954}, {"layer_params": [16, 29], "learning_rate": 0.0008505875083157496, "batch_size": 428, "loss": 0.007383614829741418}, {"layer_params": [19, 63, 53, 22], "learning_rate": 0.0024732748553719245, "batch_size": 221, "loss": 0.0023412884923163803}, {"layer_params": [53, 56, 52, 17], "learning_rate": 0.0008728809134772505, "batch_size": 26, "loss": 0.007092055955436081}, {"layer_params": [26, 47, 18], "learning_rate": 0.004116325038072019, "batch_size": 36, "loss": 0.004617494879057631}, {"layer_params": [22, 33, 59], "learning_rate": 0.008763949758289825, "batch_size": 462, "loss": 0.0023307471838779747}, {"layer_params": [46, 22, 41, 24], "learning_rate": 0.008819186156852574, "batch_size": 98, "loss": 0.004588562331628054}, {"layer_params": [19, 53, 35, 58], "learning_rate": 0.008581327244802994, "batch_size": 392, "loss": 0.002131926012225449}, {"layer_params": [52, 44, 42, 23], "learning_rate": 0.008349842738618888, "batch_size": 91, "loss": 0.0017650482489261776}, {"layer_params": [56, 32], "learning_rate": 0.0009644488966894895, "batch_size": 403, "loss": 0.005306405858136714}, {"layer_params": [52, 24, 19, 35], "learning_rate": 0.00441843030159526, "batch_size": 487, "loss": 0.0025195310707204046}, {"layer_params": [35, 17, 18], "learning_rate": 0.009797227384362882, "batch_size": 252, "loss": 0.002246727168094367}, {"layer_params": [47, 29, 22, 18], "learning_rate": 0.005263169437362813, "batch_size": 322, "loss": 0.0014242096652742474}, {"layer_params": [40, 43, 22], "learning_rate": 0.003818244417741314, "batch_size": 338, "loss": 0.0021135606605093924}, {"layer_params": [55, 64, 27, 36], "learning_rate": 0.008567939013324545, "batch_size": 443, "loss": 0.0008290942444000393}, {"layer_params": [32, 44, 34, 36, 52], "learning_rate": 0.007828661054718291, "batch_size": 460, "loss": 0.0017614295019302518}, {"layer_params": [59, 35, 62, 21], "learning_rate": 0.005184483143902788, "batch_size": 90, "loss": 0.0021990821324288845}, {"layer_params": [22, 55], "learning_rate": 0.0016919980150106304, "batch_size": 218, "loss": 0.004671439100056887}, {"layer_params": [42, 63, 28], "learning_rate": 0.008729493427206617, "batch_size": 139, "loss": 0.0012349413929041474}, {"layer_params": [36, 61], "learning_rate": 0.00948184969141562, "batch_size": 169, "loss": 0.0020997604739386587}, {"layer_params": [49, 23, 43], "learning_rate": 0.0012614144222403236, "batch_size": 319, "loss": 0.003446131490636617}, {"layer_params": [17, 37, 38, 62], "learning_rate": 0.006724547668835689, "batch_size": 330, "loss": 0.0020506617915816605}, {"layer_params": [37, 46, 29], "learning_rate": 0.005844426177999905, "batch_size": 360, "loss": 0.0015534801594913007}, {"layer_params": [20, 57], "learning_rate": 0.007294694295925328, "batch_size": 235, "loss": 0.002712748704943806}, {"layer_params": [63, 19, 58, 18], "learning_rate": 0.0011317151274384816, "batch_size": 474, "loss": 0.003503156348597258}, {"layer_params": [59, 54, 17, 35], "learning_rate": 0.0066170064931433716, "batch_size": 118, "loss": 0.002353932688711211}, {"layer_params": [37, 37, 61, 63], "learning_rate": 0.008889331985672813, "batch_size": 501, "loss": 0.000743627964402549}, {"layer_params": [60, 38], "learning_rate": 0.008614476099973139, "batch_size": 288, "loss": 0.001967554627917707}, {"layer_params": [57, 17, 28, 58], "learning_rate": 0.0077451628356133935, "batch_size": 26, "loss": 0.00666896489681676}, {"layer_params": [52, 41, 34, 61, 31], "learning_rate": 0.005318633191460038, "batch_size": 284, "loss": 0.0012801541324006394}, {"layer_params": [59, 59, 25, 60], "learning_rate": 0.007991179458676575, "batch_size": 374, "loss": 0.0009389451396418735}, {"layer_params": [49, 32, 51], "learning_rate": 0.006884122703564092, "batch_size": 314, "loss": 0.0009398002037778497}, {"layer_params": [51, 30], "learning_rate": 0.009074611232445684, "batch_size": 504, "loss": 0.0013647103135008365}, {"layer_params": [21, 55, 28], "learning_rate": 0.0018086262366235869, "batch_size": 186, "loss": 0.0037968103610910475}, {"layer_params": [41, 54, 19, 22], "learning_rate": 0.009162021451831879, "batch_size": 212, "loss": 0.004034526806790382}, {"layer_params": [39, 47, 47], "learning_rate": 0.0006235303596048166, "batch_size": 434, "loss": 0.0041854766313917935}, {"layer_params": [35, 64, 24], "learning_rate": 0.0027151011860381156, "batch_size": 42, "loss": 0.0038999139168299736}, {"layer_params": [43, 46, 52], "learning_rate": 0.0054224262437230705, "batch_size": 133, "loss": 0.0020611237897537648}, {"layer_params": [44, 49, 42], "learning_rate": 0.007473505760669131, "batch_size": 233, "loss": 0.0021668611839413643}, {"layer_params": [18, 42, 18], "learning_rate": 0.00412663625977971, "batch_size": 203, "loss": 0.005867669084109366}, {"layer_params": [41, 47], "learning_rate": 0.0029071162327389756, "batch_size": 206, "loss": 0.0035673829936422406}, {"layer_params": [43, 44, 36], "learning_rate": 0.005415715389211845, "batch_size": 123, "loss": 0.00205987217486836}, {"layer_params": [51, 17, 31], "learning_rate": 0.007833049356756902, "batch_size": 176, "loss": 0.002337081232108176}, {"layer_params": [40, 47, 57, 33], "learning_rate": 0.0027662000849528667, "batch_size": 49, "loss": 0.004427215962205082}, {"layer_params": [45, 24, 41, 61], "learning_rate": 0.00506637779869448, "batch_size": 282, "loss": 0.001653298184974119}, {"layer_params": [47, 30], "learning_rate": 0.000170734740448488, "batch_size": 294, "loss": 0.008882315997034311}, {"layer_params": [44, 51, 17], "learning_rate": 0.002133413213156494, "batch_size": 376, "loss": 0.0019041511218529194}, {"layer_params": [60, 19], "learning_rate": 0.0007615668296704833, "batch_size": 458, "loss": 0.005130261071026325}, {"layer_params": [39, 35, 18, 39, 19], "learning_rate": 0.003212979824622114, "batch_size": 412, "loss": 0.001611519327852875}, {"layer_params": [57, 29, 36, 43], "learning_rate": 0.004623191423637778, "batch_size": 104, "loss": 0.0028006704605650157}, {"layer_params": [21, 62, 62, 24], "learning_rate": 0.00889191562299734, "batch_size": 54, "loss": 0.004563884681556374}, {"layer_params": [22, 55, 39, 18, 55], "learning_rate": 0.008033810081744558, "batch_size": 276, "loss": 0.0019079543673433364}, {"layer_params": [36, 24], "learning_rate": 0.00616071264837738, "batch_size": 216, "loss": 0.001767257151659578}, {"layer_params": [42, 36, 61, 48, 37], "learning_rate": 0.0035619981657844793, "batch_size": 210, "loss": 0.001634032295551151}, {"layer_params": [35, 59], "learning_rate": 0.009434884107120576, "batch_size": 316, "loss": 0.0017091120372060686}, {"layer_params": [42, 34, 57, 42], "learning_rate": 0.0028389649738408277, "batch_size": 235, "loss": 0.002020033315056935}, {"layer_params": [50, 21, 44, 61, 57], "learning_rate": 0.002889100942828545, "batch_size": 280, "loss": 0.00188847579061985}, {"layer_params": [34, 29, 51, 63], "learning_rate": 0.00040101190427641335, "batch_size": 296, "loss": 0.006193845886737108}, {"layer_params": [34, 41, 50], "learning_rate": 0.000492763316495474, "batch_size": 321, "loss": 0.004842540696263314}, {"layer_params": [53, 48, 37, 64, 52], "learning_rate": 0.005278416321461221, "batch_size": 341, "loss": 0.001040337875019759}, {"layer_params": [60, 57], "learning_rate": 0.000697241754961086, "batch_size": 494, "loss": 0.003913516120519489}, {"layer_params": [22, 34, 63], "learning_rate": 0.007410455269206715, "batch_size": 142, "loss": 0.0019667540234513583}, {"layer_params": [26, 41, 40, 18], "learning_rate": 0.0019606692428217783, "batch_size": 62, "loss": 0.0073933353112079206}, {"layer_params": [60, 17], "learning_rate": 0.00881107100662773, "batch_size": 405, "loss": 0.0022016139957122503}, {"layer_params": [57, 40, 21, 18], "learning_rate": 0.009390702872122634, "batch_size": 102, "loss": 0.0022897610429208726}, {"layer_params": [62, 62, 27, 36, 23], "learning_rate": 0.005215191451484496, "batch_size": 203, "loss": 0.001008385696914047}, {"layer_params": [60, 39, 29], "learning_rate": 0.0016407301660738044, "batch_size": 390, "loss": 0.0038053273689001798}, {"layer_params": [60, 23, 62, 28], "learning_rate": 0.008718481819831257, "batch_size": 275, "loss": 0.002149478015489876}, {"layer_params": [63, 21, 31, 41, 60], "learning_rate": 0.009284725419825174, "batch_size": 39, "loss": 0.0059854059596546}, {"layer_params": [28, 46, 42, 24, 45], "learning_rate": 0.004717932184853363, "batch_size": 408, "loss": 0.002136548971757293}, {"layer_params": [26, 35, 53, 34], "learning_rate": 0.0075044924018551245, "batch_size": 99, "loss": 0.003368590709287673}, {"layer_params": [34, 32, 54, 25, 49], "learning_rate": 0.009834386818046718, "batch_size": 170, "loss": 0.002125300088664517}, {"layer_params": [33, 33, 35, 41, 45], "learning_rate": 0.008422706250724266, "batch_size": 202, "loss": 0.0033790251100435853}, {"layer_params": [64, 19, 63], "learning_rate": 0.00819654669192514, "batch_size": 336, "loss": 0.0021473193273413927}, {"layer_params": [55, 38], "learning_rate": 0.006900006812263719, "batch_size": 51, "loss": 0.003799326189327985}, {"layer_params": [57, 28, 36, 56, 19], "learning_rate": 0.0045186981712222445, "batch_size": 293, "loss": 0.0014698770118411631}, {"layer_params": [26, 48, 55, 44, 53], "learning_rate": 0.005028062968031682, "batch_size": 105, "loss": 0.00309184241341427}, {"layer_params": [21, 53, 52], "learning_rate": 0.005864303255385787, "batch_size": 331, "loss": 0.0015619965631049127}, {"layer_params": [28, 28, 16, 55], "learning_rate": 0.00663017633448737, "batch_size": 98, "loss": 0.003115828884765506}, {"layer_params": [43, 35, 25, 17, 30], "learning_rate": 0.001387628701464617, "batch_size": 340, "loss": 0.0034295851853676142}, {"layer_params": [52, 58, 46], "learning_rate": 0.004259471659249514, "batch_size": 413, "loss": 0.0013421935844235122}, {"layer_params": [28, 21, 57], "learning_rate": 0.005871948161947729, "batch_size": 186, "loss": 0.0018744642625097186}, {"layer_params": [63, 23, 53, 34], "learning_rate": 0.004301848755842975, "batch_size": 85, "loss": 0.004608805370517075}, {"layer_params": [56, 62, 33, 60], "learning_rate": 0.004596926128004095, "batch_size": 333, "loss": 0.0010615182190667838}, {"layer_params": [43, 64, 32, 60, 41], "learning_rate": 0.006152733095327819, "batch_size": 509, "loss": 0.0011741102195810527}, {"layer_params": [43, 36], "learning_rate": 0.0027019481035920998, "batch_size": 465, "loss": 0.00255405638134107}, {"layer_params": [31, 64, 53], "learning_rate": 0.004039209022922819, "batch_size": 129, "loss": 0.0021074307651724666}, {"layer_params": [42, 39, 31, 45, 20], "learning_rate": 0.00706635161472759, "batch_size": 366, "loss": 0.0016970636392943561}, {"layer_params": [32, 22], "learning_rate": 0.00011382133906131823, "batch_size": 86, "loss": 0.034275072067976}, {"layer_params": [40, 20, 19], "learning_rate": 0.006982323492795328, "batch_size": 485, "loss": 0.003394919878337532}, {"layer_params": [28, 18], "learning_rate": 0.0015951423522419371, "batch_size": 375, "loss": 0.005903621590696275}, {"layer_params": [47, 46, 40, 47], "learning_rate": 0.00041339968603996334, "batch_size": 462, "loss": 0.0039689195272512735}, {"layer_params": [51, 37, 32, 59, 24], "learning_rate": 0.00273831813656898, "batch_size": 429, "loss": 0.001410024721408263}, {"layer_params": [33, 21, 18, 48, 52], "learning_rate": 0.0016099505965085676, "batch_size": 346, "loss": 0.0038736510323360562}, {"layer_params": [47, 57], "learning_rate": 0.006284354359532515, "batch_size": 75, "loss": 0.0024112860881723465}, {"layer_params": [60, 24, 32], "learning_rate": 0.0007845275232036905, "batch_size": 446, "loss": 0.0027562075178138913}, {"layer_params": [64, 21], "learning_rate": 0.004512481796525577, "batch_size": 337, "loss": 0.0018431964586488902}, {"layer_params": [45, 52, 38, 57], "learning_rate": 5.3137491106533996e-05, "batch_size": 277, "loss": 0.03608602542430162}, {"layer_params": [47, 56, 49], "learning_rate": 0.00019733422818399152, "batch_size": 217, "loss": 0.006934696529060602}, {"layer_params": [61, 64, 46, 61, 22], "learning_rate": 0.009130023636271176, "batch_size": 179, "loss": 0.0012983107770560309}, {"layer_params": [51, 31, 46, 52], "learning_rate": 0.007350980875540516, "batch_size": 275, "loss": 0.000857933172956109}, {"layer_params": [32, 26], "learning_rate": 0.0006060329620499205, "batch_size": 158, "loss": 0.008005955861881376}, {"layer_params": [30, 63], "learning_rate": 0.004894289375948421, "batch_size": 45, "loss": 0.0030617657478433104}, {"layer_params": [22, 26, 26, 39, 19], "learning_rate": 0.00938741170834113, "batch_size": 357, "loss": 0.0022283328499179333}, {"layer_params": [44, 20], "learning_rate": 0.006889144931133807, "batch_size": 400, "loss": 0.003349105603992939}, {"layer_params": [54, 20], "learning_rate": 0.004551293776845341, "batch_size": 93, "loss": 0.0030633938452228906}, {"layer_params": [29, 55], "learning_rate": 0.004532925928847607, "batch_size": 108, "loss": 0.0027731824887450786}, {"layer_params": [33, 16, 61, 30, 60], "learning_rate": 0.003766702610112204, "batch_size": 175, "loss": 0.0030158198880963025}, {"layer_params": [56, 27, 53, 30, 22], "learning_rate": 0.0062272200278875945, "batch_size": 249, "loss": 0.0018494445807300509}, {"layer_params": [24, 52, 42, 62, 48], "learning_rate": 0.00737363580012997, "batch_size": 482, "loss": 0.0014130563638173044}, {"layer_params": [39, 38, 43, 60], "learning_rate": 0.002131000967789667, "batch_size": 180, "loss": 0.0029014021437615157}, {"layer_params": [24, 44, 52, 45, 19], "learning_rate": 0.007579363328726759, "batch_size": 176, "loss": 0.0021175595407839864}, {"layer_params": [57, 38, 25], "learning_rate": 0.006481201798173243, "batch_size": 303, "loss": 0.0014036711252992972}, {"layer_params": [60, 43], "learning_rate": 0.005094260271786462, "batch_size": 407, "loss": 0.0019428292091470212}, {"layer_params": [50, 53], "learning_rate": 0.0019044238359466183, "batch_size": 36, "loss": 0.0055621293419972065}, {"layer_params": [44, 19], "learning_rate": 0.004785707168979628, "batch_size": 235, "loss": 0.0033628632058389485}, {"layer_params": [62, 51, 22, 41], "learning_rate": 0.007306349014748237, "batch_size": 469, "loss": 0.0012824300507782028}, {"layer_params": [27, 21, 50, 30], "learning_rate": 0.008274030616965806, "batch_size": 217, "loss": 0.003442218881100416}, {"layer_params": [55, 16, 42, 53, 45], "learning_rate": 0.002065119071945409, "batch_size": 318, "loss": 0.0027855230192653834}, {"layer_params": [59, 30, 40, 35, 28], "learning_rate": 0.0069718348728510715, "batch_size": 142, "loss": 0.0015512080665212125}, {"layer_params": [48, 64, 53, 19], "learning_rate": 0.0029731527154788764, "batch_size": 319, "loss": 0.0013478592725005001}, {"layer_params": [32, 44, 37], "learning_rate": 0.007555705617032138, "batch_size": 135, "loss": 0.0017678337800316512}, {"layer_params": [53, 36, 39], "learning_rate": 0.0035954750777499648, "batch_size": 447, "loss": 0.0017717444687150418}, {"layer_params": [53, 64], "learning_rate": 0.0015598579840642034, "batch_size": 96, "loss": 0.0028773228207137434}, {"layer_params": [47, 16, 42, 64, 58], "learning_rate": 0.004712455397744678, "batch_size": 54, "loss": 0.004745921660214663}, {"layer_params": [56, 22, 16, 44, 44], "learning_rate": 0.005978902922616437, "batch_size": 329, "loss": 0.0029159671370871366}, {"layer_params": [47, 53, 33, 40], "learning_rate": 0.009254731106998395, "batch_size": 154, "loss": 0.001367760536959395}, {"layer_params": [54, 18], "learning_rate": 0.008718131672703891, "batch_size": 19, "loss": 0.007948355129919947}, {"layer_params": [44, 43, 41], "learning_rate": 0.009087351127766636, "batch_size": 286, "loss": 0.002084132801974192}, {"layer_params": [61, 44, 16, 19], "learning_rate": 0.005109234267244683, "batch_size": 377, "loss": 0.0008168768795439973}, {"layer_params": [27, 20, 34, 26, 16], "learning_rate": 0.0004334991301437127, "batch_size": 319, "loss": 0.00735731516033411}, {"layer_params": [46, 47, 31], "learning_rate": 0.006450320048781037, "batch_size": 98, "loss": 0.001915796947432682}, {"layer_params": [29, 16, 49, 22], "learning_rate": 0.0076160230104458495, "batch_size": 254, "loss": 0.004013384303543716}, {"layer_params": [43, 56], "learning_rate": 0.006565411170312679, "batch_size": 401, "loss": 0.0013294866296928375}, {"layer_params": [45, 25, 60], "learning_rate": 0.008475158584541197, "batch_size": 392, "loss": 0.0007960862352047116}, {"layer_params": [30, 59, 27, 52], "learning_rate": 0.0038412071249422854, "batch_size": 292, "loss": 0.0020101685053668917}, {"layer_params": [22, 40], "learning_rate": 0.003542969048541312, "batch_size": 257, "loss": 0.003889496363699436}, {"layer_params": [48, 33, 44, 32], "learning_rate": 0.0015054278951238185, "batch_size": 448, "loss": 0.0017534488160163165}, {"layer_params": [52, 33, 33, 51], "learning_rate": 0.009079365175409665, "batch_size": 301, "loss": 0.002384711952181533}, {"layer_params": [20, 42, 20, 39, 53], "learning_rate": 0.009371206193650436, "batch_size": 412, "loss": 0.0015300503745675088}, {"layer_params": [19, 45, 27, 25, 19], "learning_rate": 0.003148329782874806, "batch_size": 116, "loss": 0.003755388017743826}, {"layer_params": [56, 41, 24, 64], "learning_rate": 0.00653586332756421, "batch_size": 210, "loss": 0.001261694125714712}, {"layer_params": [21, 43, 41, 31], "learning_rate": 0.0066003442867069405, "batch_size": 511, "loss": 0.00193673484493047}, {"layer_params": [48, 56, 46, 33], "learning_rate": 0.0012559493194341817, "batch_size": 357, "loss": 0.0027169498172588645}, {"layer_params": [45, 21, 60], "learning_rate": 0.007389433172615514, "batch_size": 259, "loss": 0.0022064357018098234}, {"layer_params": [51, 30, 31, 44, 37], "learning_rate": 0.007713254463624171, "batch_size": 376, "loss": 0.0010874763381434605}, {"layer_params": [32, 22, 24], "learning_rate": 0.007063932811084946, "batch_size": 481, "loss": 0.002317291323561221}, {"layer_params": [48, 53], "learning_rate": 0.007335384842065995, "batch_size": 62, "loss": 0.0024660289322491736}, {"layer_params": [43, 20, 33], "learning_rate": 0.0058643554431152545, "batch_size": 426, "loss": 0.0020819129177834838}, {"layer_params": [18, 35, 21], "learning_rate": 0.0061278499196818015, "batch_size": 250, "loss": 0.0038155259215272965}, {"layer_params": [48, 58, 59, 34], "learning_rate": 0.006309947542094061, "batch_size": 277, "loss": 0.0016547148034442216}, {"layer_params": [24, 49], "learning_rate": 0.007884412946540194, "batch_size": 329, "loss": 0.002236945666372776}, {"layer_params": [37, 53], "learning_rate": 0.0009922414733106615, "batch_size": 436, "loss": 0.004443392336834222}, {"layer_params": [36, 21, 31], "learning_rate": 0.0027603676893392572, "batch_size": 484, "loss": 0.001829305124701932}, {"layer_params": [45, 63, 35, 62, 61], "learning_rate": 0.001418907187255064, "batch_size": 65, "loss": 0.003554555664304644}, {"layer_params": [43, 36, 17, 61], "learning_rate": 0.005555808549552442, "batch_size": 226, "loss": 0.001183384326286614}, {"layer_params": [64, 31, 50, 60, 46], "learning_rate": 0.005201117634597758, "batch_size": 345, "loss": 0.001904182331636548}, {"layer_params": [35, 17, 25, 43], "learning_rate": 0.003119154309740463, "batch_size": 253, "loss": 0.0028504870319738984}, {"layer_params": [22, 54, 34, 35, 23], "learning_rate": 0.00032479304202509535, "batch_size": 442, "loss": 0.007921341895125807}, {"layer_params": [36, 17, 38], "learning_rate": 0.008528246589849442, "batch_size": 192, "loss": 0.005953902299515903}, {"layer_params": [23, 56], "learning_rate": 0.004713333491148754, "batch_size": 235, "loss": 0.003367929048836231}, {"layer_params": [27, 43, 33, 25], "learning_rate": 0.008420851735746263, "batch_size": 239, "loss": 0.0013643587834667415}, {"layer_params": [49, 19, 17], "learning_rate": 0.006966017768418678, "batch_size": 427, "loss": 0.0012008244317257776}, {"layer_params": [34, 48, 42], "learning_rate": 0.0007220241626258305, "batch_size": 239, "loss": 0.003797858082689345}, {"layer_params": [57, 55, 37, 53, 48], "learning_rate": 0.00112418419933504, "batch_size": 148, "loss": 0.0033947319258004426}, {"layer_params": [59, 16, 24, 44, 47], "learning_rate": 0.00480968917936347, "batch_size": 345, "loss": 0.0020359666144941003}, {"layer_params": [19, 60, 58, 34, 55], "learning_rate": 0.00465953935468989, "batch_size": 137, "loss": 0.0026006658864207565}, {"layer_params": [40, 20, 22], "learning_rate": 0.008727811836497325, "batch_size": 276, "loss": 0.0022756392415612934}, {"layer_params": [55, 34, 27, 45, 55], "learning_rate": 0.0086897626944467, "batch_size": 40, "loss": 0.005650642646942288}, {"layer_params": [24, 43, 25, 48, 18], "learning_rate": 0.0030249699881952944, "batch_size": 476, "loss": 0.0021941205416806044}, {"layer_params": [52, 34, 45], "learning_rate": 0.00761175078211339, "batch_size": 44, "loss": 0.0029514350916724653}, {"layer_params": [48, 31, 30, 63], "learning_rate": 0.006456471960255791, "batch_size": 504, "loss": 0.0013493920699693262}, {"layer_params": [56, 29, 48, 28, 42], "learning_rate": 0.005352533949764618, "batch_size": 54, "loss": 0.0038740704441443084}, {"layer_params": [35, 28, 24, 35, 41], "learning_rate": 0.00789662484843198, "batch_size": 165, "loss": 0.003804998660925776}, {"layer_params": [64, 61], "learning_rate": 0.002744058890928469, "batch_size": 295, "loss": 0.0017789441568311303}, {"layer_params": [53, 25], "learning_rate": 0.00010718522119984053, "batch_size": 97, "loss": 0.035432863924652336}, {"layer_params": [47, 51, 53, 48, 41], "learning_rate": 0.0003369145327263541, "batch_size": 490, "loss": 0.004559003757312894}, {"layer_params": [57, 52, 20, 52], "learning_rate": 0.006565188331926254, "batch_size": 419, "loss": 0.0011160111415665598}, {"layer_params": [41, 25, 44], "learning_rate": 0.004225804046630688, "batch_size": 113, "loss": 0.002722425915999338}, {"layer_params": [56, 57], "learning_rate": 0.007382692972307562, "batch_size": 209, "loss": 0.0014362729719141498}, {"layer_params": [37, 42, 60], "learning_rate": 0.0013756302510387803, "batch_size": 183, "loss": 0.002495554726338014}, {"layer_params": [40, 44, 42], "learning_rate": 0.009219009108726531, "batch_size": 432, "loss": 0.001019659546436742}, {"layer_params": [26, 37, 48, 42], "learning_rate": 0.0005346092203699997, "batch_size": 243, "loss": 0.005097962473519147}, {"layer_params": [22, 17, 52], "learning_rate": 0.006945974028629999, "batch_size": 170, "loss": 0.0034551406814716757}, {"layer_params": [48, 29], "learning_rate": 0.0016095421806506564, "batch_size": 166, "loss": 0.004670386870857328}, {"layer_params": [52, 37, 54], "learning_rate": 0.003912651470931701, "batch_size": 512, "loss": 0.0012964644317980856}, {"layer_params": [39, 39, 62, 30], "learning_rate": 0.0038372521183298865, "batch_size": 171, "loss": 0.0012600449920864775}, {"layer_params": [60, 18, 44], "learning_rate": 0.005583196881324018, "batch_size": 494, "loss": 0.0014850786700844765}, {"layer_params": [61, 38], "learning_rate": 0.0059887668257083216, "batch_size": 387, "loss": 0.002924061173107475}, {"layer_params": [22, 56], "learning_rate": 0.008866057545529828, "batch_size": 126, "loss": 0.0028776632831431924}, {"layer_params": [53, 25], "learning_rate": 0.0005152903854837856, "batch_size": 351, "loss": 0.0061200960166752335}, {"layer_params": [46, 63, 20, 59], "learning_rate": 0.005976035546091384, "batch_size": 411, "loss": 0.0013161097484407946}, {"layer_params": [32, 48], "learning_rate": 0.0038394175956458576, "batch_size": 498, "loss": 0.0027869316912256183}, {"layer_params": [17, 59], "learning_rate": 0.005196758719754613, "batch_size": 371, "loss": 0.002921630924101919}, {"layer_params": [25, 24, 36], "learning_rate": 0.008062512845442774, "batch_size": 80, "loss": 0.004491503441240639}, {"layer_params": [42, 36, 43, 49], "learning_rate": 0.004494065101567517, "batch_size": 262, "loss": 0.0017949890077579766}, {"layer_params": [55, 20, 24], "learning_rate": 0.008859029053561892, "batch_size": 284, "loss": 0.002049746608827263}, {"layer_params": [44, 35, 30, 53], "learning_rate": 0.0023625766047259615, "batch_size": 464, "loss": 0.0013580947229638696}, {"layer_params": [30, 58, 44, 29, 57], "learning_rate": 0.00924850327717809, "batch_size": 285, "loss": 0.0010600364883430302}, {"layer_params": [23, 30, 48], "learning_rate": 0.006400690441085654, "batch_size": 357, "loss": 0.002509517276193947}, {"layer_params": [19, 51, 60], "learning_rate": 0.005295305854737962, "batch_size": 212, "loss": 0.0019139377051033079}, {"layer_params": [50, 18, 47], "learning_rate": 0.009528959234035106, "batch_size": 254, "loss": 0.0033215644024312497}, {"layer_params": [58, 42, 50, 55, 53], "learning_rate": 0.007772036035028918, "batch_size": 408, "loss": 0.001246627244981937}, {"layer_params": [28, 54, 54], "learning_rate": 0.005709653150868722, "batch_size": 197, "loss": 0.0014233696996234356}, {"layer_params": [55, 43, 29], "learning_rate": 0.00866185904606529, "batch_size": 229, "loss": 0.001963266464881599}, {"layer_params": [16, 51, 39, 59], "learning_rate": 0.009719198380112854, "batch_size": 57, "loss": 0.005130593015346676}, {"layer_params": [53, 37], "learning_rate": 0.006545530317083007, "batch_size": 285, "loss": 0.0022348191414494067}, {"layer_params": [39, 41], "learning_rate": 0.004285682667244883, "batch_size": 510, "loss": 0.001944460979430005}, {"layer_params": [24, 43, 60], "learning_rate": 0.001814912352476354, "batch_size": 126, "loss": 0.0063049814896658065}, {"layer_params": [26, 59, 57, 19, 31], "learning_rate": 0.00809761282202699, "batch_size": 114, "loss": 0.0031473324308171867}, {"layer_params": [25, 48], "learning_rate": 0.00985292959419076, "batch_size": 470, "loss": 0.002436429982772097}, {"layer_params": [60, 51, 33], "learning_rate": 0.00863636569605495, "batch_size": 489, "loss": 0.0016204621794167907}, {"layer_params": [39, 39, 57, 46], "learning_rate": 0.003887955356656936, "batch_size": 489, "loss": 0.00129808617872186}, {"layer_params": [20, 41, 18], "learning_rate": 0.005858911925326605, "batch_size": 157, "loss": 0.004969576485455036}, {"layer_params": [52, 48, 34, 17, 57], "learning_rate": 0.00693629877994384, "batch_size": 155, "loss": 0.0026650705572683364}, {"layer_params": [52, 47], "learning_rate": 0.0049400587935343404, "batch_size": 234, "loss": 0.002700200804974884}, {"layer_params": [20, 46, 40, 33, 25], "learning_rate": 0.0005550908608677889, "batch_size": 321, "loss": 0.004809046948794276}, {"layer_params": [57, 34, 30], "learning_rate": 0.0016474010010258313, "batch_size": 225, "loss": 0.0031695374473929405}, {"layer_params": [39, 58], "learning_rate": 0.0008869759231765875, "batch_size": 366, "loss": 0.0033306186832487584}, {"layer_params": [50, 30, 41], "learning_rate": 0.00932247182493081, "batch_size": 290, "loss": 0.0013744771061465144}, {"layer_params": [46, 21, 53], "learning_rate": 0.008091458366185087, "batch_size": 111, "loss": 0.0022055243258364498}, {"layer_params": [17, 26, 23], "learning_rate": 0.00293727066148887, "batch_size": 167, "loss": 0.004667002875357866}, {"layer_params": [42, 20, 31, 36, 53], "learning_rate": 0.009505853338207923, "batch_size": 227, "loss": 0.0011310945241712034}, {"layer_params": [55, 21, 46], "learning_rate": 0.0040368096169439245, "batch_size": 208, "loss": 0.002569651280064136}, {"layer_params": [36, 39], "learning_rate": 0.002855646505489071, "batch_size": 301, "loss": 0.0028826419031247495}, {"layer_params": [34, 39, 21, 41], "learning_rate": 0.00824354711352483, "batch_size": 63, "loss": 0.004305990654975176}, {"layer_params": [23, 37], "learning_rate": 0.005684256242887208, "batch_size": 286, "loss": 0.0033532960503362117}, {"layer_params": [51, 20, 45, 64, 50], "learning_rate": 0.006770450442012625, "batch_size": 178, "loss": 0.0025310692738275977}, {"layer_params": [28, 17, 59, 32], "learning_rate": 0.0056308940453279254, "batch_size": 163, "loss": 0.003151660782750696}, {"layer_params": [50, 45], "learning_rate": 0.008034211411209207, "batch_size": 170, "loss": 0.0021397469704970717}, {"layer_params": [58, 54, 44, 24, 31], "learning_rate": 0.00578252933356625, "batch_size": 297, "loss": 0.0012454006978077814}, {"layer_params": [28, 40, 40], "learning_rate": 0.002558775074483158, "batch_size": 223, "loss": 0.0019853836484253406}, {"layer_params": [54, 36, 55, 40, 38], "learning_rate": 0.0011207009901698785, "batch_size": 239, "loss": 0.0031353602558374404}, {"layer_params": [42, 50], "learning_rate": 0.005143088066927077, "batch_size": 115, "loss": 0.0018889388325624167}, {"layer_params": [30, 59, 33, 45, 54], "learning_rate": 0.004512734579811107, "batch_size": 451, "loss": 0.0010862962197279557}, {"layer_params": [64, 19, 40, 42], "learning_rate": 0.004277480838753729, "batch_size": 357, "loss": 0.0021171524410601703}, {"layer_params": [55, 36, 38], "learning_rate": 0.006832615917235355, "batch_size": 100, "loss": 0.0017923878075089305}, {"layer_params": [46, 18, 24, 24, 62], "learning_rate": 0.006166907537839352, "batch_size": 167, "loss": 0.003871292525436729}, {"layer_params": [62, 44, 55, 55], "learning_rate": 0.009650060627981509, "batch_size": 240, "loss": 0.0007961423986125737}, {"layer_params": [24, 50, 42, 41, 24], "learning_rate": 0.0013724849366302098, "batch_size": 128, "loss": 0.006166446255519986}, {"layer_params": [21, 58, 35, 41], "learning_rate": 0.007975023340737063, "batch_size": 287, "loss": 0.001964898930164054}, {"layer_params": [37, 29, 37], "learning_rate": 0.0019729176063281034, "batch_size": 209, "loss": 0.004193777742329985}, {"layer_params": [29, 29, 61, 16, 51], "learning_rate": 0.009694383282072436, "batch_size": 363, "loss": 0.0017337789514567702}, {"layer_params": [49, 21, 51, 18], "learning_rate": 0.0009735584122162225, "batch_size": 93, "loss": 0.007040109834633768}, {"layer_params": [37, 50, 59], "learning_rate": 0.0005303340524058088, "batch_size": 507, "loss": 0.003941068002022803}, {"layer_params": [60, 58, 62], "learning_rate": 0.00029452800340223646, "batch_size": 123, "loss": 0.0068136418610811236}, {"layer_params": [54, 61, 41, 27], "learning_rate": 0.008326213342156982, "batch_size": 144, "loss": 0.0016122608503792435}, {"layer_params": [57, 47, 19, 33, 62], "learning_rate": 0.0013129089174645015, "batch_size": 388, "loss": 0.0014263240818399936}, {"layer_params": [37, 24, 46, 24], "learning_rate": 0.005727074612877779, "batch_size": 73, "loss": 0.004169853765051812}, {"layer_params": [58, 44, 62, 29], "learning_rate": 0.0069800316000586775, "batch_size": 19, "loss": 0.006544403599109501}, {"layer_params": [63, 59, 58], "learning_rate": 0.0020815349625405762, "batch_size": 457, "loss": 0.000992883474100381}, {"layer_params": [34, 18, 19, 29, 42], "learning_rate": 0.007560427589863346, "batch_size": 169, "loss": 0.003710608014371246}, {"layer_params": [28, 21], "learning_rate": 0.0014175782976850314, "batch_size": 319, "loss": 0.005263901716098189}, {"layer_params": [57, 41, 48, 59], "learning_rate": 0.007173264129232628, "batch_size": 355, "loss": 0.00145142330089584}, {"layer_params": [19, 28], "learning_rate": 0.00554414423614175, "batch_size": 339, "loss": 0.004647044879384339}, {"layer_params": [34, 57, 48, 45, 38], "learning_rate": 0.006411016636274911, "batch_size": 166, "loss": 0.0017715202248655259}, {"layer_params": [40, 18, 56, 17, 21], "learning_rate": 0.0019493777406266132, "batch_size": 147, "loss": 0.004603457110933959}, {"layer_params": [24, 33, 33, 45, 61], "learning_rate": 0.003683785980357698, "batch_size": 308, "loss": 0.002962383818812668}, {"layer_params": [49, 29, 41, 54], "learning_rate": 0.004685458998618873, "batch_size": 320, "loss": 0.0016437418619170785}, {"layer_params": [51, 43, 29], "learning_rate": 0.003553148366397881, "batch_size": 167, "loss": 0.002226888637524098}, {"layer_params": [39, 49, 63, 27, 22], "learning_rate": 0.007214802968736258, "batch_size": 145, "loss": 0.00221177521510981}, {"layer_params": [50, 53, 37, 60, 19], "learning_rate": 0.005214383507535646, "batch_size": 249, "loss": 0.0009612775745335967}, {"layer_params": [55, 32], "learning_rate": 0.004614848177000442, "batch_size": 435, "loss": 0.0016566148155834526}, {"layer_params": [53, 21, 64, 33], "learning_rate": 0.0012857108796180264, "batch_size": 440, "loss": 0.003280983725562692}, {"layer_params": [61, 17, 19], "learning_rate": 0.007781793006717247, "batch_size": 72, "loss": 0.004734673055354506}, {"layer_params": [20, 27, 22], "learning_rate": 0.0018353996528909175, "batch_size": 125, "loss": 0.0036929687461815775}, {"layer_params": [34, 28, 50, 32], "learning_rate": 0.0027577970448690184, "batch_size": 454, "loss": 0.002041029694955796}, {"layer_params": [32, 60, 43], "learning_rate": 0.001042046579724842, "batch_size": 336, "loss": 0.003380118957720697}, {"layer_params": [31, 52, 33], "learning_rate": 0.006877543065866431, "batch_size": 249, "loss": 0.001744346481282264}, {"layer_params": [52, 21], "learning_rate": 0.007378464813278894, "batch_size": 249, "loss": 0.00434462416684255}, {"layer_params": [61, 31, 52, 28, 24], "learning_rate": 0.0022051521366730034, "batch_size": 278, "loss": 0.002947155456058681}, {"layer_params": [40, 44, 31, 62], "learning_rate": 0.005178036907569726, "batch_size": 437, "loss": 0.0020028411818202585}, {"layer_params": [53, 37], "learning_rate": 0.006773742076362716, "batch_size": 319, "loss": 0.0014402889146003873}, {"layer_params": [52, 23, 52, 17, 61], "learning_rate": 0.009548751881306305, "batch_size": 361, "loss": 0.0013758275960572065}, {"layer_params": [58, 24, 48, 49, 63], "learning_rate": 0.006273420706879627, "batch_size": 506, "loss": 0.0010483697196468711}, {"layer_params": [39, 18], "learning_rate": 0.008283426055200799, "batch_size": 192, "loss": 0.0052199192810803655}, {"layer_params": [29, 25], "learning_rate": 0.0025131360432704354, "batch_size": 261, "loss": 0.005448859198950231}, {"layer_params": [53, 29, 54], "learning_rate": 0.009950607219814313, "batch_size": 342, "loss": 0.0015239623410161585}, {"layer_params": [60, 56, 27], "learning_rate": 0.0048502273678660566, "batch_size": 221, "loss": 0.002053397611016408}, {"layer_params": [36, 36, 61, 39, 22], "learning_rate": 0.004621321409485086, "batch_size": 227, "loss": 0.0021739172365050764}, {"layer_params": [16, 27], "learning_rate": 0.007492049431540296, "batch_size": 207, "loss": 0.0053381518716923895}, {"layer_params": [46, 41, 51], "learning_rate": 0.0031538323339684597, "batch_size": 318, "loss": 0.0019273994176182896}, {"layer_params": [48, 58, 37, 21, 20], "learning_rate": 0.009297096214124551, "batch_size": 178, "loss": 0.0011883320461492986}, {"layer_params": [39, 56], "learning_rate": 0.0065226732207575985, "batch_size": 82, "loss": 0.003036449704086408}, {"layer_params": [55, 62], "learning_rate": 0.00311539301247788, "batch_size": 434, "loss": 0.0018799665488768368}, {"layer_params": [21, 45, 62, 34], "learning_rate": 0.006160468790120724, "batch_size": 124, "loss": 0.002186648747883737}, {"layer_params": [52, 16], "learning_rate": 0.009436599628686869, "batch_size": 285, "loss": 0.0026314945612102747}, {"layer_params": [48, 47, 53, 31], "learning_rate": 0.00019394726106952608, "batch_size": 178, "loss": 0.008030987232923508}, {"layer_params": [64, 16], "learning_rate": 0.003815958056051379, "batch_size": 355, "loss": 0.0027239987161010505}, {"layer_params": [28, 53, 46], "learning_rate": 0.007862511932404274, "batch_size": 69, "loss": 0.002825818342389539}, {"layer_params": [34, 49, 56, 62], "learning_rate": 0.007682090448014666, "batch_size": 89, "loss": 0.002333725386997685}, {"layer_params": [31, 41], "learning_rate": 0.007593625881828508, "batch_size": 21, "loss": 0.006760506720747799}, {"layer_params": [49, 30, 24, 38, 39], "learning_rate": 0.007876283451566036, "batch_size": 316, "loss": 0.0022625729453284293}, {"layer_params": [22, 62, 22], "learning_rate": 0.0019792398081017433, "batch_size": 204, "loss": 0.003631206420250237}, {"layer_params": [43, 23, 57, 20], "learning_rate": 0.005661780845755734, "batch_size": 114, "loss": 0.003846167349256575}, {"layer_params": [44, 35, 22], "learning_rate": 0.009566850058826713, "batch_size": 245, "loss": 0.002184939280850813}, {"layer_params": [16, 25, 37, 22], "learning_rate": 0.0003933454655715417, "batch_size": 180, "loss": 0.00928165704011917}, {"layer_params": [61, 42, 55, 43, 57], "learning_rate": 0.00748292665553747, "batch_size": 365, "loss": 0.0008201464475132525}, {"layer_params": [31, 51, 31, 54], "learning_rate": 0.0046732327776553145, "batch_size": 381, "loss": 0.0013697954372037203}, {"layer_params": [37, 39, 29], "learning_rate": 0.0002688090055339759, "batch_size": 181, "loss": 0.007291406472213566}, {"layer_params": [50, 30], "learning_rate": 0.0015713058587112092, "batch_size": 112, "loss": 0.004467384712770581}, {"layer_params": [54, 33, 24], "learning_rate": 0.0076193416402422064, "batch_size": 139, "loss": 0.002173948863055557}, {"layer_params": [21, 55, 17], "learning_rate": 0.007608468434291466, "batch_size": 95, "loss": 0.004589840895496309}, {"layer_params": [57, 38, 37, 61], "learning_rate": 0.0014303326743128645, "batch_size": 405, "loss": 0.001653219845611602}, {"layer_params": [52, 40, 27, 28], "learning_rate": 0.0019728613078385947, "batch_size": 266, "loss": 0.0019685285980813204}, {"layer_params": [44, 28, 57, 52], "learning_rate": 0.0047683152193712655, "batch_size": 265, "loss": 0.0017744528281036765}, {"layer_params": [59, 27, 57, 35, 61], "learning_rate": 0.0008860524531314617, "batch_size": 78, "loss": 0.005184626099653542}, {"layer_params": [22, 23, 46, 57, 26], "learning_rate": 0.005602593148463484, "batch_size": 286, "loss": 0.00320530082564801}, {"layer_params": [34, 63, 38], "learning_rate": 0.007538564633366764, "batch_size": 93, "loss": 0.0026457691041287036}, {"layer_params": [32, 27, 18, 64], "learning_rate": 0.0069730903619629366, "batch_size": 107, "loss": 0.0032111020339652897}, {"layer_params": [27, 33, 26, 51, 38], "learning_rate": 0.004891416305701035, "batch_size": 383, "loss": 0.002663631641771644}, {"layer_params": [24, 55, 57, 22], "learning_rate": 0.0020752321072387623, "batch_size": 351, "loss": 0.0013669671106617898}, {"layer_params": [31, 60, 18, 49, 55], "learning_rate": 0.009203351060221592, "batch_size": 304, "loss": 0.0015038612519856541}, {"layer_params": [36, 53, 37, 18], "learning_rate": 0.0043470744538221225, "batch_size": 497, "loss": 0.0012896173540502787}, {"layer_params": [32, 64], "learning_rate": 0.003920353062725942, "batch_size": 475, "loss": 0.001666099161375314}, {"layer_params": [34, 33, 38, 58, 53], "learning_rate": 0.005242258774149464, "batch_size": 83, "loss": 0.0030370454338844864}, {"layer_params": [35, 63, 46, 63], "learning_rate": 0.0015496880364200463, "batch_size": 109, "loss": 0.002573235335294157}, {"layer_params": [22, 58, 16], "learning_rate": 0.0006291548489738769, "batch_size": 269, "loss": 0.007112579536624253}, {"layer_params": [18, 17, 38, 55, 19], "learning_rate": 0.004118650656128537, "batch_size": 127, "loss": 0.0030001237615942954}, {"layer_params": [20, 53, 19, 45, 52], "learning_rate": 0.005709760961561514, "batch_size": 114, "loss": 0.002670196427498013}, {"layer_params": [30, 56, 36], "learning_rate": 0.00910788787738034, "batch_size": 503, "loss": 0.0015596429724246263}, {"layer_params": [55, 41], "learning_rate": 0.008833840534973565, "batch_size": 308, "loss": 0.0016669099871069193}, {"layer_params": [43, 33, 40, 53], "learning_rate": 8.183926864474184e-05, "batch_size": 99, "loss": 0.03290779562667012}, {"layer_params": [25, 30, 54], "learning_rate": 0.008758415845406691, "batch_size": 395, "loss": 0.00196181608363986}, {"layer_params": [49, 53], "learning_rate": 0.0045990970309393595, "batch_size": 125, "loss": 0.0019910039694514127}, {"layer_params": [44, 48, 40, 43], "learning_rate": 0.002542928986727805, "batch_size": 451, "loss": 0.0013557274523191155}, {"layer_params": [19, 20], "learning_rate": 0.0013861074867247004, "batch_size": 485, "loss": 0.006595067856833339}, {"layer_params": [37, 42, 53, 51, 48], "learning_rate": 0.005485705602713592, "batch_size": 243, "loss": 0.001235466065700166}, {"layer_params": [50, 27], "learning_rate": 0.006708934529032213, "batch_size": 266, "loss": 0.001951366919092834}, {"layer_params": [35, 52], "learning_rate": 0.009905882710280964, "batch_size": 170, "loss": 0.0016992004425264895}, {"layer_params": [28, 52, 57], "learning_rate": 0.0064476553527607105, "batch_size": 475, "loss": 0.0021248768316581845}, {"layer_params": [55, 29], "learning_rate": 0.008857119004843263, "batch_size": 61, "loss": 0.0026329539017751814}, {"layer_params": [22, 64], "learning_rate": 0.005386529701156803, "batch_size": 274, "loss": 0.0024515255249571055}, {"layer_params": [26, 29, 44, 64, 46], "learning_rate": 0.005918825770198612, "batch_size": 22, "loss": 0.006420178883709013}, {"layer_params": [28, 47, 47], "learning_rate": 0.003880241482542449, "batch_size": 325, "loss": 0.002412840040633455}, {"layer_params": [53, 50, 33, 36], "learning_rate": 0.009116215729414318, "batch_size": 295, "loss": 0.0018127092125359923}, {"layer_params": [42, 21, 28, 38], "learning_rate": 0.001564085712611712, "batch_size": 219, "loss": 0.0034544722246937455}, {"layer_params": [29, 16, 58, 61], "learning_rate": 0.005569413716038765, "batch_size": 75, "loss": 0.00547314973315224}, {"layer_params": [48, 43, 23, 44, 59], "learning_rate": 0.008201738888282713, "batch_size": 475, "loss": 0.0013531442394014448}, {"layer_params": [17, 40, 26], "learning_rate": 0.004177410733025447, "batch_size": 265, "loss": 0.002549906955100596}, {"layer_params": [18, 39, 16, 25, 31], "learning_rate": 0.00873560211204844, "batch_size": 180, "loss": 0.0035725104017183184}, {"layer_params": [49, 21, 51], "learning_rate": 0.005097289365132641, "batch_size": 195, "loss": 0.0033950695348903535}, {"layer_params": [39, 58, 43, 50], "learning_rate": 0.006197351606760224, "batch_size": 204, "loss": 0.0015887433907482774}, {"layer_params": [22, 60, 24], "learning_rate": 0.0007262916720000644, "batch_size": 76, "loss": 0.007450245758518576}, {"layer_params": [40, 63, 31, 60], "learning_rate": 0.009574521413709814, "batch_size": 457, "loss": 0.0017430172755848617}, {"layer_params": [59, 30, 35, 38, 37], "learning_rate": 0.0014934742936494536, "batch_size": 98, "loss": 0.003555722057353705}, {"layer_params": [39, 21, 62, 63, 50], "learning_rate": 0.00852948395073982, "batch_size": 363, "loss": 0.001638048317981884}, {"layer_params": [40, 31, 40, 63, 60], "learning_rate": 0.003119831091060137, "batch_size": 111, "loss": 0.004150580260902643}, {"layer_params": [43, 54], "learning_rate": 0.0012619575020052125, "batch_size": 107, "loss": 0.004516992894932628}, {"layer_params": [19, 35], "learning_rate": 0.007122516017519171, "batch_size": 504, "loss": 0.0022922974778339265}, {"layer_params": [64, 46, 37, 54, 17], "learning_rate": 0.006144611657841156, "batch_size": 65, "loss": 0.003378598224371672}, {"layer_params": [19, 57, 34, 32], "learning_rate": 0.008468377283702824, "batch_size": 122, "loss": 0.0026200995163526385}, {"layer_params": [31, 26], "learning_rate": 0.00978547069103568, "batch_size": 317, "loss": 0.003372082153800875}, {"layer_params": [60, 16, 16, 31], "learning_rate": 0.009704216348561383, "batch_size": 75, "loss": 0.003311644766945392}, {"layer_params": [48, 31, 19, 50], "learning_rate": 0.0063696930226859304, "batch_size": 489, "loss": 0.0011068823124514892}, {"layer_params": [56, 40, 48, 63, 29], "learning_rate": 0.0056037867039303675, "batch_size": 280, "loss": 0.0014619121653959156}, {"layer_params": [52, 21], "learning_rate": 0.005724139249076228, "batch_size": 201, "loss": 0.0018299620237667113}, {"layer_params": [22, 56, 56], "learning_rate": 0.009122132374107686, "batch_size": 117, "loss": 0.0029416356433648616}, {"layer_params": [57, 27], "learning_rate": 3.6693340895997055e-05, "batch_size": 118, "loss": 0.03806718643754721}, {"layer_params": [27, 34, 27, 29, 64], "learning_rate": 0.00018172906677831985, "batch_size": 165, "loss": 0.008325591501779854}, {"layer_params": [19, 64], "learning_rate": 0.007646891092697368, "batch_size": 73, "loss": 0.005603597776498646}, {"layer_params": [41, 42, 17], "learning_rate": 0.006901800489088032, "batch_size": 101, "loss": 0.0020413579721935094}, {"layer_params": [58, 44], "learning_rate": 0.0045192338100297335, "batch_size": 187, "loss": 0.0021003208006732167}, {"layer_params": [32, 39, 31, 62], "learning_rate": 0.005285002500922634, "batch_size": 243, "loss": 0.0016972118010744452}, {"layer_params": [52, 18, 23, 27], "learning_rate": 0.006197365313545445, "batch_size": 478, "loss": 0.0013880920398514718}, {"layer_params": [60, 62, 51], "learning_rate": 0.006199274681121879, "batch_size": 337, "loss": 0.0008903299900703132}, {"layer_params": [34, 40, 33], "learning_rate": 0.0014063352559526862, "batch_size": 235, "loss": 0.0037865797686390578}, {"layer_params": [31, 32, 55, 25], "learning_rate": 0.0017050316485417495, "batch_size": 453, "loss": 0.0026388717303052543}, {"layer_params": [26, 17, 16, 51], "learning_rate": 0.008565742849459186, "batch_size": 223, "loss": 0.0034202614310197533}, {"layer_params": [31, 64], "learning_rate": 0.007551201584190009, "batch_size": 107, "loss": 0.0024172917974647134}, {"layer_params": [46, 35, 27, 39, 63], "learning_rate": 0.00667589215283364, "batch_size": 45, "loss": 0.005179145867004991}, {"layer_params": [35, 62, 31, 50], "learning_rate": 0.0023486677145072065, "batch_size": 394, "loss": 0.0017841839767061174}, {"layer_params": [26, 43], "learning_rate": 0.009042908458184472, "batch_size": 184, "loss": 0.0043781877984292806}, {"layer_params": [26, 18, 24], "learning_rate": 0.005198578357756375, "batch_size": 496, "loss": 0.0035496592102572323}, {"layer_params": [26, 35, 33, 25, 17], "learning_rate": 0.0038731287001483655, "batch_size": 30, "loss": 0.007767974894959479}, {"layer_params": [42, 35, 37, 46], "learning_rate": 0.0021351091841456593, "batch_size": 180, "loss": 0.002948029867839068}, {"layer_params": [44, 50], "learning_rate": 0.005393729237648181, "batch_size": 337, "loss": 0.0020109938888344912}, {"layer_params": [49, 16], "learning_rate": 0.005167303564637415, "batch_size": 229, "loss": 0.0028768973471596836}, {"layer_params": [60, 54, 33, 22], "learning_rate": 0.008782745375523867, "batch_size": 278, "loss": 0.0012394096137722955}, {"layer_params": [27, 49, 42, 22], "learning_rate": 0.0051664951257593674, "batch_size": 46, "loss": 0.0031923689367249607}, {"layer_params": [49, 53], "learning_rate": 0.005728866669673954, "batch_size": 46, "loss": 0.004152740447316319}, {"layer_params": [53, 18, 26], "learning_rate": 0.0009011155153197081, "batch_size": 330, "loss": 0.005723785497248173}, {"layer_params": [53, 29, 28], "learning_rate": 0.0061487741194865345, "batch_size": 384, "loss": 0.003046308180782944}, {"layer_params": [17, 50, 27], "learning_rate": 0.004435283682733225, "batch_size": 458, "loss": 0.0023678700905293225}, {"layer_params": [36, 42], "learning_rate": 0.007972611525253968, "batch_size": 104, "loss": 0.0024806402996182444}, {"layer_params": [30, 60], "learning_rate": 0.002372210543279968, "batch_size": 71, "loss": 0.004535027402453124}, {"layer_params": [62, 38, 33], "learning_rate": 0.002984615873679279, "batch_size": 93, "loss": 0.003067327158059925}, {"layer_params": [62, 39, 35], "learning_rate": 0.004926603579985119, "batch_size": 312, "loss": 0.0022870670456904916}, {"layer_params": [49, 21, 42, 39], "learning_rate": 0.00879134496962277, "batch_size": 196, "loss": 0.00397923995507881}, {"layer_params": [38, 63, 61], "learning_rate": 0.003480387278157612, "batch_size": 219, "loss": 0.001580923944711685}, {"layer_params": [40, 64, 24], "learning_rate": 0.004418623708607961, "batch_size": 29, "loss": 0.006058149840682745}, {"layer_params": [21, 60, 19, 52, 53], "learning_rate": 0.00983450102468636, "batch_size": 20, "loss": 0.008847353411838413}, {"layer_params": [37, 48], "learning_rate": 0.0015629403890428514, "batch_size": 417, "loss": 0.0035655713686719537}, {"layer_params": [56, 20], "learning_rate": 0.006516960852459177, "batch_size": 384, "loss": 0.001775347233051434}, {"layer_params": [27, 55, 19], "learning_rate": 0.005761646530712215, "batch_size": 170, "loss": 0.0027606785041280092}, {"layer_params": [25, 41, 56, 46], "learning_rate": 0.006686047148918248, "batch_size": 401, "loss": 0.001788903254782781}, {"layer_params": [34, 21], "learning_rate": 0.005800746772396279, "batch_size": 395, "loss": 0.001807677170727402}, {"layer_params": [21, 60, 63], "learning_rate": 0.0054475543293206075, "batch_size": 239, "loss": 0.0018742859293706714}, {"layer_params": [46, 50, 57, 25, 22], "learning_rate": 0.006749091234670399, "batch_size": 424, "loss": 0.000680975200375542}, {"layer_params": [56, 38], "learning_rate": 0.002462207135465706, "batch_size": 213, "loss": 0.0030625942326150835}, {"layer_params": [43, 56], "learning_rate": 0.0003397922365040902, "batch_size": 115, "loss": 0.007158210072666407}, {"layer_params": [42, 47, 16], "learning_rate": 0.0025933525415039018, "batch_size": 331, "loss": 0.0018072535505052655}, {"layer_params": [18, 39, 40], "learning_rate": 0.002345470557765794, "batch_size": 354, "loss": 0.003696373919956386}, {"layer_params": [22, 26], "learning_rate": 0.003977408757534733, "batch_size": 185, "loss": 0.003996528848074376}, {"layer_params": [36, 39, 38], "learning_rate": 0.001393701790254723, "batch_size": 279, "loss": 0.0032531712111085655}, {"layer_params": [64, 45, 16, 47, 56], "learning_rate": 0.0004144511119479733, "batch_size": 298, "loss": 0.00417216713540256}, {"layer_params": [17, 54, 27, 22], "learning_rate": 0.00836994176939195, "batch_size": 329, "loss": 0.0025215425284113736}, {"layer_params": [47, 51], "learning_rate": 0.005736521831855102, "batch_size": 258, "loss": 0.0015362591028679163}, {"layer_params": [42, 39, 60, 48, 64], "learning_rate": 0.0024009579960159485, "batch_size": 367, "loss": 0.0017817103792913257}, {"layer_params": [38, 55], "learning_rate": 0.00849456179025439, "batch_size": 40, "loss": 0.005368328795302659}, {"layer_params": [44, 22], "learning_rate": 0.0003523508925883128, "batch_size": 177, "loss": 0.00997774988412857}, {"layer_params": [36, 29, 52, 44, 37], "learning_rate": 0.00614724867403404, "batch_size": 244, "loss": 0.002207636662060395}, {"layer_params": [58, 37, 21, 51], "learning_rate": 0.0036968758690469694, "batch_size": 234, "loss": 0.0031794101535342636}, {"layer_params": [34, 53, 49, 35, 59], "learning_rate": 0.002300813926474853, "batch_size": 118, "loss": 0.001878114325227216}, {"layer_params": [24, 44, 40, 63], "learning_rate": 0.00531968059325812, "batch_size": 210, "loss": 0.002221762955887243}, {"layer_params": [45, 27, 21, 23], "learning_rate": 0.008209000763042104, "batch_size": 373, "loss": 0.0011735308525385336}, {"layer_params": [29, 55, 55, 43], "learning_rate": 0.005647785662299457, "batch_size": 257, "loss": 0.001544223832897842}, {"layer_params": [40, 52, 17], "learning_rate": 0.0054699095299818425, "batch_size": 349, "loss": 0.0018575671513099223}, {"layer_params": [16, 42, 49], "learning_rate": 0.006076484481022662, "batch_size": 397, "loss": 0.0017228026990778744}, {"layer_params": [49, 55], "learning_rate": 0.006134106180861349, "batch_size": 131, "loss": 0.001639388237381354}, {"layer_params": [37, 26, 43, 63, 29], "learning_rate": 0.007296675369062239, "batch_size": 451, "loss": 0.0013985521299764514}, {"layer_params": [36, 59, 48], "learning_rate": 0.0001085185783511075, "batch_size": 292, "loss": 0.011075344551354647}, {"layer_params": [31, 48, 63, 59], "learning_rate": 0.0014684836962382093, "batch_size": 100, "loss": 0.0025337513256818056}, {"layer_params": [21, 49, 24, 25, 64], "learning_rate": 0.0003743648355308178, "batch_size": 283, "loss": 0.0071129777980968355}, {"layer_params": [56, 19, 26], "learning_rate": 0.00599036225846053, "batch_size": 58, "loss": 0.0044294610503129665}, {"layer_params": [36, 21, 35, 33], "learning_rate": 0.0018828706980386556, "batch_size": 509, "loss": 0.002237508938414976}, {"layer_params": [61, 46], "learning_rate": 0.0006817818762129848, "batch_size": 398, "loss": 0.005610837116837502}, {"layer_params": [50, 57, 29], "learning_rate": 0.004715172094358724, "batch_size": 81, "loss": 0.001972802922828123}, {"layer_params": [61, 24, 16, 27, 36], "learning_rate": 0.0013768546745278323, "batch_size": 338, "loss": 0.0037331460672430693}, {"layer_params": [51, 26, 22, 58, 24], "learning_rate": 0.0017330236118706193, "batch_size": 491, "loss": 0.002430216062348336}, {"layer_params": [51, 54, 20, 57], "learning_rate": 0.008030492258855897, "batch_size": 502, "loss": 0.0007384533289587125}, {"layer_params": [52, 62], "learning_rate": 0.007163367461374808, "batch_size": 192, "loss": 0.000950730531476438}, {"layer_params": [36, 46, 50], "learning_rate": 0.007170721633226979, "batch_size": 456, "loss": 0.002105147016700357}, {"layer_params": [44, 35, 16], "learning_rate": 0.005799093755825659, "batch_size": 280, "loss": 0.0023374626319855453}, {"layer_params": [48, 18], "learning_rate": 0.0016829441021068653, "batch_size": 456, "loss": 0.0025155488052405416}, {"layer_params": [33, 34, 56], "learning_rate": 0.0036878518249322647, "batch_size": 164, "loss": 0.0024179263471160086}, {"layer_params": [38, 23, 35, 48, 60], "learning_rate": 0.0030647417636418977, "batch_size": 32, "loss": 0.0071766569651663305}, {"layer_params": [20, 33], "learning_rate": 0.006513676071468601, "batch_size": 146, "loss": 0.0036871260148473085}, {"layer_params": [32, 34, 47, 48], "learning_rate": 0.002771829930723668, "batch_size": 470, "loss": 0.001904735416173935}, {"layer_params": [28, 41, 63], "learning_rate": 0.009632992316343394, "batch_size": 440, "loss": 0.001307107205502689}, {"layer_params": [44, 39], "learning_rate": 0.0076616647037866525, "batch_size": 185, "loss": 0.002222883835202083}, {"layer_params": [41, 23, 35, 62, 29], "learning_rate": 0.0034077248316440193, "batch_size": 134, "loss": 0.0028856472740881145}, {"layer_params": [22, 42, 37, 55], "learning_rate": 0.001952152693438103, "batch_size": 62, "loss": 0.004371758734341711}, {"layer_params": [21, 20, 17, 26], "learning_rate": 0.0003442640985404115, "batch_size": 115, "loss": 0.009119019485078752}, {"layer_params": [46, 34, 47, 58, 50], "learning_rate": 0.009107887966575884, "batch_size": 302, "loss": 0.001859536621486768}, {"layer_params": [58, 21, 39, 36, 51], "learning_rate": 0.009641184143371293, "batch_size": 382, "loss": 0.0013821024692151696}, {"layer_params": [32, 20, 61, 60, 31], "learning_rate": 0.0014365103986687983, "batch_size": 471, "loss": 0.003834577144589275}, {"layer_params": [61, 46], "learning_rate": 0.003152839499983972, "batch_size": 86, "loss": 0.0020930457150097935}, {"layer_params": [22, 46, 63, 16, 51], "learning_rate": 0.005873266353657027, "batch_size": 164, "loss": 0.0030691269761882723}, {"layer_params": [29, 59], "learning_rate": 0.0022574040038813425, "batch_size": 358, "loss": 0.002995360342320055}, {"layer_params": [18, 32, 48], "learning_rate": 0.0007456507708771381, "batch_size": 76, "loss": 0.007380718211643398}, {"layer_params": [31, 19], "learning_rate": 0.00021239415867030002, "batch_size": 504, "loss": 0.012332908352836966}, {"layer_params": [45, 21], "learning_rate": 0.004449448542097797, "batch_size": 119, "loss": 0.0041533149592578415}, {"layer_params": [38, 16, 47, 20, 62], "learning_rate": 0.005483070883037314, "batch_size": 298, "loss": 0.003954270388931036}, {"layer_params": [36, 57, 29, 43, 41], "learning_rate": 0.008541804592366673, "batch_size": 488, "loss": 0.001379526082891971}, {"layer_params": [28, 21], "learning_rate": 0.00036356716737447444, "batch_size": 164, "loss": 0.012564339432865381}, {"layer_params": [19, 29, 63], "learning_rate": 0.0019295392305242855, "batch_size": 400, "loss": 0.0023173891194164754}, {"layer_params": [61, 61], "learning_rate": 0.005250551485217393, "batch_size": 181, "loss": 0.0018627373001072556}, {"layer_params": [23, 55, 20], "learning_rate": 0.003242610866086863, "batch_size": 38, "loss": 0.006831210537347943}, {"layer_params": [28, 36, 58, 42], "learning_rate": 0.0002714334039937961, "batch_size": 328, "loss": 0.006721135005354881}, {"layer_params": [44, 24, 55, 54, 31], "learning_rate": 0.00972063628939252, "batch_size": 382, "loss": 0.0010149311507120728}, {"layer_params": [55, 56, 62, 43], "learning_rate": 0.008270886820719225, "batch_size": 467, "loss": 0.0009176135383313522}, {"layer_params": [54, 25, 35, 29, 39], "learning_rate": 0.0039312931761120995, "batch_size": 319, "loss": 0.0019281950232107193}, {"layer_params": [40, 36, 51], "learning_rate": 0.007410191181362327, "batch_size": 449, "loss": 0.0013983643974643202}, {"layer_params": [42, 32], "learning_rate": 0.004677922635264775, "batch_size": 24, "loss": 0.007842620785813778}, {"layer_params": [29, 63, 59], "learning_rate": 0.0021248123498171993, "batch_size": 62, "loss": 0.003789869344327599}, {"layer_params": [60, 51, 37, 50, 25], "learning_rate": 0.006376908087700459, "batch_size": 45, "loss": 0.0031439280568156393}, {"layer_params": [52, 25, 45, 64, 23], "learning_rate": 0.005359494005054132, "batch_size": 73, "loss": 0.002510316694388166}, {"layer_params": [19, 17, 47, 22], "learning_rate": 0.002327787498783665, "batch_size": 155, "loss": 0.005997098949737847}, {"layer_params": [19, 26, 54], "learning_rate": 0.00986557579913574, "batch_size": 237, "loss": 0.0021727388864383104}, {"layer_params": [29, 56, 48, 57, 24], "learning_rate": 0.004990560636894273, "batch_size": 86, "loss": 0.0022712933726143094}, {"layer_params": [40, 21], "learning_rate": 0.0003988896672534275, "batch_size": 500, "loss": 0.0077670757891610265}, {"layer_params": [61, 38], "learning_rate": 0.00426133274855965, "batch_size": 483, "loss": 0.0027488274616189303}, {"layer_params": [39, 38, 48], "learning_rate": 0.005162534182370967, "batch_size": 42, "loss": 0.0041341039747931066}, {"layer_params": [46, 27, 32, 22, 23], "learning_rate": 0.009399410282405927, "batch_size": 125, "loss": 0.0025243559246882798}, {"layer_params": [38, 45, 38, 54, 40], "learning_rate": 0.0027341271035918107, "batch_size": 491, "loss": 0.002268463067011908}, {"layer_params": [64, 27, 25, 38], "learning_rate": 0.009969688063845024, "batch_size": 177, "loss": 0.0016055832128040492}, {"layer_params": [60, 50, 62, 50, 59], "learning_rate": 0.004847847051299112, "batch_size": 304, "loss": 0.0007792194397188723}, {"layer_params": [16, 64, 34, 34, 18], "learning_rate": 0.00367621097012707, "batch_size": 176, "loss": 0.0026750512584112584}, {"layer_params": [28, 30, 47], "learning_rate": 0.00957464923785035, "batch_size": 22, "loss": 0.0061566596385091545}, {"layer_params": [51, 32], "learning_rate": 0.00545592177857536, "batch_size": 163, "loss": 0.0026494528364855796}, {"layer_params": [47, 61, 55, 29], "learning_rate": 0.007357844342621447, "batch_size": 250, "loss": 0.0014673341205343603}, {"layer_params": [35, 58, 45, 58], "learning_rate": 0.003777071078627571, "batch_size": 34, "loss": 0.0041974789928644896}, {"layer_params": [53, 58, 62], "learning_rate": 0.005756316160690159, "batch_size": 188, "loss": 0.002196959351422265}, {"layer_params": [50, 39, 42, 44, 39], "learning_rate": 0.00897360433692782, "batch_size": 42, "loss": 0.004140148416627199}, {"layer_params": [60, 36, 50, 48], "learning_rate": 0.006634137994433983, "batch_size": 477, "loss": 0.0011324975953903049}, {"layer_params": [17, 63, 20, 23], "learning_rate": 0.009341181028619295, "batch_size": 39, "loss": 0.0055175769538618625}, {"layer_params": [25, 44, 47], "learning_rate": 0.005487893158611193, "batch_size": 371, "loss": 0.002046996633289382}, {"layer_params": [52, 42], "learning_rate": 0.008303408095211538, "batch_size": 458, "loss": 0.0011906587064731866}, {"layer_params": [59, 61], "learning_rate": 0.0030430364975283166, "batch_size": 45, "loss": 0.003805514010600746}, {"layer_params": [63, 41, 22, 44], "learning_rate": 0.0019578762416351506, "batch_size": 460, "loss": 0.0019307287863921374}, {"layer_params": [20, 21, 40], "learning_rate": 0.006032442706081003, "batch_size": 437, "loss": 0.003267326666973531}, {"layer_params": [58, 29, 29], "learning_rate": 0.00429187846172544, "batch_size": 418, "loss": 0.0023586913442704828}, {"layer_params": [49, 51, 34, 31, 37], "learning_rate": 0.005531376756195152, "batch_size": 204, "loss": 0.0013351142487954349}, {"layer_params": [24, 51, 42, 52], "learning_rate": 0.003943028890595371, "batch_size": 329, "loss": 0.002001096330350265}, {"layer_params": [18, 41, 59, 25, 59], "learning_rate": 0.009443291385424612, "batch_size": 373, "loss": 0.002721233677584678}, {"layer_params": [25, 41], "learning_rate": 0.008199523756000623, "batch_size": 111, "loss": 0.0029861784470267593}, {"layer_params": [25, 34, 64, 53], "learning_rate": 0.007890154993201476, "batch_size": 255, "loss": 0.002633388410322368}, {"layer_params": [35, 62, 64], "learning_rate": 0.00273332919245335, "batch_size": 50, "loss": 0.0026480892614927144}, {"layer_params": [37, 54], "learning_rate": 0.008417306027761208, "batch_size": 183, "loss": 0.0017674226150847972}, {"layer_params": [61, 47, 23], "learning_rate": 0.003984129966374162, "batch_size": 266, "loss": 0.0016883157298434525}, {"layer_params": [51, 49], "learning_rate": 0.009310527561336103, "batch_size": 392, "loss": 0.0018482008390128613}, {"layer_params": [48, 58, 29], "learning_rate": 0.007994290760055384, "batch_size": 113, "loss": 0.002042756829177961}, {"layer_params": [56, 38, 47], "learning_rate": 0.009458771633904545, "batch_size": 254, "loss": 0.0012887148401932791}, {"layer_params": [39, 26, 20], "learning_rate": 0.00624878837770959, "batch_size": 471, "loss": 0.002220922186970711}, {"layer_params": [44, 62, 20], "learning_rate": 0.004693037043380254, "batch_size": 473, "loss": 0.0014619989262428135}, {"layer_params": [22, 31, 35, 64, 56], "learning_rate": 0.009117952755551323, "batch_size": 118, "loss": 0.00613448322750628}, {"layer_params": [24, 51, 31, 55, 53], "learning_rate": 0.007040396634220514, "batch_size": 280, "loss": 0.0015368506778031588}, {"layer_params": [59, 16, 51], "learning_rate": 0.002322608380290894, "batch_size": 264, "loss": 0.0022763824160210787}, {"layer_params": [63, 49, 44], "learning_rate": 0.001131120701031376, "batch_size": 67, "loss": 0.004534113986883312}, {"layer_params": [44, 33, 44, 40], "learning_rate": 0.0053054254199595505, "batch_size": 192, "loss": 0.0016261299757752568}, {"layer_params": [16, 43, 39], "learning_rate": 0.006250349410583709, "batch_size": 180, "loss": 0.003920170075725764}, {"layer_params": [64, 40, 23], "learning_rate": 0.006534315514588982, "batch_size": 473, "loss": 0.001131210965104401}, {"layer_params": [29, 22, 25, 29, 55], "learning_rate": 0.007170273567580262, "batch_size": 429, "loss": 0.0025152790849097073}, {"layer_params": [35, 47, 57, 36], "learning_rate": 0.0011649887828332605, "batch_size": 130, "loss": 0.0029696024279110135}, {"layer_params": [42, 24, 18], "learning_rate": 0.007234195041730547, "batch_size": 239, "loss": 0.002903069278690964}, {"layer_params": [45, 18, 29, 47, 38], "learning_rate": 0.0029106260778188945, "batch_size": 234, "loss": 0.0032794941193424166}, {"layer_params": [24, 47, 19], "learning_rate": 9.611737503073578e-05, "batch_size": 439, "loss": 0.02718054046854377}, {"layer_params": [55, 64, 36, 16, 40], "learning_rate": 0.00988517812179766, "batch_size": 409, "loss": 0.001389161785482429}, {"layer_params": [21, 54, 33, 28, 61], "learning_rate": 0.006526609863442237, "batch_size": 500, "loss": 0.0011015003948705272}, {"layer_params": [46, 17, 20, 16, 50], "learning_rate": 0.009527540833442172, "batch_size": 86, "loss": 0.005037160692736507}, {"layer_params": [19, 30, 28, 50], "learning_rate": 0.008881805132696336, "batch_size": 374, "loss": 0.0027133461530320347}, {"layer_params": [41, 20, 38], "learning_rate": 0.007639105701982271, "batch_size": 350, "loss": 0.002387407326605171}, {"layer_params": [56, 26], "learning_rate": 0.004071484777518657, "batch_size": 178, "loss": 0.0019594308617524804}, {"layer_params": [37, 64], "learning_rate": 0.0015396113365972754, "batch_size": 269, "loss": 0.002240586517145857}, {"layer_params": [24, 33, 42, 52], "learning_rate": 0.007816650882191318, "batch_size": 71, "loss": 0.0054324106429703535}, {"layer_params": [54, 53], "learning_rate": 0.006570307728863445, "batch_size": 379, "loss": 0.0012204904318787158}, {"layer_params": [60, 47, 63, 64, 62], "learning_rate": 0.008469496763442372, "batch_size": 358, "loss": 0.0010946918843546883}, {"layer_params": [61, 28, 37], "learning_rate": 0.0004603728345230574, "batch_size": 377, "loss": 0.0054664245853200556}, {"layer_params": [20, 30, 27, 34], "learning_rate": 0.005784127940806883, "batch_size": 492, "loss": 0.0019639943074434996}, {"layer_params": [31, 53, 49, 33, 32], "learning_rate": 0.0004008632756992717, "batch_size": 307, "loss": 0.005062668262980879}, {"layer_params": [34, 43], "learning_rate": 0.009186366349740922, "batch_size": 363, "loss": 0.0026252787350676955}, {"layer_params": [19, 40, 38], "learning_rate": 0.0075423945757731176, "batch_size": 447, "loss": 0.002780050679575652}, {"layer_params": [62, 41, 40, 49], "learning_rate": 0.004779844427218216, "batch_size": 169, "loss": 0.0014159288816154004}, {"layer_params": [32, 33], "learning_rate": 0.009421191975432756, "batch_size": 41, "loss": 0.0051064593135379255}, {"layer_params": [19, 45, 36, 21, 57], "learning_rate": 0.0021783449918351227, "batch_size": 34, "loss": 0.0058687669853679835}, {"layer_params": [34, 44, 62], "learning_rate": 0.008091134300590327, "batch_size": 345, "loss": 0.0013649021578021347}, {"layer_params": [48, 39, 28], "learning_rate": 0.002293200761148293, "batch_size": 391, "loss": 0.0015386086609214544}, {"layer_params": [25, 31, 22, 57], "learning_rate": 0.008805373500287676, "batch_size": 91, "loss": 0.0031678579933941365}, {"layer_params": [30, 44, 51], "learning_rate": 0.009480004175027503, "batch_size": 460, "loss": 0.0016798960941378028}, {"layer_params": [41, 52, 23, 42, 21], "learning_rate": 0.0097240612802767, "batch_size": 508, "loss": 0.0011608052422525362}, {"layer_params": [41, 54], "learning_rate": 0.005187924020812255, "batch_size": 282, "loss": 0.0018612213840242474}, {"layer_params": [22, 43, 38], "learning_rate": 0.008326886961595037, "batch_size": 373, "loss": 0.0018108958192169667}, {"layer_params": [34, 63], "learning_rate": 0.00042790641057914477, "batch_size": 290, "loss": 0.007054315628483892}, {"layer_params": [41, 16, 55, 19], "learning_rate": 0.0051881497546870416, "batch_size": 271, "loss": 0.001887812657514587}, {"layer_params": [22, 19, 45, 60, 56], "learning_rate": 4.295117116878426e-05, "batch_size": 301, "loss": 0.03760268826037645}, {"layer_params": [35, 32, 30, 39, 46], "learning_rate": 0.004731260637561429, "batch_size": 503, "loss": 0.0010692123521585017}, {"layer_params": [45, 53, 16, 17], "learning_rate": 0.0020345347803189893, "batch_size": 412, "loss": 0.0025586129911243914}, {"layer_params": [31, 51, 57], "learning_rate": 0.0034308355256392202, "batch_size": 131, "loss": 0.002279321108944714}, {"layer_params": [37, 32, 64], "learning_rate": 0.008485219284020223, "batch_size": 267, "loss": 0.0018757237156387418}, {"layer_params": [21, 54, 38, 46, 48], "learning_rate": 0.0038616940320656146, "batch_size": 465, "loss": 0.0015316028241068125}, {"layer_params": [33, 49, 47, 52], "learning_rate": 0.008624692568891725, "batch_size": 487, "loss": 0.0012617286946624518}, {"layer_params": [27, 16, 58], "learning_rate": 0.005407711333065159, "batch_size": 46, "loss": 0.00473887420957908}, {"layer_params": [16, 38], "learning_rate": 0.002208348254334584, "batch_size": 215, "loss": 0.005306074540130794}, {"layer_params": [31, 34, 29, 37, 18], "learning_rate": 0.00501283631059555, "batch_size": 496, "loss": 0.0018794736580457537}, {"layer_params": [47, 25, 38, 60], "learning_rate": 0.009015906919439307, "batch_size": 495, "loss": 0.0009278888866538182}, {"layer_params": [47, 64, 18, 64], "learning_rate": 0.003280978723234439, "batch_size": 428, "loss": 0.0012035536108305678}, {"layer_params": [44, 30, 36, 53], "learning_rate": 0.0026337717141889415, "batch_size": 386, "loss": 0.001525425707222894}, {"layer_params": [18, 26, 51, 59], "learning_rate": 0.0019499695448951325, "batch_size": 194, "loss": 0.005775027403142303}, {"layer_params": [42, 57, 25], "learning_rate": 0.006522099909969628, "batch_size": 49, "loss": 0.003607755232369527}, {"layer_params": [25, 58, 45, 21], "learning_rate": 0.006688722927873108, "batch_size": 318, "loss": 0.0012461860559415073}, {"layer_params": [29, 54, 44, 58, 28], "learning_rate": 0.0007924447991842508, "batch_size": 243, "loss": 0.0029284725710749626}, {"layer_params": [53, 32, 32], "learning_rate": 0.005423531618792756, "batch_size": 476, "loss": 0.0013436094054486603}, {"layer_params": [49, 39, 61, 37], "learning_rate": 0.007534690707501208, "batch_size": 85, "loss": 0.002666612910106778}, {"layer_params": [19, 21, 62, 23, 51], "learning_rate": 0.005439636623727009, "batch_size": 105, "loss": 0.004581551558803767}, {"layer_params": [38, 36, 33], "learning_rate": 0.003917424976946048, "batch_size": 214, "loss": 0.00306589781306684}, {"layer_params": [17, 29, 21, 29], "learning_rate": 0.009278277655528062, "batch_size": 454, "loss": 0.002758444806095213}, {"layer_params": [54, 24], "learning_rate": 0.006474021265895556, "batch_size": 506, "loss": 0.0029807080049067737}, {"layer_params": [41, 22, 52], "learning_rate": 0.0013211832863634396, "batch_size": 180, "loss": 0.004965075389482081}, {"layer_params": [20, 55, 21, 18, 22], "learning_rate": 0.004693124426523684, "batch_size": 180, "loss": 0.0032462102361023428}, {"layer_params": [32, 51, 27], "learning_rate": 0.004020882200209898, "batch_size": 500, "loss": 0.0008845721936086193}, {"layer_params": [29, 34], "learning_rate": 0.003719894707222355, "batch_size": 93, "loss": 0.004140589640010148}, {"layer_params": [46, 24, 25, 56], "learning_rate": 0.008166288010039066, "batch_size": 484, "loss": 0.0018862588773481549}, {"layer_params": [59, 19], "learning_rate": 0.007012731708549274, "batch_size": 280, "loss": 0.0022330212977249176}, {"layer_params": [56, 58, 38, 54], "learning_rate": 0.007435004264061125, "batch_size": 358, "loss": 0.0012234364735195413}, {"layer_params": [52, 47, 20], "learning_rate": 0.002812347986003118, "batch_size": 104, "loss": 0.0032654710276983677}, {"layer_params": [21, 56, 17, 22], "learning_rate": 0.009371967917313775, "batch_size": 494, "loss": 0.003871785730589181}, {"layer_params": [26, 31], "learning_rate": 0.003653951452768998, "batch_size": 379, "loss": 0.0041556367371231315}, {"layer_params": [51, 30, 18], "learning_rate": 0.006343890338901256, "batch_size": 216, "loss": 0.001867894970346242}, {"layer_params": [16, 31, 55, 57, 37], "learning_rate": 0.008948706361063099, "batch_size": 47, "loss": 0.004453709670342505}, {"layer_params": [31, 62, 37, 24], "learning_rate": 0.008179172055452464, "batch_size": 221, "loss": 0.0018836113496217876}, {"layer_params": [34, 58, 36], "learning_rate": 0.001969130164597367, "batch_size": 351, "loss": 0.0019761756516527384}, {"layer_params": [31, 37, 38], "learning_rate": 0.009819046816471465, "batch_size": 263, "loss": 0.0026948055205866695}, {"layer_params": [17, 33], "learning_rate": 0.00286437276902411, "batch_size": 231, "loss": 0.004946518251672387}, {"layer_params": [57, 18, 29, 28, 53], "learning_rate": 0.006919234125413827, "batch_size": 17, "loss": 0.008530212212353944}, {"layer_params": [23, 52], "learning_rate": 0.008586966729027586, "batch_size": 90, "loss": 0.003774847467429936}, {"layer_params": [50, 16], "learning_rate": 0.0032103632093727864, "batch_size": 39, "loss": 0.0047870863694697615}, {"layer_params": [54, 32, 50], "learning_rate": 0.006849914501795222, "batch_size": 352, "loss": 0.0013024386140750722}, {"layer_params": [30, 41], "learning_rate": 0.006169985636270305, "batch_size": 297, "loss": 0.0017239134514238684}, {"layer_params": [41, 26], "learning_rate": 0.008280116978464369, "batch_size": 166, "loss": 0.0024932456098031254}, {"layer_params": [27, 25, 43], "learning_rate": 0.004081589287927178, "batch_size": 511, "loss": 0.002286501098424196}, {"layer_params": [41, 57, 37, 17, 20], "learning_rate": 0.001273177602434638, "batch_size": 172, "loss": 0.002624851504806429}, {"layer_params": [51, 22, 21, 60, 42], "learning_rate": 0.006536465559851839, "batch_size": 203, "loss": 0.0026700067531783135}, {"layer_params": [60, 39, 49], "learning_rate": 0.0020568483762495498, "batch_size": 61, "loss": 0.0035234520328231156}, {"layer_params": [36, 63], "learning_rate": 0.00789356336395834, "batch_size": 274, "loss": 0.0018268123676534742}, {"layer_params": [29, 27, 29, 62], "learning_rate": 0.0002346309105907179, "batch_size": 312, "loss": 0.007358771525323391}, {"layer_params": [35, 39, 31, 17, 52], "learning_rate": 0.004861203022222679, "batch_size": 385, "loss": 0.0017078457016032188}, {"layer_params": [51, 19, 39, 42], "learning_rate": 0.001188097056746408, "batch_size": 80, "loss": 0.006803194035310298}, {"layer_params": [26, 45, 36, 50], "learning_rate": 0.006078588073658482, "batch_size": 398, "loss": 0.0018576389783993364}, {"layer_params": [37, 34], "learning_rate": 0.005837681211504419, "batch_size": 205, "loss": 0.003299808343872428}, {"layer_params": [40, 41, 39, 46, 61], "learning_rate": 0.0012326243166526185, "batch_size": 79, "loss": 0.005917463973164558}, {"layer_params": [61, 61, 35, 52], "learning_rate": 0.008475353128037329, "batch_size": 342, "loss": 0.0009779270383296534}, {"layer_params": [30, 18, 34, 56, 60], "learning_rate": 0.0012768349500124415, "batch_size": 387, "loss": 0.003299309883732349}, {"layer_params": [34, 59, 46, 16, 32], "learning_rate": 0.003930746404253529, "batch_size": 335, "loss": 0.0018081385432742536}, {"layer_params": [35, 27, 41], "learning_rate": 0.00011636797413822396, "batch_size": 200, "loss": 0.013189257914200425}, {"layer_params": [31, 32, 28, 20, 17], "learning_rate": 0.007050955619253885, "batch_size": 497, "loss": 0.001368711171671748}, {"layer_params": [17, 36, 44, 29, 26], "learning_rate": 0.00787078672880036, "batch_size": 395, "loss": 0.0020338613959029316}, {"layer_params": [52, 43, 46], "learning_rate": 0.004211114118467819, "batch_size": 277, "loss": 0.0013096241420134903}, {"layer_params": [48, 53], "learning_rate": 0.00904840038122041, "batch_size": 128, "loss": 0.0025796996022108944}, {"layer_params": [34, 61, 64], "learning_rate": 0.00303717641777365, "batch_size": 294, "loss": 0.0020073268783744424}, {"layer_params": [57, 61, 51, 27, 29], "learning_rate": 0.0008553469854768866, "batch_size": 192, "loss": 0.0032935042027384042}, {"layer_params": [20, 61, 17, 29, 43], "learning_rate": 0.0006425012495960763, "batch_size": 203, "loss": 0.005110752554610371}, {"layer_params": [26, 34, 27, 53], "learning_rate": 0.007740547085067797, "batch_size": 257, "loss": 0.001965704255271703}, {"layer_params": [58, 46, 31, 16], "learning_rate": 0.0023666820794464, "batch_size": 129, "loss": 0.001817958145402372}, {"layer_params": [47, 60, 35, 51, 26], "learning_rate": 0.00022647359681146907, "batch_size": 86, "loss": 0.008010194986127317}, {"layer_params": [63, 30, 39], "learning_rate": 0.007412903417471852, "batch_size": 50, "loss": 0.00311583079979755}, {"layer_params": [62, 36], "learning_rate": 0.005844043302931719, "batch_size": 410, "loss": 0.002050588954007253}, {"layer_params": [35, 25], "learning_rate": 0.0021600963373205476, "batch_size": 349, "loss": 0.004560578786768019}, {"layer_params": [53, 41, 57, 21, 58], "learning_rate": 0.008322229811148076, "batch_size": 185, "loss": 0.0009308998787309975}, {"layer_params": [20, 47, 61, 46, 36], "learning_rate": 0.0007812006931332421, "batch_size": 65, "loss": 0.007692259871400892}, {"layer_params": [36, 59, 46, 62], "learning_rate": 0.00488032760850581, "batch_size": 42, "loss": 0.005128330709412694}, {"layer_params": [48, 50, 51, 22, 28], "learning_rate": 0.00812505238090308, "batch_size": 243, "loss": 0.0008729032689007}, {"layer_params": [59, 22, 31, 44, 28], "learning_rate": 0.008468306949274359, "batch_size": 74, "loss": 0.0036010164534673096}, {"layer_params": [37, 33, 61], "learning_rate": 0.0038672395504422657, "batch_size": 80, "loss": 0.0033274817024357617}, {"layer_params": [31, 64], "learning_rate": 0.003948716016831595, "batch_size": 249, "loss": 0.0035463819070719184}, {"layer_params": [61, 16, 27, 43], "learning_rate": 0.004430046479763541, "batch_size": 235, "loss": 0.0030337748886086046}, {"layer_params": [17, 22, 34, 22, 37], "learning_rate": 0.003432352893330743, "batch_size": 44, "loss": 0.00754037267062813}, {"layer_params": [50, 33, 56, 33, 45], "learning_rate": 0.0003983424956692191, "batch_size": 479, "loss": 0.00459851001156494}, {"layer_params": [27, 41, 16, 40, 30], "learning_rate": 0.005116892748757421, "batch_size": 206, "loss": 0.0028394075110554696}, {"layer_params": [38, 16, 19, 37, 45], "learning_rate": 0.0020091565858544993, "batch_size": 494, "loss": 0.0028730832971632482}, {"layer_params": [46, 16, 23, 32], "learning_rate": 0.0037959412774358115, "batch_size": 99, "loss": 0.003212144039571285}, {"layer_params": [61, 60, 33], "learning_rate": 0.0030559852665698163, "batch_size": 308, "loss": 0.001741595382336527}, {"layer_params": [60, 45, 34], "learning_rate": 0.0010835723769694247, "batch_size": 253, "loss": 0.0029852380463853477}, {"layer_params": [41, 25], "learning_rate": 0.002751294081933398, "batch_size": 103, "loss": 0.005285038000438363}, {"layer_params": [37, 39], "learning_rate": 0.009748865735168553, "batch_size": 151, "loss": 0.002230974822305143}, {"layer_params": [34, 27], "learning_rate": 0.0020004708335988578, "batch_size": 441, "loss": 0.002538852617144585}, {"layer_params": [32, 30, 37], "learning_rate": 0.0025741599727753194, "batch_size": 201, "loss": 0.003061741089913994}, {"layer_params": [35, 50, 55], "learning_rate": 0.0018641110066824253, "batch_size": 213, "loss": 0.0023332044307608157}, {"layer_params": [35, 46, 26, 51], "learning_rate": 0.009796257338467229, "batch_size": 364, "loss": 0.0024570598488207907}, {"layer_params": [59, 53, 43, 27], "learning_rate": 0.005934727392633471, "batch_size": 467, "loss": 0.0009378485701745376}, {"layer_params": [25, 48, 24], "learning_rate": 0.009225862296493317, "batch_size": 482, "loss": 0.0027626517857424916}, {"layer_params": [21, 60], "learning_rate": 0.003908057005138973, "batch_size": 55, "loss": 0.00538752680644393}, {"layer_params": [20, 36, 37, 43, 37], "learning_rate": 0.0061054769513081844, "batch_size": 291, "loss": 0.0016948789509478957}, {"layer_params": [23, 38, 59, 52, 17], "learning_rate": 0.009685996262412311, "batch_size": 459, "loss": 0.0013900235493201761}, {"layer_params": [62, 35, 54], "learning_rate": 0.003966682839687805, "batch_size": 18, "loss": 0.007253313928376883}, {"layer_params": [38, 26, 60], "learning_rate": 0.004434057429681749, "batch_size": 34, "loss": 0.006149807134643197}, {"layer_params": [56, 27], "learning_rate": 0.0028667317928071623, "batch_size": 86, "loss": 0.005105595360510052}, {"layer_params": [38, 56, 39], "learning_rate": 0.0009437304158704576, "batch_size": 263, "loss": 0.0029822990810498594}, {"layer_params": [35, 29, 25, 42], "learning_rate": 0.00765251912562634, "batch_size": 506, "loss": 0.0019455500482581556}, {"layer_params": [22, 27, 45], "learning_rate": 0.003927372807322676, "batch_size": 100, "loss": 0.0038721932074986397}, {"layer_params": [38, 60], "learning_rate": 0.009314209531378658, "batch_size": 325, "loss": 0.0018998002726584673}, {"layer_params": [30, 42, 44, 60, 22], "learning_rate": 0.007873313541795334, "batch_size": 437, "loss": 0.0013892864831723272}, {"layer_params": [41, 22, 43, 41, 32], "learning_rate": 0.0003311248354892186, "batch_size": 88, "loss": 0.00734235140029341}, {"layer_params": [26, 49, 63, 40], "learning_rate": 0.0004466916905738378, "batch_size": 123, "loss": 0.007176360525190831}, {"layer_params": [56, 38, 23], "learning_rate": 0.002605890440299331, "batch_size": 73, "loss": 0.0029690386087168007}, {"layer_params": [48, 27, 47, 52], "learning_rate": 0.001194036209825908, "batch_size": 38, "loss": 0.006428714098874479}, {"layer_params": [59, 43], "learning_rate": 0.002901354535740294, "batch_size": 283, "loss": 0.0018120922846719622}, {"layer_params": [19, 41, 27], "learning_rate": 0.0044700350280895565, "batch_size": 198, "loss": 0.004766363557428122}, {"layer_params": [51, 38], "learning_rate": 0.008541223126809484, "batch_size": 91, "loss": 0.0033632400166243317}, {"layer_params": [56, 41, 26], "learning_rate": 0.009855797797696842, "batch_size": 278, "loss": 0.0011916468007257207}, {"layer_params": [43, 56, 21, 47], "learning_rate": 0.006647854944108861, "batch_size": 330, "loss": 0.001487189376493916}, {"layer_params": [49, 60], "learning_rate": 0.007933946650307779, "batch_size": 212, "loss": 0.0011499729013303296}, {"layer_params": [47, 26, 23, 18, 24], "learning_rate": 0.0008462065392702434, "batch_size": 219, "loss": 0.004839887821581215}, {"layer_params": [29, 44], "learning_rate": 0.0009215326486291739, "batch_size": 87, "loss": 0.007138988242950291}, {"layer_params": [54, 31, 63], "learning_rate": 0.001982107864355454, "batch_size": 177, "loss": 0.0018619650846812873}, {"layer_params": [20, 38], "learning_rate": 0.006640464907356306, "batch_size": 52, "loss": 0.006230085690040141}, {"layer_params": [37, 60, 49, 58, 35], "learning_rate": 0.007596893464351161, "batch_size": 417, "loss": 0.001219425418530591}, {"layer_params": [18, 60, 56, 29, 20], "learning_rate": 0.002014278281001658, "batch_size": 292, "loss": 0.0033704962162300943}, {"layer_params": [57, 64, 32, 54, 56], "learning_rate": 0.001318797269462137, "batch_size": 284, "loss": 0.0016914845677092672}, {"layer_params": [41, 60, 49], "learning_rate": 0.001902780147855244, "batch_size": 136, "loss": 0.002420917364070192}, {"layer_params": [54, 50, 27], "learning_rate": 0.00995105575454449, "batch_size": 38, "loss": 0.0028978736221324654}, {"layer_params": [58, 49, 38], "learning_rate": 0.004196740160743209, "batch_size": 485, "loss": 0.0011280888709006831}, {"layer_params": [35, 34, 41, 21], "learning_rate": 0.0083563942093635, "batch_size": 86, "loss": 0.0037808309448882937}, {"layer_params": [22, 36, 35], "learning_rate": 0.000494596044983192, "batch_size": 168, "loss": 0.007073811059817672}, {"layer_params": [36, 23, 41], "learning_rate": 0.008721081735349674, "batch_size": 21, "loss": 0.006779344966635108}, {"layer_params": [52, 17, 53], "learning_rate": 0.004190983171403548, "batch_size": 278, "loss": 0.0023761816578917205}, {"layer_params": [45, 61], "learning_rate": 0.006646330288067164, "batch_size": 223, "loss": 0.0021083266194909813}, {"layer_params": [51, 32, 25, 49], "learning_rate": 0.005414816176985372, "batch_size": 408, "loss": 0.0018485648522619158}, {"layer_params": [40, 23, 56, 19, 34], "learning_rate": 0.004242310387454566, "batch_size": 506, "loss": 0.0017827907053288073}, {"layer_params": [20, 30, 35, 30, 29], "learning_rate": 0.009175385329739163, "batch_size": 89, "loss": 0.004825190624687821}, {"layer_params": [21, 43, 56, 40], "learning_rate": 0.009199480329890482, "batch_size": 302, "loss": 0.0014764267345890403}, {"layer_params": [50, 34, 43, 34, 29], "learning_rate": 0.009444130503625341, "batch_size": 89, "loss": 0.002517295996658504}, {"layer_params": [36, 44], "learning_rate": 0.006240950761226142, "batch_size": 503, "loss": 0.0010197874519508332}, {"layer_params": [39, 27, 55], "learning_rate": 0.003029697800698132, "batch_size": 319, "loss": 0.0024295190314296633}, {"layer_params": [36, 39, 28], "learning_rate": 0.001005371022128806, "batch_size": 197, "loss": 0.004013766534626484}, {"layer_params": [62, 18, 18], "learning_rate": 0.0012283811634502346, "batch_size": 324, "loss": 0.004304728202987463}, {"layer_params": [18, 33, 59, 60], "learning_rate": 0.00751481468824369, "batch_size": 221, "loss": 0.0023710185615345835}, {"layer_params": [27, 48, 43], "learning_rate": 0.009921285449897777, "batch_size": 323, "loss": 0.001768564385129139}, {"layer_params": [37, 49, 17], "learning_rate": 0.005016591498583735, "batch_size": 404, "loss": 0.0018225618370343}, {"layer_params": [54, 63], "learning_rate": 0.0014439561746121552, "batch_size": 434, "loss": 0.00187920774333179}, {"layer_params": [29, 49], "learning_rate": 0.0058149303761526, "batch_size": 77, "loss": 0.003535611398983747}, {"layer_params": [34, 47, 22, 25, 31], "learning_rate": 0.0022295574300126137, "batch_size": 21, "loss": 0.00746893699048087}, {"layer_params": [21, 38, 63], "learning_rate": 0.009654809761568732, "batch_size": 243, "loss": 0.002833795896731317}, {"layer_params": [36, 23, 41, 56, 36], "learning_rate": 0.0026493754009247936, "batch_size": 233, "loss": 0.00479760640533641}, {"layer_params": [58, 57, 40], "learning_rate": 0.009237250369868187, "batch_size": 504, "loss": 0.0007296775700524449}, {"layer_params": [44, 44, 47, 49], "learning_rate": 0.0008067114298408079, "batch_size": 269, "loss": 0.0036811594339087607}, {"layer_params": [53, 35, 31], "learning_rate": 0.0006644647431804294, "batch_size": 321, "loss": 0.004343329423572868}, {"layer_params": [57, 35, 16, 46], "learning_rate": 0.007038382360893614, "batch_size": 252, "loss": 0.0026705703174229713}, {"layer_params": [22, 46, 43, 59], "learning_rate": 0.009741380720086188, "batch_size": 277, "loss": 0.002064653169363737}, {"layer_params": [27, 61], "learning_rate": 0.0018141393413205686, "batch_size": 126, "loss": 0.003948440405074507}, {"layer_params": [31, 56, 32], "learning_rate": 0.005818952555243932, "batch_size": 183, "loss": 0.002576063731685281}, {"layer_params": [51, 41, 26], "learning_rate": 0.005982423961769306, "batch_size": 60, "loss": 0.0038768504397012292}, {"layer_params": [61, 30], "learning_rate": 0.005857921647660892, "batch_size": 74, "loss": 0.004746183252427727}, {"layer_params": [53, 32, 53, 49, 18], "learning_rate": 0.008397650320077624, "batch_size": 335, "loss": 0.0009110518160741776}, {"layer_params": [64, 18, 34], "learning_rate": 0.005925058916173395, "batch_size": 353, "loss": 0.0025024352001491936}, {"layer_params": [52, 38], "learning_rate": 0.0008048755400535875, "batch_size": 385, "loss": 0.00420806186273694}, {"layer_params": [21, 58, 26, 42], "learning_rate": 0.0012272401306894117, "batch_size": 375, "loss": 0.003018753326032311}, {"layer_params": [51, 29, 39, 36, 62], "learning_rate": 0.0012452187196301376, "batch_size": 60, "loss": 0.005679099410772323}, {"layer_params": [39, 57, 44, 39], "learning_rate": 0.005056555809399708, "batch_size": 451, "loss": 0.0006941453367471695}, {"layer_params": [47, 16, 52], "learning_rate": 0.007416299227347308, "batch_size": 45, "loss": 0.0052511797961778935}, {"layer_params": [39, 44, 52, 57], "learning_rate": 0.0031592328709449777, "batch_size": 188, "loss": 0.002068800388369709}, {"layer_params": [54, 38, 17, 25, 21], "learning_rate": 0.0076727570575764875, "batch_size": 147, "loss": 0.0022851778008043766}, {"layer_params": [25, 26, 54, 38, 41], "learning_rate": 0.008486700444313707, "batch_size": 424, "loss": 0.002625956202391535}, {"layer_params": [62, 62, 59, 34, 22], "learning_rate": 0.002155898126472888, "batch_size": 368, "loss": 0.0008243765233783051}, {"layer_params": [52, 23, 55], "learning_rate": 0.005731848040149773, "batch_size": 199, "loss": 0.002388014298630878}, {"layer_params": [55, 46], "learning_rate": 0.007532385837577882, "batch_size": 415, "loss": 0.001392634614603594}, {"layer_params": [49, 50, 46], "learning_rate": 0.00680235288642512, "batch_size": 344, "loss": 0.0010107674618484452}, {"layer_params": [44, 59, 25, 62, 24], "learning_rate": 0.005093853039191695, "batch_size": 24, "loss": 0.004949650892522186}, {"layer_params": [18, 44, 44], "learning_rate": 0.004135649713060366, "batch_size": 455, "loss": 0.0032611026801168917}, {"layer_params": [34, 19, 40, 44], "learning_rate": 0.002550344333522058, "batch_size": 280, "loss": 0.003028828459791839}, {"layer_params": [26, 28, 24, 46], "learning_rate": 0.006690312219192745, "batch_size": 397, "loss": 0.003061408281791955}, {"layer_params": [22, 47, 60, 62], "learning_rate": 0.002723151596937536, "batch_size": 69, "loss": 0.005173062118701637}, {"layer_params": [17, 47], "learning_rate": 0.0014715674610320457, "batch_size": 303, "loss": 0.007102567199617624}, {"layer_params": [47, 56, 41, 30], "learning_rate": 0.00038880667094887486, "batch_size": 484, "loss": 0.005917417039163411}, {"layer_params": [36, 18, 52, 62, 22], "learning_rate": 0.00894128438652286, "batch_size": 131, "loss": 0.0032335500442422925}, {"layer_params": [36, 55], "learning_rate": 0.0009261179622752786, "batch_size": 489, "loss": 0.002805971514899284}, {"layer_params": [49, 25], "learning_rate": 0.006869201776307291, "batch_size": 322, "loss": 0.0030327180190943184}, {"layer_params": [50, 31], "learning_rate": 0.008384721516047598, "batch_size": 50, "loss": 0.003519491945626214}, {"layer_params": [35, 26, 52, 46, 38], "learning_rate": 0.00542952793885041, "batch_size": 223, "loss": 0.0023098603705875576}, {"layer_params": [51, 37, 21], "learning_rate": 0.005139648619336153, "batch_size": 492, "loss": 0.0016873518307693302}, {"layer_params": [59, 59, 63, 51, 41], "learning_rate": 0.004102198053820855, "batch_size": 400, "loss": 0.0014472201594617218}, {"layer_params": [27, 50, 44], "learning_rate": 0.009593432980321743, "batch_size": 239, "loss": 0.0018765696010086686}, {"layer_params": [27, 16], "learning_rate": 0.007987014681836364, "batch_size": 226, "loss": 0.005995745779946446}, {"layer_params": [19, 44, 21, 27, 35], "learning_rate": 0.004838369693467834, "batch_size": 449, "loss": 0.0021074474893976003}, {"layer_params": [64, 30, 33, 34], "learning_rate": 0.009321529939822461, "batch_size": 262, "loss": 0.0008570370747474954}, {"layer_params": [19, 54, 24, 19], "learning_rate": 0.007669899143567886, "batch_size": 165, "loss": 0.003072615349665284}, {"layer_params": [25, 25, 46, 26], "learning_rate": 0.007969883697027018, "batch_size": 394, "loss": 0.002464586596470326}, {"layer_params": [28, 36, 24, 33, 16], "learning_rate": 0.0035047906226692263, "batch_size": 374, "loss": 0.0028808750840835272}, {"layer_params": [57, 63, 19], "learning_rate": 0.0027718289399653513, "batch_size": 412, "loss": 0.0017024974932428449}, {"layer_params": [21, 17, 26, 39], "learning_rate": 0.0019388766066069441, "batch_size": 155, "loss": 0.005360259977169335}, {"layer_params": [60, 52], "learning_rate": 0.009043538469821042, "batch_size": 77, "loss": 0.0021470241236966102}, {"layer_params": [63, 52, 56, 55, 36], "learning_rate": 0.005816276517305086, "batch_size": 483, "loss": 0.0009033301641466096}, {"layer_params": [16, 26, 24], "learning_rate": 0.007083429044437976, "batch_size": 283, "loss": 0.0030757363489829002}, {"layer_params": [49, 40, 37, 21], "learning_rate": 0.007858731907652166, "batch_size": 212, "loss": 0.0018962079158518464}, {"layer_params": [52, 19, 34, 18, 43], "learning_rate": 0.001051341294578717, "batch_size": 36, "loss": 0.006969758046325296}, {"layer_params": [41, 19, 60], "learning_rate": 0.00020865326625181063, "batch_size": 488, "loss": 0.007947773593477904}, {"layer_params": [18, 38, 45, 59, 50], "learning_rate": 0.005510946469612319, "batch_size": 334, "loss": 0.0021561080811079592}, {"layer_params": [44, 39, 22], "learning_rate": 0.0028647396070127437, "batch_size": 186, "loss": 0.002274993718601763}, {"layer_params": [16, 43], "learning_rate": 0.0012516121017676475, "batch_size": 303, "loss": 0.007869523349218071}, {"layer_params": [36, 23], "learning_rate": 0.00897833051742711, "batch_size": 145, "loss": 0.003965375474654138}, {"layer_params": [50, 27, 33], "learning_rate": 0.0009383391786301955, "batch_size": 348, "loss": 0.004403900259640068}, {"layer_params": [49, 28], "learning_rate": 0.0025407899403588003, "batch_size": 368, "loss": 0.0028131526592187583}, {"layer_params": [51, 22, 36, 47], "learning_rate": 0.0017424094705730585, "batch_size": 18, "loss": 0.007806708186399192}, {"layer_params": [52, 28], "learning_rate": 0.003098423276558847, "batch_size": 171, "loss": 0.0032626489433459937}, {"layer_params": [29, 57, 62, 25], "learning_rate": 0.007718389115840347, "batch_size": 309, "loss": 0.0009690406691515818}, {"layer_params": [35, 61, 35], "learning_rate": 0.00023404335175165254, "batch_size": 456, "loss": 0.007025838871486485}, {"layer_params": [17, 26, 48], "learning_rate": 0.008626779275764522, "batch_size": 498, "loss": 0.004142437609843909}, {"layer_params": [21, 63, 16, 29], "learning_rate": 0.0023857500973911037, "batch_size": 106, "loss": 0.00391732326708734}, {"layer_params": [28, 57, 31, 40], "learning_rate": 0.001048802242812245, "batch_size": 43, "loss": 0.005069977766834199}, {"layer_params": [20, 50, 30], "learning_rate": 0.004749891823428774, "batch_size": 291, "loss": 0.0027173362718895078}, {"layer_params": [34, 53, 64], "learning_rate": 0.001691639694555471, "batch_size": 234, "loss": 0.0020448964345268906}, {"layer_params": [27, 57, 46, 28, 58], "learning_rate": 0.005418107062686318, "batch_size": 215, "loss": 0.0012943429133156314}, {"layer_params": [62, 24, 35, 63], "learning_rate": 0.0008207555864346093, "batch_size": 323, "loss": 0.00417704681167379}, {"layer_params": [43, 57], "learning_rate": 0.004904280008324024, "batch_size": 512, "loss": 0.0026546403765678405}, {"layer_params": [63, 49], "learning_rate": 0.0006879138135073132, "batch_size": 459, "loss": 0.003953999734949321}, {"layer_params": [24, 40], "learning_rate": 0.009091955789282085, "batch_size": 70, "loss": 0.004177482426166534}, {"layer_params": [40, 51, 36, 22], "learning_rate": 0.007944169437237338, "batch_size": 237, "loss": 0.0011701364448526875}, {"layer_params": [63, 43, 61], "learning_rate": 0.004427707953199024, "batch_size": 143, "loss": 0.0014547323435544967}, {"layer_params": [39, 18, 60, 38, 22], "learning_rate": 0.003717009787715704, "batch_size": 213, "loss": 0.0024980136984959246}, {"layer_params": [25, 59], "learning_rate": 0.0008094004350753082, "batch_size": 405, "loss": 0.005985548263415694}, {"layer_params": [28, 39, 42], "learning_rate": 0.006311961668997438, "batch_size": 78, "loss": 0.003030488051008433}, {"layer_params": [61, 19, 64, 58, 48], "learning_rate": 0.008805462037595944, "batch_size": 242, "loss": 0.0010166729963384568}, {"layer_params": [33, 34, 61], "learning_rate": 0.0013600198104570989, "batch_size": 254, "loss": 0.0036742278607562184}, {"layer_params": [64, 34, 46, 42], "learning_rate": 0.003824192661519864, "batch_size": 492, "loss": 0.001181660071015358}, {"layer_params": [48, 32, 64, 45, 51], "learning_rate": 0.0033693525787249962, "batch_size": 170, "loss": 0.002459517871029675}, {"layer_params": [44, 21, 26, 49], "learning_rate": 0.005643863653275341, "batch_size": 99, "loss": 0.0038842112640850245}, {"layer_params": [34, 17, 52], "learning_rate": 0.003386293171508189, "batch_size": 376, "loss": 0.002635316173546016}, {"layer_params": [30, 33, 57, 59, 43], "learning_rate": 0.0029454134364866697, "batch_size": 458, "loss": 0.0015407677902840077}, {"layer_params": [41, 34, 36, 48], "learning_rate": 0.00028184129896884064, "batch_size": 511, "loss": 0.006869630464352667}, {"layer_params": [44, 63, 42, 40, 37], "learning_rate": 0.007729096781801131, "batch_size": 81, "loss": 0.0027402679971419274}, {"layer_params": [61, 44, 34], "learning_rate": 0.004113697963356373, "batch_size": 509, "loss": 0.0006513972190441564}, {"layer_params": [52, 47, 51], "learning_rate": 0.008384604055680249, "batch_size": 235, "loss": 0.0016319918783847243}, {"layer_params": [43, 59, 46, 31], "learning_rate": 0.0017699192605907365, "batch_size": 187, "loss": 0.0030435626953840256}, {"layer_params": [21, 45], "learning_rate": 0.008296711138129782, "batch_size": 390, "loss": 0.002076920534018427}, {"layer_params": [20, 60, 55, 27], "learning_rate": 0.0063783389597595825, "batch_size": 303, "loss": 0.0015869264339562505}, {"layer_params": [25, 31, 58], "learning_rate": 0.0017238553307661235, "batch_size": 256, "loss": 0.0041310440562665465}, {"layer_params": [31, 34, 61, 33, 17], "learning_rate": 0.00027738424374688193, "batch_size": 77, "loss": 0.008264399752952158}, {"layer_params": [24, 49], "learning_rate": 0.006614419373753679, "batch_size": 151, "loss": 0.004547299982514233}, {"layer_params": [31, 34, 62, 31, 39], "learning_rate": 0.0072606965459690665, "batch_size": 227, "loss": 0.0021064712747465818}, {"layer_params": [19, 19, 41], "learning_rate": 0.002455144324968306, "batch_size": 215, "loss": 0.006346928020939231}, {"layer_params": [33, 18], "learning_rate": 0.005431433793838445, "batch_size": 302, "loss": 0.003984277395065874}, {"layer_params": [24, 46, 30, 48, 60], "learning_rate": 0.00610397704254245, "batch_size": 297, "loss": 0.0018308581644669176}, {"layer_params": [53, 47], "learning_rate": 0.0042010601869451256, "batch_size": 294, "loss": 0.0021902751270681618}, {"layer_params": [39, 51], "learning_rate": 0.0017746603737252965, "batch_size": 128, "loss": 0.005385284854564815}, {"layer_params": [59, 39, 43, 54, 34], "learning_rate": 0.005381834299388547, "batch_size": 165, "loss": 0.0025152298447210343}, {"layer_params": [51, 49], "learning_rate": 0.003880437979516904, "batch_size": 172, "loss": 0.002162099132547155}, {"layer_params": [63, 28], "learning_rate": 0.008574806286264995, "batch_size": 19, "loss": 0.007325076879933477}, {"layer_params": [52, 51, 47, 47], "learning_rate": 0.0005873180895503519, "batch_size": 365, "loss": 0.0030110954167321324}, {"layer_params": [16, 25, 19, 56, 50], "learning_rate": 0.0013299447824502838, "batch_size": 296, "loss": 0.005114744524471462}, {"layer_params": [57, 27, 37, 20], "learning_rate": 0.00802580706902993, "batch_size": 148, "loss": 0.003503382403869182}, {"layer_params": [26, 38, 18, 50, 36], "learning_rate": 0.009347231716230902, "batch_size": 503, "loss": 0.002042477901559323}, {"layer_params": [20, 62], "learning_rate": 0.004118138530776101, "batch_size": 52, "loss": 0.006485562329180539}, {"layer_params": [60, 34, 55], "learning_rate": 0.00326831598024195, "batch_size": 246, "loss": 0.0018018532206770033}, {"layer_params": [52, 61], "learning_rate": 0.0090913295072288, "batch_size": 256, "loss": 0.0016565992368850857}, {"layer_params": [62, 40, 23], "learning_rate": 0.007108185284588156, "batch_size": 213, "loss": 0.0015199096908327192}, {"layer_params": [56, 43], "learning_rate": 0.004677290424880047, "batch_size": 189, "loss": 0.001477737464592792}, {"layer_params": [20, 63, 57, 50], "learning_rate": 0.005505228712115233, "batch_size": 35, "loss": 0.0064556551375426355}, {"layer_params": [32, 62, 20, 37], "learning_rate": 0.0010833577775981693, "batch_size": 18, "loss": 0.008011883967556059}, {"layer_params": [58, 23, 47], "learning_rate": 0.007328329035468546, "batch_size": 503, "loss": 0.0019648648577276617}, {"layer_params": [45, 40], "learning_rate": 0.0008099162069748324, "batch_size": 371, "loss": 0.0037323778728023172}, {"layer_params": [62, 24, 58, 32, 46], "learning_rate": 0.007569011191930384, "batch_size": 106, "loss": 0.001789185901870951}, {"layer_params": [29, 51], "learning_rate": 0.0027384456777859376, "batch_size": 101, "loss": 0.005342820363584906}, {"layer_params": [34, 47, 64, 26, 39], "learning_rate": 0.007012635046549287, "batch_size": 272, "loss": 0.001412371131591499}, {"layer_params": [47, 60], "learning_rate": 0.0005469925066355868, "batch_size": 336, "loss": 0.004763735921587795}, {"layer_params": [37, 40, 37, 55, 22], "learning_rate": 0.002454989198848957, "batch_size": 27, "loss": 0.006581542557105422}, {"layer_params": [33, 18], "learning_rate": 0.002558685791310815, "batch_size": 330, "loss": 0.007525179623626172}, {"layer_params": [28, 17], "learning_rate": 0.0060656461672066375, "batch_size": 485, "loss": 0.004626196308527142}, {"layer_params": [61, 60, 30, 27], "learning_rate": 0.0036472087842991155, "batch_size": 504, "loss": 0.0010848835611250252}, {"layer_params": [30, 16, 32, 41, 38], "learning_rate": 0.00028398324628319406, "batch_size": 412, "loss": 0.00746626375708729}, {"layer_params": [55, 61, 20, 41, 34], "learning_rate": 0.00010317801113675365, "batch_size": 138, "loss": 0.01617753623984754}, {"layer_params": [48, 58, 41, 62, 64], "learning_rate": 0.00934185919160508, "batch_size": 242, "loss": 0.001153079088544473}, {"layer_params": [49, 35, 46, 37, 20], "learning_rate": 0.008702006444718012, "batch_size": 220, "loss": 0.0010191938502248376}, {"layer_params": [26, 36, 30], "learning_rate": 0.008780061879486958, "batch_size": 37, "loss": 0.004283348657190799}, {"layer_params": [30, 47, 49], "learning_rate": 0.00606855908443315, "batch_size": 54, "loss": 0.0032658778689801694}, {"layer_params": [36, 64, 17], "learning_rate": 0.0038750113893623924, "batch_size": 385, "loss": 0.0013535874977242202}, {"layer_params": [29, 56, 44, 64, 42], "learning_rate": 0.0063946908405817845, "batch_size": 250, "loss": 0.002570431873900816}, {"layer_params": [19, 44, 28, 57, 42], "learning_rate": 0.00814160623762959, "batch_size": 430, "loss": 0.0013720113364979625}, {"layer_params": [36, 38], "learning_rate": 0.003551457048522398, "batch_size": 507, "loss": 0.0025861394265666604}, {"layer_params": [48, 18], "learning_rate": 0.0014641981559789597, "batch_size": 29, "loss": 0.007671067141927779}, {"layer_params": [34, 20, 26, 26], "learning_rate": 0.0018186930365645397, "batch_size": 94, "loss": 0.005739970249123871}, {"layer_params": [27, 20, 23, 24], "learning_rate": 0.005506779810904795, "batch_size": 361, "loss": 0.0027618361031636596}, {"layer_params": [23, 35], "learning_rate": 0.005077219005987271, "batch_size": 68, "loss": 0.004551722705364227}, {"layer_params": [42, 62, 30], "learning_rate": 0.0010058307126897565, "batch_size": 17, "loss": 0.007855678086634725}, {"layer_params": [36, 27, 21], "learning_rate": 0.0006740236363210724, "batch_size": 136, "loss": 0.008383235628716647}, {"layer_params": [60, 62, 53, 21], "learning_rate": 0.005762032211481577, "batch_size": 220, "loss": 0.001808926472440362}, {"layer_params": [45, 43, 37, 39], "learning_rate": 0.0029258522958917244, "batch_size": 37, "loss": 0.005255501349456609}, {"layer_params": [25, 31, 49], "learning_rate": 0.0033352237613180204, "batch_size": 208, "loss": 0.0029632426518946885}, {"layer_params": [33, 60, 44, 25], "learning_rate": 0.0038437514912819395, "batch_size": 95, "loss": 0.0032524891919456424}, {"layer_params": [61, 25, 35, 52], "learning_rate": 0.006025409177038478, "batch_size": 397, "loss": 0.0018076728784944861}, {"layer_params": [52, 25, 58, 36], "learning_rate": 0.003811329289701386, "batch_size": 24, "loss": 0.0061068090423941615}, {"layer_params": [53, 53, 22, 62, 43], "learning_rate": 0.006512184786961175, "batch_size": 502, "loss": 0.0011430198082234711}, {"layer_params": [27, 18], "learning_rate": 0.004109876619796898, "batch_size": 98, "loss": 0.0044180842651985585}, {"layer_params": [51, 52, 35, 29, 16], "learning_rate": 0.00019364984056320834, "batch_size": 38, "loss": 0.01717314123176038}, {"layer_params": [36, 25, 36, 59], "learning_rate": 0.002460004101546565, "batch_size": 386, "loss": 0.0019636997731868177}, {"layer_params": [22, 27, 50], "learning_rate": 0.0019900223232054096, "batch_size": 420, "loss": 0.0033422384178265927}, {"layer_params": [62, 54, 45], "learning_rate": 0.00030518082102341186, "batch_size": 217, "loss": 0.00638683969154954}, {"layer_params": [20, 31, 53, 61], "learning_rate": 0.0030354630858244664, "batch_size": 402, "loss": 0.001492720568785444}, {"layer_params": [33, 29, 56, 60], "learning_rate": 0.003800753085840585, "batch_size": 207, "loss": 0.0023740352387540044}, {"layer_params": [54, 40, 50, 35], "learning_rate": 0.002629129886853014, "batch_size": 316, "loss": 0.0015236750699114054}, {"layer_params": [35, 31, 34, 46, 50], "learning_rate": 0.006025107267004253, "batch_size": 161, "loss": 0.00256011612364091}, {"layer_params": [62, 57, 28, 22, 54], "learning_rate": 0.004655964946530328, "batch_size": 91, "loss": 0.0029684090719092637}, {"layer_params": [44, 45, 47, 52, 34], "learning_rate": 0.004469294774519593, "batch_size": 313, "loss": 0.0018300293385982514}, {"layer_params": [57, 62], "learning_rate": 0.003917785426774295, "batch_size": 88, "loss": 0.0028397665824741124}, {"layer_params": [54, 47, 21, 23, 27], "learning_rate": 0.004061453195605085, "batch_size": 492, "loss": 0.0013708196207880975}, {"layer_params": [56, 51, 57], "learning_rate": 0.007683522091813317, "batch_size": 209, "loss": 0.0014584574062610045}, {"layer_params": [59, 50, 28], "learning_rate": 0.003945291091543631, "batch_size": 28, "loss": 0.006454196383710951}, {"layer_params": [19, 35], "learning_rate": 0.004411505899619342, "batch_size": 291, "loss": 0.00364119473611936}, {"layer_params": [41, 21, 35, 59, 57], "learning_rate": 0.005710303599047821, "batch_size": 366, "loss": 0.0027118130843155086}, {"layer_params": [17, 24], "learning_rate": 0.003976458558252186, "batch_size": 264, "loss": 0.004324665241874755}, {"layer_params": [29, 27, 45], "learning_rate": 0.000628136952999477, "batch_size": 162, "loss": 0.0065410415641963485}, {"layer_params": [34, 17, 38], "learning_rate": 0.005166892481097835, "batch_size": 455, "loss": 0.0022951959888450803}, {"layer_params": [59, 40, 58], "learning_rate": 0.004801419457720889, "batch_size": 267, "loss": 0.0015319532831199467}, {"layer_params": [26, 24, 31, 52], "learning_rate": 0.008506751001563078, "batch_size": 202, "loss": 0.0022758442256599664}, {"layer_params": [30, 59, 41], "learning_rate": 0.005684441439425112, "batch_size": 148, "loss": 0.0028185882419347764}, {"layer_params": [48, 31, 28, 57, 25], "learning_rate": 0.005954394660823519, "batch_size": 361, "loss": 0.000864634295576252}, {"layer_params": [53, 55, 53], "learning_rate": 0.009777645281654439, "batch_size": 62, "loss": 0.0021261859219521284}, {"layer_params": [16, 29, 32, 46], "learning_rate": 0.0004177231723031246, "batch_size": 245, "loss": 0.0077480912581086156}, {"layer_params": [56, 33, 64], "learning_rate": 0.0007369968100325564, "batch_size": 383, "loss": 0.0023967280006036164}, {"layer_params": [34, 60, 17, 26], "learning_rate": 0.003938639638789126, "batch_size": 352, "loss": 0.0008435644942801446}, {"layer_params": [43, 16, 41, 23], "learning_rate": 0.004467728174034595, "batch_size": 330, "loss": 0.0019087341928388922}, {"layer_params": [20, 55, 39], "learning_rate": 0.00269922762446081, "batch_size": 211, "loss": 0.0022681982000358402}, {"layer_params": [23, 36], "learning_rate": 0.00010804320694925706, "batch_size": 204, "loss": 0.035549579188227654}, {"layer_params": [24, 43, 45], "learning_rate": 0.0058026743906199555, "batch_size": 61, "loss": 0.0025094471278134735}, {"layer_params": [58, 18, 20, 22, 38], "learning_rate": 0.003831053053889245, "batch_size": 387, "loss": 0.0022463931702077387}, {"layer_params": [16, 48, 40, 25], "learning_rate": 0.009327854533205131, "batch_size": 495, "loss": 0.0017916238331235944}, {"layer_params": [22, 28, 36, 61], "learning_rate": 0.008237328938340466, "batch_size": 85, "loss": 0.003054355416679755}, {"layer_params": [20, 36, 44, 37], "learning_rate": 0.00489845551932165, "batch_size": 386, "loss": 0.0031509190401993693}, {"layer_params": [17, 19], "learning_rate": 0.00653552228298324, "batch_size": 149, "loss": 0.0058871835516765714}, {"layer_params": [42, 33], "learning_rate": 0.000892958438441468, "batch_size": 249, "loss": 0.005159823466092348}, {"layer_params": [50, 56, 50, 50], "learning_rate": 3.394521145617904e-05, "batch_size": 55, "loss": 0.03901694472879171}, {"layer_params": [30, 29, 20], "learning_rate": 0.001172496936956338, "batch_size": 420, "loss": 0.0030268018413335085}, {"layer_params": [46, 38, 56], "learning_rate": 0.008532009886041084, "batch_size": 126, "loss": 0.0029776513832621278}, {"layer_params": [39, 60, 17, 64], "learning_rate": 0.0029244234095204477, "batch_size": 278, "loss": 0.0019141815835610032}, {"layer_params": [34, 48, 38], "learning_rate": 0.004997109667732499, "batch_size": 199, "loss": 0.003290124267805368}, {"layer_params": [29, 35, 50], "learning_rate": 0.009394360024777556, "batch_size": 203, "loss": 0.0024872005626093594}, {"layer_params": [29, 43, 20], "learning_rate": 0.0008268140277993995, "batch_size": 248, "loss": 0.004628944182768464}, {"layer_params": [23, 52], "learning_rate": 0.003920014559117971, "batch_size": 491, "loss": 0.003151368673425168}, {"layer_params": [24, 53, 23, 21], "learning_rate": 0.0032518634965668803, "batch_size": 89, "loss": 0.003001582828583196}, {"layer_params": [20, 27, 45, 39], "learning_rate": 0.009819897617653643, "batch_size": 345, "loss": 0.0018028542352840305}, {"layer_params": [25, 20, 25, 16, 62], "learning_rate": 0.006435013947616681, "batch_size": 469, "loss": 0.002670341420453042}, {"layer_params": [35, 39], "learning_rate": 0.002912918808402948, "batch_size": 441, "loss": 0.0013864162715617567}, {"layer_params": [33, 35, 37], "learning_rate": 0.00895881998118652, "batch_size": 418, "loss": 0.0019041070993989705}, {"layer_params": [18, 60, 23], "learning_rate": 0.009863401454549092, "batch_size": 75, "loss": 0.005757404421456158}, {"layer_params": [32, 41, 62], "learning_rate": 0.005702611510203315, "batch_size": 310, "loss": 0.0014130669971928}, {"layer_params": [23, 30], "learning_rate": 0.005546977407371524, "batch_size": 181, "loss": 0.0058237341744825245}, {"layer_params": [40, 35, 19], "learning_rate": 0.008392882105620355, "batch_size": 163, "loss": 0.0024386990000493823}, {"layer_params": [61, 36, 55, 47], "learning_rate": 0.00040421656041404036, "batch_size": 346, "loss": 0.004942956934683025}, {"layer_params": [44, 43, 43], "learning_rate": 0.009126506690095855, "batch_size": 493, "loss": 0.0010407347412547097}, {"layer_params": [40, 16, 27], "learning_rate": 0.0012382508903587782, "batch_size": 442, "loss": 0.0033266789279878138}, {"layer_params": [49, 37, 38, 54, 39], "learning_rate": 0.008810944791629215, "batch_size": 190, "loss": 0.001711557835806161}, {"layer_params": [62, 41, 20, 33], "learning_rate": 0.0014474202344365115, "batch_size": 455, "loss": 0.0014560269704088568}, {"layer_params": [50, 36, 33], "learning_rate": 0.0033331595092917594, "batch_size": 499, "loss": 0.0019264900404959916}, {"layer_params": [39, 18, 53, 50], "learning_rate": 0.0017867038643488902, "batch_size": 144, "loss": 0.002803748098667711}, {"layer_params": [40, 18, 30], "learning_rate": 0.009949230441161548, "batch_size": 95, "loss": 0.0036085907788947227}, {"layer_params": [36, 57, 30, 47, 38], "learning_rate": 0.008920337665832398, "batch_size": 211, "loss": 0.0019506510626524686}, {"layer_params": [30, 38], "learning_rate": 0.009963874485691209, "batch_size": 321, "loss": 0.0019985259370878337}, {"layer_params": [42, 33, 44], "learning_rate": 0.004616949846800797, "batch_size": 483, "loss": 0.0012704545573797078}, {"layer_params": [50, 26], "learning_rate": 0.008883079012152522, "batch_size": 59, "loss": 0.005251128592062742}, {"layer_params": [38, 19, 50], "learning_rate": 0.003077241424841759, "batch_size": 378, "loss": 0.0018311357439961284}, {"layer_params": [47, 48, 60, 21, 57], "learning_rate": 0.008692928489594447, "batch_size": 161, "loss": 0.002803758813533932}, {"layer_params": [64, 48, 51, 49], "learning_rate": 0.007915318108576855, "batch_size": 393, "loss": 0.0013871781958732755}, {"layer_params": [28, 55, 39], "learning_rate": 0.0005824458447130443, "batch_size": 318, "loss": 0.004123426307924092}, {"layer_params": [23, 42, 44, 44], "learning_rate": 0.000997539145810906, "batch_size": 139, "loss": 0.005660580242983997}, {"layer_params": [19, 23, 50, 34, 32], "learning_rate": 0.00781564421402061, "batch_size": 346, "loss": 0.003103132303804159}, {"layer_params": [33, 16, 62, 55, 57], "learning_rate": 0.002374549239942755, "batch_size": 106, "loss": 0.004284890200942755}, {"layer_params": [27, 52, 18, 64], "learning_rate": 0.009436500866814697, "batch_size": 189, "loss": 0.0021626580553129313}, {"layer_params": [27, 29], "learning_rate": 0.004605559247940173, "batch_size": 260, "loss": 0.0026194965187460186}, {"layer_params": [35, 16, 36, 28, 24], "learning_rate": 0.0011864868510500718, "batch_size": 64, "loss": 0.006330335666425526}, {"layer_params": [55, 39], "learning_rate": 0.0009843899528026781, "batch_size": 317, "loss": 0.0035550341662019492}, {"layer_params": [41, 49, 40], "learning_rate": 0.0009488904040420746, "batch_size": 419, "loss": 0.004055102118290961}, {"layer_params": [19, 28, 34], "learning_rate": 0.00041201052486344517, "batch_size": 433, "loss": 0.0066752227349206805}, {"layer_params": [51, 23, 26], "learning_rate": 0.0009899628681571946, "batch_size": 204, "loss": 0.005509913507848978}, {"layer_params": [35, 29], "learning_rate": 0.004081660844850146, "batch_size": 508, "loss": 0.0023131834901869296}, {"layer_params": [58, 56, 60, 49, 43], "learning_rate": 0.009762343868805638, "batch_size": 43, "loss": 0.00413874517660588}, {"layer_params": [17, 57], "learning_rate": 0.00553234475182675, "batch_size": 296, "loss": 0.002603467954322696}, {"layer_params": [56, 39, 25, 30, 59], "learning_rate": 0.0059239949148912905, "batch_size": 26, "loss": 0.006130749627482146}, {"layer_params": [16, 46], "learning_rate": 0.003746591961288908, "batch_size": 262, "loss": 0.003181539033539593}, {"layer_params": [48, 48, 52, 61], "learning_rate": 0.007725183253556584, "batch_size": 317, "loss": 0.0010425611835671589}, {"layer_params": [52, 35, 35], "learning_rate": 0.009645079103102154, "batch_size": 507, "loss": 0.001088918867171742}, {"layer_params": [25, 60, 52, 46, 22], "learning_rate": 0.006467688722538016, "batch_size": 103, "loss": 0.0032254599593579767}, {"layer_params": [44, 24, 31, 28, 47], "learning_rate": 0.0009388841232644795, "batch_size": 294, "loss": 0.003534904846455902}, {"layer_params": [41, 64, 32, 50, 48], "learning_rate": 0.004196112684259284, "batch_size": 104, "loss": 0.0021766650152858346}, {"layer_params": [17, 20], "learning_rate": 0.007385896411342808, "batch_size": 274, "loss": 0.006479410976171493}, {"layer_params": [33, 55, 37, 28], "learning_rate": 0.004130653757160144, "batch_size": 500, "loss": 0.0007165583368623629}, {"layer_params": [38, 40, 20, 58, 28], "learning_rate": 0.004037525895018843, "batch_size": 98, "loss": 0.03782655019313097}, {"layer_params": [36, 40], "learning_rate": 0.006582129711030619, "batch_size": 272, "loss": 0.0029980838112533092}, {"layer_params": [27, 57], "learning_rate": 0.003378082240507308, "batch_size": 367, "loss": 0.0022386704746168106}, {"layer_params": [40, 24, 54, 37, 59], "learning_rate": 0.007425579641968221, "batch_size": 381, "loss": 0.001645864447345957}, {"layer_params": [27, 32], "learning_rate": 0.008502417769847432, "batch_size": 392, "loss": 0.004197696326300502}, {"layer_params": [27, 45], "learning_rate": 0.008731760383324438, "batch_size": 464, "loss": 0.0026586727239191533}, {"layer_params": [64, 52, 27, 47, 37], "learning_rate": 0.00011208484942623597, "batch_size": 249, "loss": 0.017227393174543977}, {"layer_params": [63, 61, 39, 21], "learning_rate": 0.00235337021383676, "batch_size": 376, "loss": 0.0013903896836563944}, {"layer_params": [38, 59], "learning_rate": 0.005603945187995123, "batch_size": 68, "loss": 0.0023411504039540887}, {"layer_params": [50, 52], "learning_rate": 0.0055244834855565205, "batch_size": 438, "loss": 0.0015933545178268105}, {"layer_params": [21, 43, 57, 35, 54], "learning_rate": 0.004991165884996804, "batch_size": 344, "loss": 0.0015324487851466984}, {"layer_params": [30, 22], "learning_rate": 0.0005634056713326783, "batch_size": 341, "loss": 0.0076609698589891195}, {"layer_params": [51, 30], "learning_rate": 0.00835489627329391, "batch_size": 177, "loss": 0.0024144297605380415}, {"layer_params": [48, 26, 61], "learning_rate": 0.0015313620562458846, "batch_size": 389, "loss": 0.0032796655455604195}, {"layer_params": [23, 55, 63, 62, 54], "learning_rate": 0.002892947980956349, "batch_size": 315, "loss": 0.0017141905764583498}, {"layer_params": [51, 60, 56, 23, 49], "learning_rate": 0.006373124072453958, "batch_size": 25, "loss": 0.00492251543328166}, {"layer_params": [17, 59], "learning_rate": 0.002999053854217292, "batch_size": 302, "loss": 0.0031136033148504794}, {"layer_params": [23, 43], "learning_rate": 0.008914795079541921, "batch_size": 94, "loss": 0.003198338772635907}, {"layer_params": [22, 38, 64], "learning_rate": 0.004321745014172602, "batch_size": 388, "loss": 0.002171281649498269}, {"layer_params": [41, 45, 32, 44], "learning_rate": 0.001710843784341184, "batch_size": 157, "loss": 0.0019175939436536283}, {"layer_params": [28, 24, 39, 24, 53], "learning_rate": 0.007268552210240912, "batch_size": 415, "loss": 0.0023888064362108706}, {"layer_params": [55, 28, 36], "learning_rate": 0.009556615208113335, "batch_size": 205, "loss": 0.001790807305369526}, {"layer_params": [33, 52, 59, 49], "learning_rate": 0.0023403825329183837, "batch_size": 202, "loss": 0.0020058625203091653}, {"layer_params": [28, 49], "learning_rate": 0.0088954802280371, "batch_size": 370, "loss": 0.0015349420462734996}, {"layer_params": [46, 59], "learning_rate": 0.009054106339622062, "batch_size": 445, "loss": 0.0020622053404804317}, {"layer_params": [45, 56], "learning_rate": 0.00021625516735119445, "batch_size": 344, "loss": 0.006989432256668806}, {"layer_params": [20, 35, 22, 41], "learning_rate": 0.008604430157195668, "batch_size": 373, "loss": 0.003534120146650821}, {"layer_params": [60, 22], "learning_rate": 0.003307782999022592, "batch_size": 117, "loss": 0.00370937132043764}, {"layer_params": [47, 44, 32], "learning_rate": 0.005923217096086175, "batch_size": 172, "loss": 0.0013181428873213009}, {"layer_params": [23, 30, 40, 34, 63], "learning_rate": 0.006798540412705778, "batch_size": 69, "loss": 0.0038029332482255995}, {"layer_params": [44, 36, 52], "learning_rate": 0.004315338166730579, "batch_size": 330, "loss": 0.0020103977690450847}, {"layer_params": [58, 54, 49], "learning_rate": 0.0039320264847076845, "batch_size": 39, "loss": 0.004508561345282942}, {"layer_params": [33, 29, 29], "learning_rate": 0.00464169917109791, "batch_size": 154, "loss": 0.004508579887915403}, {"layer_params": [29, 38, 26, 24, 47], "learning_rate": 0.0033411603317444, "batch_size": 223, "loss": 0.004426739357877523}, {"layer_params": [63, 53, 44], "learning_rate": 0.0014988709502490069, "batch_size": 220, "loss": 0.0020091199199669062}, {"layer_params": [47, 21], "learning_rate": 0.008774728982411622, "batch_size": 511, "loss": 0.0019497485528700053}, {"layer_params": [52, 21], "learning_rate": 0.006138134058836273, "batch_size": 51, "loss": 0.004575801081955433}, {"layer_params": [20, 51], "learning_rate": 0.0009713914778465139, "batch_size": 365, "loss": 0.006001636064611376}, {"layer_params": [62, 23, 40], "learning_rate": 0.001973567281739513, "batch_size": 43, "loss": 0.00510492391884327}, {"layer_params": [54, 52], "learning_rate": 0.0019220867577707315, "batch_size": 337, "loss": 0.0018169429199770093}, {"layer_params": [27, 49], "learning_rate": 0.007146591704707062, "batch_size": 468, "loss": 0.001850883214501664}, {"layer_params": [21, 20, 41, 62, 62], "learning_rate": 0.005610759387614915, "batch_size": 380, "loss": 0.002043194939615205}, {"layer_params": [60, 55, 19, 51], "learning_rate": 0.0020331794643023817, "batch_size": 323, "loss": 0.001688714042538777}, {"layer_params": [59, 59, 51, 56, 38], "learning_rate": 0.0013699728897438783, "batch_size": 287, "loss": 0.0018697014800272882}, {"layer_params": [55, 57], "learning_rate": 0.007746785260555577, "batch_size": 469, "loss": 0.0011890693206805735}, {"layer_params": [39, 47], "learning_rate": 0.009438846791043112, "batch_size": 462, "loss": 0.0015987987502012401}, {"layer_params": [42, 17, 28, 52, 29], "learning_rate": 0.00924683681747159, "batch_size": 322, "loss": 0.0018597560317721218}, {"layer_params": [48, 44, 31, 34], "learning_rate": 0.001845344831285089, "batch_size": 177, "loss": 0.002416057211812586}, {"layer_params": [50, 60, 24, 27], "learning_rate": 0.00611868304338961, "batch_size": 104, "loss": 0.0019189422577619553}, {"layer_params": [33, 33, 26, 48, 20], "learning_rate": 0.001328554175889382, "batch_size": 246, "loss": 0.002712200575042516}, {"layer_params": [24, 62, 36, 44], "learning_rate": 0.005420669354962907, "batch_size": 490, "loss": 0.00256658086553216}, {"layer_params": [37, 41, 23, 47], "learning_rate": 0.008925901913145545, "batch_size": 482, "loss": 0.0014431057847104968}, {"layer_params": [45, 37], "learning_rate": 0.006197977848490383, "batch_size": 107, "loss": 0.00309574336046353}, {"layer_params": [60, 62], "learning_rate": 0.00550869948231135, "batch_size": 431, "loss": 0.001105656674480997}, {"layer_params": [58, 56], "learning_rate": 0.003989419819684472, "batch_size": 338, "loss": 0.0023151885287370534}, {"layer_params": [39, 26, 30], "learning_rate": 0.0017862852171244522, "batch_size": 434, "loss": 0.002543271470349282}, {"layer_params": [17, 34, 26, 53], "learning_rate": 0.0018564679372475956, "batch_size": 265, "loss": 0.003979926297906786}, {"layer_params": [32, 21, 18, 33, 35], "learning_rate": 0.004871786949229509, "batch_size": 144, "loss": 0.005092395043466241}, {"layer_params": [32, 32, 48, 50], "learning_rate": 0.0017383034195911278, "batch_size": 397, "loss": 0.0020255210530012845}, {"layer_params": [47, 23, 45, 50], "learning_rate": 0.006736130871844939, "batch_size": 354, "loss": 0.0016410549206193536}, {"layer_params": [36, 40, 31, 61, 36], "learning_rate": 0.00021883947866773115, "batch_size": 407, "loss": 0.0072903410904109475}, {"layer_params": [47, 53], "learning_rate": 0.009571352587832977, "batch_size": 488, "loss": 0.0014992368954699486}, {"layer_params": [43, 30], "learning_rate": 0.003789060049730159, "batch_size": 141, "loss": 0.0025802523375023155}, {"layer_params": [28, 48], "learning_rate": 0.005655116422741971, "batch_size": 53, "loss": 0.0030953626055270434}, {"layer_params": [28, 29, 22, 57, 25], "learning_rate": 0.003170394119057309, "batch_size": 484, "loss": 0.002731008499395102}, {"layer_params": [63, 40, 40, 32, 45], "learning_rate": 0.0008884774849204744, "batch_size": 351, "loss": 0.0033913263329304754}, {"layer_params": [39, 63], "learning_rate": 0.0008866191848620378, "batch_size": 288, "loss": 0.004053353930357844}, {"layer_params": [50, 38, 37, 55, 60], "learning_rate": 0.0014027216038723389, "batch_size": 126, "loss": 0.0037172434385865927}, {"layer_params": [50, 56, 40], "learning_rate": 0.00752736256952543, "batch_size": 138, "loss": 0.001660361650865525}, {"layer_params": [35, 28], "learning_rate": 0.0055998250172178, "batch_size": 231, "loss": 0.002107288253027946}, {"layer_params": [38, 23], "learning_rate": 0.000776736147560043, "batch_size": 475, "loss": 0.00761417574249208}, {"layer_params": [19, 30], "learning_rate": 0.00028708348161450814, "batch_size": 469, "loss": 0.02619913384318352}, {"layer_params": [55, 53, 38, 62], "learning_rate": 0.0073333919583946, "batch_size": 418, "loss": 0.0009976586839184165}, {"layer_params": [64, 16, 60], "learning_rate": 0.0001746795317163598, "batch_size": 135, "loss": 0.013643619511276484}, {"layer_params": [18, 64, 30], "learning_rate": 0.001776647354001473, "batch_size": 415, "loss": 0.0034561154060065748}, {"layer_params": [27, 42], "learning_rate": 0.003484863667366704, "batch_size": 114, "loss": 0.004218720770440995}, {"layer_params": [39, 45], "learning_rate": 0.003314253284457981, "batch_size": 220, "loss": 0.002260936883976683}, {"layer_params": [56, 64], "learning_rate": 0.0018938497592421851, "batch_size": 197, "loss": 0.003200306580401957}, {"layer_params": [35, 52, 54, 18, 36], "learning_rate": 0.0015290228935638335, "batch_size": 69, "loss": 0.0035755399824120102}, {"layer_params": [55, 53], "learning_rate": 0.004601326975211102, "batch_size": 234, "loss": 0.0018329955055378377}, {"layer_params": [37, 64, 55], "learning_rate": 0.0026159228320121217, "batch_size": 305, "loss": 0.0011874021613039077}, {"layer_params": [18, 28, 60, 62, 19], "learning_rate": 0.0037280631273413616, "batch_size": 24, "loss": 0.007587088728323579}, {"layer_params": [44, 18, 61], "learning_rate": 0.0017475828014281503, "batch_size": 502, "loss": 0.0030254291999153794}, {"layer_params": [52, 52, 62], "learning_rate": 0.005959086609674662, "batch_size": 292, "loss": 0.0009441205352777615}, {"layer_params": [43, 47], "learning_rate": 0.004785991591797182, "batch_size": 35, "loss": 0.004222489651292563}, {"layer_params": [50, 40], "learning_rate": 0.0016292771147414199, "batch_size": 211, "loss": 0.002876810091547668}, {"layer_params": [25, 17, 40, 38], "learning_rate": 0.00024741143210360497, "batch_size": 45, "loss": 0.01617885421961546}, {"layer_params": [54, 41, 26], "learning_rate": 0.004018475238169647, "batch_size": 444, "loss": 0.0018105822382494807}, {"layer_params": [31, 51, 57], "learning_rate": 0.004790650443104119, "batch_size": 37, "loss": 0.005628346484154462}, {"layer_params": [45, 40], "learning_rate": 0.008451121099933406, "batch_size": 176, "loss": 0.001687919069081545}, {"layer_params": [34, 48, 59, 59, 37], "learning_rate": 0.0030110143234307373, "batch_size": 71, "loss": 0.0033235142379999163}, {"layer_params": [43, 48], "learning_rate": 0.004192095565265657, "batch_size": 361, "loss": 0.0033265219116583467}, {"layer_params": [49, 20, 31, 48], "learning_rate": 0.008152579903546838, "batch_size": 99, "loss": 0.0038930509937927125}, {"layer_params": [56, 61, 28, 33, 46], "learning_rate": 0.007887933413256259, "batch_size": 346, "loss": 0.001046026353724301}, {"layer_params": [49, 40, 61], "learning_rate": 0.001968038930494852, "batch_size": 332, "loss": 0.002782534477300942}, {"layer_params": [55, 51, 21], "learning_rate": 0.009267282493196178, "batch_size": 364, "loss": 0.000972780417650938}, {"layer_params": [64, 32, 53, 49], "learning_rate": 0.007652298970439521, "batch_size": 484, "loss": 0.0008526989887468517}, {"layer_params": [53, 52], "learning_rate": 0.0026055865513956284, "batch_size": 322, "loss": 0.0018408706656191497}, {"layer_params": [42, 29, 27, 16], "learning_rate": 0.0023002599448891, "batch_size": 261, "loss": 0.004837113146204501}, {"layer_params": [19, 34, 51, 44], "learning_rate": 0.009021280539039105, "batch_size": 238, "loss": 0.002780712947715074}, {"layer_params": [30, 38, 56], "learning_rate": 0.005481412122655583, "batch_size": 365, "loss": 0.0011179916455876081}, {"layer_params": [35, 53, 41], "learning_rate": 0.005061675289074418, "batch_size": 406, "loss": 0.0011625417735194787}, {"layer_params": [37, 60, 23, 58], "learning_rate": 0.008375922636008904, "batch_size": 104, "loss": 0.002295216048369184}, {"layer_params": [32, 47, 51, 44], "learning_rate": 0.004395482411637627, "batch_size": 148, "loss": 0.003035935526713729}, {"layer_params": [37, 19, 39], "learning_rate": 0.006915261153757194, "batch_size": 182, "loss": 0.003928413868416101}, {"layer_params": [33, 27, 47, 47], "learning_rate": 0.0017854411816262152, "batch_size": 486, "loss": 0.0017145120759960264}, {"layer_params": [60, 26, 36, 41], "learning_rate": 0.006568343398902228, "batch_size": 393, "loss": 0.0018476593564264476}, {"layer_params": [61, 57, 42], "learning_rate": 0.002398132301262973, "batch_size": 418, "loss": 0.0023458825040142983}, {"layer_params": [47, 59, 57], "learning_rate": 0.004947885658293908, "batch_size": 306, "loss": 0.001049338627490215}, {"layer_params": [47, 28, 57, 51, 33], "learning_rate": 0.008243382731518594, "batch_size": 455, "loss": 0.0013125174038577825}, {"layer_params": [54, 60, 35], "learning_rate": 0.0026874163324559267, "batch_size": 78, "loss": 0.0017490882007405162}, {"layer_params": [42, 42, 24], "learning_rate": 0.005971875631285032, "batch_size": 36, "loss": 0.00415839773719199}, {"layer_params": [46, 20, 35, 22, 40], "learning_rate": 0.00022129022506745783, "batch_size": 383, "loss": 0.007322549927048385}, {"layer_params": [51, 45, 36, 18, 17], "learning_rate": 0.0015114207939245915, "batch_size": 59, "loss": 0.004170102197676897}, {"layer_params": [43, 55, 50, 20, 63], "learning_rate": 0.006674185522074971, "batch_size": 125, "loss": 0.001975239689927548}, {"layer_params": [47, 63, 43, 50], "learning_rate": 0.004257448716015097, "batch_size": 63, "loss": 0.0025165991741232575}, {"layer_params": [35, 28, 25, 29, 19], "learning_rate": 0.005522766079956048, "batch_size": 98, "loss": 0.005319816118571907}, {"layer_params": [58, 57, 43], "learning_rate": 0.00225932928578052, "batch_size": 291, "loss": 0.0012623937230091542}, {"layer_params": [17, 54, 21, 59, 27], "learning_rate": 0.009913426392793743, "batch_size": 314, "loss": 0.0016044500330463052}, {"layer_params": [17, 59, 21, 45], "learning_rate": 0.007997458010839294, "batch_size": 240, "loss": 0.0026411252038087696}, {"layer_params": [36, 47, 31], "learning_rate": 0.00808423100951104, "batch_size": 98, "loss": 0.0034577293624170123}, {"layer_params": [44, 43, 51, 59], "learning_rate": 0.0027970616374798723, "batch_size": 152, "loss": 0.0022133272548671814}, {"layer_params": [42, 55, 46], "learning_rate": 0.004265871469987371, "batch_size": 421, "loss": 0.001269383723847568}, {"layer_params": [61, 16, 35, 55, 35], "learning_rate": 0.008967598752596447, "batch_size": 388, "loss": 0.00395708613563329}, {"layer_params": [34, 23, 29, 36, 64], "learning_rate": 0.0030009570489268863, "batch_size": 305, "loss": 0.0025766478199511765}, {"layer_params": [30, 51, 62, 61], "learning_rate": 0.007168304607345188, "batch_size": 387, "loss": 0.0015874716092366724}, {"layer_params": [61, 54, 46, 51], "learning_rate": 0.001968135596677756, "batch_size": 90, "loss": 0.0020606355683412403}, {"layer_params": [25, 53], "learning_rate": 0.002390391843489555, "batch_size": 180, "loss": 0.004226906774565577}, {"layer_params": [33, 49, 21, 20], "learning_rate": 0.005458968991021337, "batch_size": 56, "loss": 0.003724548744503409}, {"layer_params": [49, 55, 19, 20, 33], "learning_rate": 0.006741345008660593, "batch_size": 62, "loss": 0.0035290620534215124}, {"layer_params": [61, 51, 41, 16, 29], "learning_rate": 0.006326141603134168, "batch_size": 453, "loss": 0.0010186059057014064}, {"layer_params": [44, 27], "learning_rate": 0.004470105341865585, "batch_size": 167, "loss": 0.002834977547172457}, {"layer_params": [26, 32, 56], "learning_rate": 0.0002082211801557439, "batch_size": 167, "loss": 0.009098084126599133}, {"layer_params": [37, 29, 30, 40, 41], "learning_rate": 0.0002574751887546164, "batch_size": 399, "loss": 0.005764622734859586}, {"layer_params": [27, 20, 42], "learning_rate": 0.006875515111591361, "batch_size": 265, "loss": 0.0033793034311383964}, {"layer_params": [47, 49], "learning_rate": 0.00615813771238783, "batch_size": 467, "loss": 0.00201206858153455}, {"layer_params": [23, 20, 33, 29, 34], "learning_rate": 0.006541110109431044, "batch_size": 38, "loss": 0.006988473299425095}, {"layer_params": [23, 59, 21, 63], "learning_rate": 0.0030543039128216234, "batch_size": 61, "loss": 0.004326283608097583}, {"layer_params": [48, 20, 23, 33, 49], "learning_rate": 0.007172600858388007, "batch_size": 468, "loss": 0.002590487312991172}, {"layer_params": [22, 23, 46], "learning_rate": 0.007815755919981345, "batch_size": 47, "loss": 0.005088020574767142}, {"layer_params": [59, 34, 16, 60], "learning_rate": 0.002908854754162895, "batch_size": 154, "loss": 0.0023683769023045897}, {"layer_params": [26, 44], "learning_rate": 0.0024676401612270553, "batch_size": 120, "loss": 0.004048425573855639}, {"layer_params": [32, 18, 50], "learning_rate": 0.0026035654992433584, "batch_size": 469, "loss": 0.0032407357334159315}, {"layer_params": [17, 17], "learning_rate": 0.000736262252677086, "batch_size": 380, "loss": 0.015277166869491338}, {"layer_params": [48, 34, 45, 38], "learning_rate": 0.008439188004047072, "batch_size": 303, "loss": 0.0021021770464722065}, {"layer_params": [38, 50], "learning_rate": 0.004131668229296312, "batch_size": 299, "loss": 0.0029687021346762777}, {"layer_params": [33, 26, 54], "learning_rate": 0.0020330836239802006, "batch_size": 151, "loss": 0.0043235495733097195}, {"layer_params": [22, 23, 60, 36, 51], "learning_rate": 0.009986445342613863, "batch_size": 137, "loss": 0.006445229444652796}, {"layer_params": [45, 29, 31, 48], "learning_rate": 0.006315741078866804, "batch_size": 456, "loss": 0.0009201995056355373}, {"layer_params": [18, 47, 50, 20], "learning_rate": 0.0066024977999028425, "batch_size": 369, "loss": 0.0026277111656963824}, {"layer_params": [35, 38, 32], "learning_rate": 0.009527433718371722, "batch_size": 351, "loss": 0.0023961399286054077}, {"layer_params": [16, 32, 61, 47], "learning_rate": 0.004609912459878348, "batch_size": 173, "loss": 0.0025057538656983523}, {"layer_params": [35, 24, 47, 43], "learning_rate": 0.008121468196346916, "batch_size": 441, "loss": 0.0010246618156088516}, {"layer_params": [53, 21, 47, 16], "learning_rate": 0.007579317093254836, "batch_size": 340, "loss": 0.0018797961925156414}, {"layer_params": [54, 55, 21, 53], "learning_rate": 0.004388361415346999, "batch_size": 459, "loss": 0.0014091944834217429}, {"layer_params": [26, 29, 61, 43, 23], "learning_rate": 0.008153492501815223, "batch_size": 158, "loss": 0.002464651493355632}, {"layer_params": [22, 40, 52, 61, 25], "learning_rate": 0.000975783877719805, "batch_size": 140, "loss": 0.005942854033783078}, {"layer_params": [25, 30], "learning_rate": 0.0030575876531188447, "batch_size": 108, "loss": 0.004153351094573736}, {"layer_params": [64, 19, 36, 17, 25], "learning_rate": 0.009102858479912677, "batch_size": 125, "loss": 0.004430058761499822}, {"layer_params": [34, 22, 39, 38], "learning_rate": 0.0070979421599184425, "batch_size": 234, "loss": 0.0034976418665610253}, {"layer_params": [17, 31, 26, 62, 36], "learning_rate": 0.0033388092000221714, "batch_size": 457, "loss": 0.0025751430029049517}, {"layer_params": [30, 51, 62], "learning_rate": 0.003990571404625412, "batch_size": 261, "loss": 0.0018742036866024137}, {"layer_params": [64, 21], "learning_rate": 0.0049817054027024915, "batch_size": 430, "loss": 0.002483430744614452}, {"layer_params": [51, 59], "learning_rate": 0.0016945346067079572, "batch_size": 346, "loss": 0.001930188189726323}, {"layer_params": [40, 42, 18, 42, 17], "learning_rate": 0.00504126201498711, "batch_size": 393, "loss": 0.00193070393987}, {"layer_params": [31, 23], "learning_rate": 0.008653296650539828, "batch_size": 318, "loss": 0.003810284729115665}, {"layer_params": [31, 34, 55, 20], "learning_rate": 0.0017081978968744717, "batch_size": 71, "loss": 0.005399285599123687}, {"layer_params": [49, 64], "learning_rate": 0.0001843137488812093, "batch_size": 451, "loss": 0.00819973279722035}, {"layer_params": [53, 47, 60], "learning_rate": 0.007288332908496168, "batch_size": 494, "loss": 0.0008572043816093356}, {"layer_params": [27, 28, 60, 54, 58], "learning_rate": 0.0013443382860991334, "batch_size": 220, "loss": 0.0033550811465829613}, {"layer_params": [34, 53, 28, 32, 57], "learning_rate": 0.0010134522259591682, "batch_size": 302, "loss": 0.0033235070598311724}, {"layer_params": [27, 45, 54, 32], "learning_rate": 0.004844061422021877, "batch_size": 452, "loss": 0.00162140799802728}, {"layer_params": [17, 19], "learning_rate": 0.008224031525175606, "batch_size": 363, "loss": 0.0049620639369823034}, {"layer_params": [22, 54, 36, 34, 28], "learning_rate": 0.006603058269196842, "batch_size": 448, "loss": 0.0015153936122078448}, {"layer_params": [47, 57, 54, 22, 52], "learning_rate": 0.0025638093043752856, "batch_size": 416, "loss": 0.0013616023387294262}, {"layer_params": [22, 46], "learning_rate": 0.00877224612776231, "batch_size": 400, "loss": 0.0020534173306077717}, {"layer_params": [44, 23, 32, 22], "learning_rate": 0.004900160262640194, "batch_size": 37, "loss": 0.006447452865540981}, {"layer_params": [37, 34, 39, 48], "learning_rate": 0.004250585628132888, "batch_size": 494, "loss": 0.0014282490580808372}, {"layer_params": [41, 36, 48, 22], "learning_rate": 0.0031535347309393624, "batch_size": 246, "loss": 0.0015740259108133613}, {"layer_params": [52, 24, 27, 25, 62], "learning_rate": 0.005211353028155329, "batch_size": 170, "loss": 0.001581398897105828}, {"layer_params": [38, 29, 32, 21, 62], "learning_rate": 0.0010484981638193133, "batch_size": 72, "loss": 0.006481392413843423}, {"layer_params": [45, 61, 48], "learning_rate": 0.009094225453196346, "batch_size": 332, "loss": 0.0009533614024985581}, {"layer_params": [33, 18, 49], "learning_rate": 0.004504711992350143, "batch_size": 121, "loss": 0.0033466863143257796}, {"layer_params": [58, 31, 30, 48], "learning_rate": 0.006461687830851743, "batch_size": 479, "loss": 0.001715531317749992}, {"layer_params": [16, 64, 41, 38, 49], "learning_rate": 0.0020036569563917713, "batch_size": 167, "loss": 0.0046488368348218505}, {"layer_params": [36, 33, 55], "learning_rate": 0.00525099741773163, "batch_size": 195, "loss": 0.0017729934072121978}, {"layer_params": [29, 46, 37, 49, 49], "learning_rate": 0.007814800366429979, "batch_size": 68, "loss": 0.004455438801087439}, {"layer_params": [37, 64, 17], "learning_rate": 0.00884113616938062, "batch_size": 179, "loss": 0.0017190757731441408}, {"layer_params": [46, 53, 51, 23], "learning_rate": 0.007115987567452992, "batch_size": 358, "loss": 0.0009780258656246587}, {"layer_params": [47, 25, 30, 26], "learning_rate": 0.0089657082871274, "batch_size": 385, "loss": 0.001958479263121262}, {"layer_params": [36, 44, 34, 37, 27], "learning_rate": 0.005898809685153359, "batch_size": 448, "loss": 0.000992859792895615}, {"layer_params": [31, 52, 36], "learning_rate": 0.00829244026524536, "batch_size": 84, "loss": 0.004157280719373375}, {"layer_params": [55, 20], "learning_rate": 0.0017594408980326401, "batch_size": 271, "loss": 0.0035544191277585924}, {"layer_params": [33, 57, 39], "learning_rate": 0.00966456906035888, "batch_size": 161, "loss": 0.002261034813709557}, {"layer_params": [47, 43], "learning_rate": 0.009299882788774234, "batch_size": 375, "loss": 0.00318186265649274}, {"layer_params": [20, 39], "learning_rate": 0.009209021632816596, "batch_size": 466, "loss": 0.002006409979658201}, {"layer_params": [43, 40], "learning_rate": 0.0005862690011129659, "batch_size": 343, "loss": 0.0069908120622858404}, {"layer_params": [56, 20, 59, 58, 46], "learning_rate": 0.0034086770939151757, "batch_size": 435, "loss": 0.0014335910871159285}, {"layer_params": [57, 27], "learning_rate": 0.001989401658237984, "batch_size": 151, "loss": 0.0036606418713927267}, {"layer_params": [52, 43, 64, 52], "learning_rate": 0.008659904278285101, "batch_size": 501, "loss": 0.0014788362116087228}, {"layer_params": [43, 46], "learning_rate": 0.009636144121728094, "batch_size": 18, "loss": 0.007340130237862468}, {"layer_params": [27, 20, 25], "learning_rate": 3.260323723121561e-05, "batch_size": 84, "loss": 0.03695574490353465}, {"layer_params": [59, 51, 17, 38], "learning_rate": 0.0015665733130863595, "batch_size": 324, "loss": 0.0025415007467381656}, {"layer_params": [48, 53, 48, 34], "learning_rate": 0.007353257177235552, "batch_size": 19, "loss": 0.0059618707629851995}, {"layer_params": [28, 18, 50, 48, 61], "learning_rate": 0.0057643758615670134, "batch_size": 244, "loss": 0.003638134521897882}, {"layer_params": [46, 49], "learning_rate": 0.002623690811853302, "batch_size": 269, "loss": 0.002184930567163974}, {"layer_params": [36, 58, 18, 50, 61], "learning_rate": 0.00337841879674538, "batch_size": 274, "loss": 0.0013819116528611631}, {"layer_params": [40, 41, 25], "learning_rate": 0.004763897464143639, "batch_size": 429, "loss": 0.0016003116476349534}, {"layer_params": [53, 45], "learning_rate": 0.008291372000743313, "batch_size": 245, "loss": 0.001361785939661786}, {"layer_params": [36, 24, 61], "learning_rate": 0.007700225615080728, "batch_size": 145, "loss": 0.0024433470878284427}, {"layer_params": [38, 24, 58], "learning_rate": 0.005276549081779086, "batch_size": 311, "loss": 0.0021781959081999956}, {"layer_params": [19, 54, 49, 63, 17], "learning_rate": 0.006304604060492653, "batch_size": 237, "loss": 0.0017302720947191118}, {"layer_params": [17, 59, 46], "learning_rate": 0.006137454800453979, "batch_size": 241, "loss": 0.0026512152212671935}, {"layer_params": [55, 54, 33, 63, 25], "learning_rate": 0.0064447299225469604, "batch_size": 356, "loss": 0.0011964852397795766}, {"layer_params": [35, 54, 21, 24], "learning_rate": 0.009738838681069107, "batch_size": 22, "loss": 0.006591813182458281}, {"layer_params": [31, 42, 16, 49, 43], "learning_rate": 0.009512688190318504, "batch_size": 210, "loss": 0.002596094540785998}, {"layer_params": [50, 58], "learning_rate": 0.0013763142073779221, "batch_size": 386, "loss": 0.003195424247533083}, {"layer_params": [64, 59, 24, 32], "learning_rate": 0.0023910116628615735, "batch_size": 110, "loss": 0.0018968679988756775}, {"layer_params": [56, 48, 18], "learning_rate": 0.009713025450345008, "batch_size": 447, "loss": 0.0010381240857532247}, {"layer_params": [56, 28, 39, 40], "learning_rate": 0.005420921758166577, "batch_size": 277, "loss": 0.001556295215850696}, {"layer_params": [33, 41, 16, 64, 30], "learning_rate": 0.008049131754799196, "batch_size": 183, "loss": 0.003175639945548028}, {"layer_params": [37, 34, 53, 25, 16], "learning_rate": 0.005396256069084652, "batch_size": 119, "loss": 0.0034079927555285393}, {"layer_params": [47, 30, 61], "learning_rate": 0.004139061614054897, "batch_size": 425, "loss": 0.0015742422221228481}, {"layer_params": [54, 35, 45, 53, 63], "learning_rate": 0.006029699246537501, "batch_size": 397, "loss": 0.0014247030869591981}, {"layer_params": [55, 17], "learning_rate": 0.007913869193508675, "batch_size": 191, "loss": 0.0020893665263429285}, {"layer_params": [57, 29, 64], "learning_rate": 0.0017706202732811678, "batch_size": 214, "loss": 0.0020849117159377783}, {"layer_params": [34, 48, 20, 30], "learning_rate": 0.009797743532700718, "batch_size": 483, "loss": 0.0021712664689403026}, {"layer_params": [41, 18], "learning_rate": 0.002890410252857293, "batch_size": 432, "loss": 0.0036285907099954783}, {"layer_params": [25, 30, 58, 57], "learning_rate": 0.003981393489678633, "batch_size": 198, "loss": 0.002356831895885989}, {"layer_params": [19, 28, 53], "learning_rate": 0.000701682677482685, "batch_size": 445, "loss": 0.005623119096271694}, {"layer_params": [56, 32], "learning_rate": 0.009562749371129673, "batch_size": 48, "loss": 0.0026502036838792265}, {"layer_params": [48, 42], "learning_rate": 0.009395940391075506, "batch_size": 200, "loss": 0.001912676258943975}, {"layer_params": [61, 24, 30, 63, 42], "learning_rate": 0.002803078260312395, "batch_size": 87, "loss": 0.0028736803133506328}, {"layer_params": [51, 46, 24, 41, 32], "learning_rate": 0.0034659762398376996, "batch_size": 399, "loss": 0.001684231492690742}, {"layer_params": [23, 64], "learning_rate": 0.0009637474960855572, "batch_size": 441, "loss": 0.00700931191444397}, {"layer_params": [32, 18, 26], "learning_rate": 0.00021289468161363471, "batch_size": 205, "loss": 0.016798553206026554}, {"layer_params": [29, 59, 37, 57], "learning_rate": 0.006442027266056642, "batch_size": 397, "loss": 0.0015124638099223374}, {"layer_params": [47, 46], "learning_rate": 0.0018919036983064432, "batch_size": 30, "loss": 0.005053408008534461}, {"layer_params": [24, 28, 22], "learning_rate": 0.005360810022749708, "batch_size": 340, "loss": 0.0034792542760260403}, {"layer_params": [25, 36, 36, 20], "learning_rate": 0.008694885579417598, "batch_size": 264, "loss": 0.0018802847678307444}, {"layer_params": [35, 47, 30, 58], "learning_rate": 0.0035609500371929764, "batch_size": 165, "loss": 0.0025319650082383303}, {"layer_params": [50, 24, 52], "learning_rate": 0.0003716956147544407, "batch_size": 371, "loss": 0.006227070689201355}, {"layer_params": [19, 57, 29, 58, 35], "learning_rate": 0.004788562733688522, "batch_size": 312, "loss": 0.0014237388141918926}, {"layer_params": [52, 58, 49, 50], "learning_rate": 0.00974070414223384, "batch_size": 19, "loss": 0.0071228203037753705}, {"layer_params": [20, 29], "learning_rate": 0.0030660287578271493, "batch_size": 290, "loss": 0.0035294938110746444}, {"layer_params": [62, 30], "learning_rate": 0.004849536269359002, "batch_size": 490, "loss": 0.0010468865791335702}, {"layer_params": [50, 30, 46, 27], "learning_rate": 0.009460634190725426, "batch_size": 348, "loss": 0.0012833216396393255}, {"layer_params": [40, 24, 63, 60], "learning_rate": 0.0022326533736723676, "batch_size": 323, "loss": 0.0019361150765325873}, {"layer_params": [20, 45, 60, 24, 44], "learning_rate": 0.004400402379080499, "batch_size": 137, "loss": 0.0031883485778234897}, {"layer_params": [60, 59, 48], "learning_rate": 0.0009567942610540667, "batch_size": 335, "loss": 0.0020608417876064778}, {"layer_params": [48, 59, 51], "learning_rate": 0.009957181985794082, "batch_size": 63, "loss": 0.0030644581245724114}, {"layer_params": [30, 42, 16], "learning_rate": 0.00514702939619395, "batch_size": 439, "loss": 0.00209366655908525}, {"layer_params": [63, 23, 21, 39, 63], "learning_rate": 0.0073601430250875765, "batch_size": 59, "loss": 0.003754853914724663}, {"layer_params": [25, 52], "learning_rate": 0.003151806524821933, "batch_size": 385, "loss": 0.004015653622336686}, {"layer_params": [30, 25, 36], "learning_rate": 0.009663264991179454, "batch_size": 164, "loss": 0.0027882293064612896}, {"layer_params": [50, 60, 28], "learning_rate": 0.00934968141812156, "batch_size": 141, "loss": 0.0021302819333504884}, {"layer_params": [43, 17], "learning_rate": 0.007243313751455013, "batch_size": 292, "loss": 0.0023514788202010097}, {"layer_params": [63, 40, 45], "learning_rate": 0.004137436183517416, "batch_size": 52, "loss": 0.0024225476011633875}, {"layer_params": [46, 63, 29, 18], "learning_rate": 0.0008443481297432318, "batch_size": 279, "loss": 0.0035064331511966886}, {"layer_params": [49, 56, 36, 49], "learning_rate": 0.0013820259275092372, "batch_size": 266, "loss": 0.001550747937289998}, {"layer_params": [26, 38, 63, 64, 61], "learning_rate": 0.005672211883753617, "batch_size": 195, "loss": 0.00259937982307747}, {"layer_params": [25, 54, 23, 37], "learning_rate": 0.0014742174135862363, "batch_size": 155, "loss": 0.004159850184805691}, {"layer_params": [39, 19], "learning_rate": 0.006449687907098239, "batch_size": 320, "loss": 0.0030541742057539523}, {"layer_params": [21, 26, 48, 22, 17], "learning_rate": 0.007363522437149454, "batch_size": 194, "loss": 0.003949491749517619}, {"layer_params": [34, 64, 29, 55, 26], "learning_rate": 0.007103427302797847, "batch_size": 123, "loss": 0.0021381940029095857}, {"layer_params": [19, 27, 18], "learning_rate": 0.009617158094644685, "batch_size": 457, "loss": 0.0032559904898516834}, {"layer_params": [34, 35, 36, 64, 61], "learning_rate": 0.0009186701561171005, "batch_size": 64, "loss": 0.005761203619185835}, {"layer_params": [53, 56], "learning_rate": 0.0043308954730048865, "batch_size": 208, "loss": 0.0015178695158101618}, {"layer_params": [46, 49, 20, 38], "learning_rate": 0.007794547126228562, "batch_size": 480, "loss": 0.001032561533502303}, {"layer_params": [33, 62], "learning_rate": 0.001698417131512568, "batch_size": 202, "loss": 0.003296478632837534}, {"layer_params": [39, 47, 40, 40, 45], "learning_rate": 0.002412546255542089, "batch_size": 24, "loss": 0.00634376764530316}, {"layer_params": [42, 31], "learning_rate": 0.0001475773870426838, "batch_size": 406, "loss": 0.020507257916033268}, {"layer_params": [38, 27, 25, 52], "learning_rate": 0.009830305244966057, "batch_size": 366, "loss": 0.0019727529014926404}, {"layer_params": [50, 44, 53], "learning_rate": 0.0053248604737724786, "batch_size": 327, "loss": 0.0009557340358151123}, {"layer_params": [28, 58, 22], "learning_rate": 0.0022190182850908785, "batch_size": 127, "loss": 0.00415337948827073}, {"layer_params": [17, 35, 18, 23], "learning_rate": 0.001994639320179654, "batch_size": 503, "loss": 0.004803047869354486}, {"layer_params": [25, 30], "learning_rate": 0.005336966389538761, "batch_size": 446, "loss": 0.003819052432663739}, {"layer_params": [19, 25, 52, 18], "learning_rate": 0.0038395747742235504, "batch_size": 341, "loss": 0.002710217060521245}, {"layer_params": [60, 31, 53], "learning_rate": 0.007022209155310582, "batch_size": 285, "loss": 0.0028044154937379062}, {"layer_params": [41, 21, 56], "learning_rate": 0.009745643756623698, "batch_size": 415, "loss": 0.0019493831356521697}, {"layer_params": [34, 46, 61], "learning_rate": 0.006185680424769469, "batch_size": 42, "loss": 0.0036434830515645446}, {"layer_params": [34, 19, 38, 43], "learning_rate": 2.9406337099821035e-05, "batch_size": 338, "loss": 0.03885114144533872}, {"layer_params": [24, 37, 47, 61], "learning_rate": 0.00974052501932848, "batch_size": 373, "loss": 0.0012831282458500937}, {"layer_params": [56, 36, 28], "learning_rate": 0.009714695715882266, "batch_size": 143, "loss": 0.00217546196305193}, {"layer_params": [59, 24, 51, 37, 33], "learning_rate": 0.0043290045250248274, "batch_size": 214, "loss": 0.002216582883847877}, {"layer_params": [17, 28, 62, 54], "learning_rate": 0.00541011639410862, "batch_size": 297, "loss": 0.0026066872128285468}, {"layer_params": [22, 35], "learning_rate": 0.009598714019581834, "batch_size": 197, "loss": 0.0025712826452217994}, {"layer_params": [63, 57], "learning_rate": 0.008259658813809922, "batch_size": 402, "loss": 0.0015724589547608048}, {"layer_params": [30, 27, 35, 28, 62], "learning_rate": 0.005986960112708587, "batch_size": 378, "loss": 0.0021107339835725724}, {"layer_params": [21, 64, 39, 16, 30], "learning_rate": 3.760985594209282e-05, "batch_size": 327, "loss": 0.03754646595567465}, {"layer_params": [63, 39], "learning_rate": 0.005201212960300716, "batch_size": 272, "loss": 0.0024817468249239026}, {"layer_params": [54, 52], "learning_rate": 0.009604867218989553, "batch_size": 21, "loss": 0.006065712353447452}, {"layer_params": [61, 47, 40, 40], "learning_rate": 0.002502863148022842, "batch_size": 340, "loss": 0.0017706236045341938}, {"layer_params": [50, 26], "learning_rate": 0.006587406823883448, "batch_size": 168, "loss": 0.0018058843055041506}, {"layer_params": [21, 25, 58, 23, 47], "learning_rate": 0.0032589469998743977, "batch_size": 442, "loss": 0.003032689760439098}, {"layer_params": [27, 33], "learning_rate": 0.008786185479890638, "batch_size": 169, "loss": 0.0033376593282446266}, {"layer_params": [62, 21, 28, 57, 17], "learning_rate": 0.008959065635196887, "batch_size": 328, "loss": 0.0017048877011984587}, {"layer_params": [61, 18], "learning_rate": 0.0069995062501556, "batch_size": 494, "loss": 0.0012915508670266718}, {"layer_params": [58, 37, 24], "learning_rate": 0.0003941334347912262, "batch_size": 212, "loss": 0.006188413263298571}, {"layer_params": [23, 25], "learning_rate": 0.005108090674519483, "batch_size": 236, "loss": 0.006717139147222042}, {"layer_params": [42, 42, 24, 37], "learning_rate": 0.00931083013892875, "batch_size": 266, "loss": 0.001622488695429638}, {"layer_params": [30, 21, 28], "learning_rate": 0.0009928770192653162, "batch_size": 437, "loss": 0.0040542946965433655}, {"layer_params": [52, 26, 48, 32, 21], "learning_rate": 0.00024976837174327314, "batch_size": 49, "loss": 0.008897540364414454}, {"layer_params": [48, 51, 55, 48], "learning_rate": 3.8996289325310005e-05, "batch_size": 324, "loss": 0.03513299176469445}, {"layer_params": [23, 17, 23], "learning_rate": 0.0020485715959244802, "batch_size": 219, "loss": 0.004035224714316428}, {"layer_params": [38, 16], "learning_rate": 0.00022143974660441575, "batch_size": 432, "loss": 0.010540527803823353}, {"layer_params": [64, 46], "learning_rate": 0.0013431208189508886, "batch_size": 231, "loss": 0.00246794935897924}, {"layer_params": [59, 63, 17, 28], "learning_rate": 0.0045573382041607996, "batch_size": 73, "loss": 0.0031599334394559263}, {"layer_params": [58, 48, 21, 53], "learning_rate": 0.0016662515376511331, "batch_size": 44, "loss": 0.0049240502365864814}, {"layer_params": [25, 17, 40, 54, 33], "learning_rate": 0.009264376908951313, "batch_size": 88, "loss": 0.005809117227327079}, {"layer_params": [64, 43], "learning_rate": 0.008372560653097919, "batch_size": 199, "loss": 0.001175814606831409}, {"layer_params": [54, 54, 24], "learning_rate": 0.005715154929676791, "batch_size": 376, "loss": 0.0010856442374642939}, {"layer_params": [25, 51, 41], "learning_rate": 0.002963416566889072, "batch_size": 211, "loss": 0.0018821115617174656}, {"layer_params": [42, 32, 45], "learning_rate": 0.007819652238391426, "batch_size": 248, "loss": 0.0018732004426419734}, {"layer_params": [41, 18, 22, 40], "learning_rate": 0.00953220723562359, "batch_size": 66, "loss": 0.004287339015863836}, {"layer_params": [37, 50, 18, 38], "learning_rate": 0.0004256363860904187, "batch_size": 446, "loss": 0.006547425254248083}, {"layer_params": [41, 53, 48, 58], "learning_rate": 0.00798936711581594, "batch_size": 444, "loss": 0.0009598860371625051}, {"layer_params": [61, 51, 50, 19], "learning_rate": 0.009581542728242205, "batch_size": 380, "loss": 0.0015502451674547046}, {"layer_params": [43, 42, 29], "learning_rate": 0.0031566897815215236, "batch_size": 98, "loss": 0.003186416244134307}, {"layer_params": [23, 43, 39, 20], "learning_rate": 0.0048271548596322015, "batch_size": 83, "loss": 0.006028777412138879}, {"layer_params": [50, 61, 45, 49, 16], "learning_rate": 0.006980503069823025, "batch_size": 477, "loss": 0.0015524303750135005}, {"layer_params": [33, 25, 35, 39, 44], "learning_rate": 0.008587072681664186, "batch_size": 343, "loss": 0.00159013521973975}, {"layer_params": [49, 35, 28, 22], "learning_rate": 0.003171487772690802, "batch_size": 98, "loss": 0.004535295504610986}, {"layer_params": [45, 36, 55, 56, 38], "learning_rate": 0.0007470329435686585, "batch_size": 182, "loss": 0.0052630474511533975}, {"layer_params": [62, 27, 39, 62, 19], "learning_rate": 0.0071849085021612235, "batch_size": 258, "loss": 0.0020311733870767056}, {"layer_params": [43, 56, 20], "learning_rate": 0.005819926541941503, "batch_size": 357, "loss": 0.0016573665372561664}, {"layer_params": [17, 56], "learning_rate": 0.0016929347156549985, "batch_size": 376, "loss": 0.0028150773304514588}, {"layer_params": [28, 18, 42], "learning_rate": 0.0005805690923888008, "batch_size": 277, "loss": 0.0065685070492327215}, {"layer_params": [44, 52, 64], "learning_rate": 0.0027173383103944733, "batch_size": 212, "loss": 0.0025014424312394114}, {"layer_params": [21, 38, 38, 40], "learning_rate": 0.001261715542132652, "batch_size": 381, "loss": 0.0049926120648160575}, {"layer_params": [44, 30, 43, 17, 34], "learning_rate": 0.0049716835679163495, "batch_size": 405, "loss": 0.0017605059593915938}, {"layer_params": [27, 27, 64, 37], "learning_rate": 0.008740689636512153, "batch_size": 417, "loss": 0.0015469842473976314}, {"layer_params": [34, 61, 42, 43, 42], "learning_rate": 0.003937275091246314, "batch_size": 82, "loss": 0.002215226604603231}, {"layer_params": [32, 48, 25, 52, 55], "learning_rate": 0.003526580667693598, "batch_size": 485, "loss": 0.001382275860523805}, {"layer_params": [42, 38, 48, 31, 39], "learning_rate": 0.008820455182914784, "batch_size": 48, "loss": 0.004895168307702988}, {"layer_params": [64, 62], "learning_rate": 0.007662511025010669, "batch_size": 293, "loss": 0.001017141084303148}, {"layer_params": [55, 32, 32], "learning_rate": 0.009500728693489188, "batch_size": 343, "loss": 0.0014006504521239548}, {"layer_params": [35, 58, 18, 23, 50], "learning_rate": 0.00899720551151563, "batch_size": 282, "loss": 0.002386535940458998}, {"layer_params": [52, 50, 52, 61], "learning_rate": 0.0010775713368650058, "batch_size": 109, "loss": 0.003024068381637335}, {"layer_params": [61, 30, 27, 50], "learning_rate": 0.0012403420763614555, "batch_size": 145, "loss": 0.004841649073641747}, {"layer_params": [50, 59, 17, 49, 50], "learning_rate": 0.007602987517362056, "batch_size": 333, "loss": 0.0015238001919351519}, {"layer_params": [45, 48], "learning_rate": 0.0031020015511067935, "batch_size": 106, "loss": 0.00348283507861197}, {"layer_params": [40, 24, 53, 54, 24], "learning_rate": 0.007705261536166778, "batch_size": 390, "loss": 0.0022130991599988194}, {"layer_params": [55, 28], "learning_rate": 0.009513240815318768, "batch_size": 296, "loss": 0.0024487896577920763}, {"layer_params": [51, 42, 36, 59], "learning_rate": 0.009384467762539655, "batch_size": 360, "loss": 0.0016209864092525095}, {"layer_params": [63, 64], "learning_rate": 0.0011382650964645786, "batch_size": 263, "loss": 0.0023974058229941876}, {"layer_params": [34, 35], "learning_rate": 0.005829775427227182, "batch_size": 19, "loss": 0.006283934076782316}, {"layer_params": [27, 26, 56, 64, 19], "learning_rate": 0.007234905942152821, "batch_size": 293, "loss": 0.0018495362938847392}, {"layer_params": [18, 46, 24, 62, 32], "learning_rate": 0.00830978227606638, "batch_size": 54, "loss": 0.0059262437326833605}, {"layer_params": [28, 24, 17, 46], "learning_rate": 0.004206770681541265, "batch_size": 114, "loss": 0.0032348037627525626}, {"layer_params": [25, 33, 18, 45, 52], "learning_rate": 0.008354123844439489, "batch_size": 118, "loss": 0.003382720034569502}, {"layer_params": [47, 56, 17, 63], "learning_rate": 0.001006464268793753, "batch_size": 453, "loss": 0.002430205763084814}, {"layer_params": [40, 63, 24, 45, 61], "learning_rate": 0.006664280947138855, "batch_size": 150, "loss": 0.002047898176824674}, {"layer_params": [24, 45, 62], "learning_rate": 0.0025896688200951873, "batch_size": 114, "loss": 0.003035930383484811}, {"layer_params": [27, 23, 54], "learning_rate": 0.007425860377591097, "batch_size": 104, "loss": 0.004183462085202336}, {"layer_params": [57, 59, 34], "learning_rate": 0.009846272129024971, "batch_size": 254, "loss": 0.0015513778268359602}, {"layer_params": [28, 63, 61, 36, 45], "learning_rate": 0.0037135575299903152, "batch_size": 113, "loss": 0.0037076049321331083}, {"layer_params": [60, 30], "learning_rate": 0.006594063510261501, "batch_size": 477, "loss": 0.0011610143486177548}, {"layer_params": [25, 59], "learning_rate": 0.006103000048090286, "batch_size": 386, "loss": 0.0022226182173471897}, {"layer_params": [23, 16], "learning_rate": 0.004121529224045421, "batch_size": 232, "loss": 0.005533964321948588}, {"layer_params": [28, 27, 54, 64, 37], "learning_rate": 0.008609641423236468, "batch_size": 422, "loss": 0.002398539640707895}, {"layer_params": [46, 16, 58, 60, 18], "learning_rate": 0.0051337243065608775, "batch_size": 234, "loss": 0.002611416302388534}, {"layer_params": [52, 24, 20], "learning_rate": 0.0043193048216217484, "batch_size": 459, "loss": 0.003311013616621494}, {"layer_params": [16, 39, 47], "learning_rate": 0.00159497186605616, "batch_size": 295, "loss": 0.004855216699652374}, {"layer_params": [49, 52], "learning_rate": 0.003150192162502768, "batch_size": 447, "loss": 0.002648527445271611}, {"layer_params": [50, 30, 24, 62, 43], "learning_rate": 0.007197009121462061, "batch_size": 442, "loss": 0.0019501173053868115}, {"layer_params": [55, 44], "learning_rate": 0.003331022930721777, "batch_size": 333, "loss": 0.0017750284040812404}, {"layer_params": [17, 18, 52], "learning_rate": 0.0028453727351665497, "batch_size": 271, "loss": 0.003330623807851225}, {"layer_params": [56, 44, 16, 31, 53], "learning_rate": 0.0046977936076861605, "batch_size": 150, "loss": 0.002353052266407758}, {"layer_params": [52, 44, 34, 61], "learning_rate": 0.006634880912647199, "batch_size": 511, "loss": 0.000944361577858217}, {"layer_params": [26, 23], "learning_rate": 0.002570778174884469, "batch_size": 369, "loss": 0.0032364038890227674}, {"layer_params": [45, 22], "learning_rate": 0.0007766257065009502, "batch_size": 299, "loss": 0.005259002950042486}, {"layer_params": [40, 58, 31, 53], "learning_rate": 0.007100895063914992, "batch_size": 254, "loss": 0.0017214245698414744}, {"layer_params": [21, 57, 37, 24, 34], "learning_rate": 0.0028574244738793445, "batch_size": 306, "loss": 0.0022576733212918043}, {"layer_params": [23, 36, 61, 33], "learning_rate": 0.0013157067632134673, "batch_size": 54, "loss": 0.006370893723797053}, {"layer_params": [57, 61], "learning_rate": 0.007081007447833227, "batch_size": 134, "loss": 0.0018280127190519124}, {"layer_params": [59, 38, 64, 24, 64], "learning_rate": 0.007438460633917291, "batch_size": 79, "loss": 0.0031391645758412777}, {"layer_params": [35, 46, 39], "learning_rate": 0.009773081607156465, "batch_size": 107, "loss": 0.003014312859158963}, {"layer_params": [33, 39, 49, 42, 41], "learning_rate": 0.0049943993223494935, "batch_size": 162, "loss": 0.0027225717168767004}, {"layer_params": [25, 49, 59, 30, 23], "learning_rate": 0.0002548866990991176, "batch_size": 127, "loss": 0.008227542461827397}, {"layer_params": [63, 53, 56], "learning_rate": 0.009291307822908325, "batch_size": 486, "loss": 0.0013788767391815782}, {"layer_params": [48, 51, 25], "learning_rate": 0.009485255513128427, "batch_size": 49, "loss": 0.0024667149933520704}, {"layer_params": [47, 16, 18], "learning_rate": 0.0011271618707607508, "batch_size": 83, "loss": 0.007068279990926385}, {"layer_params": [23, 29, 36, 41, 42], "learning_rate": 0.008802176527421228, "batch_size": 411, "loss": 0.00249023113399744}, {"layer_params": [58, 61], "learning_rate": 0.006353129260909015, "batch_size": 231, "loss": 0.002008006020914763}, {"layer_params": [42, 23, 58, 28, 55], "learning_rate": 0.005185528930951261, "batch_size": 332, "loss": 0.00239981499616988}, {"layer_params": [55, 64, 52, 42, 44], "learning_rate": 0.00011226287738482827, "batch_size": 289, "loss": 0.007822365695610643}, {"layer_params": [48, 26, 35, 48], "learning_rate": 0.004885161394170543, "batch_size": 139, "loss": 0.0027760175941511987}, {"layer_params": [50, 48], "learning_rate": 0.009464264115264387, "batch_size": 211, "loss": 0.0016196988325100391}, {"layer_params": [30, 44], "learning_rate": 0.0027231821157175135, "batch_size": 269, "loss": 0.0026768275699578224}, {"layer_params": [63, 24, 34], "learning_rate": 0.006732779555610785, "batch_size": 161, "loss": 0.0018761772487778216}, {"layer_params": [61, 52, 31, 60, 22], "learning_rate": 0.005570091780067287, "batch_size": 86, "loss": 0.00185849052737467}, {"layer_params": [40, 51, 47, 27], "learning_rate": 0.004320855633631541, "batch_size": 503, "loss": 0.0010824917728314177}, {"layer_params": [63, 48], "learning_rate": 0.007486223259816898, "batch_size": 372, "loss": 0.0013573641993571072}, {"layer_params": [23, 30], "learning_rate": 0.003921483309403397, "batch_size": 484, "loss": 0.0026083760941401123}, {"layer_params": [28, 51, 28, 30, 32], "learning_rate": 0.0025473487717512754, "batch_size": 390, "loss": 0.0015938806370832026}, {"layer_params": [26, 32, 21], "learning_rate": 0.006317980608327688, "batch_size": 497, "loss": 0.003173067169263959}, {"layer_params": [25, 24, 26], "learning_rate": 0.005799230421691094, "batch_size": 481, "loss": 0.004012936176732183}, {"layer_params": [17, 17, 46, 25], "learning_rate": 0.0029380179650043683, "batch_size": 73, "loss": 0.007068869560025632}, {"layer_params": [35, 56, 46, 62, 55], "learning_rate": 0.006282068510186454, "batch_size": 48, "loss": 0.003994703392963856}, {"layer_params": [22, 61, 23], "learning_rate": 0.009492607493305022, "batch_size": 261, "loss": 0.001691557188751176}, {"layer_params": [37, 45, 34], "learning_rate": 0.003679858421077181, "batch_size": 64, "loss": 0.004665330161806196}, {"layer_params": [47, 19, 55, 49, 36], "learning_rate": 0.005760162820348021, "batch_size": 198, "loss": 0.0025044953997712584}, {"layer_params": [22, 44, 26, 35], "learning_rate": 0.0019758795400349914, "batch_size": 492, "loss": 0.003042444621678442}, {"layer_params": [37, 46], "learning_rate": 0.00025998920860496156, "batch_size": 155, "loss": 0.009329985096119344}, {"layer_params": [36, 18, 56, 61, 19], "learning_rate": 0.00833862326274298, "batch_size": 219, "loss": 0.0027438135724514724}, {"layer_params": [58, 40, 20], "learning_rate": 0.0021632902932650563, "batch_size": 382, "loss": 0.002105613127350807}, {"layer_params": [40, 34], "learning_rate": 0.0021363853529672333, "batch_size": 325, "loss": 0.004319106894545257}, {"layer_params": [37, 60, 48], "learning_rate": 0.001528567838326951, "batch_size": 285, "loss": 0.002628178813029081}, {"layer_params": [39, 57, 59], "learning_rate": 0.005947479657781148, "batch_size": 287, "loss": 0.0014681159285828472}, {"layer_params": [35, 19, 54], "learning_rate": 0.008330420065206456, "batch_size": 282, "loss": 0.001322487024590373}, {"layer_params": [27, 39, 29, 59, 61], "learning_rate": 0.0011294574654484779, "batch_size": 350, "loss": 0.004153322507627308}, {"layer_params": [45, 27, 31, 17], "learning_rate": 0.008979446833942148, "batch_size": 248, "loss": 0.0017285868246108293}, {"layer_params": [62, 54, 34], "learning_rate": 0.00689886140553203, "batch_size": 439, "loss": 0.0021298992133233696}, {"layer_params": [23, 49, 20, 25, 32], "learning_rate": 0.006347653182082643, "batch_size": 376, "loss": 0.0019745048182085155}, {"layer_params": [26, 57, 31], "learning_rate": 0.005084502042310192, "batch_size": 98, "loss": 0.004421357566025108}, {"layer_params": [35, 30, 19], "learning_rate": 0.0007114635202282149, "batch_size": 428, "loss": 0.004730138890445232}, {"layer_params": [43, 25, 31, 34, 20], "learning_rate": 0.00481440970834995, "batch_size": 421, "loss": 0.001124068324570544}, {"layer_params": [25, 62, 17, 47], "learning_rate": 0.004147775454791872, "batch_size": 456, "loss": 0.0018443530111107976}, {"layer_params": [51, 53], "learning_rate": 0.0035858471831527318, "batch_size": 368, "loss": 0.0014091294386889787}, {"layer_params": [33, 32, 48, 20], "learning_rate": 0.0011171200337190958, "batch_size": 286, "loss": 0.0038211906887590883}, {"layer_params": [26, 51], "learning_rate": 0.0036536653016660168, "batch_size": 358, "loss": 0.0018385959346778691}, {"layer_params": [30, 52], "learning_rate": 0.005176989708897848, "batch_size": 267, "loss": 0.0016904767230153084}, {"layer_params": [20, 49], "learning_rate": 0.00904227746636412, "batch_size": 29, "loss": 0.005896912328898907}, {"layer_params": [63, 16], "learning_rate": 0.005454447572411372, "batch_size": 32, "loss": 0.006881295165512711}, {"layer_params": [17, 63, 36], "learning_rate": 2.1416374225338787e-05, "batch_size": 58, "loss": 0.038364582676440474}, {"layer_params": [45, 38, 46, 52], "learning_rate": 0.003429524487677909, "batch_size": 147, "loss": 0.001839698419207707}, {"layer_params": [31, 22, 55, 64], "learning_rate": 0.004813140225710498, "batch_size": 465, "loss": 0.001999219250865281}, {"layer_params": [21, 17, 59, 64], "learning_rate": 0.007991681251354436, "batch_size": 234, "loss": 0.0034350537345744668}, {"layer_params": [55, 64, 33, 43, 46], "learning_rate": 0.00421506070104067, "batch_size": 239, "loss": 0.0017128367081750183}, {"layer_params": [21, 23, 43, 23], "learning_rate": 0.0011497714968476134, "batch_size": 477, "loss": 0.005101569024845958}, {"layer_params": [53, 18], "learning_rate": 0.009112515174221502, "batch_size": 434, "loss": 0.002838938154745847}, {"layer_params": [53, 58, 27], "learning_rate": 0.009551067623101338, "batch_size": 426, "loss": 0.0006186500506009906}, {"layer_params": [36, 34], "learning_rate": 0.006496279403749558, "batch_size": 132, "loss": 0.0017503899405710399}, {"layer_params": [35, 26, 59], "learning_rate": 0.009444797720483449, "batch_size": 246, "loss": 0.002906641806475818}, {"layer_params": [27, 55, 19, 40], "learning_rate": 0.0010885469934782644, "batch_size": 444, "loss": 0.002561866601463407}, {"layer_params": [44, 50, 28, 21], "learning_rate": 0.00425633349289435, "batch_size": 106, "loss": 0.0035958067257888613}, {"layer_params": [26, 35, 62, 26], "learning_rate": 0.004440317495440366, "batch_size": 39, "loss": 0.005567426844500005}, {"layer_params": [62, 57, 25, 33], "learning_rate": 0.0021442594757013662, "batch_size": 99, "loss": 0.0029253318533301355}, {"layer_params": [34, 31, 37], "learning_rate": 0.0046139296334546925, "batch_size": 244, "loss": 0.002292854634579271}, {"layer_params": [16, 56, 56, 52, 47], "learning_rate": 0.005363397201335371, "batch_size": 223, "loss": 0.002451651853043586}, {"layer_params": [43, 50], "learning_rate": 0.003479975470837947, "batch_size": 84, "loss": 0.0039039476681500675}, {"layer_params": [30, 26, 58, 31], "learning_rate": 0.005608942456839104, "batch_size": 288, "loss": 0.0020787617354653776}, {"layer_params": [30, 39, 30, 39, 34], "learning_rate": 0.0056162186395064696, "batch_size": 447, "loss": 0.0014934729086235165}, {"layer_params": [23, 57], "learning_rate": 0.0011730563279807695, "batch_size": 284, "loss": 0.005373874418437481}, {"layer_params": [60, 22], "learning_rate": 0.006784026393149073, "batch_size": 77, "loss": 0.004288750893902033}, {"layer_params": [39, 52, 22, 36], "learning_rate": 0.006278718062400979, "batch_size": 347, "loss": 0.0020278863864950838}, {"layer_params": [63, 38, 28], "learning_rate": 0.004307472057082064, "batch_size": 254, "loss": 0.0010272665688535198}, {"layer_params": [18, 51, 28], "learning_rate": 0.0005244483156022664, "batch_size": 217, "loss": 0.007955116871744394}, {"layer_params": [34, 34, 45, 27], "learning_rate": 0.005878532993574534, "batch_size": 171, "loss": 0.0031906808190979062}, {"layer_params": [56, 32, 35], "learning_rate": 0.00614883482526564, "batch_size": 503, "loss": 0.001093870650511235}, {"layer_params": [45, 61, 19], "learning_rate": 0.0012892349366943592, "batch_size": 359, "loss": 0.0028298563370481133}, {"layer_params": [22, 19, 26, 20], "learning_rate": 0.0039230534218191344, "batch_size": 177, "loss": 0.005932052843272686}, {"layer_params": [16, 40, 46, 19, 41], "learning_rate": 0.0007352226159545742, "batch_size": 118, "loss": 0.006429262021556497}, {"layer_params": [32, 36], "learning_rate": 0.007547911756190485, "batch_size": 358, "loss": 0.002497088466770947}, {"layer_params": [59, 47, 27, 42], "learning_rate": 0.009527993980473316, "batch_size": 124, "loss": 0.0016071470687165855}, {"layer_params": [23, 36, 53, 18, 64], "learning_rate": 0.0023821474912974782, "batch_size": 88, "loss": 0.0038197868247516454}, {"layer_params": [53, 38, 19], "learning_rate": 0.0026804825851420955, "batch_size": 189, "loss": 0.0015481669432483613}, {"layer_params": [55, 23], "learning_rate": 0.0011457927464520695, "batch_size": 69, "loss": 0.006848855689167976}, {"layer_params": [28, 45, 30, 20], "learning_rate": 0.0038033297221682313, "batch_size": 77, "loss": 0.0025205806049052627}, {"layer_params": [43, 42], "learning_rate": 0.00582509594928485, "batch_size": 246, "loss": 0.0016730126074980943}, {"layer_params": [18, 24], "learning_rate": 0.004983435454367897, "batch_size": 387, "loss": 0.004007917130365968}, {"layer_params": [38, 18, 32], "learning_rate": 0.008266543686894766, "batch_size": 424, "loss": 0.0023893651762045918}, {"layer_params": [57, 53, 53, 54], "learning_rate": 0.0027945854765646394, "batch_size": 265, "loss": 0.0012206606910331174}, {"layer_params": [56, 39, 43], "learning_rate": 0.00041379319162871867, "batch_size": 144, "loss": 0.006209500422701239}, {"layer_params": [27, 46, 48, 20, 41], "learning_rate": 0.0004027094208768503, "batch_size": 64, "loss": 0.007865340672433377}, {"layer_params": [29, 49], "learning_rate": 0.0039175847359172525, "batch_size": 307, "loss": 0.002837919695302844}, {"layer_params": [47, 31], "learning_rate": 0.004724698723275816, "batch_size": 464, "loss": 0.0020623162982519715}, {"layer_params": [32, 61], "learning_rate": 0.0017350436957796014, "batch_size": 510, "loss": 0.0026719971979036927}, {"layer_params": [26, 60, 61, 62], "learning_rate": 0.006762603557247951, "batch_size": 388, "loss": 0.0009891370678087696}, {"layer_params": [44, 21, 37, 57], "learning_rate": 0.005275393846579469, "batch_size": 474, "loss": 0.0017237127386033535}, {"layer_params": [44, 28, 54], "learning_rate": 0.00032745064686960873, "batch_size": 174, "loss": 0.007983046974986792}, {"layer_params": [60, 31, 19, 27, 17], "learning_rate": 0.008539253197176805, "batch_size": 150, "loss": 0.002049226554809138}, {"layer_params": [16, 42, 17, 30], "learning_rate": 0.00877849683264438, "batch_size": 34, "loss": 0.007321540277916938}, {"layer_params": [38, 26, 37, 61, 60], "learning_rate": 0.007082023926038835, "batch_size": 29, "loss": 0.006821005884557962}, {"layer_params": [44, 21, 37, 56, 24], "learning_rate": 0.006010604608307653, "batch_size": 231, "loss": 0.0016736367146950215}, {"layer_params": [43, 54, 26], "learning_rate": 0.008658227853173626, "batch_size": 213, "loss": 0.0015816092758905143}, {"layer_params": [23, 29, 19], "learning_rate": 0.007792492609568417, "batch_size": 86, "loss": 0.00568194726947695}, {"layer_params": [36, 23, 27], "learning_rate": 0.0016977323394576345, "batch_size": 325, "loss": 0.005494758631102741}, {"layer_params": [51, 47, 38, 63], "learning_rate": 0.0010208549692849792, "batch_size": 355, "loss": 0.002789755912963301}, {"layer_params": [39, 28], "learning_rate": 0.004011972567936398, "batch_size": 60, "loss": 0.00349259085371159}, {"layer_params": [62, 52, 42, 37, 46], "learning_rate": 0.0011911084294926957, "batch_size": 54, "loss": 0.004146403360646218}, {"layer_params": [61, 33], "learning_rate": 0.009112142720735045, "batch_size": 88, "loss": 0.0048325340123847125}, {"layer_params": [17, 29, 45], "learning_rate": 0.0028484711506128056, "batch_size": 66, "loss": 0.004966379192192108}, {"layer_params": [43, 27, 26], "learning_rate": 0.0012036720815248488, "batch_size": 169, "loss": 0.006549730943515897}, {"layer_params": [43, 41, 62, 45], "learning_rate": 0.0014608373930269367, "batch_size": 120, "loss": 0.002683466182788834}, {"layer_params": [47, 18, 58, 59, 42], "learning_rate": 0.006066430378485952, "batch_size": 348, "loss": 0.0027427926170639693}, {"layer_params": [16, 30, 17, 52], "learning_rate": 0.0023431667698521163, "batch_size": 200, "loss": 0.003965231978800148}, {"layer_params": [61, 50], "learning_rate": 0.0016139784547120218, "batch_size": 236, "loss": 0.002568011919502169}, {"layer_params": [60, 29, 23, 26], "learning_rate": 0.0015645835140873688, "batch_size": 348, "loss": 0.0029701692960225046}, {"layer_params": [17, 17, 40], "learning_rate": 0.0001771780626991506, "batch_size": 417, "loss": 0.014994920948520302}, {"layer_params": [44, 32], "learning_rate": 0.0012203754526273999, "batch_size": 510, "loss": 0.0025046438863500953}, {"layer_params": [19, 55, 24, 19, 57], "learning_rate": 0.0034465549085650232, "batch_size": 291, "loss": 0.0020542803988792004}, {"layer_params": [31, 60], "learning_rate": 0.0041528721868597795, "batch_size": 235, "loss": 0.0030592166306450965}, {"layer_params": [54, 25, 19, 64, 59], "learning_rate": 0.0016181279362333795, "batch_size": 67, "loss": 0.0045811493671499195}, {"layer_params": [38, 48, 16], "learning_rate": 0.004704454287150031, "batch_size": 355, "loss": 0.0020286612631753085}, {"layer_params": [47, 19], "learning_rate": 0.0003248612625575208, "batch_size": 484, "loss": 0.008214898975566029}, {"layer_params": [32, 64, 25], "learning_rate": 0.005626052566455145, "batch_size": 335, "loss": 0.0025245831115171314}, {"layer_params": [55, 30, 30, 25, 61], "learning_rate": 0.009354750283569349, "batch_size": 26, "loss": 0.007567112124525011}, {"layer_params": [48, 51, 48, 32], "learning_rate": 0.00043027917439645284, "batch_size": 509, "loss": 0.003752317342441529}, {"layer_params": [32, 18], "learning_rate": 0.004849199885709755, "batch_size": 372, "loss": 0.004513601022772491}, {"layer_params": [32, 49, 24, 63, 17], "learning_rate": 0.001982105192195109, "batch_size": 299, "loss": 0.0033460181695409118}, {"layer_params": [24, 44, 29, 42], "learning_rate": 0.004618451909471958, "batch_size": 21, "loss": 0.008239024193026126}, {"layer_params": [26, 17, 34, 57, 43], "learning_rate": 0.0073595705373264075, "batch_size": 54, "loss": 0.005494457329623401}, {"layer_params": [50, 18, 45, 52], "learning_rate": 0.006962201161767546, "batch_size": 258, "loss": 0.0018708961899392307}, {"layer_params": [38, 56, 60, 60], "learning_rate": 0.009460122674413606, "batch_size": 334, "loss": 0.001549864518456161}, {"layer_params": [44, 43, 63, 20], "learning_rate": 0.00840360993925867, "batch_size": 163, "loss": 0.0013731930288486184}, {"layer_params": [32, 46, 32, 23, 61], "learning_rate": 0.0054147299640092935, "batch_size": 219, "loss": 0.0014176408428465948}, {"layer_params": [54, 54], "learning_rate": 0.0017857423990773223, "batch_size": 338, "loss": 0.0028040669159963725}, {"layer_params": [28, 19, 60], "learning_rate": 0.004993188154125031, "batch_size": 354, "loss": 0.0020311592298094183}, {"layer_params": [36, 62], "learning_rate": 0.005125637774407313, "batch_size": 404, "loss": 0.0017878773994743824}, {"layer_params": [61, 35, 63], "learning_rate": 0.00982660782773923, "batch_size": 272, "loss": 0.0014767468231730162}, {"layer_params": [43, 62], "learning_rate": 0.009304990927664033, "batch_size": 369, "loss": 0.0018928282067645341}, {"layer_params": [23, 59], "learning_rate": 0.0028228153883682414, "batch_size": 48, "loss": 0.006279468778520822}, {"layer_params": [26, 42, 52, 28], "learning_rate": 0.0024960854009351786, "batch_size": 369, "loss": 0.0020634005090687424}, {"layer_params": [39, 33, 39, 33], "learning_rate": 0.006143560738581247, "batch_size": 320, "loss": 0.0017020551289897413}, {"layer_params": [20, 26], "learning_rate": 0.008609636398729385, "batch_size": 166, "loss": 0.004744723078329116}, {"layer_params": [36, 40], "learning_rate": 0.008242106272104147, "batch_size": 489, "loss": 0.00282045608619228}, {"layer_params": [43, 54, 52, 52], "learning_rate": 0.0034946776400324223, "batch_size": 440, "loss": 0.0013478125550318509}, {"layer_params": [28, 48, 28, 22], "learning_rate": 0.0009943205819936873, "batch_size": 245, "loss": 0.004226117569487542}, {"layer_params": [61, 36, 53, 28, 27], "learning_rate": 0.0018605553974847284, "batch_size": 293, "loss": 0.0019394439656753094}, {"layer_params": [35, 19, 45, 46, 52], "learning_rate": 0.00472759029167573, "batch_size": 429, "loss": 0.002856284868903458}, {"layer_params": [22, 37], "learning_rate": 0.0060357817474131215, "batch_size": 102, "loss": 0.0033870303560979663}, {"layer_params": [52, 33], "learning_rate": 0.005358803653281982, "batch_size": 28, "loss": 0.005964031554758549}, {"layer_params": [53, 22, 55, 48, 41], "learning_rate": 0.008155108642419468, "batch_size": 219, "loss": 0.0018608823872637004}, {"layer_params": [34, 51, 57], "learning_rate": 0.000931216425304312, "batch_size": 299, "loss": 0.0038312785420566795}, {"layer_params": [46, 26, 61], "learning_rate": 0.009037158396247257, "batch_size": 499, "loss": 0.0010338983492692933}, {"layer_params": [41, 64, 31, 57], "learning_rate": 0.003418029518186034, "batch_size": 382, "loss": 0.0020858070463873448}, {"layer_params": [42, 46, 45], "learning_rate": 0.0012301359769122115, "batch_size": 410, "loss": 0.003180806792806834}, {"layer_params": [36, 33, 61], "learning_rate": 0.003629123832789585, "batch_size": 95, "loss": 0.005242426167242229}, {"layer_params": [30, 51], "learning_rate": 0.004692728098833514, "batch_size": 246, "loss": 0.0019376053567975759}, {"layer_params": [41, 56, 64, 59], "learning_rate": 0.008448688829840303, "batch_size": 63, "loss": 0.0026559493131935595}, {"layer_params": [38, 51], "learning_rate": 0.009791195374143405, "batch_size": 288, "loss": 0.0017836059082765132}, {"layer_params": [60, 16, 61, 60, 28], "learning_rate": 0.0013822269835325443, "batch_size": 303, "loss": 0.0035111225652508437}, {"layer_params": [27, 55, 18, 40, 18], "learning_rate": 0.0025448073592775275, "batch_size": 190, "loss": 0.0026033856137655676}, {"layer_params": [57, 32, 47, 34, 42], "learning_rate": 0.00680309075823037, "batch_size": 27, "loss": 0.00577380258589983}, {"layer_params": [36, 30], "learning_rate": 0.003825113606726073, "batch_size": 305, "loss": 0.0032319419970735907}, {"layer_params": [64, 19], "learning_rate": 0.0019177280147382992, "batch_size": 329, "loss": 0.0025422729924321173}, {"layer_params": [29, 49, 34, 64], "learning_rate": 0.007623979764239956, "batch_size": 155, "loss": 0.0016376430715899914}, {"layer_params": [44, 34, 42, 47, 44], "learning_rate": 0.000538281418886841, "batch_size": 459, "loss": 0.002958547140005976}, {"layer_params": [21, 57, 31], "learning_rate": 0.0010499182901786272, "batch_size": 493, "loss": 0.002886065491475165}, {"layer_params": [63, 62, 24], "learning_rate": 0.001197466067518672, "batch_size": 356, "loss": 0.0026394650526344776}, {"layer_params": [47, 32, 61], "learning_rate": 0.005329015895728191, "batch_size": 104, "loss": 0.0026241945824585855}, {"layer_params": [40, 58, 39, 43, 34], "learning_rate": 0.009312163953204286, "batch_size": 466, "loss": 0.0017493550048675388}, {"layer_params": [58, 49, 58, 30], "learning_rate": 6.411269447839752e-05, "batch_size": 470, "loss": 0.029092934262007476}, {"layer_params": [44, 59, 61, 28], "learning_rate": 0.008082002388528952, "batch_size": 107, "loss": 0.0020804266014602035}, {"layer_params": [61, 59, 22, 64, 62], "learning_rate": 0.002410593012513077, "batch_size": 104, "loss": 0.0033383326209150254}, {"layer_params": [63, 32, 41, 42, 50], "learning_rate": 0.0007397870571182764, "batch_size": 406, "loss": 0.002495869586709887}, {"layer_params": [34, 46, 26, 52], "learning_rate": 0.005974149614267382, "batch_size": 179, "loss": 0.0017814087658189236}, {"layer_params": [26, 60, 47, 37], "learning_rate": 0.007383867825226334, "batch_size": 263, "loss": 0.002769464405719191}, {"layer_params": [35, 46, 31, 57], "learning_rate": 0.004999446936255578, "batch_size": 462, "loss": 0.0012554816540796309}, {"layer_params": [58, 26, 25, 60, 25], "learning_rate": 0.0027110585677311734, "batch_size": 149, "loss": 0.0025449805334210396}, {"layer_params": [43, 27, 62], "learning_rate": 0.006829862873442577, "batch_size": 274, "loss": 0.0023847021197434515}, {"layer_params": [39, 63, 28], "learning_rate": 0.005128338558880947, "batch_size": 237, "loss": 0.001592462717089802}, {"layer_params": [42, 44, 43], "learning_rate": 0.004376748769432952, "batch_size": 107, "loss": 0.0018811094830743968}, {"layer_params": [23, 38, 30, 33, 63], "learning_rate": 0.005014107442806736, "batch_size": 367, "loss": 0.0020833441230934113}, {"layer_params": [24, 20, 61], "learning_rate": 0.007649265767500808, "batch_size": 278, "loss": 0.0022246514295693486}, {"layer_params": [16, 28], "learning_rate": 0.0018302455662981875, "batch_size": 119, "loss": 0.0071976330410689114}, {"layer_params": [33, 51, 35, 43, 57], "learning_rate": 0.005860647814730275, "batch_size": 218, "loss": 0.0014301779773086309}, {"layer_params": [49, 27, 28], "learning_rate": 0.007740608783765169, "batch_size": 449, "loss": 0.0031933696661144493}, {"layer_params": [47, 48, 39], "learning_rate": 0.009653719088988984, "batch_size": 245, "loss": 0.001106527296360582}, {"layer_params": [26, 36, 62, 20], "learning_rate": 0.006578720026883818, "batch_size": 87, "loss": 0.002839983218582347}, {"layer_params": [52, 48], "learning_rate": 0.0002936280273868718, "batch_size": 37, "loss": 0.009186028335243464}, {"layer_params": [44, 48], "learning_rate": 0.009071627939611372, "batch_size": 67, "loss": 0.0046250865678302945}, {"layer_params": [55, 54, 29, 62], "learning_rate": 0.0030086987112505504, "batch_size": 208, "loss": 0.0019858409429434685}, {"layer_params": [18, 30], "learning_rate": 0.008939502101900754, "batch_size": 452, "loss": 0.003621687383856624}, {"layer_params": [42, 37, 17, 52, 33], "learning_rate": 0.009411573676188372, "batch_size": 285, "loss": 0.0015397528558969498}, {"layer_params": [56, 29, 16], "learning_rate": 0.005131103392334798, "batch_size": 181, "loss": 0.004244139005895704}, {"layer_params": [58, 33, 19, 29, 27], "learning_rate": 0.007036112189131522, "batch_size": 448, "loss": 0.0007819867046782746}, {"layer_params": [54, 20, 22, 57], "learning_rate": 0.002343126542038248, "batch_size": 155, "loss": 0.0034925362351350487}, {"layer_params": [50, 40, 47, 34], "learning_rate": 0.007287166875626071, "batch_size": 345, "loss": 0.0012766370811732486}, {"layer_params": [32, 55, 30], "learning_rate": 0.0023774201494639094, "batch_size": 212, "loss": 0.00318030568305403}, {"layer_params": [45, 19, 18], "learning_rate": 0.002449320888297686, "batch_size": 284, "loss": 0.003114007851108909}, {"layer_params": [22, 28, 50, 54, 57], "learning_rate": 0.005371388227519289, "batch_size": 388, "loss": 0.0017737162893172354}, {"layer_params": [63, 23, 29, 24], "learning_rate": 0.0072850919401460466, "batch_size": 429, "loss": 0.0013229367602616549}, {"layer_params": [57, 37, 64, 23, 25], "learning_rate": 0.0011240429022533222, "batch_size": 95, "loss": 0.004227020798716694}, {"layer_params": [52, 62, 48], "learning_rate": 0.007092631063039966, "batch_size": 27, "loss": 0.004925481292884797}, {"layer_params": [49, 40, 33, 47, 47], "learning_rate": 0.005122902571999255, "batch_size": 404, "loss": 0.0014941195084247738}, {"layer_params": [29, 46], "learning_rate": 0.0070643337549448435, "batch_size": 245, "loss": 0.0032658463809639216}, {"layer_params": [47, 63, 41], "learning_rate": 0.007732457727816479, "batch_size": 290, "loss": 0.0023197739373426885}, {"layer_params": [54, 61, 26], "learning_rate": 0.008064063083984578, "batch_size": 485, "loss": 0.001238274375209585}, {"layer_params": [57, 33, 37], "learning_rate": 0.005236664699965633, "batch_size": 463, "loss": 0.0011945780587848277}, {"layer_params": [44, 22, 20], "learning_rate": 0.0065924822106126655, "batch_size": 396, "loss": 0.003029853522311896}, {"layer_params": [45, 36, 31, 36], "learning_rate": 0.005969739710045956, "batch_size": 429, "loss": 0.0015234926098491996}, {"layer_params": [18, 51], "learning_rate": 0.008275107975869066, "batch_size": 47, "loss": 0.005142564803827554}, {"layer_params": [22, 42, 32], "learning_rate": 0.0048591166387719755, "batch_size": 371, "loss": 0.0018003600742667913}, {"layer_params": [46, 63, 45, 35], "learning_rate": 0.009525516824583139, "batch_size": 63, "loss": 0.003848241639789194}, {"layer_params": [63, 51, 50, 31, 43], "learning_rate": 0.0060397230398348475, "batch_size": 506, "loss": 0.0011742304894141852}, {"layer_params": [18, 59], "learning_rate": 0.005896532253331143, "batch_size": 512, "loss": 0.002355689360992983}, {"layer_params": [56, 42, 16], "learning_rate": 0.009626260663601702, "batch_size": 206, "loss": 0.002842145600588992}, {"layer_params": [55, 57, 42], "learning_rate": 0.008658319970825622, "batch_size": 215, "loss": 0.001116568663273938}, {"layer_params": [59, 36, 61, 40, 27], "learning_rate": 0.0005508242810471416, "batch_size": 252, "loss": 0.00494925985345617}, {"layer_params": [43, 64, 44], "learning_rate": 0.006463917458652628, "batch_size": 128, "loss": 0.002112391192931682}, {"layer_params": [62, 34, 20], "learning_rate": 0.00891470280039836, "batch_size": 229, "loss": 0.0018853606027550995}, {"layer_params": [26, 57], "learning_rate": 0.003689829401598686, "batch_size": 209, "loss": 0.00575916207395494}, {"layer_params": [34, 54, 25, 20, 26], "learning_rate": 0.007126700316756041, "batch_size": 232, "loss": 0.0014524496579542757}, {"layer_params": [39, 46, 52, 44], "learning_rate": 0.007984149699413492, "batch_size": 264, "loss": 0.0012417816324159503}, {"layer_params": [48, 59, 22, 31], "learning_rate": 0.005524440898383622, "batch_size": 402, "loss": 0.0010211348213488235}, {"layer_params": [57, 34, 34, 24, 58], "learning_rate": 0.004965388355026477, "batch_size": 68, "loss": 0.002633668722119182}, {"layer_params": [36, 40, 33, 60], "learning_rate": 0.002707265459880002, "batch_size": 32, "loss": 0.005171815040521324}, {"layer_params": [35, 51], "learning_rate": 0.0017901387676562582, "batch_size": 254, "loss": 0.0034929669043049214}, {"layer_params": [38, 59], "learning_rate": 0.002013468772829433, "batch_size": 237, "loss": 0.0034986510965973137}, {"layer_params": [19, 22, 16, 27, 22], "learning_rate": 0.0022500532777446915, "batch_size": 183, "loss": 0.005402281354181468}, {"layer_params": [49, 20, 25, 17, 30], "learning_rate": 0.0027447456572472647, "batch_size": 509, "loss": 0.001951307700946927}, {"layer_params": [45, 32], "learning_rate": 0.0021264062423794593, "batch_size": 369, "loss": 0.0026706085237674414}, {"layer_params": [20, 16, 32, 56], "learning_rate": 0.008775873426901285, "batch_size": 495, "loss": 0.0031907632714137436}, {"layer_params": [47, 62, 61], "learning_rate": 0.008790183576356, "batch_size": 150, "loss": 0.001527935891645029}, {"layer_params": [35, 43, 29], "learning_rate": 0.005661810551709683, "batch_size": 407, "loss": 0.0015023869602009655}, {"layer_params": [40, 23, 35, 32], "learning_rate": 0.009019913923746617, "batch_size": 225, "loss": 0.002400361258769408}, {"layer_params": [54, 60, 34], "learning_rate": 0.0021185165610076145, "batch_size": 377, "loss": 0.001427116773556918}, {"layer_params": [45, 52], "learning_rate": 0.0031518540845966517, "batch_size": 471, "loss": 0.0017101306875701994}, {"layer_params": [22, 37], "learning_rate": 0.0006545613226647529, "batch_size": 59, "loss": 0.007569260038435459}, {"layer_params": [36, 25, 62, 38, 21], "learning_rate": 0.00035771457465876, "batch_size": 299, "loss": 0.006401608856394887}, {"layer_params": [46, 17, 58, 39], "learning_rate": 0.006890266003198348, "batch_size": 343, "loss": 0.001559435762465}, {"layer_params": [46, 50, 32, 39], "learning_rate": 0.0037507488366942568, "batch_size": 85, "loss": 0.002785755309741944}, {"layer_params": [60, 61, 33], "learning_rate": 0.009974954531938833, "batch_size": 54, "loss": 0.0026169219217263163}, {"layer_params": [51, 27, 25], "learning_rate": 0.00900546059950827, "batch_size": 330, "loss": 0.00229383219149895}, {"layer_params": [18, 58, 35, 58, 61], "learning_rate": 0.006870300594551369, "batch_size": 430, "loss": 0.0014528868871275336}, {"layer_params": [17, 35], "learning_rate": 0.002194716820264917, "batch_size": 48, "loss": 0.007478158918675035}, {"layer_params": [53, 59, 38], "learning_rate": 0.00824263858629277, "batch_size": 189, "loss": 0.0014796982594998554}, {"layer_params": [49, 53, 44, 60], "learning_rate": 0.007307057337333858, "batch_size": 242, "loss": 0.0015062663389835507}, {"layer_params": [21, 26], "learning_rate": 0.00972939539016178, "batch_size": 399, "loss": 0.004400256092194468}, {"layer_params": [22, 40, 27, 43], "learning_rate": 0.008441430082945407, "batch_size": 117, "loss": 0.00417929416988045}, {"layer_params": [52, 58, 46], "learning_rate": 0.009161658499003147, "batch_size": 445, "loss": 0.0009096784511348232}, {"layer_params": [34, 55, 60, 40, 21], "learning_rate": 0.006765617158759177, "batch_size": 323, "loss": 0.0017197200853843243}, {"layer_params": [33, 55], "learning_rate": 0.007756041143537183, "batch_size": 384, "loss": 0.001999300093157217}, {"layer_params": [40, 48, 48], "learning_rate": 0.007040264917181641, "batch_size": 222, "loss": 0.0011913897114573047}, {"layer_params": [20, 43], "learning_rate": 0.007437367123084914, "batch_size": 367, "loss": 0.0024349424347747117}, {"layer_params": [24, 54, 41, 33], "learning_rate": 1.5726325736415724e-05, "batch_size": 23, "loss": 0.07098295275121927}, {"layer_params": [19, 33, 53], "learning_rate": 0.0047092744712123845, "batch_size": 33, "loss": 0.00822435979731381}, {"layer_params": [57, 32], "learning_rate": 0.009219120373848004, "batch_size": 107, "loss": 0.0026670330343768}, {"layer_params": [20, 59, 57, 18, 49], "learning_rate": 0.005322518679306527, "batch_size": 35, "loss": 0.005895321064163}, {"layer_params": [32, 55, 30, 38, 48], "learning_rate": 0.0020964905351962175, "batch_size": 139, "loss": 0.002434366176603362}, {"layer_params": [39, 56, 59, 21], "learning_rate": 0.004403621946050673, "batch_size": 246, "loss": 0.0015438448067288846}, {"layer_params": [62, 35, 29], "learning_rate": 0.007646314392018566, "batch_size": 203, "loss": 0.0020056267478503285}, {"layer_params": [50, 60], "learning_rate": 0.0014701360001959276, "batch_size": 52, "loss": 0.004846978832501918}, {"layer_params": [27, 54, 60, 40, 37], "learning_rate": 0.006715436784780758, "batch_size": 407, "loss": 0.001697497059358284}, {"layer_params": [17, 53, 33, 45, 19], "learning_rate": 0.004926550416408088, "batch_size": 222, "loss": 0.0031231118482537568}, {"layer_params": [25, 59, 57, 19], "learning_rate": 0.007329062879553317, "batch_size": 362, "loss": 0.001214521116344258}, {"layer_params": [20, 29, 58], "learning_rate": 0.0077863427723220465, "batch_size": 160, "loss": 0.003226545718498528}, {"layer_params": [36, 19, 35], "learning_rate": 0.001066434239450757, "batch_size": 305, "loss": 0.006154847093857825}, {"layer_params": [21, 16], "learning_rate": 0.006743769511807105, "batch_size": 299, "loss": 0.00287312249885872}, {"layer_params": [25, 62, 43, 38, 41], "learning_rate": 0.00935722155118403, "batch_size": 120, "loss": 0.003841426700819284}, {"layer_params": [59, 58, 46], "learning_rate": 0.007569747620621472, "batch_size": 143, "loss": 0.0015323989721946418}, {"layer_params": [26, 18, 57, 30, 45], "learning_rate": 0.00999155835228041, "batch_size": 30, "loss": 0.00952527426648885}, {"layer_params": [43, 56, 22, 45], "learning_rate": 0.0027697831926378836, "batch_size": 313, "loss": 0.0016655732796061783}, {"layer_params": [21, 46, 32, 39], "learning_rate": 0.00033108185848903593, "batch_size": 203, "loss": 0.007259660996496677}, {"layer_params": [61, 40, 19, 56, 42], "learning_rate": 0.0063538466697446545, "batch_size": 29, "loss": 0.003809029966359958}, {"layer_params": [41, 63, 32, 43], "learning_rate": 0.008909804412955188, "batch_size": 195, "loss": 0.0017712007206864655}, {"layer_params": [64, 29, 19, 40, 17], "learning_rate": 0.005608878591799938, "batch_size": 431, "loss": 0.0009028841136023403}, {"layer_params": [63, 21, 57, 43, 52], "learning_rate": 0.005346076472375791, "batch_size": 249, "loss": 0.001290471073007211}, {"layer_params": [25, 29, 49, 60, 31], "learning_rate": 0.008938869228112678, "batch_size": 408, "loss": 0.002507384788477793}, {"layer_params": [53, 20, 42, 57, 35], "learning_rate": 0.0004923423895568389, "batch_size": 377, "loss": 0.004558877283707261}, {"layer_params": [58, 48, 47, 19, 19], "learning_rate": 0.0003432224848301914, "batch_size": 416, "loss": 0.006138252215459943}, {"layer_params": [58, 33, 23, 24, 52], "learning_rate": 0.00015628992556983035, "batch_size": 236, "loss": 0.008728904975578189}, {"layer_params": [43, 49, 32, 22, 56], "learning_rate": 0.008378931241275107, "batch_size": 152, "loss": 0.002024994739331305}, {"layer_params": [61, 26, 57, 44, 57], "learning_rate": 0.0003027925547578768, "batch_size": 443, "loss": 0.005027752046007663}, {"layer_params": [28, 56, 59, 38], "learning_rate": 0.007618110342776745, "batch_size": 386, "loss": 0.0020954112231265755}, {"layer_params": [22, 56, 64], "learning_rate": 0.007953427634629306, "batch_size": 181, "loss": 0.0024490990140475333}, {"layer_params": [61, 17, 42], "learning_rate": 0.0061781733340844445, "batch_size": 46, "loss": 0.003723719442496076}, {"layer_params": [18, 42, 42], "learning_rate": 0.003953999401484389, "batch_size": 103, "loss": 0.004486818229779601}, {"layer_params": [18, 62, 50, 50], "learning_rate": 0.006137751612851896, "batch_size": 374, "loss": 0.0015853276627603918}, {"layer_params": [63, 45, 22, 30, 29], "learning_rate": 0.005275846234377493, "batch_size": 317, "loss": 0.0013167948881164194}, {"layer_params": [18, 31, 58, 53, 18], "learning_rate": 0.0014997229444661416, "batch_size": 493, "loss": 0.0035012558777816594}, {"layer_params": [49, 28, 34], "learning_rate": 0.006055834344868166, "batch_size": 288, "loss": 0.0016547977668233216}, {"layer_params": [38, 23, 64, 37, 42], "learning_rate": 0.0011637300200591988, "batch_size": 480, "loss": 0.002989022184628993}, {"layer_params": [40, 36, 28, 31], "learning_rate": 0.007318905486203547, "batch_size": 299, "loss": 0.0021977830468676986}, {"layer_params": [25, 39, 59, 25], "learning_rate": 0.007718185701770486, "batch_size": 337, "loss": 0.001998506207019091}, {"layer_params": [28, 52, 64, 55, 60], "learning_rate": 0.009928987105576863, "batch_size": 440, "loss": 0.001226450358517468}, {"layer_params": [45, 35], "learning_rate": 0.0012828850937293729, "batch_size": 478, "loss": 0.004367263568565249}, {"layer_params": [30, 60, 46], "learning_rate": 0.0003375892475238241, "batch_size": 425, "loss": 0.0060011227754876014}, {"layer_params": [53, 24, 64, 37, 52], "learning_rate": 0.006814908717355732, "batch_size": 254, "loss": 0.0024233727378305046}, {"layer_params": [40, 33, 21, 32, 16], "learning_rate": 0.003133002087585149, "batch_size": 61, "loss": 0.004675348023883998}, {"layer_params": [49, 41], "learning_rate": 0.007432923367497282, "batch_size": 24, "loss": 0.004355528529267758}, {"layer_params": [41, 19, 60, 28], "learning_rate": 0.0009069473548815633, "batch_size": 314, "loss": 0.0035133352130651474}, {"layer_params": [54, 27, 63, 37], "learning_rate": 0.0011058872940597343, "batch_size": 374, "loss": 0.0023897891666274517}, {"layer_params": [51, 32, 49, 58], "learning_rate": 0.005979982958226592, "batch_size": 469, "loss": 0.0008617018611403182}, {"layer_params": [42, 60, 47, 29, 57], "learning_rate": 0.00970771639780028, "batch_size": 416, "loss": 0.0007984317233785987}, {"layer_params": [55, 23], "learning_rate": 0.004830146290426334, "batch_size": 330, "loss": 0.002275363130029291}, {"layer_params": [58, 64, 63, 50], "learning_rate": 0.0004623671662466379, "batch_size": 295, "loss": 0.002354784592753276}, {"layer_params": [46, 63, 23, 17, 59], "learning_rate": 0.009655731768170915, "batch_size": 214, "loss": 0.0016088929411489517}, {"layer_params": [44, 57, 46, 23], "learning_rate": 0.0009334730461975682, "batch_size": 509, "loss": 0.0020224534254521132}, {"layer_params": [57, 18, 22, 46], "learning_rate": 0.00978725091030768, "batch_size": 364, "loss": 0.002262005890952423}, {"layer_params": [34, 55], "learning_rate": 0.005575272664484804, "batch_size": 442, "loss": 0.0018468572478741408}, {"layer_params": [50, 40, 30, 59, 24], "learning_rate": 0.0069593356407088485, "batch_size": 487, "loss": 0.0011159510258585215}, {"layer_params": [59, 36, 35, 53], "learning_rate": 0.000306442065489147, "batch_size": 405, "loss": 0.004703359315171838}, {"layer_params": [48, 24], "learning_rate": 0.0018441080812333858, "batch_size": 384, "loss": 0.0032457865425385536}, {"layer_params": [17, 59, 29], "learning_rate": 0.008700296679191576, "batch_size": 87, "loss": 0.00549875850090757}, {"layer_params": [40, 49], "learning_rate": 0.0009616832411170739, "batch_size": 502, "loss": 0.0033662823657505214}, {"layer_params": [45, 51, 20], "learning_rate": 0.009505670354856293, "batch_size": 502, "loss": 0.0010822232015198097}, {"layer_params": [64, 53, 19, 20], "learning_rate": 0.006202316588175557, "batch_size": 486, "loss": 0.0010168767481809483}, {"layer_params": [48, 33], "learning_rate": 0.009270937510188948, "batch_size": 24, "loss": 0.0064256680896505715}, {"layer_params": [19, 37, 37, 43], "learning_rate": 0.0091843076704614, "batch_size": 218, "loss": 0.0033718264428898694}, {"layer_params": [39, 38, 17, 41, 28], "learning_rate": 0.0013155999675322093, "batch_size": 372, "loss": 0.0020057470758911224}, {"layer_params": [17, 64, 63, 16], "learning_rate": 0.008295655864371951, "batch_size": 55, "loss": 0.004876547493040562}, {"layer_params": [31, 22, 60, 58], "learning_rate": 0.006494650710440256, "batch_size": 305, "loss": 0.0021372986841015516}, {"layer_params": [43, 45, 44], "learning_rate": 0.0058950998821808865, "batch_size": 379, "loss": 0.0015772806527093054}, {"layer_params": [28, 40, 48, 39, 43], "learning_rate": 0.00419749349678738, "batch_size": 437, "loss": 0.0017815263580996544}, {"layer_params": [25, 21, 22], "learning_rate": 0.0036835688002615635, "batch_size": 104, "loss": 0.006284169112332165}, {"layer_params": [46, 45, 48, 43, 47], "learning_rate": 0.008431797444679126, "batch_size": 216, "loss": 0.0011217124073300512}, {"layer_params": [46, 36, 20], "learning_rate": 0.002524142751573637, "batch_size": 100, "loss": 0.004619951387867332}, {"layer_params": [43, 44, 45], "learning_rate": 0.0055637614612149364, "batch_size": 300, "loss": 0.0018407437985297293}, {"layer_params": [53, 34, 46], "learning_rate": 0.0011459685026244243, "batch_size": 201, "loss": 0.003967110216617584}, {"layer_params": [44, 52], "learning_rate": 0.006463898519773137, "batch_size": 192, "loss": 0.0018407449894584716}, {"layer_params": [55, 24, 57, 60, 60], "learning_rate": 0.009077064514997606, "batch_size": 324, "loss": 0.001684456521179527}, {"layer_params": [41, 27, 56, 27, 40], "learning_rate": 0.005284213710722006, "batch_size": 193, "loss": 0.002363786471541971}, {"layer_params": [30, 25, 49], "learning_rate": 0.003136222072314026, "batch_size": 61, "loss": 0.003914523562416434}, {"layer_params": [62, 22, 39], "learning_rate": 0.008848576144057345, "batch_size": 386, "loss": 0.0010758075054036454}, {"layer_params": [29, 49, 23, 47], "learning_rate": 0.009910189477160785, "batch_size": 211, "loss": 0.002534587279660627}, {"layer_params": [18, 59, 31, 38], "learning_rate": 0.007735184065843259, "batch_size": 396, "loss": 0.0013144188647856935}, {"layer_params": [23, 16, 42, 54], "learning_rate": 0.009150935777510284, "batch_size": 288, "loss": 0.002961382241919637}, {"layer_params": [46, 23], "learning_rate": 0.006086303967803159, "batch_size": 48, "loss": 0.004654476959258318}, {"layer_params": [19, 61, 33, 37], "learning_rate": 0.005050702439677764, "batch_size": 241, "loss": 0.0023270547983702274}, {"layer_params": [42, 33, 16, 42], "learning_rate": 0.00018305320521745145, "batch_size": 433, "loss": 0.008351021711714566}, {"layer_params": [42, 62], "learning_rate": 0.0037142747852162298, "batch_size": 314, "loss": 0.001488513246877119}, {"layer_params": [45, 52, 43, 36, 64], "learning_rate": 0.00941265785887512, "batch_size": 51, "loss": 0.003175314642721787}, {"layer_params": [40, 49, 50, 32], "learning_rate": 0.008175979884316927, "batch_size": 490, "loss": 0.0010360683675389737}, {"layer_params": [36, 51, 41], "learning_rate": 0.0032378560535769093, "batch_size": 390, "loss": 0.001334951773751527}, {"layer_params": [50, 16, 34, 30, 27], "learning_rate": 0.007392847652801913, "batch_size": 470, "loss": 0.0020114247174933555}, {"layer_params": [64, 25, 26, 60, 18], "learning_rate": 0.006628478573554306, "batch_size": 170, "loss": 0.001602784035494551}, {"layer_params": [39, 44, 46, 40], "learning_rate": 0.009087897666548926, "batch_size": 497, "loss": 0.0020688623609021305}, {"layer_params": [25, 63, 32, 51], "learning_rate": 0.005382377304954781, "batch_size": 250, "loss": 0.0014804710843600332}, {"layer_params": [64, 37, 29], "learning_rate": 0.004017390045613826, "batch_size": 77, "loss": 0.003349513306748122}, {"layer_params": [45, 51], "learning_rate": 0.007857953548961924, "batch_size": 73, "loss": 0.003415961923310533}, {"layer_params": [42, 57, 34], "learning_rate": 0.009963105764920882, "batch_size": 199, "loss": 0.0012495967576978727}, {"layer_params": [49, 61, 38], "learning_rate": 0.0056123526174645675, "batch_size": 221, "loss": 0.0010561958834296092}, {"layer_params": [60, 60, 30], "learning_rate": 0.009004385508745636, "batch_size": 18, "loss": 0.006743771194014698}, {"layer_params": [43, 26], "learning_rate": 0.006152743014610436, "batch_size": 466, "loss": 0.0036770718358457087}, {"layer_params": [24, 45, 54, 49], "learning_rate": 0.009009382598198713, "batch_size": 394, "loss": 0.0017274467821698635}, {"layer_params": [25, 38, 47], "learning_rate": 0.004748242177030386, "batch_size": 99, "loss": 0.003445870529394597}, {"layer_params": [58, 21, 48], "learning_rate": 0.0018343660846731316, "batch_size": 93, "loss": 0.004490025404375046}, {"layer_params": [35, 51, 33, 54, 29], "learning_rate": 0.005920892283579187, "batch_size": 314, "loss": 0.001727899860125035}, {"layer_params": [53, 26], "learning_rate": 0.0013780848089032312, "batch_size": 511, "loss": 0.003546780329197645}, {"layer_params": [25, 39], "learning_rate": 0.006633816556922608, "batch_size": 284, "loss": 0.0035606474871747195}, {"layer_params": [23, 21, 45], "learning_rate": 0.0094331810002, "batch_size": 164, "loss": 0.003015088199172169}, {"layer_params": [30, 62, 45, 26, 48], "learning_rate": 0.0011040409919385683, "batch_size": 466, "loss": 0.00228466107044369}, {"layer_params": [53, 57], "learning_rate": 0.005869480908300797, "batch_size": 145, "loss": 0.0024044095142744483}, {"layer_params": [61, 33], "learning_rate": 0.0006801380685136748, "batch_size": 313, "loss": 0.005438237530179322}, {"layer_params": [62, 42, 57, 21, 35], "learning_rate": 0.0010916867722195868, "batch_size": 138, "loss": 0.0037123648286797105}, {"layer_params": [19, 50, 55, 57, 54], "learning_rate": 0.0011259167044371772, "batch_size": 231, "loss": 0.003360763853415847}, {"layer_params": [61, 36, 37, 61], "learning_rate": 0.0017376028405045477, "batch_size": 150, "loss": 0.002292480455944315}, {"layer_params": [53, 27, 22, 53, 37], "learning_rate": 0.00834366635333409, "batch_size": 499, "loss": 0.0013387230888474732}, {"layer_params": [57, 54, 58, 26], "learning_rate": 0.0026992489816771363, "batch_size": 494, "loss": 0.0013727873377501964}, {"layer_params": [53, 33, 25, 40], "learning_rate": 0.006705551799286404, "batch_size": 100, "loss": 0.0023732920188922436}, {"layer_params": [62, 40, 37, 32, 50], "learning_rate": 0.006188733007464307, "batch_size": 301, "loss": 0.0011395097168860958}, {"layer_params": [29, 48, 63, 61], "learning_rate": 0.0035388306481919105, "batch_size": 355, "loss": 0.0012362198467599228}, {"layer_params": [45, 47, 60, 26, 28], "learning_rate": 0.0098036158422348, "batch_size": 98, "loss": 0.003382606441155076}, {"layer_params": [46, 55, 46, 63, 43], "learning_rate": 0.002483079129102805, "batch_size": 472, "loss": 0.0011805220582755283}, {"layer_params": [56, 21], "learning_rate": 0.009201349030164662, "batch_size": 315, "loss": 0.002605587695725262}, {"layer_params": [42, 51], "learning_rate": 0.0007859398849038497, "batch_size": 295, "loss": 0.006301873307675124}, {"layer_params": [42, 58, 50, 60, 26], "learning_rate": 0.002636688968122914, "batch_size": 18, "loss": 0.0075958050484769045}, {"layer_params": [17, 27, 63], "learning_rate": 0.007239954835415936, "batch_size": 245, "loss": 0.0033167328406125307}, {"layer_params": [17, 26, 29], "learning_rate": 0.0027099941452064557, "batch_size": 332, "loss": 0.003946660838555545}, {"layer_params": [62, 17, 53, 58], "learning_rate": 0.00018101455826185033, "batch_size": 20, "loss": 0.010480513430666178}, {"layer_params": [36, 48, 51, 56, 50], "learning_rate": 0.0010166296919016883, "batch_size": 99, "loss": 0.005673732014838606}, {"layer_params": [31, 32, 35], "learning_rate": 0.0069928866491866, "batch_size": 474, "loss": 0.0031572574540041387}, {"layer_params": [61, 25], "learning_rate": 0.0010998171624581924, "batch_size": 386, "loss": 0.0036123983329162}, {"layer_params": [62, 58], "learning_rate": 0.00783376738613955, "batch_size": 26, "loss": 0.004498503541108221}, {"layer_params": [63, 44], "learning_rate": 0.005516727194044508, "batch_size": 407, "loss": 0.0011157893476774917}, {"layer_params": [41, 54, 25, 49], "learning_rate": 0.00816228857441176, "batch_size": 418, "loss": 0.0011593601474305616}, {"layer_params": [23, 29, 57, 45, 60], "learning_rate": 0.0035198711081959764, "batch_size": 116, "loss": 0.002732091440120712}, {"layer_params": [33, 31, 59, 61], "learning_rate": 0.00808659717778559, "batch_size": 105, "loss": 0.0028383576194755734}, {"layer_params": [31, 42, 52], "learning_rate": 0.008132648173912715, "batch_size": 465, "loss": 0.0017942315025720745}, {"layer_params": [39, 60, 25], "learning_rate": 0.004953259329896094, "batch_size": 159, "loss": 0.0018478446116205304}, {"layer_params": [59, 62, 24, 59, 40], "learning_rate": 0.007688008699706478, "batch_size": 489, "loss": 0.0016069309914018958}, {"layer_params": [52, 48, 48, 19, 19], "learning_rate": 0.006536389828655574, "batch_size": 383, "loss": 0.0009221238049212843}, {"layer_params": [30, 50, 16], "learning_rate": 0.004783830430112397, "batch_size": 250, "loss": 0.0024987803876865655}, {"layer_params": [42, 42], "learning_rate": 0.0030060496050321873, "batch_size": 353, "loss": 0.002168123658047989}, {"layer_params": [25, 29, 40], "learning_rate": 0.007197124464815217, "batch_size": 94, "loss": 0.003423051661811769}, {"layer_params": [57, 23, 45], "learning_rate": 0.000122033026483311, "batch_size": 441, "loss": 0.02760380558669567}, {"layer_params": [28, 43, 40, 30], "learning_rate": 0.0045845562983697075, "batch_size": 331, "loss": 0.0016514157562050968}, {"layer_params": [49, 25, 58], "learning_rate": 0.0052989423219456985, "batch_size": 506, "loss": 0.0016751146491151303}, {"layer_params": [55, 18, 22, 19, 32], "learning_rate": 0.0050705246362980514, "batch_size": 116, "loss": 0.0035832826630212366}, {"layer_params": [62, 18, 28, 53], "learning_rate": 0.00039058526030754997, "batch_size": 159, "loss": 0.007121597272343933}, {"layer_params": [47, 16, 62, 45], "learning_rate": 0.0068841300457616215, "batch_size": 419, "loss": 0.0018673723470419646}, {"layer_params": [39, 17], "learning_rate": 0.0049864292486686, "batch_size": 80, "loss": 0.0034465667326003314}, {"layer_params": [20, 59, 42, 41, 51], "learning_rate": 0.006381664361515459, "batch_size": 57, "loss": 0.0053541569714434445}, {"layer_params": [28, 25], "learning_rate": 0.0018093321788997334, "batch_size": 454, "loss": 0.00562350167427212}, {"layer_params": [59, 19, 50, 35], "learning_rate": 0.0028408335775362897, "batch_size": 27, "loss": 0.006502605478744954}, {"layer_params": [43, 54, 63], "learning_rate": 0.009422154583778621, "batch_size": 182, "loss": 0.0023707254813052714}, {"layer_params": [16, 18, 36], "learning_rate": 0.00884304031058985, "batch_size": 267, "loss": 0.006719773397780955}, {"layer_params": [43, 60], "learning_rate": 0.007106137075000155, "batch_size": 272, "loss": 0.0010958523134468124}, {"layer_params": [44, 39, 16], "learning_rate": 0.0010291616570551835, "batch_size": 459, "loss": 0.002498255926184356}, {"layer_params": [42, 25], "learning_rate": 0.00625030571413011, "batch_size": 42, "loss": 0.00374282167525962}, {"layer_params": [49, 55, 38, 24], "learning_rate": 0.0018657892273075704, "batch_size": 99, "loss": 0.0032784618809819223}, {"layer_params": [34, 27], "learning_rate": 0.0024010435995652246, "batch_size": 32, "loss": 0.007247710055671632}, {"layer_params": [44, 30], "learning_rate": 0.0003876507493089724, "batch_size": 307, "loss": 0.007593285758048296}, {"layer_params": [36, 37], "learning_rate": 0.009874473679363067, "batch_size": 449, "loss": 0.0019368985237088055}, {"layer_params": [45, 43, 62, 49, 35], "learning_rate": 0.006030713334815665, "batch_size": 296, "loss": 0.001148592671379447}, {"layer_params": [47, 59, 44, 45, 44], "learning_rate": 0.009629507859480704, "batch_size": 80, "loss": 0.0021432548214215786}, {"layer_params": [36, 43, 56], "learning_rate": 0.007489119967145985, "batch_size": 305, "loss": 0.0020077877957373857}, {"layer_params": [25, 23, 45], "learning_rate": 0.005748287018468585, "batch_size": 173, "loss": 0.003250054959207773}, {"layer_params": [53, 39, 48, 29, 48], "learning_rate": 0.009725587591953208, "batch_size": 291, "loss": 0.000956150199053809}, {"layer_params": [19, 49, 44], "learning_rate": 0.005823250191876511, "batch_size": 359, "loss": 0.002051324010826647}, {"layer_params": [37, 51], "learning_rate": 0.0038869220031202585, "batch_size": 234, "loss": 0.003158554427791387}, {"layer_params": [61, 16], "learning_rate": 0.00726719307202656, "batch_size": 392, "loss": 0.0027498249593190848}, {"layer_params": [25, 29, 44, 40, 63], "learning_rate": 0.006654887239040404, "batch_size": 21, "loss": 0.007690742791164666}, {"layer_params": [17, 25, 60, 35, 37], "learning_rate": 0.006683440468741944, "batch_size": 337, "loss": 0.0028428806085139514}, {"layer_params": [21, 24, 24], "learning_rate": 0.0005198361034873994, "batch_size": 115, "loss": 0.00770128944888711}, {"layer_params": [62, 40, 33], "learning_rate": 0.006328971203137689, "batch_size": 232, "loss": 0.0024214255949482322}, {"layer_params": [32, 50, 32, 35], "learning_rate": 0.006332843698351891, "batch_size": 458, "loss": 0.0014924877905286849}, {"layer_params": [56, 28], "learning_rate": 0.0009457041242115297, "batch_size": 141, "loss": 0.00558332743588835}, {"layer_params": [52, 28, 44, 45, 23], "learning_rate": 0.003798873006249358, "batch_size": 139, "loss": 0.0018939938768744468}, {"layer_params": [33, 34, 34, 45, 58], "learning_rate": 0.0045785972746864535, "batch_size": 261, "loss": 0.002013900764286518}, {"layer_params": [35, 51, 58], "learning_rate": 0.0009935269524484075, "batch_size": 181, "loss": 0.0050384335033595564}, {"layer_params": [55, 54, 23, 35, 38], "learning_rate": 0.0017229362290222877, "batch_size": 150, "loss": 0.0024779375840444117}, {"layer_params": [17, 51, 43, 46, 39], "learning_rate": 0.004269833924881905, "batch_size": 377, "loss": 0.001938764238730073}, {"layer_params": [47, 45], "learning_rate": 0.004263315871075558, "batch_size": 471, "loss": 0.0016196056071203203}, {"layer_params": [64, 17, 38], "learning_rate": 0.007855774600204615, "batch_size": 180, "loss": 0.00263629732420668}, {"layer_params": [49, 40, 45, 50, 20], "learning_rate": 0.004191374416930636, "batch_size": 448, "loss": 0.0010146258026361465}, {"layer_params": [30, 64], "learning_rate": 0.0069483169236239685, "batch_size": 359, "loss": 0.0018257379962597043}, {"layer_params": [23, 53], "learning_rate": 0.0005562597431180521, "batch_size": 56, "loss": 0.008803990203887224}, {"layer_params": [48, 24], "learning_rate": 0.00018785541374903572, "batch_size": 328, "loss": 0.011743722595274448}, {"layer_params": [49, 28, 20], "learning_rate": 0.005116569218533466, "batch_size": 173, "loss": 0.0032167057087644935}, {"layer_params": [63, 54, 41, 41], "learning_rate": 0.009793456718933901, "batch_size": 40, "loss": 0.0031718510040082038}, {"layer_params": [34, 30, 43, 45, 55], "learning_rate": 0.009772287906380019, "batch_size": 360, "loss": 0.0025878417142666875}, {"layer_params": [41, 63, 18, 27, 21], "learning_rate": 0.007050951536460077, "batch_size": 378, "loss": 0.0010383474442642183}, {"layer_params": [20, 34], "learning_rate": 0.00199940724145092, "batch_size": 27, "loss": 0.008212282182648778}, {"layer_params": [47, 24, 58, 60, 17], "learning_rate": 0.0003345136853157683, "batch_size": 289, "loss": 0.0076457613287493585}, {"layer_params": [40, 59, 51], "learning_rate": 0.0017442741191920179, "batch_size": 222, "loss": 0.0023405841912608593}, {"layer_params": [61, 40, 54], "learning_rate": 0.0025582130600846375, "batch_size": 58, "loss": 0.0025296366983093323}, {"layer_params": [49, 16, 16, 55, 30], "learning_rate": 0.008639838871710296, "batch_size": 288, "loss": 0.0016343900305218996}, {"layer_params": [35, 31, 26], "learning_rate": 0.0017925111147883035, "batch_size": 291, "loss": 0.0031363667431287467}, {"layer_params": [34, 57, 63, 29, 24], "learning_rate": 0.007517272939068732, "batch_size": 465, "loss": 0.0011638407979626209}, {"layer_params": [55, 50, 23, 42, 27], "learning_rate": 0.006508160028714706, "batch_size": 62, "loss": 0.0027179739298298956}, {"layer_params": [39, 40, 60, 34, 52], "learning_rate": 0.0016618565413548433, "batch_size": 130, "loss": 0.002440243567107245}, {"layer_params": [22, 64, 18, 30, 44], "learning_rate": 0.008632002697937577, "batch_size": 284, "loss": 0.00199030029354617}, {"layer_params": [28, 59, 28], "learning_rate": 0.003764860877856705, "batch_size": 99, "loss": 0.0026835330692119895}, {"layer_params": [56, 40], "learning_rate": 0.002889513492061326, "batch_size": 382, "loss": 0.0015500622987747192}, {"layer_params": [48, 63, 51, 19, 34], "learning_rate": 0.0015734605325273036, "batch_size": 167, "loss": 0.0018155929690692573}, {"layer_params": [61, 28], "learning_rate": 0.008868484250979589, "batch_size": 377, "loss": 0.002516650214092806}, {"layer_params": [57, 51], "learning_rate": 0.004399512144513698, "batch_size": 257, "loss": 0.0014166204573120922}, {"layer_params": [45, 28], "learning_rate": 0.009541138727093487, "batch_size": 144, "loss": 0.0031027782591991127}, {"layer_params": [47, 55, 37, 39, 50], "learning_rate": 0.0066724080811574925, "batch_size": 245, "loss": 0.0019012135791126638}, {"layer_params": [48, 58, 51], "learning_rate": 0.0075856532533855004, "batch_size": 489, "loss": 0.001483726070728153}, {"layer_params": [20, 51, 50, 19], "learning_rate": 0.00830987433112649, "batch_size": 275, "loss": 0.0011390688468236477}, {"layer_params": [24, 32, 52, 36], "learning_rate": 0.0021693877650926295, "batch_size": 413, "loss": 0.0020396374154370276}, {"layer_params": [52, 28], "learning_rate": 0.007961562885158422, "batch_size": 312, "loss": 0.003743660575710237}, {"layer_params": [37, 57, 59], "learning_rate": 0.00028263309371593347, "batch_size": 35, "loss": 0.008768291682936252}, {"layer_params": [54, 58], "learning_rate": 0.005503532091994625, "batch_size": 39, "loss": 0.00357311524101533}, {"layer_params": [34, 41, 59, 24], "learning_rate": 0.006147666262459419, "batch_size": 496, "loss": 0.001273642015294172}, {"layer_params": [42, 21], "learning_rate": 0.006461245185134911, "batch_size": 358, "loss": 0.0015012506174389272}, {"layer_params": [31, 36], "learning_rate": 0.006596030524373669, "batch_size": 286, "loss": 0.0014056949550285936}, {"layer_params": [44, 29, 45, 52, 36], "learning_rate": 0.0021996292568452333, "batch_size": 144, "loss": 0.0027805559290573}, {"layer_params": [24, 58, 45, 39], "learning_rate": 0.0029759094431838166, "batch_size": 89, "loss": 0.003736802153289318}, {"layer_params": [38, 25], "learning_rate": 0.002436415398293054, "batch_size": 421, "loss": 0.0027090866467915477}, {"layer_params": [49, 24, 25], "learning_rate": 0.001624527868180154, "batch_size": 38, "loss": 0.00616753997746855}, {"layer_params": [25, 44, 46, 55], "learning_rate": 0.002902476393368881, "batch_size": 114, "loss": 0.0026788982911966743}, {"layer_params": [59, 21, 20, 64], "learning_rate": 0.006910889778317297, "batch_size": 157, "loss": 0.002731766030192375}, {"layer_params": [22, 51, 38, 38, 37], "learning_rate": 0.0014093674475130393, "batch_size": 187, "loss": 0.003370497964788228}, {"layer_params": [47, 22, 63, 59], "learning_rate": 0.008092717030733887, "batch_size": 149, "loss": 0.0029058132343925537}, {"layer_params": [41, 38], "learning_rate": 0.0005290931916877898, "batch_size": 259, "loss": 0.007236226443201304}, {"layer_params": [60, 26, 61], "learning_rate": 0.005494551259957373, "batch_size": 98, "loss": 0.0031515084696002306}, {"layer_params": [41, 22, 41, 41], "learning_rate": 0.005378349459542763, "batch_size": 413, "loss": 0.0016819076775573193}, {"layer_params": [35, 45, 58], "learning_rate": 0.005115257453801904, "batch_size": 208, "loss": 0.001820881471503526}, {"layer_params": [49, 59, 32], "learning_rate": 0.006551283368397972, "batch_size": 443, "loss": 0.0009672658680938184}, {"layer_params": [49, 47, 56, 26, 18], "learning_rate": 0.0049756956243937394, "batch_size": 68, "loss": 0.002281974363140762}, {"layer_params": [36, 20, 26, 51, 34], "learning_rate": 0.0064265300134578, "batch_size": 367, "loss": 0.002557753303553909}, {"layer_params": [41, 28, 64], "learning_rate": 0.008830970841199819, "batch_size": 303, "loss": 0.002034579016035423}, {"layer_params": [49, 31, 35, 28, 37], "learning_rate": 0.005094608218402892, "batch_size": 62, "loss": 0.0029954273952171205}, {"layer_params": [20, 58, 29], "learning_rate": 0.0073965883451907145, "batch_size": 348, "loss": 0.0021978220995515583}, {"layer_params": [16, 41], "learning_rate": 0.0010744002468609489, "batch_size": 39, "loss": 0.008915688991546631}, {"layer_params": [48, 58, 39, 23, 57], "learning_rate": 0.0032486837368422097, "batch_size": 497, "loss": 0.0012495957064675167}, {"layer_params": [34, 17, 45, 17, 58], "learning_rate": 0.0030236920716199974, "batch_size": 376, "loss": 0.0021502665302250536}, {"layer_params": [55, 58], "learning_rate": 0.0013389677934922465, "batch_size": 375, "loss": 0.00206260516657494}, {"layer_params": [47, 64, 20], "learning_rate": 0.0019829831962535588, "batch_size": 52, "loss": 0.004660165528766811}, {"layer_params": [63, 56], "learning_rate": 0.0012187443421659509, "batch_size": 117, "loss": 0.0038754783454351127}, {"layer_params": [39, 59, 52, 58], "learning_rate": 0.004939830176043768, "batch_size": 448, "loss": 0.000893953274935484}, {"layer_params": [46, 47, 21, 23, 38], "learning_rate": 0.008651677622709021, "batch_size": 211, "loss": 0.0013344022235833109}, {"layer_params": [24, 61, 47, 58], "learning_rate": 0.002313671354317987, "batch_size": 457, "loss": 0.0019256585696712136}, {"layer_params": [38, 21, 23, 60, 47], "learning_rate": 0.006155439652024963, "batch_size": 221, "loss": 0.0016105494031216948}, {"layer_params": [25, 52, 28, 35, 38], "learning_rate": 0.002743017472311974, "batch_size": 485, "loss": 0.0018601590720936656}, {"layer_params": [46, 22, 22, 44, 54], "learning_rate": 0.0069115100767761254, "batch_size": 269, "loss": 0.003304868331179023}, {"layer_params": [27, 56, 50, 22, 48], "learning_rate": 0.008858886206827942, "batch_size": 506, "loss": 0.0014839065086562186}, {"layer_params": [16, 48, 40], "learning_rate": 0.005036365792205914, "batch_size": 190, "loss": 0.00526324677746743}, {"layer_params": [54, 30], "learning_rate": 0.0004381191483784282, "batch_size": 442, "loss": 0.006961263823322952}, {"layer_params": [49, 48], "learning_rate": 0.0035180294067995665, "batch_size": 191, "loss": 0.00212799011496827}, {"layer_params": [60, 55, 64], "learning_rate": 0.003971882993450381, "batch_size": 477, "loss": 0.0010110711259767413}, {"layer_params": [64, 35, 34, 18, 57], "learning_rate": 0.00467466916026152, "batch_size": 373, "loss": 0.001037418523337692}, {"layer_params": [23, 24], "learning_rate": 0.008127415425690444, "batch_size": 180, "loss": 0.0025788572791498156}, {"layer_params": [17, 28, 16], "learning_rate": 0.000286279165732745, "batch_size": 269, "loss": 0.008801397401839495}, {"layer_params": [63, 23, 29, 62], "learning_rate": 0.009882476072233243, "batch_size": 182, "loss": 0.002052547886269167}, {"layer_params": [22, 53, 53, 27, 32], "learning_rate": 0.009985246547414665, "batch_size": 141, "loss": 0.0033224505139514806}, {"layer_params": [40, 44, 27, 29], "learning_rate": 0.007995487421683186, "batch_size": 119, "loss": 0.002002508449368179}, {"layer_params": [26, 32], "learning_rate": 0.004243191917692666, "batch_size": 391, "loss": 0.002375258228275925}, {"layer_params": [51, 40, 42, 27, 17], "learning_rate": 0.0027501574783904813, "batch_size": 407, "loss": 0.0017498219606932252}, {"layer_params": [33, 54, 27, 57], "learning_rate": 0.004286764442273043, "batch_size": 154, "loss": 0.0019183704059105367}, {"layer_params": [30, 49, 20, 64], "learning_rate": 0.0020113122253256153, "batch_size": 282, "loss": 0.0020403456245549024}, {"layer_params": [33, 20, 59, 32], "learning_rate": 0.0050970540291000194, "batch_size": 434, "loss": 0.0022019258339423687}, {"layer_params": [52, 37], "learning_rate": 0.009264248923564346, "batch_size": 450, "loss": 0.0012763087917119264}, {"layer_params": [42, 31, 31, 17], "learning_rate": 0.0014368229724378747, "batch_size": 210, "loss": 0.00407062083715573}, {"layer_params": [60, 57, 64, 53, 20], "learning_rate": 0.000618323140844316, "batch_size": 289, "loss": 0.00301212107995525}, {"layer_params": [39, 27, 23, 28, 16], "learning_rate": 0.009089767496160705, "batch_size": 422, "loss": 0.003290452384389937}, {"layer_params": [50, 20, 25, 40, 31], "learning_rate": 0.0036751988426552357, "batch_size": 140, "loss": 0.0034403011575341227}, {"layer_params": [19, 56, 54, 32, 58], "learning_rate": 0.004019354335405266, "batch_size": 162, "loss": 0.002565378434956074}, {"layer_params": [38, 18, 61, 39], "learning_rate": 0.0059239245874196066, "batch_size": 155, "loss": 0.003235301170498133}, {"layer_params": [40, 57, 33, 34], "learning_rate": 0.009792123344394705, "batch_size": 176, "loss": 0.00226008803001605}, {"layer_params": [25, 50, 63, 37, 58], "learning_rate": 0.009299607098180361, "batch_size": 196, "loss": 0.003047540346160531}, {"layer_params": [18, 56, 46, 48], "learning_rate": 0.003356618466353477, "batch_size": 105, "loss": 0.003501786352135241}, {"layer_params": [30, 55], "learning_rate": 0.003892557175853475, "batch_size": 253, "loss": 0.0019957246794365347}, {"layer_params": [38, 34, 41, 64], "learning_rate": 0.004819399933914082, "batch_size": 204, "loss": 0.00205630362033844}, {"layer_params": [36, 50, 61], "learning_rate": 0.0018566846031951001, "batch_size": 68, "loss": 0.002857152974465862}, {"layer_params": [40, 26, 53], "learning_rate": 3.304498977905448e-05, "batch_size": 30, "loss": 0.03603968547657132}, {"layer_params": [60, 50, 21, 39], "learning_rate": 0.0023666087114492473, "batch_size": 281, "loss": 0.001700641914503649}, {"layer_params": [59, 40, 58], "learning_rate": 0.0012220680067297181, "batch_size": 102, "loss": 0.0037444238387979566}, {"layer_params": [26, 32], "learning_rate": 0.0016177659228256292, "batch_size": 327, "loss": 0.004056680481880903}, {"layer_params": [45, 44], "learning_rate": 0.003933661036208178, "batch_size": 151, "loss": 0.0022631848289165644}, {"layer_params": [64, 47, 64, 26, 56], "learning_rate": 0.008963701320528218, "batch_size": 174, "loss": 0.001572829921497032}, {"layer_params": [44, 48], "learning_rate": 0.0011183154506604611, "batch_size": 455, "loss": 0.00312126103322953}, {"layer_params": [31, 42, 44, 22], "learning_rate": 0.00712383940743679, "batch_size": 126, "loss": 0.0021777323132846503}, {"layer_params": [32, 21, 63, 46], "learning_rate": 0.001544870916260757, "batch_size": 413, "loss": 0.0026494902418926357}, {"layer_params": [46, 21], "learning_rate": 0.006516197208718383, "batch_size": 512, "loss": 0.0021209110179916026}, {"layer_params": [61, 30, 37, 17, 30], "learning_rate": 0.0035884912333427966, "batch_size": 237, "loss": 0.0032885185803752394}, {"layer_params": [37, 61], "learning_rate": 0.002554540935123572, "batch_size": 313, "loss": 0.0022976431413553656}, {"layer_params": [23, 16, 30], "learning_rate": 1.3600367944821265e-05, "batch_size": 293, "loss": 0.03808987256139517}, {"layer_params": [63, 60, 17], "learning_rate": 0.0033134259284680802, "batch_size": 341, "loss": 0.002727895504795015}, {"layer_params": [46, 31, 46, 28, 53], "learning_rate": 0.007565595640765109, "batch_size": 40, "loss": 0.0032654298772104083}, {"layer_params": [52, 44, 16], "learning_rate": 0.0069711005895294305, "batch_size": 379, "loss": 0.001345929023809731}, {"layer_params": [48, 56, 36, 40, 57], "learning_rate": 0.00210716285648825, "batch_size": 101, "loss": 0.0023840924911201}, {"layer_params": [26, 53, 40], "learning_rate": 0.0008112389392137338, "batch_size": 263, "loss": 0.004851107108406722}, {"layer_params": [44, 43], "learning_rate": 0.0016258600430583648, "batch_size": 221, "loss": 0.0035116015118546785}, {"layer_params": [57, 33, 55, 53], "learning_rate": 0.0076415086422101175, "batch_size": 165, "loss": 0.0017825028742663562}, {"layer_params": [47, 30, 52], "learning_rate": 0.00797076158254052, "batch_size": 502, "loss": 0.0014413685945328324}, {"layer_params": [51, 45, 56], "learning_rate": 0.009667762489975272, "batch_size": 329, "loss": 0.0015890124754514546}, {"layer_params": [51, 25, 55], "learning_rate": 0.0037209253270713318, "batch_size": 349, "loss": 0.0019546631269622594}, {"layer_params": [45, 50, 44], "learning_rate": 0.0031740948500342354, "batch_size": 307, "loss": 0.001409811396151781}, {"layer_params": [49, 63, 59, 60, 40], "learning_rate": 0.009134464768205213, "batch_size": 346, "loss": 0.0015526187652722002}, {"layer_params": [28, 55, 64, 56, 37], "learning_rate": 0.0030434647385265685, "batch_size": 384, "loss": 0.002137111919000745}, {"layer_params": [40, 30, 55, 40], "learning_rate": 0.000750823244979878, "batch_size": 443, "loss": 0.0029210576391778885}, {"layer_params": [31, 50, 62, 27, 63], "learning_rate": 4.2514929797296956e-05, "batch_size": 136, "loss": 0.03592606548219919}, {"layer_params": [28, 49, 40, 57, 61], "learning_rate": 0.004454990377913916, "batch_size": 61, "loss": 0.0035054238326847555}, {"layer_params": [17, 53, 55], "learning_rate": 0.002393931793474914, "batch_size": 211, "loss": 0.004419059467036277}, {"layer_params": [34, 36, 60, 35], "learning_rate": 0.006131113777935226, "batch_size": 383, "loss": 0.0009313798596849665}, {"layer_params": [55, 36, 59], "learning_rate": 0.008976408286044108, "batch_size": 388, "loss": 0.0013187961501535028}, {"layer_params": [44, 36, 40, 22], "learning_rate": 0.001371921463498081, "batch_size": 475, "loss": 0.00202180300373584}, {"layer_params": [33, 43, 35, 61], "learning_rate": 0.0005492930838994268, "batch_size": 292, "loss": 0.004674545975867659}, {"layer_params": [28, 36, 58, 38], "learning_rate": 0.001633950252371506, "batch_size": 418, "loss": 0.0019586787396110596}, {"layer_params": [61, 59, 18], "learning_rate": 0.004249150615873378, "batch_size": 74, "loss": 0.0032867288356646894}, {"layer_params": [28, 21, 61], "learning_rate": 0.002254036761835977, "batch_size": 228, "loss": 0.0026419271237682553}, {"layer_params": [45, 42, 23, 22, 17], "learning_rate": 0.006542532125549616, "batch_size": 36, "loss": 0.00679020568029955}, {"layer_params": [59, 64, 52], "learning_rate": 0.006485353526291251, "batch_size": 379, "loss": 0.0006346359482267872}, {"layer_params": [17, 18], "learning_rate": 0.0071179420153838595, "batch_size": 173, "loss": 0.006380397486500442}, {"layer_params": [45, 38, 56], "learning_rate": 0.0011001440246170733, "batch_size": 307, "loss": 0.0037750974809750916}, {"layer_params": [29, 25], "learning_rate": 0.008186645093951691, "batch_size": 48, "loss": 0.005719113829545677}, {"layer_params": [38, 52, 29, 51, 43], "learning_rate": 0.006693907592563756, "batch_size": 351, "loss": 0.0019466820324305445}, {"layer_params": [27, 48, 44, 21, 24], "learning_rate": 0.004328734338902445, "batch_size": 462, "loss": 0.0016672383109107613}, {"layer_params": [60, 32], "learning_rate": 0.009221197122269932, "batch_size": 398, "loss": 0.0011255329311825335}, {"layer_params": [57, 41, 49, 38], "learning_rate": 0.007822607925427334, "batch_size": 467, "loss": 0.0015414839354343712}, {"layer_params": [25, 49, 34, 22], "learning_rate": 0.0066705351930174935, "batch_size": 313, "loss": 0.0035864321584813297}, {"layer_params": [60, 39], "learning_rate": 0.009994916222895995, "batch_size": 385, "loss": 0.0011085245182039217}, {"layer_params": [22, 34, 28, 58], "learning_rate": 0.003965976674469132, "batch_size": 381, "loss": 0.002703448347747326}, {"layer_params": [43, 36, 63, 54, 28], "learning_rate": 0.009754663804606342, "batch_size": 192, "loss": 0.002145184932742268}, {"layer_params": [37, 38, 51, 37, 22], "learning_rate": 0.0034156153139478494, "batch_size": 488, "loss": 0.001261113696382381}, {"layer_params": [50, 24, 23, 59], "learning_rate": 0.006285272025063197, "batch_size": 244, "loss": 0.002337655248120427}, {"layer_params": [59, 29, 48, 22, 57], "learning_rate": 0.0018559677034377668, "batch_size": 160, "loss": 0.00258567281649448}, {"layer_params": [57, 26, 18], "learning_rate": 0.00016876881646641343, "batch_size": 17, "loss": 0.01920866363681853}, {"layer_params": [31, 28, 44, 27], "learning_rate": 0.004713984347113558, "batch_size": 247, "loss": 0.0029962840559892355}, {"layer_params": [64, 44, 41], "learning_rate": 0.0019233016518700285, "batch_size": 445, "loss": 0.00125414245063439}, {"layer_params": [48, 63, 36], "learning_rate": 0.00706386434359358, "batch_size": 450, "loss": 0.001110076563199982}, {"layer_params": [55, 57, 37, 61, 56], "learning_rate": 0.008164643028833343, "batch_size": 197, "loss": 0.0010660876950714738}, {"layer_params": [17, 40, 34], "learning_rate": 0.006089162826295706, "batch_size": 357, "loss": 0.005014426466077566}, {"layer_params": [22, 23, 50], "learning_rate": 0.009906278451570997, "batch_size": 90, "loss": 0.003355154942255467}, {"layer_params": [16, 54, 50, 48, 38], "learning_rate": 0.006750771977827901, "batch_size": 91, "loss": 0.005958405053243041}, {"layer_params": [27, 36, 62], "learning_rate": 0.0038664393349174173, "batch_size": 258, "loss": 0.0021806785173248498}, {"layer_params": [27, 35, 47], "learning_rate": 0.008156785814902968, "batch_size": 394, "loss": 0.001858238277491182}, {"layer_params": [62, 49, 45, 34], "learning_rate": 0.0025346495014737253, "batch_size": 283, "loss": 0.0010236500267637894}, {"layer_params": [23, 44, 41, 20], "learning_rate": 0.000688176902453054, "batch_size": 218, "loss": 0.006169394161552191}, {"layer_params": [24, 19, 46], "learning_rate": 0.00904289668487676, "batch_size": 228, "loss": 0.00386259859893471}, {"layer_params": [30, 42, 22], "learning_rate": 0.002267847602689013, "batch_size": 34, "loss": 0.006789842604193836}, {"layer_params": [52, 19, 27, 57], "learning_rate": 0.009950806687493681, "batch_size": 154, "loss": 0.0026109773048665374}, {"layer_params": [23, 27, 27, 32], "learning_rate": 0.007572636446780931, "batch_size": 490, "loss": 0.0022506695555057376}, {"layer_params": [39, 34, 50], "learning_rate": 0.006756048699316516, "batch_size": 276, "loss": 0.002655560220591724}, {"layer_params": [31, 57, 50, 34], "learning_rate": 0.0005154701498608831, "batch_size": 106, "loss": 0.00616400578757748}, {"layer_params": [58, 45], "learning_rate": 0.00047324847085436283, "batch_size": 42, "loss": 0.00796623342204839}, {"layer_params": [43, 48, 41, 33], "learning_rate": 0.0013422044235502808, "batch_size": 255, "loss": 0.002791253635659814}, {"layer_params": [27, 35], "learning_rate": 0.00697292431350055, "batch_size": 360, "loss": 0.0027625348581932483}, {"layer_params": [51, 50, 60, 54], "learning_rate": 0.0036513265023459403, "batch_size": 99, "loss": 0.0021389761206228285}, {"layer_params": [45, 50], "learning_rate": 0.0037044202151894578, "batch_size": 181, "loss": 0.001450495095923543}, {"layer_params": [33, 34, 28, 19], "learning_rate": 0.0045173274843707265, "batch_size": 506, "loss": 0.0019070694129914045}, {"layer_params": [23, 44, 30, 61], "learning_rate": 0.004892040321405601, "batch_size": 74, "loss": 0.0035886652045883237}, {"layer_params": [41, 39], "learning_rate": 0.008974356482612121, "batch_size": 417, "loss": 0.0011500440473901107}, {"layer_params": [62, 37, 55, 47, 44], "learning_rate": 0.0032198248608521518, "batch_size": 478, "loss": 0.0014608847245108337}, {"layer_params": [41, 19, 17, 37, 42], "learning_rate": 0.002480814626997645, "batch_size": 155, "loss": 0.003872853140346706}, {"layer_params": [18, 38, 41, 17], "learning_rate": 0.005502841051967411, "batch_size": 88, "loss": 0.003663077647797763}, {"layer_params": [20, 25, 24], "learning_rate": 0.0014964892614675643, "batch_size": 43, "loss": 0.008408574052155018}, {"layer_params": [21, 52], "learning_rate": 0.006735416514113863, "batch_size": 112, "loss": 0.004055223504547029}, {"layer_params": [36, 36], "learning_rate": 0.005375576649547853, "batch_size": 113, "loss": 0.0033258005976676943}, {"layer_params": [22, 56, 57], "learning_rate": 0.00021505313309261366, "batch_size": 492, "loss": 0.006922602988779545}, {"layer_params": [57, 55, 36, 63], "learning_rate": 0.001380921313003867, "batch_size": 288, "loss": 0.0013969266379717737}, {"layer_params": [21, 27, 20, 64, 16], "learning_rate": 0.00013965643996848227, "batch_size": 273, "loss": 0.01854719091206789}, {"layer_params": [29, 60], "learning_rate": 0.006953396919590869, "batch_size": 210, "loss": 0.0018027803453151137}, {"layer_params": [44, 40, 48, 30], "learning_rate": 0.009042257514350196, "batch_size": 280, "loss": 0.0018864617019426079}, {"layer_params": [34, 38], "learning_rate": 0.005352827864962419, "batch_size": 147, "loss": 0.003171188281849027}, {"layer_params": [41, 57, 31], "learning_rate": 0.009794597698006854, "batch_size": 256, "loss": 0.0013752007915172725}, {"layer_params": [47, 55, 26, 17], "learning_rate": 0.0010962960735694275, "batch_size": 458, "loss": 0.00266182025661692}, {"layer_params": [28, 24, 47], "learning_rate": 0.001118495765677276, "batch_size": 371, "loss": 0.006681618331931531}, {"layer_params": [59, 18, 32, 64, 44], "learning_rate": 0.0035219087999638085, "batch_size": 165, "loss": 0.00288995657581836}, {"layer_params": [49, 39, 21, 37, 34], "learning_rate": 0.0003564400790926884, "batch_size": 206, "loss": 0.00803532422054559}, {"layer_params": [54, 37], "learning_rate": 0.0018361829478847809, "batch_size": 77, "loss": 0.003988354066386819}, {"layer_params": [27, 20], "learning_rate": 0.0061580190312172135, "batch_size": 475, "loss": 0.002069477727636695}, {"layer_params": [47, 27], "learning_rate": 0.0017243548409484855, "batch_size": 35, "loss": 0.006062532900832593}, {"layer_params": [43, 22], "learning_rate": 0.001546085983111052, "batch_size": 132, "loss": 0.004246442322619259}, {"layer_params": [47, 47, 32, 57, 51], "learning_rate": 0.0029090298713524707, "batch_size": 128, "loss": 0.0028999143093824385}, {"layer_params": [63, 36, 26, 50], "learning_rate": 0.006296592248996929, "batch_size": 269, "loss": 0.0016903970530256628}, {"layer_params": [50, 28, 26, 18], "learning_rate": 0.007204624160443303, "batch_size": 420, "loss": 0.0009311236516805365}, {"layer_params": [16, 57, 49], "learning_rate": 0.0020383061430454376, "batch_size": 174, "loss": 0.002635405161418021}, {"layer_params": [54, 49, 33], "learning_rate": 0.004900528699448482, "batch_size": 445, "loss": 0.001047152745886706}, {"layer_params": [58, 27], "learning_rate": 0.007471920139517391, "batch_size": 27, "loss": 0.003727067522704601}, {"layer_params": [27, 61, 19, 18, 54], "learning_rate": 0.007263596268103575, "batch_size": 160, "loss": 0.002683798529906198}, {"layer_params": [33, 58, 39, 22, 29], "learning_rate": 0.009202498381971224, "batch_size": 113, "loss": 0.0019319081236608326}, {"layer_params": [34, 64, 45, 17, 63], "learning_rate": 0.006027974267390332, "batch_size": 325, "loss": 0.0014710574632044882}, {"layer_params": [41, 20, 20, 24], "learning_rate": 0.0016109590893935062, "batch_size": 26, "loss": 0.00758067469112575}, {"layer_params": [33, 34, 41], "learning_rate": 0.0036748128715537393, "batch_size": 204, "loss": 0.0016571863426361232}, {"layer_params": [61, 16, 26, 32], "learning_rate": 0.0034575568657080414, "batch_size": 177, "loss": 0.0028182128979824484}, {"layer_params": [36, 17, 20, 54, 25], "learning_rate": 0.006153882920866194, "batch_size": 314, "loss": 0.0038102563726715743}, {"layer_params": [41, 52, 42, 37], "learning_rate": 0.004051955548962789, "batch_size": 378, "loss": 0.0013894664240069686}, {"layer_params": [56, 23], "learning_rate": 0.006962898746934954, "batch_size": 360, "loss": 0.0015832730603870004}, {"layer_params": [33, 23], "learning_rate": 0.0007718584538882469, "batch_size": 376, "loss": 0.0058650373201817275}, {"layer_params": [39, 51, 22], "learning_rate": 0.0035623918058031584, "batch_size": 178, "loss": 0.0019206986820790918}, {"layer_params": [56, 54], "learning_rate": 0.0014745924902915596, "batch_size": 291, "loss": 0.0025794411706738176}, {"layer_params": [19, 42, 29, 61], "learning_rate": 0.002144501672610314, "batch_size": 304, "loss": 0.003566429386846721}, {"layer_params": [47, 28], "learning_rate": 0.006402455244324322, "batch_size": 61, "loss": 0.002925218892050907}, {"layer_params": [18, 48, 37, 19, 37], "learning_rate": 0.003866582665625402, "batch_size": 481, "loss": 0.001470814875792712}, {"layer_params": [53, 52], "learning_rate": 0.0003353040993484936, "batch_size": 145, "loss": 0.007015994950197637}, {"layer_params": [44, 52, 46], "learning_rate": 0.0014461059907327225, "batch_size": 133, "loss": 0.0038053911575116218}, {"layer_params": [25, 47, 48], "learning_rate": 0.009038705079314943, "batch_size": 258, "loss": 0.003081958582624793}, {"layer_params": [50, 16, 20, 44, 56], "learning_rate": 0.0034638987033282663, "batch_size": 226, "loss": 0.0024079868569970133}, {"layer_params": [60, 22, 43], "learning_rate": 0.005501146323185604, "batch_size": 208, "loss": 0.0024742825981229543}, {"layer_params": [54, 44], "learning_rate": 0.0028783243970667274, "batch_size": 451, "loss": 0.0021182243153452874}, {"layer_params": [61, 36, 20, 51, 63], "learning_rate": 0.0012381883646685147, "batch_size": 504, "loss": 0.002478387006558478}, {"layer_params": [47, 17], "learning_rate": 0.0009497103241061087, "batch_size": 109, "loss": 0.0068293545208871365}, {"layer_params": [39, 21, 38, 54, 23], "learning_rate": 0.004924265598143683, "batch_size": 141, "loss": 0.002543986887903884}, {"layer_params": [48, 35, 39, 49, 60], "learning_rate": 0.008722862568075338, "batch_size": 264, "loss": 0.001603928275872022}, {"layer_params": [64, 63], "learning_rate": 0.006857716395938942, "batch_size": 246, "loss": 0.0012521130917593837}, {"layer_params": [35, 29, 22], "learning_rate": 0.009663831750246087, "batch_size": 130, "loss": 0.002553204381838441}, {"layer_params": [57, 16, 43, 24, 64], "learning_rate": 0.008853093846257758, "batch_size": 297, "loss": 0.0017677458887919784}, {"layer_params": [49, 46], "learning_rate": 0.008912905365418989, "batch_size": 183, "loss": 0.0014940887968987225}, {"layer_params": [45, 57], "learning_rate": 0.0031531692147854884, "batch_size": 256, "loss": 0.0017566504899878055}, {"layer_params": [34, 48, 30, 62, 49], "learning_rate": 0.003748703131568611, "batch_size": 490, "loss": 0.000985374795855023}, {"layer_params": [16, 39], "learning_rate": 0.0005689287708184422, "batch_size": 68, "loss": 0.009375964514911175}, {"layer_params": [20, 54, 44, 49, 60], "learning_rate": 0.007600193987561401, "batch_size": 159, "loss": 0.00260081650223583}, {"layer_params": [57, 39, 39, 21], "learning_rate": 0.006804387925071849, "batch_size": 157, "loss": 0.0016835648636333645}, {"layer_params": [64, 31, 26, 57], "learning_rate": 0.009399659939392313, "batch_size": 40, "loss": 0.0029871028708294035}, {"layer_params": [56, 58, 39, 51], "learning_rate": 0.0006561490660537553, "batch_size": 208, "loss": 0.0023425796127412466}, {"layer_params": [24, 62, 18], "learning_rate": 0.004663606924631168, "batch_size": 66, "loss": 0.004002188188023865}, {"layer_params": [36, 43, 21, 63], "learning_rate": 0.007054967050970738, "batch_size": 159, "loss": 0.002186127578606829}, {"layer_params": [53, 17], "learning_rate": 0.004692829903494491, "batch_size": 126, "loss": 0.0037330244667828083}, {"layer_params": [16, 47, 50], "learning_rate": 0.005764707407735542, "batch_size": 128, "loss": 0.004109416846185923}, {"layer_params": [52, 32, 16], "learning_rate": 0.004717526056652828, "batch_size": 332, "loss": 0.0011630745028378441}, {"layer_params": [61, 34], "learning_rate": 0.000693364717805991, "batch_size": 161, "loss": 0.0069272851198911665}, {"layer_params": [50, 59], "learning_rate": 0.00565874027837992, "batch_size": 460, "loss": 0.0014919502509292215}, {"layer_params": [56, 55, 19], "learning_rate": 0.0029039399408776773, "batch_size": 415, "loss": 0.0019636897277086974}, {"layer_params": [47, 18, 45, 37], "learning_rate": 0.004275032770394581, "batch_size": 310, "loss": 0.00143366030883044}, {"layer_params": [18, 44, 23, 39], "learning_rate": 0.0012364223788951492, "batch_size": 151, "loss": 0.004995661198627203}, {"layer_params": [46, 62, 42, 63], "learning_rate": 0.0007677731674374543, "batch_size": 82, "loss": 0.0040653181145899}, {"layer_params": [37, 50], "learning_rate": 0.006544419122953073, "batch_size": 460, "loss": 0.0015737739577889442}, {"layer_params": [18, 51], "learning_rate": 0.005178021772624186, "batch_size": 182, "loss": 0.002750120919663459}, {"layer_params": [50, 28, 23, 56, 29], "learning_rate": 0.002586376029772788, "batch_size": 30, "loss": 0.005502766098361462}, {"layer_params": [53, 59, 62], "learning_rate": 0.006230142868306415, "batch_size": 108, "loss": 0.0018059434043243528}, {"layer_params": [64, 55], "learning_rate": 0.0004021824192036717, "batch_size": 382, "loss": 0.00579350461717695}, {"layer_params": [42, 33, 31], "learning_rate": 0.00661293813133952, "batch_size": 449, "loss": 0.0024539355793967844}, {"layer_params": [24, 52, 19, 56], "learning_rate": 0.00045611264117519584, "batch_size": 287, "loss": 0.006109197307378054}, {"layer_params": [35, 42, 49, 49, 38], "learning_rate": 0.007508663701127803, "batch_size": 338, "loss": 0.001535689003067091}, {"layer_params": [43, 36, 33, 44, 20], "learning_rate": 0.006014547854033328, "batch_size": 503, "loss": 0.0012189048662548884}, {"layer_params": [47, 61], "learning_rate": 0.004567122113870014, "batch_size": 500, "loss": 0.001897442190675065}, {"layer_params": [52, 25, 61], "learning_rate": 0.005158278250261287, "batch_size": 476, "loss": 0.001830178862437606}, {"layer_params": [25, 59, 36, 38, 26], "learning_rate": 0.004331820956466952, "batch_size": 475, "loss": 0.002076347809052095}, {"layer_params": [18, 57, 17, 62], "learning_rate": 0.009284615393070657, "batch_size": 61, "loss": 0.004908063802868128}, {"layer_params": [36, 18, 43], "learning_rate": 0.0023167318053509806, "batch_size": 251, "loss": 0.003192046626936644}, {"layer_params": [37, 41, 29, 48], "learning_rate": 0.0005398740925478946, "batch_size": 246, "loss": 0.005728807742707431}, {"layer_params": [49, 35, 49], "learning_rate": 0.0033626850161383487, "batch_size": 82, "loss": 0.0024280581658240406}, {"layer_params": [21, 48, 41, 58, 47], "learning_rate": 0.004082098929060198, "batch_size": 509, "loss": 0.0010203439259203152}, {"layer_params": [58, 37, 36, 24, 63], "learning_rate": 0.00948664706501873, "batch_size": 309, "loss": 0.001079408364603296}, {"layer_params": [61, 61], "learning_rate": 0.002271924672820954, "batch_size": 163, "loss": 0.0020089147263206543}, {"layer_params": [29, 33, 44, 50, 45], "learning_rate": 0.0002899312936274312, "batch_size": 181, "loss": 0.00711861526593566}, {"layer_params": [35, 33], "learning_rate": 0.005251761343223538, "batch_size": 384, "loss": 0.0013698444538749754}, {"layer_params": [40, 48], "learning_rate": 0.004537433774353622, "batch_size": 387, "loss": 0.002393421058077365}, {"layer_params": [36, 54, 32, 32, 47], "learning_rate": 0.005973499049627239, "batch_size": 320, "loss": 0.0009996233048150316}, {"layer_params": [27, 51], "learning_rate": 0.0070449803163193875, "batch_size": 348, "loss": 0.0019484227767679841}, {"layer_params": [37, 34, 37, 22, 27], "learning_rate": 0.004795099806026951, "batch_size": 234, "loss": 0.0017776321212295443}, {"layer_params": [38, 56], "learning_rate": 0.002156258820778711, "batch_size": 314, "loss": 0.0018856887228321283}, {"layer_params": [21, 40], "learning_rate": 0.0012472244574029522, "batch_size": 287, "loss": 0.00656546728219837}, {"layer_params": [34, 43], "learning_rate": 0.009054115787013463, "batch_size": 23, "loss": 0.007144471963401884}, {"layer_params": [64, 57], "learning_rate": 0.0001966788716181095, "batch_size": 179, "loss": 0.009112890237011015}, {"layer_params": [22, 61, 56], "learning_rate": 0.0033334172746520003, "batch_size": 443, "loss": 0.0019967800262384117}, {"layer_params": [34, 18], "learning_rate": 0.0020908363587525767, "batch_size": 386, "loss": 0.004391891623381525}, {"layer_params": [44, 29], "learning_rate": 0.0015502640904248434, "batch_size": 289, "loss": 0.0031286204606294633}, {"layer_params": [45, 25, 36], "learning_rate": 0.004030353799259031, "batch_size": 467, "loss": 0.001861762470798567}, {"layer_params": [56, 52, 59, 59, 29], "learning_rate": 0.006011600622750614, "batch_size": 36, "loss": 0.0040496155002620075}, {"layer_params": [62, 62, 29, 21, 56], "learning_rate": 0.008536210827865248, "batch_size": 256, "loss": 0.0010235878499224782}, {"layer_params": [40, 36, 20], "learning_rate": 0.009368311959369859, "batch_size": 125, "loss": 0.00327036876231432}, {"layer_params": [45, 20], "learning_rate": 0.004226238211662608, "batch_size": 297, "loss": 0.0038272886048071088}, {"layer_params": [64, 35, 31, 56, 37], "learning_rate": 0.003304025578828434, "batch_size": 432, "loss": 0.0018400161783210932}, {"layer_params": [55, 36, 35], "learning_rate": 0.0030936773502801235, "batch_size": 259, "loss": 0.0017666138522326946}, {"layer_params": [46, 49, 48, 44, 44], "learning_rate": 0.004062929221222577, "batch_size": 386, "loss": 0.001308451622026041}, {"layer_params": [20, 42], "learning_rate": 0.00578707637490247, "batch_size": 416, "loss": 0.0037711984640918673}, {"layer_params": [53, 21, 26], "learning_rate": 0.005919130844576525, "batch_size": 301, "loss": 0.002246526413364336}, {"layer_params": [45, 61], "learning_rate": 0.008417295110153876, "batch_size": 492, "loss": 0.0011093846545554697}, {"layer_params": [58, 18, 37, 36], "learning_rate": 0.005605004523980175, "batch_size": 145, "loss": 0.003015736227389425}, {"layer_params": [53, 27], "learning_rate": 0.001735502701576525, "batch_size": 416, "loss": 0.0028592031309381126}, {"layer_params": [27, 49, 30, 17, 36], "learning_rate": 0.0009864589996754747, "batch_size": 352, "loss": 0.0032249327539466324}, {"layer_params": [30, 42, 50, 20], "learning_rate": 0.008001459798818328, "batch_size": 361, "loss": 0.0018199464061763137}, {"layer_params": [16, 47], "learning_rate": 0.0014324395274907416, "batch_size": 153, "loss": 0.005917810103856027}, {"layer_params": [59, 60, 47, 18, 32], "learning_rate": 0.003101822897051915, "batch_size": 49, "loss": 0.0027654730854555967}, {"layer_params": [28, 56, 21, 34, 47], "learning_rate": 0.00119931268172453, "batch_size": 204, "loss": 0.0040838076011277735}, {"layer_params": [56, 58, 32, 25], "learning_rate": 0.0026215094860021376, "batch_size": 365, "loss": 0.001183143894886598}, {"layer_params": [61, 50, 22], "learning_rate": 0.001161513875156141, "batch_size": 430, "loss": 0.0023203029681462795}, {"layer_params": [39, 23], "learning_rate": 0.00022817005616119685, "batch_size": 17, "loss": 0.020085487831383943}, {"layer_params": [60, 60], "learning_rate": 0.006283721757773549, "batch_size": 482, "loss": 0.0015526572533417493}, {"layer_params": [61, 44, 46, 18, 49], "learning_rate": 0.004909062342489098, "batch_size": 185, "loss": 0.0018361657194327563}, {"layer_params": [35, 64], "learning_rate": 0.002951543924211424, "batch_size": 378, "loss": 0.0024622150673530995}, {"layer_params": [56, 41, 16, 30, 18], "learning_rate": 0.007001310264853707, "batch_size": 26, "loss": 0.00876738021383062}, {"layer_params": [27, 29, 64], "learning_rate": 0.0011655432365375432, "batch_size": 122, "loss": 0.005341267506591976}, {"layer_params": [27, 40, 46, 27], "learning_rate": 0.002453547899385281, "batch_size": 165, "loss": 0.0029507588385604324}, {"layer_params": [33, 24], "learning_rate": 0.003999360764431169, "batch_size": 510, "loss": 0.0038834349624812603}, {"layer_params": [34, 48, 28, 53], "learning_rate": 0.008289753189430692, "batch_size": 65, "loss": 0.003676558913430199}, {"layer_params": [61, 26, 33, 28, 35], "learning_rate": 0.004016564922864442, "batch_size": 37, "loss": 0.005014189390931278}, {"layer_params": [46, 22, 31, 45, 63], "learning_rate": 0.0044887337383328185, "batch_size": 352, "loss": 0.0018074730748776347}, {"layer_params": [64, 54, 16], "learning_rate": 0.00954281362279393, "batch_size": 393, "loss": 0.0025079034781083464}, {"layer_params": [54, 38, 33, 64], "learning_rate": 0.0032587054624536034, "batch_size": 61, "loss": 0.002861896922113374}, {"layer_params": [54, 30, 59, 34], "learning_rate": 0.0023834928010721744, "batch_size": 194, "loss": 0.0018380114040337503}, {"layer_params": [56, 25, 61, 44], "learning_rate": 0.00996532828923915, "batch_size": 453, "loss": 0.0026765862491447477}, {"layer_params": [50, 30, 58, 35], "learning_rate": 0.004183214828564578, "batch_size": 91, "loss": 0.004115109296981246}, {"layer_params": [49, 32, 53, 61, 63], "learning_rate": 0.0020494434061430495, "batch_size": 236, "loss": 0.0022778488299809397}, {"layer_params": [63, 44, 30, 46, 53], "learning_rate": 0.003002095199773624, "batch_size": 340, "loss": 0.0010994376713642851}, {"layer_params": [31, 36, 32, 59, 32], "learning_rate": 0.007189807535095729, "batch_size": 89, "loss": 0.002684297994710505}, {"layer_params": [16, 24, 42], "learning_rate": 0.00575221715672129, "batch_size": 116, "loss": 0.005973250702954829}, {"layer_params": [16, 46, 30, 61, 32], "learning_rate": 0.004215910879385927, "batch_size": 165, "loss": 0.003219563232269138}, {"layer_params": [50, 62], "learning_rate": 0.008037602986571095, "batch_size": 37, "loss": 0.003629292577970773}, {"layer_params": [31, 49, 58, 39], "learning_rate": 0.0007849200039197871, "batch_size": 116, "loss": 0.004093687334097922}, {"layer_params": [35, 16], "learning_rate": 0.0052458918622428664, "batch_size": 357, "loss": 0.004290289606433362}, {"layer_params": [45, 42, 41, 39, 20], "learning_rate": 0.009716971036020757, "batch_size": 99, "loss": 0.0021830390626564624}, {"layer_params": [28, 53, 43, 18], "learning_rate": 0.009244714532553749, "batch_size": 49, "loss": 0.004655644639860838}, {"layer_params": [31, 34, 54, 17], "learning_rate": 0.009975918644404605, "batch_size": 162, "loss": 0.0019158205820713192}, {"layer_params": [28, 44, 39, 48, 22], "learning_rate": 0.005770172127028177, "batch_size": 390, "loss": 0.0013007601455319673}, {"layer_params": [58, 29, 27, 21], "learning_rate": 0.0008093026872922764, "batch_size": 105, "loss": 0.004982815459370613}, {"layer_params": [62, 57], "learning_rate": 0.0014799042397090907, "batch_size": 112, "loss": 0.004203517520800233}, {"layer_params": [59, 52, 52, 45, 63], "learning_rate": 0.00605171618991825, "batch_size": 215, "loss": 0.0007843012045486831}, {"layer_params": [49, 41, 61], "learning_rate": 0.007768631960272593, "batch_size": 301, "loss": 0.0008141373179387301}, {"layer_params": [29, 17, 31], "learning_rate": 0.00865706192800888, "batch_size": 46, "loss": 0.003786701028002426}, {"layer_params": [49, 45, 27], "learning_rate": 0.004615225841418098, "batch_size": 309, "loss": 0.0023699357581790535}, {"layer_params": [34, 38, 62, 59, 27], "learning_rate": 0.0027140470011909304, "batch_size": 231, "loss": 0.0021872245124541223}, {"layer_params": [38, 58], "learning_rate": 0.00863056858519925, "batch_size": 477, "loss": 0.001930514619452879}, {"layer_params": [38, 32, 57], "learning_rate": 0.002051673200086831, "batch_size": 57, "loss": 0.005130092327017337}, {"layer_params": [50, 33, 21, 49], "learning_rate": 0.005381774155808558, "batch_size": 213, "loss": 0.0018525869748555123}, {"layer_params": [50, 24], "learning_rate": 8.563596734854601e-05, "batch_size": 93, "loss": 0.03751081747934222}, {"layer_params": [42, 38, 52, 54], "learning_rate": 0.008880725793447715, "batch_size": 259, "loss": 0.001860829791985452}, {"layer_params": [20, 52, 31, 23, 22], "learning_rate": 0.008452080930274384, "batch_size": 440, "loss": 0.0030545964324846862}, {"layer_params": [42, 48, 40, 54, 28], "learning_rate": 0.008517184756371048, "batch_size": 155, "loss": 0.001945673783775419}, {"layer_params": [24, 20, 41, 50, 56], "learning_rate": 0.004021976971637557, "batch_size": 472, "loss": 0.0017218718654476105}, {"layer_params": [40, 60, 62, 32, 28], "learning_rate": 0.001565036127374658, "batch_size": 332, "loss": 0.001664277360541746}, {"layer_params": [22, 26, 27, 62, 64], "learning_rate": 0.008692437176432408, "batch_size": 317, "loss": 0.0031688026641495527}, {"layer_params": [49, 26, 60, 19, 21], "learning_rate": 0.007999323164688259, "batch_size": 46, "loss": 0.0045995883014984425}, {"layer_params": [51, 19], "learning_rate": 0.005728653652060988, "batch_size": 80, "loss": 0.0024360789894126355}, {"layer_params": [49, 47, 44, 41, 59], "learning_rate": 0.0019567457900294015, "batch_size": 312, "loss": 0.001783927723299712}, {"layer_params": [53, 34, 35, 54], "learning_rate": 0.008058981349226713, "batch_size": 200, "loss": 0.0023712995368987324}, {"layer_params": [54, 50, 63, 31], "learning_rate": 0.00033047507249602193, "batch_size": 249, "loss": 0.004808190532494336}, {"layer_params": [62, 40, 39, 51], "learning_rate": 0.0032836306512805825, "batch_size": 49, "loss": 0.003592707049101591}, {"layer_params": [23, 34, 53, 45], "learning_rate": 0.003374032749594845, "batch_size": 466, "loss": 0.001563404401531443}, {"layer_params": [52, 37, 38, 32], "learning_rate": 0.0032920483864320917, "batch_size": 353, "loss": 0.001508808146463707}, {"layer_params": [22, 30], "learning_rate": 0.006156036953404604, "batch_size": 441, "loss": 0.003601501411758363}, {"layer_params": [55, 43, 44, 19, 47], "learning_rate": 0.002416841645905201, "batch_size": 485, "loss": 0.0017761745408643038}, {"layer_params": [35, 25, 64, 42], "learning_rate": 0.0006600589354425006, "batch_size": 201, "loss": 0.005342372190207243}, {"layer_params": [52, 59, 49, 57], "learning_rate": 0.0075744211763676865, "batch_size": 496, "loss": 0.0007737862085923552}, {"layer_params": [64, 38, 50, 59, 35], "learning_rate": 0.0007351577159425578, "batch_size": 323, "loss": 0.002642584757413715}, {"layer_params": [52, 32, 20], "learning_rate": 0.006452133430414626, "batch_size": 130, "loss": 0.002414601299678907}, {"layer_params": [39, 23, 60, 50], "learning_rate": 0.0039911780380575985, "batch_size": 225, "loss": 0.0034457620768807828}, {"layer_params": [63, 34, 39], "learning_rate": 0.004619332572206224, "batch_size": 193, "loss": 0.0011743766855215653}, {"layer_params": [44, 51, 23, 29, 26], "learning_rate": 0.006173598786064393, "batch_size": 126, "loss": 0.0026620593608822673}, {"layer_params": [24, 35, 18, 55, 50], "learning_rate": 0.004599670597112091, "batch_size": 497, "loss": 0.0018455965619068593}, {"layer_params": [31, 25, 18, 37, 48], "learning_rate": 0.0008061076675896056, "batch_size": 221, "loss": 0.005884690540842712}, {"layer_params": [44, 30, 23], "learning_rate": 0.00337395106591426, "batch_size": 354, "loss": 0.0026482862583361564}, {"layer_params": [59, 32, 37, 39], "learning_rate": 0.0005940373999514842, "batch_size": 417, "loss": 0.003798425819259137}, {"layer_params": [28, 63], "learning_rate": 0.0071586217363935785, "batch_size": 193, "loss": 0.002833744608797133}, {"layer_params": [52, 64, 27], "learning_rate": 0.007306927733929188, "batch_size": 323, "loss": 0.0013756418641423806}, {"layer_params": [27, 29, 34, 30], "learning_rate": 0.00011702076104139588, "batch_size": 305, "loss": 0.02390745796263218}, {"layer_params": [28, 57], "learning_rate": 0.009089554947801412, "batch_size": 447, "loss": 0.0018008709605783224}, {"layer_params": [49, 38, 20], "learning_rate": 0.008522370916422627, "batch_size": 230, "loss": 0.0010483798891073094}, {"layer_params": [28, 35, 16, 28], "learning_rate": 0.005770372958994554, "batch_size": 369, "loss": 0.0019216772704385222}, {"layer_params": [43, 64, 38, 24, 44], "learning_rate": 0.009384377352071066, "batch_size": 165, "loss": 0.0017639140377286823}, {"layer_params": [40, 63, 39, 21, 28], "learning_rate": 0.006796188675243959, "batch_size": 121, "loss": 0.001942675878526643}, {"layer_params": [35, 20, 22], "learning_rate": 0.005870043510160055, "batch_size": 413, "loss": 0.002693240020889789}, {"layer_params": [64, 26, 52], "learning_rate": 0.005639801103436755, "batch_size": 131, "loss": 0.0015870257001370193}, {"layer_params": [31, 47, 30, 21, 47], "learning_rate": 0.005843737320236495, "batch_size": 211, "loss": 0.0021903016546275466}, {"layer_params": [27, 29, 42, 23], "learning_rate": 0.007316745276733292, "batch_size": 206, "loss": 0.0025441811932250856}, {"layer_params": [37, 20], "learning_rate": 0.0032155779419021516, "batch_size": 178, "loss": 0.0036547133605927228}, {"layer_params": [33, 21, 36, 34, 38], "learning_rate": 0.008151089326461193, "batch_size": 438, "loss": 0.00431313561508432}, {"layer_params": [26, 46, 49, 27], "learning_rate": 0.0026006460819245625, "batch_size": 434, "loss": 0.0018412907328456641}, {"layer_params": [37, 23, 63, 44], "learning_rate": 0.006571278654260224, "batch_size": 293, "loss": 0.0017467919667251408}, {"layer_params": [33, 44, 55], "learning_rate": 0.007603691365684135, "batch_size": 40, "loss": 0.0051772376103326676}, {"layer_params": [64, 31, 26], "learning_rate": 0.007047571176358579, "batch_size": 84, "loss": 0.0033146092446986585}, {"layer_params": [17, 39, 19, 58, 44], "learning_rate": 0.0046717271340998125, "batch_size": 319, "loss": 0.002395654059946537}, {"layer_params": [57, 53, 43, 52, 64], "learning_rate": 0.005394902543774601, "batch_size": 329, "loss": 0.0011312029347755016}, {"layer_params": [20, 37, 51], "learning_rate": 0.001006033075875606, "batch_size": 240, "loss": 0.0060859365016222}, {"layer_params": [26, 63, 39, 22], "learning_rate": 0.0010996150869192315, "batch_size": 24, "loss": 0.008058442356996239}, {"layer_params": [20, 19, 58, 37, 31], "learning_rate": 0.0016010832847071466, "batch_size": 247, "loss": 0.0031262914161197843}, {"layer_params": [39, 28], "learning_rate": 0.0008245493683372481, "batch_size": 481, "loss": 0.00644780364818871}, {"layer_params": [32, 21], "learning_rate": 0.005798921121402429, "batch_size": 99, "loss": 0.004881992838345468}, {"layer_params": [63, 39, 35, 54, 56], "learning_rate": 0.008285863416271981, "batch_size": 43, "loss": 0.0031582434754818677}, {"layer_params": [59, 47, 17, 19, 59], "learning_rate": 0.009626367440179145, "batch_size": 464, "loss": 0.0009698721877066419}, {"layer_params": [45, 17, 23], "learning_rate": 0.00789598060639073, "batch_size": 507, "loss": 0.0015550174622330814}, {"layer_params": [31, 25, 27, 35], "learning_rate": 0.002183205335826312, "batch_size": 307, "loss": 0.003891540067270398}, {"layer_params": [60, 43], "learning_rate": 0.003122334781099823, "batch_size": 403, "loss": 0.00298491200665012}, {"layer_params": [39, 40, 41, 27, 41], "learning_rate": 0.007927769325035777, "batch_size": 482, "loss": 0.0016495086951181293}, {"layer_params": [22, 49, 56, 60, 56], "learning_rate": 0.009824146722362256, "batch_size": 486, "loss": 0.001482259170152247}, {"layer_params": [19, 57, 21, 30, 26], "learning_rate": 0.0066444246913473955, "batch_size": 415, "loss": 0.0020280437101610005}, {"layer_params": [37, 55, 57], "learning_rate": 0.005862935434987916, "batch_size": 36, "loss": 0.0044647303712554275}, {"layer_params": [22, 61], "learning_rate": 0.006285746827982937, "batch_size": 253, "loss": 0.0024156426871195435}, {"layer_params": [32, 16], "learning_rate": 0.0009912623596682938, "batch_size": 387, "loss": 0.007206160947680474}, {"layer_params": [18, 18, 43, 57, 46], "learning_rate": 0.009934024635762912, "batch_size": 175, "loss": 0.006823770366609096}, {"layer_params": [29, 60, 48, 46], "learning_rate": 0.0013144913125638829, "batch_size": 72, "loss": 0.0047398912697099145}, {"layer_params": [61, 45], "learning_rate": 0.004568251780840254, "batch_size": 420, "loss": 0.0013997901906259358}, {"layer_params": [21, 49, 61, 32, 54], "learning_rate": 0.003440620448074442, "batch_size": 144, "loss": 0.0027749534894246607}, {"layer_params": [26, 29, 25, 26], "learning_rate": 0.007535264904988098, "batch_size": 468, "loss": 0.001806009147549048}, {"layer_params": [32, 62, 20, 58, 53], "learning_rate": 0.006185440486398222, "batch_size": 208, "loss": 0.0017259207100141793}, {"layer_params": [57, 45], "learning_rate": 0.0036277244013836725, "batch_size": 252, "loss": 0.0020545850531198083}, {"layer_params": [45, 30, 42, 34, 16], "learning_rate": 0.001933939586420097, "batch_size": 264, "loss": 0.002628667380195111}, {"layer_params": [35, 26, 51], "learning_rate": 0.0036968716269828, "batch_size": 20, "loss": 0.0061068503232672815}, {"layer_params": [19, 30, 56], "learning_rate": 0.007950248310566259, "batch_size": 269, "loss": 0.0023542847333010287}, {"layer_params": [44, 17], "learning_rate": 0.00694023708011552, "batch_size": 313, "loss": 0.003234751292038709}, {"layer_params": [48, 46, 31], "learning_rate": 0.004609465148097086, "batch_size": 258, "loss": 0.0017605401563923805}, {"layer_params": [32, 34, 43, 28], "learning_rate": 0.006791786089388863, "batch_size": 446, "loss": 0.0014641683746594936}, {"layer_params": [43, 61, 49, 27, 59], "learning_rate": 0.0035862126976744704, "batch_size": 306, "loss": 0.001205135992495343}, {"layer_params": [54, 30], "learning_rate": 0.002401474843350024, "batch_size": 63, "loss": 0.004120606847573071}, {"layer_params": [25, 47], "learning_rate": 0.003435065029354594, "batch_size": 495, "loss": 0.0024350430350750683}, {"layer_params": [21, 61, 62, 40, 42], "learning_rate": 0.009909430335940163, "batch_size": 425, "loss": 0.0017829255200922489}, {"layer_params": [52, 26, 52], "learning_rate": 0.008346723111333394, "batch_size": 201, "loss": 0.0018253028567414731}, {"layer_params": [62, 42], "learning_rate": 0.003144382109678488, "batch_size": 427, "loss": 0.0012195850542047993}, {"layer_params": [64, 55, 17, 33], "learning_rate": 0.007690435078537837, "batch_size": 476, "loss": 0.0009896423341706395}, {"layer_params": [54, 25], "learning_rate": 0.009516494319708467, "batch_size": 360, "loss": 0.0014170889591332526}, {"layer_params": [49, 16], "learning_rate": 0.008527582564574351, "batch_size": 27, "loss": 0.007932062367908657}, {"layer_params": [52, 63, 34, 25, 64], "learning_rate": 0.0030226386743704343, "batch_size": 77, "loss": 0.002828497211448848}, {"layer_params": [41, 60, 24, 61, 58], "learning_rate": 0.00422678742762381, "batch_size": 36, "loss": 0.005006081310566515}, {"layer_params": [23, 24], "learning_rate": 0.0037050179168786348, "batch_size": 212, "loss": 0.0031806340627372263}, {"layer_params": [61, 19, 26, 26], "learning_rate": 0.0068123694189845315, "batch_size": 323, "loss": 0.0013883296097628771}, {"layer_params": [44, 18], "learning_rate": 0.004361268900630643, "batch_size": 102, "loss": 0.003405494466423988}, {"layer_params": [49, 45], "learning_rate": 0.009956322809573925, "batch_size": 443, "loss": 0.0021668979269452394}, {"layer_params": [33, 53, 57, 52, 46], "learning_rate": 0.007537427513717124, "batch_size": 228, "loss": 0.002056724326685071}, {"layer_params": [50, 33, 25, 33], "learning_rate": 0.007656288505003828, "batch_size": 230, "loss": 0.004002255038358271}, {"layer_params": [56, 63, 24], "learning_rate": 0.009066202794168301, "batch_size": 203, "loss": 0.0011582901346264406}, {"layer_params": [38, 39, 41, 50], "learning_rate": 0.006620038003982354, "batch_size": 45, "loss": 0.00509633107110858}, {"layer_params": [64, 59, 39, 57], "learning_rate": 0.0015715686050622572, "batch_size": 477, "loss": 0.001572865832131356}, {"layer_params": [27, 45], "learning_rate": 0.0009946425053582587, "batch_size": 116, "loss": 0.006212092670612037}, {"layer_params": [37, 31], "learning_rate": 0.007623148310550786, "batch_size": 257, "loss": 0.0027470371196977794}, {"layer_params": [41, 34, 31], "learning_rate": 0.0019525902683265163, "batch_size": 496, "loss": 0.0017242283921223133}, {"layer_params": [37, 17, 19, 38], "learning_rate": 0.0009752238478405799, "batch_size": 383, "loss": 0.0050912284338846805}, {"layer_params": [38, 22, 38, 56], "learning_rate": 0.0035555249379747526, "batch_size": 273, "loss": 0.003117850599810481}, {"layer_params": [51, 33, 41, 34], "learning_rate": 0.005583312537541382, "batch_size": 411, "loss": 0.0008382171229459345}, {"layer_params": [23, 27, 41], "learning_rate": 0.0021168094292575482, "batch_size": 507, "loss": 0.003222241576295346}, {"layer_params": [43, 42, 39, 20], "learning_rate": 0.007664701721605754, "batch_size": 230, "loss": 0.0017270919622387737}, {"layer_params": [29, 56, 49], "learning_rate": 0.0033750665470899483, "batch_size": 36, "loss": 0.00520468155387789}, {"layer_params": [40, 23], "learning_rate": 0.003888288580125229, "batch_size": 120, "loss": 0.003452225248329341}, {"layer_params": [55, 19, 16, 38, 63], "learning_rate": 0.001888186860354715, "batch_size": 243, "loss": 0.0037247815425507725}, {"layer_params": [63, 51], "learning_rate": 0.006707104730855263, "batch_size": 168, "loss": 0.0013463831803528592}, {"layer_params": [17, 47, 26], "learning_rate": 0.0070956653468039746, "batch_size": 389, "loss": 0.00475655791349709}, {"layer_params": [25, 64, 45, 63, 36], "learning_rate": 0.0006735005568115706, "batch_size": 251, "loss": 0.003159981786739081}, {"layer_params": [58, 40, 58, 57, 50], "learning_rate": 0.005744947047740732, "batch_size": 123, "loss": 0.0018144615227356554}, {"layer_params": [30, 57, 58], "learning_rate": 0.0013931455727882983, "batch_size": 399, "loss": 0.0029294016235508025}, {"layer_params": [57, 24], "learning_rate": 0.004524839423965588, "batch_size": 134, "loss": 0.003270124695263803}, {"layer_params": [62, 18, 42, 42, 53], "learning_rate": 0.005622688703409968, "batch_size": 458, "loss": 0.0021989873819984497}, {"layer_params": [22, 29, 49, 41], "learning_rate": 0.0028387537782828018, "batch_size": 303, "loss": 0.0024878946342505514}, {"layer_params": [60, 38], "learning_rate": 0.007189813014565547, "batch_size": 479, "loss": 0.0014080126909539103}, {"layer_params": [18, 43, 18, 56], "learning_rate": 0.007871094992210415, "batch_size": 33, "loss": 0.007097547634039074}, {"layer_params": [43, 22, 38], "learning_rate": 3.88678432473978e-05, "batch_size": 442, "loss": 0.038510276302695275}, {"layer_params": [49, 44, 62, 60, 39], "learning_rate": 5.734934506768167e-05, "batch_size": 470, "loss": 0.013753567170351744}, {"layer_params": [39, 55, 55], "learning_rate": 0.005583346027242217, "batch_size": 421, "loss": 0.0009326335421064869}, {"layer_params": [20, 22, 38, 39], "learning_rate": 0.008655211702895958, "batch_size": 489, "loss": 0.0028963328688405452}, {"layer_params": [54, 54, 57], "learning_rate": 0.000590863637192282, "batch_size": 462, "loss": 0.003328004125505686}, {"layer_params": [41, 59, 54], "learning_rate": 0.009890530249860108, "batch_size": 333, "loss": 0.001856922903098166}, {"layer_params": [59, 19, 37, 22], "learning_rate": 0.0015240578802695115, "batch_size": 321, "loss": 0.0034970298688858747}, {"layer_params": [23, 59, 34, 53], "learning_rate": 0.00022119386164219356, "batch_size": 497, "loss": 0.006741516161710024}, {"layer_params": [46, 18, 25], "learning_rate": 0.0051492501111827195, "batch_size": 486, "loss": 0.0020842971501406284}, {"layer_params": [40, 49], "learning_rate": 0.0029968678777259473, "batch_size": 197, "loss": 0.0022533733618911355}, {"layer_params": [28, 39, 44], "learning_rate": 0.00584671924313132, "batch_size": 452, "loss": 0.0014945092529524118}, {"layer_params": [18, 47], "learning_rate": 0.0012189972707710064, "batch_size": 318, "loss": 0.00634970405139029}, {"layer_params": [23, 42, 24, 19, 57], "learning_rate": 0.0013315839516103143, "batch_size": 220, "loss": 0.005623566373251379}, {"layer_params": [33, 58, 62], "learning_rate": 0.008599797522467227, "batch_size": 413, "loss": 0.0010585557512240483}, {"layer_params": [22, 30, 36], "learning_rate": 0.002344716612749805, "batch_size": 493, "loss": 0.0028078510379418733}, {"layer_params": [33, 31, 18], "learning_rate": 0.0014380722053817438, "batch_size": 377, "loss": 0.004431541301310063}, {"layer_params": [62, 59, 44, 49], "learning_rate": 0.0035866239040143835, "batch_size": 48, "loss": 0.0031857752369251102}, {"layer_params": [45, 55, 63, 24], "learning_rate": 0.0027486369063019923, "batch_size": 471, "loss": 0.001230054427869618}, {"layer_params": [20, 44, 34, 29, 61], "learning_rate": 0.002759673836366904, "batch_size": 27, "loss": 0.007091348934918642}, {"layer_params": [36, 20, 23, 64], "learning_rate": 0.0033403117129071624, "batch_size": 228, "loss": 0.003433876323979348}, {"layer_params": [25, 20, 23, 34, 56], "learning_rate": 0.007797346845357607, "batch_size": 28, "loss": 0.00787029852392152}, {"layer_params": [39, 36], "learning_rate": 0.0016166960761217668, "batch_size": 511, "loss": 0.0044480972434394065}, {"layer_params": [48, 27, 36, 46, 45], "learning_rate": 0.0022014992095360703, "batch_size": 230, "loss": 0.00274032871122472}, {"layer_params": [52, 30], "learning_rate": 0.006871222977865037, "batch_size": 441, "loss": 0.0027243374148383736}, {"layer_params": [46, 46, 25], "learning_rate": 0.009374063209010233, "batch_size": 378, "loss": 0.0014935924496967345}, {"layer_params": [58, 32, 52, 32, 27], "learning_rate": 0.005202179403638599, "batch_size": 174, "loss": 0.0017286249960307032}, {"layer_params": [41, 45, 31], "learning_rate": 0.005255074671368173, "batch_size": 183, "loss": 0.0027051761839538813}, {"layer_params": [54, 27, 47], "learning_rate": 0.0025700709710651595, "batch_size": 444, "loss": 0.0020566671481356026}, {"layer_params": [58, 50, 27], "learning_rate": 0.0034439892721679064, "batch_size": 377, "loss": 0.00247850047191605}, {"layer_params": [30, 50, 46, 64, 61], "learning_rate": 0.0006014122475068857, "batch_size": 370, "loss": 0.0058058507787063715}, {"layer_params": [34, 61], "learning_rate": 0.0010698031061754257, "batch_size": 148, "loss": 0.00702120613772422}, {"layer_params": [41, 23, 28, 44], "learning_rate": 0.0046637035418089145, "batch_size": 255, "loss": 0.0021547333197668196}, {"layer_params": [52, 41, 52, 58, 47], "learning_rate": 0.009089675461142385, "batch_size": 210, "loss": 0.0028453843691386284}, {"layer_params": [21, 23, 64], "learning_rate": 0.009720064975621653, "batch_size": 165, "loss": 0.004065392471384257}, {"layer_params": [53, 35, 39, 16, 26], "learning_rate": 0.0004929152876843988, "batch_size": 481, "loss": 0.005654381792992353}, {"layer_params": [19, 34, 18, 21], "learning_rate": 0.005135351322560639, "batch_size": 107, "loss": 0.005819023831281811}, {"layer_params": [64, 62], "learning_rate": 0.003702657489402877, "batch_size": 188, "loss": 0.0037168598058633508}, {"layer_params": [63, 45, 47], "learning_rate": 0.007656580910129246, "batch_size": 354, "loss": 0.0014031106641050428}, {"layer_params": [60, 49, 24], "learning_rate": 0.0034116638979105594, "batch_size": 221, "loss": 0.0018782962230034172}, {"layer_params": [21, 19, 45, 46], "learning_rate": 0.0066103478186387956, "batch_size": 344, "loss": 0.0037436307477764787}, {"layer_params": [18, 28, 47, 36, 20], "learning_rate": 0.0038248311911062054, "batch_size": 102, "loss": 0.0035930732963606717}, {"layer_params": [31, 18], "learning_rate": 0.004465476766253709, "batch_size": 466, "loss": 0.003635597643442452}, {"layer_params": [22, 42, 27, 47], "learning_rate": 0.006487410811417102, "batch_size": 86, "loss": 0.00414748061913997}, {"layer_params": [49, 29], "learning_rate": 0.006574586289241204, "batch_size": 442, "loss": 0.00304152324795723}, {"layer_params": [47, 45, 25, 24], "learning_rate": 0.003669257693653595, "batch_size": 233, "loss": 0.0015444196562748402}, {"layer_params": [41, 37, 57, 18], "learning_rate": 0.0004633547572026825, "batch_size": 450, "loss": 0.0051578141655772925}, {"layer_params": [25, 52, 48], "learning_rate": 0.008319387936648387, "batch_size": 45, "loss": 0.004939382500015199}, {"layer_params": [18, 43], "learning_rate": 0.005659888141049304, "batch_size": 488, "loss": 0.003080671359784901}, {"layer_params": [28, 23], "learning_rate": 0.0010390539511610497, "batch_size": 436, "loss": 0.007870159721933305}, {"layer_params": [55, 16], "learning_rate": 0.003194895757111225, "batch_size": 135, "loss": 0.004704896677285433}, {"layer_params": [52, 53, 30, 40], "learning_rate": 0.008433126766170721, "batch_size": 54, "loss": 0.0034625028306618333}, {"layer_params": [37, 53, 39, 63], "learning_rate": 0.008756181104537433, "batch_size": 195, "loss": 0.002561824566219002}, {"layer_params": [59, 54, 36, 50], "learning_rate": 0.0003894084874729272, "batch_size": 368, "loss": 0.0042812631209380924}, {"layer_params": [64, 62, 20], "learning_rate": 0.006496439746781922, "batch_size": 113, "loss": 0.0018893042451236398}, {"layer_params": [55, 17, 43], "learning_rate": 0.007400988591819258, "batch_size": 409, "loss": 0.0022903492068871855}, {"layer_params": [50, 33, 32], "learning_rate": 0.007244242122889642, "batch_size": 471, "loss": 0.001220174680929631}, {"layer_params": [39, 26, 20], "learning_rate": 0.002232598920013945, "batch_size": 268, "loss": 0.0038263911311514675}, {"layer_params": [33, 58, 46, 60, 42], "learning_rate": 0.008319997482950424, "batch_size": 435, "loss": 0.0011638720275368541}, {"layer_params": [50, 36], "learning_rate": 0.009380946127677302, "batch_size": 335, "loss": 0.0034012532141059638}, {"layer_params": [42, 22], "learning_rate": 0.0036650282791133052, "batch_size": 208, "loss": 0.0038839574344456196}, {"layer_params": [38, 53, 34, 18], "learning_rate": 0.007478272928428667, "batch_size": 371, "loss": 0.0013070514361606912}, {"layer_params": [48, 16, 43, 58, 63], "learning_rate": 0.0014914219845759487, "batch_size": 174, "loss": 0.003299602558836341}, {"layer_params": [32, 43, 38], "learning_rate": 0.007017034054051484, "batch_size": 82, "loss": 0.0030705923936329782}, {"layer_params": [18, 39, 42, 35], "learning_rate": 0.0063210218250964005, "batch_size": 234, "loss": 0.00270447529386729}, {"layer_params": [60, 54, 22, 21, 64], "learning_rate": 0.005281808497173684, "batch_size": 56, "loss": 0.004163251880090684}, {"layer_params": [20, 20, 22], "learning_rate": 0.009720798957444616, "batch_size": 314, "loss": 0.005954782073386014}, {"layer_params": [28, 37, 56, 52], "learning_rate": 0.0020342005830560716, "batch_size": 264, "loss": 0.0025073742866516114}, {"layer_params": [34, 22, 64, 23], "learning_rate": 0.004907320489008363, "batch_size": 52, "loss": 0.005096421032212675}, {"layer_params": [36, 19, 32, 30], "learning_rate": 0.006841721795188805, "batch_size": 179, "loss": 0.002690772123169154}, {"layer_params": [48, 62, 26, 64, 49], "learning_rate": 0.0006804979741158125, "batch_size": 195, "loss": 0.003940456639975309}, {"layer_params": [54, 63, 62, 26, 38], "learning_rate": 0.0016566483950547328, "batch_size": 212, "loss": 0.001595087512396276}, {"layer_params": [55, 43, 57, 26, 18], "learning_rate": 0.001519900365675647, "batch_size": 171, "loss": 0.0026621072413399813}, {"layer_params": [33, 26, 64, 29, 50], "learning_rate": 0.008640089015210992, "batch_size": 432, "loss": 0.0018005146645009517}, {"layer_params": [38, 46, 36], "learning_rate": 0.004539949151573995, "batch_size": 239, "loss": 0.0027280742023140193}, {"layer_params": [41, 44], "learning_rate": 0.004302158342282077, "batch_size": 426, "loss": 0.0028362692589871587}, {"layer_params": [34, 16, 47, 22], "learning_rate": 0.002443460656705724, "batch_size": 220, "loss": 0.004586098662111908}, {"layer_params": [25, 31, 60, 38, 34], "learning_rate": 0.0031154976509400467, "batch_size": 80, "loss": 0.003153864248888567}, {"layer_params": [62, 35, 39, 21, 16], "learning_rate": 0.0009968216970922346, "batch_size": 500, "loss": 0.001661409738007933}, {"layer_params": [57, 32, 44], "learning_rate": 0.00902559145895768, "batch_size": 362, "loss": 0.0009326625755056738}, {"layer_params": [46, 50], "learning_rate": 0.005201008254014773, "batch_size": 185, "loss": 0.00148451752087567}, {"layer_params": [62, 47], "learning_rate": 0.003340245511626481, "batch_size": 407, "loss": 0.0011946374451508746}, {"layer_params": [53, 61, 47, 23], "learning_rate": 0.0064598493007392, "batch_size": 48, "loss": 0.0036211251409258693}, {"layer_params": [33, 32, 19], "learning_rate": 0.0013203318856747901, "batch_size": 65, "loss": 0.007077805092558264}, {"layer_params": [23, 62, 25, 53], "learning_rate": 0.00033573478055409913, "batch_size": 482, "loss": 0.007010194626636803}, {"layer_params": [27, 64], "learning_rate": 0.006457201661142372, "batch_size": 153, "loss": 0.0027864436618983746}, {"layer_params": [26, 40, 24, 60], "learning_rate": 0.0011053471194656765, "batch_size": 222, "loss": 0.004621186524163931}, {"layer_params": [25, 33, 58, 19, 47], "learning_rate": 0.0006574702816272293, "batch_size": 365, "loss": 0.0043499239534139636}, {"layer_params": [50, 18], "learning_rate": 0.0078013729451163905, "batch_size": 354, "loss": 0.0016924541408661752}, {"layer_params": [58, 22, 59], "learning_rate": 0.003391490667352945, "batch_size": 403, "loss": 0.0021035956835839895}, {"layer_params": [44, 46, 34, 60], "learning_rate": 0.008841324704055614, "batch_size": 473, "loss": 0.0010720777790993452}, {"layer_params": [57, 52], "learning_rate": 0.005342899975725991, "batch_size": 226, "loss": 0.001051745624281466}, {"layer_params": [63, 31], "learning_rate": 0.00029985875448310806, "batch_size": 112, "loss": 0.007115045618265867}, {"layer_params": [16, 40], "learning_rate": 0.0013796026555430785, "batch_size": 183, "loss": 0.0065322532365098595}, {"layer_params": [30, 34, 50, 56], "learning_rate": 0.008298433680785162, "batch_size": 477, "loss": 0.001451464556157589}, {"layer_params": [38, 31], "learning_rate": 0.009458415967480401, "batch_size": 463, "loss": 0.00118163516104687}, {"layer_params": [60, 61, 64, 22, 24], "learning_rate": 0.0018054523085620318, "batch_size": 192, "loss": 0.0014228193508461118}, {"layer_params": [46, 41, 41], "learning_rate": 0.008146277269758332, "batch_size": 203, "loss": 0.001918104401556775}, {"layer_params": [62, 62, 29, 63], "learning_rate": 0.00040147433504849673, "batch_size": 454, "loss": 0.0032131540798582135}, {"layer_params": [58, 48, 31, 63, 26], "learning_rate": 0.006127663518630429, "batch_size": 298, "loss": 0.0009901898534735664}, {"layer_params": [56, 29, 17], "learning_rate": 0.009860414822025251, "batch_size": 297, "loss": 0.0013848113978747279}, {"layer_params": [50, 55, 25], "learning_rate": 0.007627797600116053, "batch_size": 509, "loss": 0.0012578426871914417}, {"layer_params": [30, 61], "learning_rate": 0.009561964617506292, "batch_size": 463, "loss": 0.0010324474517256022}, {"layer_params": [38, 16, 33, 22, 62], "learning_rate": 0.007202332383595125, "batch_size": 379, "loss": 0.002319798582466319}, {"layer_params": [58, 50], "learning_rate": 0.0003478885676187336, "batch_size": 175, "loss": 0.007728022346273064}, {"layer_params": [26, 58], "learning_rate": 0.007101876286415556, "batch_size": 466, "loss": 0.0012982070725411177}, {"layer_params": [53, 18, 34, 43, 62], "learning_rate": 7.11792529132646e-05, "batch_size": 504, "loss": 0.022821471802890302}, {"layer_params": [22, 34, 51, 37, 34], "learning_rate": 0.0021487116063683355, "batch_size": 257, "loss": 0.0049480428919196125}, {"layer_params": [16, 57], "learning_rate": 0.0003990460879118013, "batch_size": 147, "loss": 0.008787179971113801}, {"layer_params": [18, 53], "learning_rate": 0.009877001955240008, "batch_size": 332, "loss": 0.0018767831043805926}, {"layer_params": [36, 56, 34], "learning_rate": 0.003796248118269481, "batch_size": 209, "loss": 0.0022812749864533546}, {"layer_params": [54, 54], "learning_rate": 0.005719666823159274, "batch_size": 222, "loss": 0.0020438970462419094}, {"layer_params": [37, 60, 31, 55], "learning_rate": 0.007891877894822829, "batch_size": 134, "loss": 0.0026223386137280615}, {"layer_params": [17, 58, 47], "learning_rate": 0.0010898269215199343, "batch_size": 436, "loss": 0.004420662701595575}, {"layer_params": [44, 36, 25, 37], "learning_rate": 0.008032597541219674, "batch_size": 209, "loss": 0.00205428916728124}, {"layer_params": [51, 20, 40], "learning_rate": 0.0023599445360375005, "batch_size": 315, "loss": 0.002830783543176949}, {"layer_params": [51, 57, 47], "learning_rate": 0.008552101625456691, "batch_size": 161, "loss": 0.0014116174587979913}, {"layer_params": [33, 17, 55, 17, 46], "learning_rate": 0.005467404860400256, "batch_size": 505, "loss": 0.002322829986223951}, {"layer_params": [52, 53], "learning_rate": 0.008722826273939189, "batch_size": 221, "loss": 0.0014669048902578653}, {"layer_params": [52, 61, 36, 47, 64], "learning_rate": 0.007781826331289481, "batch_size": 28, "loss": 0.006552828766871244}, {"layer_params": [32, 56, 48, 43], "learning_rate": 0.002173122312253504, "batch_size": 416, "loss": 0.00227670940104872}, {"layer_params": [23, 55, 43], "learning_rate": 0.00796388738212009, "batch_size": 32, "loss": 0.00733797701774165}, {"layer_params": [35, 43], "learning_rate": 0.002566371071494978, "batch_size": 118, "loss": 0.004810753774363547}, {"layer_params": [51, 52, 53, 48], "learning_rate": 0.0008515216444976096, "batch_size": 18, "loss": 0.008078439160017296}, {"layer_params": [33, 29, 18], "learning_rate": 0.0006036319982000766, "batch_size": 101, "loss": 0.00664782336447388}, {"layer_params": [32, 24], "learning_rate": 0.0039960924408451405, "batch_size": 330, "loss": 0.004398739135358483}, {"layer_params": [41, 24, 57], "learning_rate": 0.009333797273698121, "batch_size": 500, "loss": 0.0009947057138197123}, {"layer_params": [18, 47, 40, 38], "learning_rate": 0.005808646729694073, "batch_size": 141, "loss": 0.002749808980152011}, {"layer_params": [31, 49, 56, 23, 31], "learning_rate": 0.0014928548920648496, "batch_size": 219, "loss": 0.0033159549185074865}, {"layer_params": [58, 53, 58, 39], "learning_rate": 0.0036260704535423295, "batch_size": 391, "loss": 0.0010188484285026788}, {"layer_params": [49, 29, 53, 29], "learning_rate": 0.003355804680283147, "batch_size": 489, "loss": 0.0017727823299355805}, {"layer_params": [57, 41, 42, 39, 20], "learning_rate": 0.006513953114626638, "batch_size": 254, "loss": 0.00146599548519589}, {"layer_params": [25, 32, 50, 42, 20], "learning_rate": 0.004793465867669936, "batch_size": 248, "loss": 0.0024261178483720868}, {"layer_params": [63, 47, 28, 20, 16], "learning_rate": 0.003200426406888834, "batch_size": 470, "loss": 0.0012035740725696087}, {"layer_params": [48, 41], "learning_rate": 0.0038687619532190624, "batch_size": 105, "loss": 0.0028404924809001387}, {"layer_params": [64, 38, 61, 35, 21], "learning_rate": 0.00970089054152383, "batch_size": 155, "loss": 0.0016126085293944924}, {"layer_params": [52, 58], "learning_rate": 0.003730896241907487, "batch_size": 491, "loss": 0.0015955214051064104}, {"layer_params": [21, 55, 29], "learning_rate": 0.00020051860396237204, "batch_size": 473, "loss": 0.008462884519249201}, {"layer_params": [33, 37], "learning_rate": 0.001707123089403873, "batch_size": 418, "loss": 0.0028807899821549653}, {"layer_params": [33, 18, 19, 55, 29], "learning_rate": 0.006679513182512231, "batch_size": 234, "loss": 0.0029008987662382424}, {"layer_params": [21, 18, 58, 31, 29], "learning_rate": 0.002960138679660604, "batch_size": 334, "loss": 0.002793493685312569}, {"layer_params": [17, 60], "learning_rate": 0.0050022421593000094, "batch_size": 441, "loss": 0.0026041708094999196}, {"layer_params": [16, 48, 64, 29, 30], "learning_rate": 0.002500860176671784, "batch_size": 484, "loss": 0.00233882847474888}, {"layer_params": [28, 36, 61], "learning_rate": 0.007625518680502723, "batch_size": 309, "loss": 0.002477901935344562}, {"layer_params": [25, 61, 42], "learning_rate": 0.007383414454403789, "batch_size": 91, "loss": 0.0031764340563677253}, {"layer_params": [36, 26, 35], "learning_rate": 0.0008850534020023577, "batch_size": 92, "loss": 0.0070075639244168994}, {"layer_params": [35, 38], "learning_rate": 0.0018794283440236672, "batch_size": 112, "loss": 0.003850007092114538}, {"layer_params": [29, 32], "learning_rate": 0.009775538890382667, "batch_size": 422, "loss": 0.002162446306319907}, {"layer_params": [16, 46, 26, 51], "learning_rate": 0.006165369985214645, "batch_size": 17, "loss": 0.008759308005683124}, {"layer_params": [63, 56], "learning_rate": 0.007682916054730978, "batch_size": 237, "loss": 0.0010972297337139025}, {"layer_params": [52, 28, 47, 58], "learning_rate": 0.008713330519763977, "batch_size": 61, "loss": 0.0030569145572371783}, {"layer_params": [50, 33, 24, 48, 38], "learning_rate": 0.007619566030142053, "batch_size": 364, "loss": 0.0011955328658223151}, {"layer_params": [53, 26, 52], "learning_rate": 0.007135419645632427, "batch_size": 238, "loss": 0.0014327238901751117}, {"layer_params": [26, 32, 19, 37], "learning_rate": 0.005582855562657962, "batch_size": 182, "loss": 0.002704568182816729}, {"layer_params": [58, 39, 24, 23, 41], "learning_rate": 0.0037298764818725835, "batch_size": 377, "loss": 0.002342331502586603}, {"layer_params": [34, 45], "learning_rate": 0.002654970898779252, "batch_size": 45, "loss": 0.006045549043919891}, {"layer_params": [61, 33, 26, 60, 55], "learning_rate": 0.008122628798978009, "batch_size": 183, "loss": 0.001303083177190274}, {"layer_params": [43, 42, 35, 37], "learning_rate": 0.001624591381895715, "batch_size": 486, "loss": 0.0019896723120473325}, {"layer_params": [42, 40], "learning_rate": 0.0020000703936164472, "batch_size": 268, "loss": 0.00425134772202}, {"layer_params": [42, 43], "learning_rate": 0.006366756974994632, "batch_size": 353, "loss": 0.0015110059548169375}, {"layer_params": [41, 33, 55, 45, 37], "learning_rate": 0.008752645597315966, "batch_size": 36, "loss": 0.006505591287277639}, {"layer_params": [19, 44, 61, 53, 17], "learning_rate": 0.006962138995318325, "batch_size": 49, "loss": 0.005444736070930958}, {"layer_params": [31, 28, 59], "learning_rate": 0.006241165488392038, "batch_size": 491, "loss": 0.0014389144175220281}, {"layer_params": [36, 22, 47, 45, 36], "learning_rate": 0.003331461979504688, "batch_size": 244, "loss": 0.001734830749919638}, {"layer_params": [58, 45, 38, 46], "learning_rate": 0.0046049784307107345, "batch_size": 294, "loss": 0.0015221949270926415}, {"layer_params": [38, 16, 55], "learning_rate": 0.0055047160225244595, "batch_size": 408, "loss": 0.002460417868569493}, {"layer_params": [28, 56, 43], "learning_rate": 0.007915882701844163, "batch_size": 59, "loss": 0.003503792576957494}, {"layer_params": [26, 50, 50, 40, 25], "learning_rate": 0.00858133732105191, "batch_size": 189, "loss": 0.001659730145474896}, {"layer_params": [31, 61, 37, 45, 47], "learning_rate": 0.00033875821779533904, "batch_size": 26, "loss": 0.008356732702814042}, {"layer_params": [24, 53, 56], "learning_rate": 0.00023660398135524934, "batch_size": 186, "loss": 0.00765672855079174}, {"layer_params": [24, 52], "learning_rate": 0.004466587552756389, "batch_size": 92, "loss": 0.00437467829324305}, {"layer_params": [18, 56, 54, 40], "learning_rate": 0.0012245707183669314, "batch_size": 483, "loss": 0.0026926720445044337}, {"layer_params": [64, 62, 59], "learning_rate": 0.001985868329932986, "batch_size": 76, "loss": 0.0028987048647832127}, {"layer_params": [32, 45, 55, 24], "learning_rate": 0.00999324705325024, "batch_size": 287, "loss": 0.0013608621020102874}, {"layer_params": [37, 51, 47], "learning_rate": 0.004968031858425089, "batch_size": 444, "loss": 0.0012185010284883901}, {"layer_params": [48, 31], "learning_rate": 0.0016595420760871392, "batch_size": 276, "loss": 0.003929522002581507}, {"layer_params": [23, 40, 59, 21], "learning_rate": 0.00902326000754262, "batch_size": 108, "loss": 0.0024655334441922605}, {"layer_params": [28, 46, 16], "learning_rate": 0.006342125429800016, "batch_size": 211, "loss": 0.001614687447436154}, {"layer_params": [56, 60, 61, 41], "learning_rate": 0.0068200614522276794, "batch_size": 444, "loss": 0.0011469311761902645}, {"layer_params": [35, 23], "learning_rate": 0.009297261051833991, "batch_size": 292, "loss": 0.005140936695970595}, {"layer_params": [64, 64, 57], "learning_rate": 0.0018186080277412021, "batch_size": 231, "loss": 0.0018662175559438765}, {"layer_params": [24, 58, 55, 62, 22], "learning_rate": 0.00017801891647955525, "batch_size": 67, "loss": 0.008763982770033181}, {"layer_params": [37, 42, 21], "learning_rate": 0.0006638830965706278, "batch_size": 87, "loss": 0.007298422739841044}, {"layer_params": [40, 38], "learning_rate": 0.0044230305722981955, "batch_size": 263, "loss": 0.002099653626792133}, {"layer_params": [27, 59, 18, 57], "learning_rate": 0.005011553399875999, "batch_size": 452, "loss": 0.002252204050309956}, {"layer_params": [53, 36, 21], "learning_rate": 0.009804228691768129, "batch_size": 403, "loss": 0.0020057681598700584}, {"layer_params": [35, 48, 52], "learning_rate": 0.008240462122316185, "batch_size": 304, "loss": 0.0018594509130343796}, {"layer_params": [24, 42, 55], "learning_rate": 0.007990615520126882, "batch_size": 392, "loss": 0.001881277245702222}, {"layer_params": [16, 22, 38, 22], "learning_rate": 0.007837298028724281, "batch_size": 430, "loss": 0.0038448553695343436}, {"layer_params": [35, 18], "learning_rate": 0.0014551129642993267, "batch_size": 147, "loss": 0.005130170718766749}, {"layer_params": [37, 36, 25, 54, 27], "learning_rate": 0.0002184909128790892, "batch_size": 276, "loss": 0.007799144950695336}, {"layer_params": [46, 34, 30], "learning_rate": 0.005573519485032327, "batch_size": 234, "loss": 0.0023009715927764774}, {"layer_params": [64, 49, 23], "learning_rate": 0.006739450324827378, "batch_size": 178, "loss": 0.0012495334155391902}, {"layer_params": [17, 33, 46, 29], "learning_rate": 0.005432119064564196, "batch_size": 144, "loss": 0.005139151336625219}, {"layer_params": [51, 34], "learning_rate": 0.003702374615255122, "batch_size": 339, "loss": 0.0019922757416497914}, {"layer_params": [36, 57, 45, 58], "learning_rate": 0.004444252832859492, "batch_size": 435, "loss": 0.0013333041267469526}, {"layer_params": [17, 23, 56, 23, 28], "learning_rate": 0.005404890046864318, "batch_size": 354, "loss": 0.0025623059715144335}, {"layer_params": [47, 62, 25, 26, 46], "learning_rate": 0.0002464483372785313, "batch_size": 419, "loss": 0.006535635809414088}, {"layer_params": [30, 48, 63, 16], "learning_rate": 0.0017339388855500532, "batch_size": 21, "loss": 0.008715443394612521}, {"layer_params": [35, 34, 50], "learning_rate": 0.00741414393037304, "batch_size": 271, "loss": 0.002452351108659059}, {"layer_params": [24, 50, 49, 33], "learning_rate": 0.007458023257637529, "batch_size": 222, "loss": 0.002014624454313889}, {"layer_params": [31, 17, 56, 21], "learning_rate": 0.006820443856955392, "batch_size": 319, "loss": 0.0018942700687330216}, {"layer_params": [53, 53, 29], "learning_rate": 0.0033817505739092797, "batch_size": 308, "loss": 0.001898507212754339}, {"layer_params": [16, 59, 49, 59, 41], "learning_rate": 0.004444742195199154, "batch_size": 414, "loss": 0.003487750310450792}, {"layer_params": [33, 60, 16], "learning_rate": 0.001522045984585699, "batch_size": 167, "loss": 0.0034747861232608556}, {"layer_params": [22, 62, 62], "learning_rate": 0.008745080500635376, "batch_size": 505, "loss": 0.001851043115602806}, {"layer_params": [25, 19, 35, 34], "learning_rate": 0.0064425274441747915, "batch_size": 65, "loss": 0.004341583740897477}, {"layer_params": [56, 43, 60, 26, 54], "learning_rate": 0.006835194265230933, "batch_size": 171, "loss": 0.0014845397515455261}, {"layer_params": [20, 33, 27, 33, 24], "learning_rate": 0.0015363908854831307, "batch_size": 129, "loss": 0.006200942117720843}, {"layer_params": [54, 21, 17], "learning_rate": 0.002273081691343482, "batch_size": 304, "loss": 0.0031171916099265217}, {"layer_params": [26, 37], "learning_rate": 7.508238858791874e-05, "batch_size": 511, "loss": 0.03534688662737608}, {"layer_params": [48, 18, 44], "learning_rate": 0.009482345253465183, "batch_size": 142, "loss": 0.003947046983521432}, {"layer_params": [64, 53], "learning_rate": 0.004370254996636049, "batch_size": 497, "loss": 0.0016171157942153514}, {"layer_params": [34, 51, 29, 59], "learning_rate": 0.003692282828768635, "batch_size": 270, "loss": 0.002605664099100977}, {"layer_params": [30, 64], "learning_rate": 0.0014638480236190887, "batch_size": 112, "loss": 0.004550699684768915}, {"layer_params": [61, 39, 58, 24], "learning_rate": 0.0011238159164371655, "batch_size": 478, "loss": 0.002365736023057252}, {"layer_params": [24, 21], "learning_rate": 0.00531953406639208, "batch_size": 269, "loss": 0.0030569826369173823}, {"layer_params": [38, 62, 35, 20, 55], "learning_rate": 0.0037525497213942807, "batch_size": 457, "loss": 0.0014154183899518103}, {"layer_params": [31, 45], "learning_rate": 0.0009160089686256908, "batch_size": 64, "loss": 0.006860996019095182}, {"layer_params": [28, 44, 57, 60], "learning_rate": 0.007470244155535004, "batch_size": 68, "loss": 0.0036011136311572046}, {"layer_params": [25, 32], "learning_rate": 0.0035546149056213867, "batch_size": 349, "loss": 0.00264475115807727}, {"layer_params": [32, 59], "learning_rate": 0.00777018913702465, "batch_size": 229, "loss": 0.0020018830243498085}, {"layer_params": [29, 61, 55, 41, 21], "learning_rate": 0.006379890361920568, "batch_size": 319, "loss": 0.001431878990260884}, {"layer_params": [43, 35, 22], "learning_rate": 0.004257209849626054, "batch_size": 222, "loss": 0.0027693109633401035}, {"layer_params": [41, 34, 34, 61], "learning_rate": 0.00020131826767416785, "batch_size": 111, "loss": 0.007738985321484506}, {"layer_params": [55, 25], "learning_rate": 0.0008342799225994684, "batch_size": 213, "loss": 0.005232830625027418}, {"layer_params": [30, 37], "learning_rate": 0.005778938252842509, "batch_size": 214, "loss": 0.0021936975396238266}, {"layer_params": [20, 19, 25, 46], "learning_rate": 0.002569085365427292, "batch_size": 321, "loss": 0.005297047039493919}, {"layer_params": [35, 20, 62], "learning_rate": 0.003321497432203928, "batch_size": 191, "loss": 0.0023932889045681803}, {"layer_params": [58, 27, 27, 31], "learning_rate": 0.0013693302934997744, "batch_size": 198, "loss": 0.0032477288343943657}, {"layer_params": [18, 29], "learning_rate": 0.007964560388871297, "batch_size": 427, "loss": 0.0036764361965470017}, {"layer_params": [52, 38], "learning_rate": 0.007475132673657933, "batch_size": 312, "loss": 0.0017807735421229154}, {"layer_params": [18, 22, 61, 22], "learning_rate": 0.0030782919161934244, "batch_size": 271, "loss": 0.003392949232365936}, {"layer_params": [53, 24, 33, 58, 43], "learning_rate": 0.005332267269248604, "batch_size": 344, "loss": 0.002184749699663371}, {"layer_params": [32, 61, 36, 42, 49], "learning_rate": 0.002916226144882541, "batch_size": 298, "loss": 0.0020513061771634967}, {"layer_params": [64, 59], "learning_rate": 0.0033217137698285625, "batch_size": 402, "loss": 0.0016016747569665313}, {"layer_params": [59, 44], "learning_rate": 0.00873939184924507, "batch_size": 492, "loss": 0.0014097433374263347}, {"layer_params": [32, 64, 46, 63], "learning_rate": 0.006247425135120526, "batch_size": 67, "loss": 0.0029686920915264637}, {"layer_params": [26, 31], "learning_rate": 0.009839119170887086, "batch_size": 152, "loss": 0.002339228888740763}, {"layer_params": [41, 36, 61, 62, 53], "learning_rate": 0.003675560352800754, "batch_size": 332, "loss": 0.0016585937677882612}, {"layer_params": [46, 54, 61, 50, 20], "learning_rate": 0.0014455357831578077, "batch_size": 414, "loss": 0.0020255945401731878}, {"layer_params": [54, 27, 49, 56, 60], "learning_rate": 0.009617855345262282, "batch_size": 221, "loss": 0.0023057372425682844}, {"layer_params": [20, 61, 45, 62, 56], "learning_rate": 0.007024929562220642, "batch_size": 386, "loss": 0.001077340564224869}, {"layer_params": [47, 42], "learning_rate": 0.00805602757953452, "batch_size": 447, "loss": 0.002486388117540628}, {"layer_params": [25, 28, 22, 50, 39], "learning_rate": 0.0005770930594543819, "batch_size": 348, "loss": 0.006380497980862856}, {"layer_params": [25, 37, 53, 33], "learning_rate": 0.008351131934223939, "batch_size": 400, "loss": 0.0020643128745723516}, {"layer_params": [61, 18, 22, 54, 50], "learning_rate": 0.006139055101102481, "batch_size": 380, "loss": 0.002409143577096984}, {"layer_params": [47, 24, 60, 53, 19], "learning_rate": 0.005583101853725441, "batch_size": 47, "loss": 0.003179407389834523}, {"layer_params": [56, 32, 47, 24], "learning_rate": 0.004964407478302251, "batch_size": 318, "loss": 0.001580900807166472}, {"layer_params": [63, 55, 54, 50, 17], "learning_rate": 0.0015149146960408133, "batch_size": 38, "loss": 0.004246741703245789}, {"layer_params": [32, 44], "learning_rate": 0.0062756528385920695, "batch_size": 83, "loss": 0.0029149634786881508}, {"layer_params": [20, 64], "learning_rate": 0.0024120112902997824, "batch_size": 358, "loss": 0.003831336384173483}, {"layer_params": [19, 37], "learning_rate": 0.0038901313918565327, "batch_size": 217, "loss": 0.0053119194158352916}, {"layer_params": [38, 24], "learning_rate": 0.00799854573421181, "batch_size": 110, "loss": 0.003113505123183131}, {"layer_params": [20, 42], "learning_rate": 0.007762460960400731, "batch_size": 299, "loss": 0.0020498791511636225}, {"layer_params": [62, 56, 16], "learning_rate": 0.00792696013212396, "batch_size": 362, "loss": 0.0008897123759379611}, {"layer_params": [56, 29, 48, 44], "learning_rate": 0.0038905155938994615, "batch_size": 401, "loss": 0.0012371791992336512}, {"layer_params": [18, 17, 27], "learning_rate": 0.002631396816658405, "batch_size": 95, "loss": 0.0067008967651054265}, {"layer_params": [31, 16, 51], "learning_rate": 0.006572517734123727, "batch_size": 310, "loss": 0.003498213621787727}, {"layer_params": [60, 64], "learning_rate": 0.004893691867605694, "batch_size": 511, "loss": 0.0011552314384607597}, {"layer_params": [34, 29, 21], "learning_rate": 0.00437272377546114, "batch_size": 184, "loss": 0.0031615877337753773}, {"layer_params": [36, 16, 50, 19], "learning_rate": 0.006816859486005662, "batch_size": 348, "loss": 0.0026376367919147014}, {"layer_params": [23, 40, 51, 55, 38], "learning_rate": 0.006766017933842037, "batch_size": 369, "loss": 0.001776248358655721}, {"layer_params": [32, 20, 19, 33, 33], "learning_rate": 0.0012295406176689274, "batch_size": 223, "loss": 0.004628665160853415}, {"layer_params": [48, 41, 29, 35], "learning_rate": 0.0058721959522585335, "batch_size": 397, "loss": 0.0007923944311914965}, {"layer_params": [34, 24, 46], "learning_rate": 0.008280703820833676, "batch_size": 71, "loss": 0.0038272471446543933}, {"layer_params": [36, 22, 40, 57], "learning_rate": 1.5918390400913968e-05, "batch_size": 134, "loss": 0.03864664433524013}, {"layer_params": [23, 43], "learning_rate": 0.0027515711315762334, "batch_size": 399, "loss": 0.003006286050658673}, {"layer_params": [63, 31, 38], "learning_rate": 0.008617676773058474, "batch_size": 495, "loss": 0.0010001711297081784}, {"layer_params": [61, 35, 51, 45], "learning_rate": 0.0024951293302436046, "batch_size": 236, "loss": 0.001728502414189279}, {"layer_params": [43, 49], "learning_rate": 0.004570570284783197, "batch_size": 333, "loss": 0.002097693836549297}, {"layer_params": [53, 58, 18], "learning_rate": 0.008024857233850012, "batch_size": 48, "loss": 0.003605016393121332}, {"layer_params": [28, 49], "learning_rate": 0.009228872164665364, "batch_size": 467, "loss": 0.002648362915497273}, {"layer_params": [63, 56, 27], "learning_rate": 0.007925791459527142, "batch_size": 269, "loss": 0.0017982234444934874}, {"layer_params": [44, 55, 55], "learning_rate": 0.0025634665762597534, "batch_size": 486, "loss": 0.0012476483162026852}, {"layer_params": [32, 51, 62, 35, 37], "learning_rate": 0.0010845903047651758, "batch_size": 50, "loss": 0.006849383064545691}, {"layer_params": [28, 59, 52], "learning_rate": 0.005210213088147992, "batch_size": 361, "loss": 0.0019938222330529243}, {"layer_params": [38, 25], "learning_rate": 0.0003114617829509315, "batch_size": 295, "loss": 0.010013837232254446}, {"layer_params": [63, 20, 20], "learning_rate": 0.007789569923243092, "batch_size": 219, "loss": 0.002096499970648438}, {"layer_params": [22, 62], "learning_rate": 0.0074761841014571355, "batch_size": 112, "loss": 0.0030923051829449834}, {"layer_params": [50, 38, 37, 58], "learning_rate": 0.00487831498780604, "batch_size": 141, "loss": 0.0022002442262601105}, {"layer_params": [33, 44, 26, 28], "learning_rate": 0.007699794738259296, "batch_size": 401, "loss": 0.0014754880836699159}, {"layer_params": [48, 36, 30, 35], "learning_rate": 0.0001436804070097857, "batch_size": 478, "loss": 0.01180761911906302}, {"layer_params": [54, 50], "learning_rate": 0.0015539414050375756, "batch_size": 108, "loss": 0.0033381894393824042}, {"layer_params": [40, 46, 57, 34], "learning_rate": 0.008648641304124417, "batch_size": 484, "loss": 0.0021386099769733847}, {"layer_params": [36, 35, 56, 52, 37], "learning_rate": 0.007988543725816867, "batch_size": 68, "loss": 0.0031701269757468255}, {"layer_params": [49, 49, 16, 37], "learning_rate": 0.0005247742501620404, "batch_size": 305, "loss": 0.005756302154622972}, {"layer_params": [22, 20, 32, 43, 51], "learning_rate": 0.00013265014771563085, "batch_size": 303, "loss": 0.017191047389060257}, {"layer_params": [22, 64, 38, 21, 27], "learning_rate": 0.006430372620060873, "batch_size": 113, "loss": 0.0034842261741869153}, {"layer_params": [57, 42, 44], "learning_rate": 0.0015873324380635263, "batch_size": 223, "loss": 0.002698867052095011}, {"layer_params": [31, 29], "learning_rate": 0.0027168652895232814, "batch_size": 33, "loss": 0.007220722970087082}, {"layer_params": [16, 25], "learning_rate": 0.005181629905186927, "batch_size": 200, "loss": 0.0034416754660196603}, {"layer_params": [26, 34], "learning_rate": 0.005710534576217826, "batch_size": 25, "loss": 0.007465611530933529}, {"layer_params": [56, 18], "learning_rate": 0.0022591385149853694, "batch_size": 158, "loss": 0.0022282988450024275}, {"layer_params": [42, 21, 43, 34, 53], "learning_rate": 0.00978693299829408, "batch_size": 17, "loss": 0.009059842221904545}, {"layer_params": [24, 39], "learning_rate": 0.005106880202039075, "batch_size": 331, "loss": 0.0029860585252754392}, {"layer_params": [55, 46, 59, 26], "learning_rate": 0.008787065041253971, "batch_size": 184, "loss": 0.0014092290063854307}, {"layer_params": [30, 24, 40], "learning_rate": 0.004034978030604744, "batch_size": 200, "loss": 0.002950331347528845}, {"layer_params": [33, 38, 59, 30, 55], "learning_rate": 0.005536541774883683, "batch_size": 311, "loss": 0.0016873449098784477}, {"layer_params": [63, 55], "learning_rate": 0.0007631339280212084, "batch_size": 22, "loss": 0.007421136675402522}, {"layer_params": [30, 58], "learning_rate": 0.008677563151745001, "batch_size": 347, "loss": 0.0013714195787906647}, {"layer_params": [50, 60], "learning_rate": 0.009775732623448684, "batch_size": 427, "loss": 0.0011401375476270915}, {"layer_params": [19, 57, 19], "learning_rate": 0.006406736498588144, "batch_size": 243, "loss": 0.0023549937352072446}, {"layer_params": [50, 53, 36, 47, 59], "learning_rate": 0.0010285866729633527, "batch_size": 170, "loss": 0.0030193444271571935}, {"layer_params": [18, 40, 62, 50], "learning_rate": 0.002267674452659266, "batch_size": 378, "loss": 0.002490622628247365}, {"layer_params": [32, 38, 29], "learning_rate": 0.0005654610266848187, "batch_size": 317, "loss": 0.006109570423141122}, {"layer_params": [59, 19, 24, 55], "learning_rate": 0.006755686822520829, "batch_size": 90, "loss": 0.003156171978916973}, {"layer_params": [21, 56, 50, 31, 42], "learning_rate": 0.00722231700668302, "batch_size": 244, "loss": 0.0019855873310007156}, {"layer_params": [54, 61, 28], "learning_rate": 0.007154618609180389, "batch_size": 294, "loss": 0.0011649955896427854}, {"layer_params": [44, 54, 28], "learning_rate": 0.006235832122110195, "batch_size": 239, "loss": 0.0011482661025365814}, {"layer_params": [16, 62, 25, 32], "learning_rate": 0.0007280100851431564, "batch_size": 70, "loss": 0.007541755633428693}, {"layer_params": [52, 17, 23, 56, 60], "learning_rate": 0.006534464179872876, "batch_size": 140, "loss": 0.004028359863441438}, {"layer_params": [43, 57, 24, 23, 32], "learning_rate": 0.007268107599057858, "batch_size": 58, "loss": 0.003626885279081762}, {"layer_params": [36, 47, 29], "learning_rate": 0.0009164019730972385, "batch_size": 25, "loss": 0.008067598438356072}, {"layer_params": [36, 35, 33, 58, 37], "learning_rate": 0.0002671972386801254, "batch_size": 271, "loss": 0.007040110887028277}, {"layer_params": [59, 44, 17, 25, 26], "learning_rate": 0.005719410031997911, "batch_size": 511, "loss": 0.0009947018377715721}, {"layer_params": [41, 46, 42], "learning_rate": 0.009368165642189992, "batch_size": 365, "loss": 0.0013871700887102634}, {"layer_params": [38, 29, 57], "learning_rate": 0.002037404325402143, "batch_size": 204, "loss": 0.0026988199818879367}, {"layer_params": [43, 35, 21, 26], "learning_rate": 0.004182194245873635, "batch_size": 76, "loss": 0.004480181967373938}, {"layer_params": [52, 45, 35], "learning_rate": 0.001985427691574552, "batch_size": 306, "loss": 0.002212759011890739}, {"layer_params": [63, 55], "learning_rate": 0.009512556528556293, "batch_size": 393, "loss": 0.0015533682028762996}, {"layer_params": [36, 55], "learning_rate": 0.008498889724172124, "batch_size": 211, "loss": 0.0032714452315121888}, {"layer_params": [39, 45, 19], "learning_rate": 0.002104011960675232, "batch_size": 288, "loss": 0.002396157302428037}, {"layer_params": [59, 36, 53, 24, 41], "learning_rate": 0.005807194986618807, "batch_size": 127, "loss": 0.001775719173019752}, {"layer_params": [44, 42, 27, 19], "learning_rate": 0.002556142260683286, "batch_size": 253, "loss": 0.0016928604419808836}, {"layer_params": [40, 37, 16, 54, 32], "learning_rate": 0.008756888073606564, "batch_size": 137, "loss": 0.002081850677495822}, {"layer_params": [19, 41], "learning_rate": 0.006185164559253016, "batch_size": 230, "loss": 0.0034905264317058025}, {"layer_params": [35, 36], "learning_rate": 0.0040828208934282975, "batch_size": 99, "loss": 0.0028683855070266873}, {"layer_params": [45, 32, 64], "learning_rate": 0.0049148064375384454, "batch_size": 465, "loss": 0.00127159577968996}, {"layer_params": [32, 39, 60, 46, 61], "learning_rate": 0.009862629760664508, "batch_size": 340, "loss": 0.0009494925616309047}, {"layer_params": [63, 42, 64, 60, 16], "learning_rate": 0.003868431138945753, "batch_size": 469, "loss": 0.001928781553870067}, {"layer_params": [35, 48], "learning_rate": 0.006131585328672813, "batch_size": 51, "loss": 0.0030434355500619857}, {"layer_params": [20, 16, 44, 18], "learning_rate": 0.008331721217189935, "batch_size": 101, "loss": 0.0033201136253774165}, {"layer_params": [37, 35, 34, 60], "learning_rate": 0.000433820946447514, "batch_size": 110, "loss": 0.00733537245541811}, {"layer_params": [46, 51, 30, 24], "learning_rate": 0.006831170377788011, "batch_size": 209, "loss": 0.0012066109210718424}, {"layer_params": [44, 37, 48, 50, 24], "learning_rate": 0.000957570066656598, "batch_size": 419, "loss": 0.003096676541026682}, {"layer_params": [57, 64], "learning_rate": 0.0023736470278240976, "batch_size": 302, "loss": 0.0020890446205157785}, {"layer_params": [34, 24, 42, 48, 29], "learning_rate": 0.0006659326977378464, "batch_size": 282, "loss": 0.005255873934365809}, {"layer_params": [62, 21, 49, 37], "learning_rate": 0.008587018096801683, "batch_size": 434, "loss": 0.0011363727698335425}, {"layer_params": [58, 31], "learning_rate": 0.0020416222945875678, "batch_size": 249, "loss": 0.003109263489022851}, {"layer_params": [22, 22, 48], "learning_rate": 0.005028504990641628, "batch_size": 468, "loss": 0.0025451098196208476}, {"layer_params": [28, 56, 31, 56], "learning_rate": 0.005009826773256866, "batch_size": 61, "loss": 0.003695962238125503}, {"layer_params": [53, 55, 52, 56, 24], "learning_rate": 0.005346630686072995, "batch_size": 148, "loss": 0.0020087162789423018}, {"layer_params": [27, 33, 21, 60], "learning_rate": 0.008296123656928648, "batch_size": 405, "loss": 0.0031993695185519753}, {"layer_params": [49, 19, 22, 24], "learning_rate": 0.008270992373704454, "batch_size": 49, "loss": 0.004443086171522737}, {"layer_params": [44, 43, 54], "learning_rate": 0.002393317854962404, "batch_size": 190, "loss": 0.0021952323301229625}, {"layer_params": [21, 55], "learning_rate": 0.008718928486837788, "batch_size": 466, "loss": 0.0014509810658637433}, {"layer_params": [40, 42, 52, 59, 62], "learning_rate": 0.008672009083368999, "batch_size": 487, "loss": 0.001426255659898743}, {"layer_params": [61, 30, 20], "learning_rate": 0.0034497913984239317, "batch_size": 278, "loss": 0.002076081243576482}, {"layer_params": [44, 62], "learning_rate": 0.00801832188355603, "batch_size": 472, "loss": 0.0009016719413921237}, {"layer_params": [60, 18], "learning_rate": 0.002410142759300257, "batch_size": 90, "loss": 0.005724968484137207}, {"layer_params": [20, 29], "learning_rate": 0.002199869032282177, "batch_size": 354, "loss": 0.0031144853751175106}, {"layer_params": [48, 44], "learning_rate": 0.0015159760233051664, "batch_size": 227, "loss": 0.002435726569965482}, {"layer_params": [29, 48], "learning_rate": 0.0014129599353869314, "batch_size": 325, "loss": 0.004721073010005057}, {"layer_params": [17, 46, 54, 34], "learning_rate": 0.009529494135640238, "batch_size": 486, "loss": 0.0015183266741223634}, {"layer_params": [62, 64, 47, 46, 61], "learning_rate": 0.0073102888614616345, "batch_size": 171, "loss": 0.001614183009369299}, {"layer_params": [34, 58, 43, 46, 38], "learning_rate": 0.00710969537243206, "batch_size": 144, "loss": 0.0018115099845454096}, {"layer_params": [55, 62, 46, 27, 47], "learning_rate": 0.001784972513052498, "batch_size": 410, "loss": 0.0015304667642340064}, {"layer_params": [43, 27, 51, 34, 19], "learning_rate": 0.004635313678601753, "batch_size": 350, "loss": 0.0025660263933241366}, {"layer_params": [60, 46, 56], "learning_rate": 0.0005593582840395521, "batch_size": 154, "loss": 0.004310925740282983}, {"layer_params": [28, 25, 53, 44, 51], "learning_rate": 0.005859138186773196, "batch_size": 442, "loss": 0.0017266901687253266}, {"layer_params": [43, 47, 45], "learning_rate": 0.004356138469115667, "batch_size": 432, "loss": 0.0011769080307567493}, {"layer_params": [46, 23, 23], "learning_rate": 0.004165953612134908, "batch_size": 353, "loss": 0.0016282369662076234}, {"layer_params": [17, 51, 58, 62, 57], "learning_rate": 0.004302266643634041, "batch_size": 241, "loss": 0.0019209005206357688}, {"layer_params": [30, 45, 57, 37, 52], "learning_rate": 0.009480437002651243, "batch_size": 479, "loss": 0.0014911918353755027}, {"layer_params": [58, 53, 57, 25, 16], "learning_rate": 0.008742328939378173, "batch_size": 66, "loss": 0.0024600944702979177}, {"layer_params": [26, 63], "learning_rate": 0.0028540741405054743, "batch_size": 163, "loss": 0.0024141803360544145}, {"layer_params": [29, 53, 27, 41, 49], "learning_rate": 0.00646615896827207, "batch_size": 417, "loss": 0.0021309384307824073}, {"layer_params": [31, 60, 21, 38, 19], "learning_rate": 0.008478971061454867, "batch_size": 237, "loss": 0.0019923231669235976}, {"layer_params": [18, 62], "learning_rate": 0.008482717047979213, "batch_size": 259, "loss": 0.0026204763411078603}, {"layer_params": [34, 40, 17, 42], "learning_rate": 0.007747323986202641, "batch_size": 364, "loss": 0.0014227467984892427}, {"layer_params": [40, 49], "learning_rate": 0.009498120053409744, "batch_size": 57, "loss": 0.0029399205604568124}, {"layer_params": [25, 34, 47, 52], "learning_rate": 0.0006375297861081689, "batch_size": 208, "loss": 0.005909097008407116}, {"layer_params": [57, 57, 22, 59, 51], "learning_rate": 0.0013053911585258519, "batch_size": 470, "loss": 0.0016189257707446814}, {"layer_params": [48, 30, 20, 56, 45], "learning_rate": 0.004870935547146869, "batch_size": 263, "loss": 0.0020713147358037533}, {"layer_params": [32, 21, 55, 44, 62], "learning_rate": 0.005398950028654459, "batch_size": 418, "loss": 0.004064254250843078}, {"layer_params": [36, 33, 19], "learning_rate": 0.002396451410158214, "batch_size": 46, "loss": 0.006699828566052019}, {"layer_params": [26, 33, 53, 54, 49], "learning_rate": 0.0054417244440543916, "batch_size": 96, "loss": 0.0028985872492194175}, {"layer_params": [20, 43, 56], "learning_rate": 0.004683870823011326, "batch_size": 418, "loss": 0.0018464135483372956}, {"layer_params": [37, 56, 18], "learning_rate": 0.00015320650057905553, "batch_size": 58, "loss": 0.025588084738701583}, {"layer_params": [18, 25, 19], "learning_rate": 0.004042982744580296, "batch_size": 451, "loss": 0.0025333439046517016}, {"layer_params": [44, 39], "learning_rate": 0.00980155185560545, "batch_size": 19, "loss": 0.008362763240002095}, {"layer_params": [23, 42], "learning_rate": 0.003716847322768195, "batch_size": 115, "loss": 0.0026045643317047507}, {"layer_params": [33, 61], "learning_rate": 0.004248878354813421, "batch_size": 306, "loss": 0.0019113690382800996}, {"layer_params": [21, 56, 50, 40], "learning_rate": 0.005761093896051572, "batch_size": 107, "loss": 0.0031288573739584537}, {"layer_params": [27, 59], "learning_rate": 0.00029907377103302157, "batch_size": 237, "loss": 0.008066922961734235}, {"layer_params": [56, 19], "learning_rate": 0.007918140439608925, "batch_size": 334, "loss": 0.001964787873439491}, {"layer_params": [32, 27], "learning_rate": 0.006840717138103491, "batch_size": 122, "loss": 0.0031544122961349786}, {"layer_params": [36, 37, 58, 30, 51], "learning_rate": 0.0024274001738756666, "batch_size": 50, "loss": 0.003938890979625285}, {"layer_params": [48, 32, 62, 57, 60], "learning_rate": 0.009668655550515147, "batch_size": 209, "loss": 0.0017839226184878498}, {"layer_params": [47, 17, 33, 28], "learning_rate": 0.0016764869305176792, "batch_size": 226, "loss": 0.002301335778320208}, {"layer_params": [31, 58, 45], "learning_rate": 0.0008256860678553365, "batch_size": 32, "loss": 0.007331812479533255}, {"layer_params": [48, 26], "learning_rate": 0.003805296645026312, "batch_size": 114, "loss": 0.003706658098381013}, {"layer_params": [51, 24, 56], "learning_rate": 0.008201460426155398, "batch_size": 270, "loss": 0.00154603936127387}, {"layer_params": [19, 36, 38, 40], "learning_rate": 0.006916331458964225, "batch_size": 413, "loss": 0.003122563445940614}, {"layer_params": [18, 61, 42, 46, 62], "learning_rate": 0.0056410255281282035, "batch_size": 28, "loss": 0.007135802961420268}, {"layer_params": [17, 47, 50, 52], "learning_rate": 0.0069409848575947815, "batch_size": 112, "loss": 0.003359704636968672}, {"layer_params": [36, 21, 52], "learning_rate": 0.007470604964320988, "batch_size": 19, "loss": 0.005649690625723451}, {"layer_params": [23, 46, 58, 61, 55], "learning_rate": 0.0032422741605881177, "batch_size": 442, "loss": 0.0011361433600541205}, {"layer_params": [38, 20, 26], "learning_rate": 0.0005771871436063283, "batch_size": 266, "loss": 0.007862312952056527}, {"layer_params": [51, 19], "learning_rate": 0.005451406680471135, "batch_size": 510, "loss": 0.0018075986602343619}, {"layer_params": [50, 42, 45, 42, 26], "learning_rate": 0.002399637504472143, "batch_size": 232, "loss": 0.0022319216036703437}, {"layer_params": [63, 43, 38, 28], "learning_rate": 0.005988383739591425, "batch_size": 389, "loss": 0.0006914754619356245}, {"layer_params": [35, 43, 21], "learning_rate": 0.0019485003179411408, "batch_size": 450, "loss": 0.0025563410599716008}, {"layer_params": [27, 27, 43, 35], "learning_rate": 0.0014164081230059282, "batch_size": 282, "loss": 0.005420579928904772}, {"layer_params": [62, 35, 29, 31, 19], "learning_rate": 0.0036938341920776103, "batch_size": 90, "loss": 0.003154777606250718}, {"layer_params": [20, 60, 51, 23], "learning_rate": 0.0014665675388251017, "batch_size": 259, "loss": 0.003105010078288615}, {"layer_params": [24, 63, 27, 31, 35], "learning_rate": 0.003420967498577971, "batch_size": 343, "loss": 0.0014317245152778923}, {"layer_params": [37, 40, 23], "learning_rate": 0.007734543645420915, "batch_size": 369, "loss": 0.0029230783320963382}, {"layer_params": [50, 56, 16, 46], "learning_rate": 0.007845919227312214, "batch_size": 453, "loss": 0.0015930834691971541}, {"layer_params": [29, 31, 58, 33, 55], "learning_rate": 0.004926569939993558, "batch_size": 353, "loss": 0.0012993861956056207}, {"layer_params": [17, 50, 34, 17], "learning_rate": 0.007174742455879298, "batch_size": 492, "loss": 0.004573923880234361}, {"layer_params": [22, 17, 19], "learning_rate": 0.006421436134696053, "batch_size": 169, "loss": 0.004683781748171896}, {"layer_params": [25, 30, 57, 35], "learning_rate": 0.00994402824500572, "batch_size": 403, "loss": 0.0018231873330660164}, {"layer_params": [55, 57, 52], "learning_rate": 0.0071838841712645474, "batch_size": 313, "loss": 0.0008036705560516566}, {"layer_params": [41, 64, 56], "learning_rate": 0.0007432236941997684, "batch_size": 336, "loss": 0.0034592308104038237}, {"layer_params": [45, 31, 59, 51], "learning_rate": 0.0017452768781218739, "batch_size": 78, "loss": 0.0037326331553049386}, {"layer_params": [31, 24, 60], "learning_rate": 0.004594348910166526, "batch_size": 286, "loss": 0.0023359372373670338}, {"layer_params": [36, 35, 52], "learning_rate": 0.0039093998680699744, "batch_size": 37, "loss": 0.005293419531080872}, {"layer_params": [33, 42], "learning_rate": 0.003441416909932051, "batch_size": 303, "loss": 0.002989080895204097}, {"layer_params": [60, 18, 28, 30], "learning_rate": 0.004286391634747912, "batch_size": 321, "loss": 0.002759212024975568}, {"layer_params": [51, 26, 59, 47, 38], "learning_rate": 0.008668609381837522, "batch_size": 410, "loss": 0.0009522395767271518}, {"layer_params": [55, 45, 40], "learning_rate": 0.004917252701888952, "batch_size": 132, "loss": 0.002183710184181109}, {"layer_params": [40, 54, 16], "learning_rate": 0.006621817314835058, "batch_size": 38, "loss": 0.005637551427353174}, {"layer_params": [35, 53, 52], "learning_rate": 0.006699764058643261, "batch_size": 371, "loss": 0.0010287048859754578}, {"layer_params": [30, 17], "learning_rate": 0.0014132196599078734, "batch_size": 507, "loss": 0.0060931136133149265}, {"layer_params": [63, 55], "learning_rate": 0.0038944005876234, "batch_size": 322, "loss": 0.002383087145863101}, {"layer_params": [56, 60, 36, 17], "learning_rate": 0.0051357887260666795, "batch_size": 120, "loss": 0.003204605197533965}, {"layer_params": [33, 18, 26, 27, 49], "learning_rate": 0.007198848962972273, "batch_size": 321, "loss": 0.003974857302382589}, {"layer_params": [16, 49, 52, 23, 20], "learning_rate": 0.0018257903907241415, "batch_size": 421, "loss": 0.0046178887155838315}, {"layer_params": [27, 63, 18, 19], "learning_rate": 0.009524536107844372, "batch_size": 491, "loss": 0.0015162545954808594}, {"layer_params": [16, 43, 29], "learning_rate": 0.001322221101471057, "batch_size": 477, "loss": 0.0032120205438695847}, {"layer_params": [22, 46, 58, 41, 46], "learning_rate": 0.007019391682299266, "batch_size": 349, "loss": 0.002245102785527706}, {"layer_params": [48, 19], "learning_rate": 0.007562483876924767, "batch_size": 452, "loss": 0.0021204609354026614}, {"layer_params": [58, 32], "learning_rate": 0.007386155998686693, "batch_size": 423, "loss": 0.0029429053654894234}, {"layer_params": [58, 54], "learning_rate": 0.006805447184411472, "batch_size": 506, "loss": 0.0010227789281634615}, {"layer_params": [22, 40, 43, 31], "learning_rate": 0.00017733006832992195, "batch_size": 92, "loss": 0.02338776976801455}, {"layer_params": [35, 47, 42], "learning_rate": 0.002015002557066456, "batch_size": 257, "loss": 0.002276385212317109}, {"layer_params": [29, 25, 64, 57], "learning_rate": 0.006018819725984577, "batch_size": 73, "loss": 0.004657967064995319}, {"layer_params": [34, 55], "learning_rate": 0.002660731503701582, "batch_size": 80, "loss": 0.0030946505861356856}, {"layer_params": [49, 29, 51, 59, 60], "learning_rate": 0.004659579464661916, "batch_size": 19, "loss": 0.006178175632376224}, {"layer_params": [34, 53, 54, 51], "learning_rate": 0.008766442081366843, "batch_size": 67, "loss": 0.005124653105158358}, {"layer_params": [47, 60, 41], "learning_rate": 0.0075771368022395265, "batch_size": 464, "loss": 0.0009347551962127909}, {"layer_params": [22, 17, 62, 38, 22], "learning_rate": 0.00319843679020829, "batch_size": 52, "loss": 0.00667718960903585}, {"layer_params": [28, 17], "learning_rate": 0.007551928655636265, "batch_size": 91, "loss": 0.0038784967106766997}, {"layer_params": [37, 40, 18, 43, 33], "learning_rate": 0.007257633940608861, "batch_size": 247, "loss": 0.0020701949519570917}, {"layer_params": [21, 48, 30], "learning_rate": 0.0003079681840617667, "batch_size": 509, "loss": 0.008463579677045346}, {"layer_params": [17, 55, 53], "learning_rate": 0.0020743264746707355, "batch_size": 408, "loss": 0.0032779277954250573}, {"layer_params": [27, 46, 58, 23, 43], "learning_rate": 0.008262984159329429, "batch_size": 410, "loss": 0.001412542386678979}, {"layer_params": [32, 58, 26, 26, 25], "learning_rate": 0.004261444122606416, "batch_size": 356, "loss": 0.0014890023600310088}, {"layer_params": [21, 16, 26, 37, 51], "learning_rate": 0.006103609764839687, "batch_size": 167, "loss": 0.002944579052273184}, {"layer_params": [30, 17], "learning_rate": 0.00912442361221631, "batch_size": 326, "loss": 0.002503524824278429}, {"layer_params": [53, 25, 50], "learning_rate": 0.00878776801949438, "batch_size": 315, "loss": 0.0014725864934735}, {"layer_params": [30, 38], "learning_rate": 0.00412987708841659, "batch_size": 403, "loss": 0.0021221634198445825}, {"layer_params": [39, 34, 27, 39, 51], "learning_rate": 0.000949184395560254, "batch_size": 18, "loss": 0.008468494632979854}, {"layer_params": [30, 37, 41], "learning_rate": 0.0038810372484312807, "batch_size": 134, "loss": 0.002208813838660717}, {"layer_params": [22, 33, 38, 17, 63], "learning_rate": 0.007615077973267079, "batch_size": 256, "loss": 0.002541984791168943}, {"layer_params": [30, 58, 31], "learning_rate": 0.006025657095834115, "batch_size": 427, "loss": 0.0015619827550835907}, {"layer_params": [24, 16, 21, 51], "learning_rate": 0.007224664496005675, "batch_size": 39, "loss": 0.006781434020958841}, {"layer_params": [38, 54, 30, 22, 49], "learning_rate": 0.0061210869656925454, "batch_size": 250, "loss": 0.0024134988675359637}, {"layer_params": [29, 22, 33, 24], "learning_rate": 0.005909382054947925, "batch_size": 126, "loss": 0.0025527018576394765}, {"layer_params": [49, 23, 29, 42, 27], "learning_rate": 0.007984399302353699, "batch_size": 36, "loss": 0.00522517875302583}, {"layer_params": [24, 24, 47, 26, 17], "learning_rate": 0.003966350256874758, "batch_size": 209, "loss": 0.002951279904227704}, {"layer_params": [22, 35, 48, 19, 35], "learning_rate": 0.005480808957531435, "batch_size": 244, "loss": 0.004105976780410856}, {"layer_params": [30, 49], "learning_rate": 0.009628842267305898, "batch_size": 82, "loss": 0.003930418738164008}, {"layer_params": [39, 38, 16], "learning_rate": 0.0021042524401372526, "batch_size": 223, "loss": 0.004180436381138861}, {"layer_params": [21, 22], "learning_rate": 0.00022042546968461675, "batch_size": 207, "loss": 0.02124653646722436}, {"layer_params": [26, 35, 40, 58, 39], "learning_rate": 0.0069564054102992205, "batch_size": 401, "loss": 0.002239291275618598}, {"layer_params": [43, 26], "learning_rate": 0.002013908584009998, "batch_size": 456, "loss": 0.005480650900863111}, {"layer_params": [39, 53, 50], "learning_rate": 0.0075455097858401566, "batch_size": 40, "loss": 0.003618642520159483}, {"layer_params": [35, 52, 45, 60, 20], "learning_rate": 0.008034095824313775, "batch_size": 455, "loss": 0.0009843778813956306}, {"layer_params": [43, 27], "learning_rate": 0.009029718910696035, "batch_size": 261, "loss": 0.0016846284735947848}, {"layer_params": [49, 42, 48, 40], "learning_rate": 0.009759397955087576, "batch_size": 102, "loss": 0.001972772211302072}, {"layer_params": [58, 24, 64, 24, 29], "learning_rate": 0.002389065776778289, "batch_size": 474, "loss": 0.0014892082975711673}, {"layer_params": [54, 26, 59, 55], "learning_rate": 0.0009863186468821222, "batch_size": 439, "loss": 0.002414979280438274}, {"layer_params": [35, 58, 55, 19], "learning_rate": 0.006351617727238105, "batch_size": 458, "loss": 0.0015987898921594023}, {"layer_params": [18, 28, 31, 21], "learning_rate": 0.007422301609739947, "batch_size": 395, "loss": 0.004298987439833582}, {"layer_params": [48, 22, 36, 39], "learning_rate": 0.005535004737411269, "batch_size": 201, "loss": 0.002262522578239441}, {"layer_params": [58, 23, 60], "learning_rate": 0.009841326233620848, "batch_size": 60, "loss": 0.003946954549755901}, {"layer_params": [44, 28, 56, 56], "learning_rate": 0.004358867215724417, "batch_size": 336, "loss": 0.002346927117323503}, {"layer_params": [59, 21, 32], "learning_rate": 0.007007926444631864, "batch_size": 259, "loss": 0.0014936877484433354}, {"layer_params": [24, 47, 44, 64], "learning_rate": 0.009392395348639239, "batch_size": 147, "loss": 0.001923487833701074}, {"layer_params": [29, 62, 21], "learning_rate": 0.008854771804994355, "batch_size": 498, "loss": 0.002178243368398398}, {"layer_params": [28, 45, 24], "learning_rate": 0.007836429415425478, "batch_size": 106, "loss": 0.002621945940190926}, {"layer_params": [42, 22, 61, 34], "learning_rate": 0.000614594000431306, "batch_size": 348, "loss": 0.004802100148517638}, {"layer_params": [54, 56, 60, 33, 50], "learning_rate": 0.0033611902033351404, "batch_size": 70, "loss": 0.0035663554980419577}, {"layer_params": [43, 23, 22, 39, 57], "learning_rate": 0.0008180462685074426, "batch_size": 334, "loss": 0.0030944835394620895}, {"layer_params": [39, 32, 63, 41], "learning_rate": 0.009497945669399, "batch_size": 450, "loss": 0.0019742996676359328}, {"layer_params": [21, 48, 50, 63], "learning_rate": 0.006862726098232896, "batch_size": 151, "loss": 0.0023850817326456306}, {"layer_params": [60, 50], "learning_rate": 0.005308061489622579, "batch_size": 384, "loss": 0.0018865045229904355}, {"layer_params": [26, 53, 58, 43], "learning_rate": 0.0057526835916938465, "batch_size": 326, "loss": 0.0014015823346562684}, {"layer_params": [50, 32, 24], "learning_rate": 0.0003231425089130011, "batch_size": 465, "loss": 0.007071938938461244}, {"layer_params": [59, 33, 23, 48], "learning_rate": 0.009980734500943769, "batch_size": 43, "loss": 0.004942859990987927}, {"layer_params": [30, 48, 23, 57], "learning_rate": 0.005186270598288627, "batch_size": 287, "loss": 0.0013970836042426526}, {"layer_params": [36, 49, 51, 64, 52], "learning_rate": 0.009046044689933301, "batch_size": 465, "loss": 0.001856195128057152}, {"layer_params": [47, 60], "learning_rate": 0.0021544438841770257, "batch_size": 310, "loss": 0.0023199556418694554}, {"layer_params": [21, 25, 48, 22], "learning_rate": 0.009612787449070933, "batch_size": 213, "loss": 0.0027108384389430283}, {"layer_params": [38, 40], "learning_rate": 0.00898315447178804, "batch_size": 130, "loss": 0.003103646042291075}, {"layer_params": [26, 32, 39, 44], "learning_rate": 0.004719269084210909, "batch_size": 226, "loss": 0.003353682835586369}, {"layer_params": [26, 32, 44], "learning_rate": 0.007445915574400492, "batch_size": 284, "loss": 0.001934399554738775}, {"layer_params": [32, 53, 36], "learning_rate": 0.00130084692917934, "batch_size": 104, "loss": 0.005657789180986583}, {"layer_params": [21, 19], "learning_rate": 0.009882229687827431, "batch_size": 178, "loss": 0.006933731674216688}, {"layer_params": [49, 22, 61, 44], "learning_rate": 0.0038898711287189184, "batch_size": 114, "loss": 0.003805671592708677}, {"layer_params": [41, 44, 54, 45, 62], "learning_rate": 0.006601325362289252, "batch_size": 430, "loss": 0.00117265316483099}, {"layer_params": [62, 29, 50], "learning_rate": 0.006413406641566914, "batch_size": 210, "loss": 0.0012936600449029356}, {"layer_params": [28, 19, 39, 17], "learning_rate": 0.008042875579573954, "batch_size": 16, "loss": 0.007703752696979791}, {"layer_params": [30, 56], "learning_rate": 0.005002985056354594, "batch_size": 410, "loss": 0.0019779249432031066}, {"layer_params": [35, 56], "learning_rate": 0.004330551286438572, "batch_size": 196, "loss": 0.001482627185760066}, {"layer_params": [51, 30, 16, 42], "learning_rate": 0.008029090325688028, "batch_size": 349, "loss": 0.0008525182632729411}, {"layer_params": [17, 33, 61, 48], "learning_rate": 0.0044136011989417395, "batch_size": 486, "loss": 0.0038227274385280907}, {"layer_params": [47, 27], "learning_rate": 0.0077575068461785785, "batch_size": 135, "loss": 0.003190670469775796}, {"layer_params": [52, 30, 28], "learning_rate": 0.0027710579979557306, "batch_size": 436, "loss": 0.0015821151866111905}, {"layer_params": [31, 58, 51], "learning_rate": 0.005688049555993268, "batch_size": 278, "loss": 0.001664421521127224}, {"layer_params": [38, 22, 18], "learning_rate": 0.0009073775285587659, "batch_size": 67, "loss": 0.007141661522909999}, {"layer_params": [56, 47, 30], "learning_rate": 0.003029114369085165, "batch_size": 232, "loss": 0.0014217244042083622}, {"layer_params": [60, 16, 58, 46, 53], "learning_rate": 0.006276419376766387, "batch_size": 309, "loss": 0.001271055755787529}, {"layer_params": [52, 30, 23, 27, 46], "learning_rate": 0.009243847932871965, "batch_size": 478, "loss": 0.0009528690634761005}, {"layer_params": [37, 45], "learning_rate": 0.008831696646811871, "batch_size": 132, "loss": 0.0037893501855432985}, {"layer_params": [27, 22, 49], "learning_rate": 0.0049410846378010985, "batch_size": 321, "loss": 0.002229778893524781}, {"layer_params": [34, 51, 52, 19, 22], "learning_rate": 0.004429511899524565, "batch_size": 477, "loss": 0.0014783349283970892}, {"layer_params": [16, 50, 33, 63], "learning_rate": 0.008566930449491476, "batch_size": 484, "loss": 0.0022374881489668043}, {"layer_params": [25, 62, 34], "learning_rate": 0.0029795463627160777, "batch_size": 141, "loss": 0.002794231058796868}, {"layer_params": [46, 43, 38], "learning_rate": 0.005745314569930678, "batch_size": 191, "loss": 0.0011728287750156596}, {"layer_params": [34, 25, 25, 63, 55], "learning_rate": 0.0015299676434740095, "batch_size": 145, "loss": 0.0029391447675880043}, {"layer_params": [27, 61, 56, 28, 19], "learning_rate": 0.0021888549173089957, "batch_size": 122, "loss": 0.004210339612327516}, {"layer_params": [59, 53, 60, 58, 56], "learning_rate": 0.003923930006501981, "batch_size": 46, "loss": 0.002799253115663305}, {"layer_params": [29, 22], "learning_rate": 0.004297406761788232, "batch_size": 337, "loss": 0.002990967051591724}, {"layer_params": [45, 45], "learning_rate": 0.0041891408491000065, "batch_size": 241, "loss": 0.0018990589736495166}, {"layer_params": [52, 61, 40], "learning_rate": 0.004307252640613093, "batch_size": 122, "loss": 0.001727690603584051}, {"layer_params": [53, 56, 28, 23, 37], "learning_rate": 0.0005371421793476611, "batch_size": 499, "loss": 0.0030345071433112024}, {"layer_params": [17, 59, 42, 40], "learning_rate": 0.0014294008305618918, "batch_size": 298, "loss": 0.0035793840466067195}, {"layer_params": [43, 60], "learning_rate": 0.007962631767727256, "batch_size": 85, "loss": 0.004472228281665594}, {"layer_params": [28, 44, 26, 45, 56], "learning_rate": 0.008268247896480407, "batch_size": 50, "loss": 0.005122967220377177}, {"layer_params": [52, 58], "learning_rate": 0.0020787619893929423, "batch_size": 271, "loss": 0.0018383628665469586}, {"layer_params": [62, 64], "learning_rate": 0.003266218299454815, "batch_size": 367, "loss": 0.0014614123839419334}, {"layer_params": [17, 22, 55, 38], "learning_rate": 0.0009430326007384249, "batch_size": 412, "loss": 0.005933503368869424}, {"layer_params": [40, 41, 24, 20, 30], "learning_rate": 0.007688935041308159, "batch_size": 206, "loss": 0.0018654287524987013}, {"layer_params": [32, 48, 49, 60], "learning_rate": 0.003488803351671375, "batch_size": 388, "loss": 0.001253742162953131}, {"layer_params": [19, 22], "learning_rate": 0.009726164845869955, "batch_size": 283, "loss": 0.0034574317187070847}, {"layer_params": [37, 50, 54, 33, 61], "learning_rate": 0.009915532018015052, "batch_size": 33, "loss": 0.005187177434563637}, {"layer_params": [30, 56, 28], "learning_rate": 0.00026078425837414507, "batch_size": 216, "loss": 0.0074508788716048}, {"layer_params": [55, 46], "learning_rate": 0.007141047663942747, "batch_size": 48, "loss": 0.0024573482549749316}, {"layer_params": [18, 27, 30, 19, 55], "learning_rate": 0.005589956229858724, "batch_size": 346, "loss": 0.0027410330483689906}, {"layer_params": [57, 46, 45, 62], "learning_rate": 0.00926096834718716, "batch_size": 144, "loss": 0.0011448328208643944}, {"layer_params": [21, 26, 20], "learning_rate": 0.001222071401893597, "batch_size": 68, "loss": 0.006691261259838939}, {"layer_params": [51, 20, 54, 60, 55], "learning_rate": 0.006425944214261647, "batch_size": 159, "loss": 0.0023763774801045657}, {"layer_params": [34, 46], "learning_rate": 0.0025299739765899196, "batch_size": 341, "loss": 0.002184592040721327}, {"layer_params": [60, 47, 32], "learning_rate": 0.0020660952464998353, "batch_size": 224, "loss": 0.002240397558780387}, {"layer_params": [36, 47, 38, 51], "learning_rate": 0.009022557471255159, "batch_size": 112, "loss": 0.0021702994988299904}, {"layer_params": [50, 42, 48], "learning_rate": 0.00412411267369858, "batch_size": 122, "loss": 0.0023365075746551154}, {"layer_params": [34, 22], "learning_rate": 0.008574386241331357, "batch_size": 372, "loss": 0.0024458614469040187}, {"layer_params": [61, 64, 46, 27], "learning_rate": 0.005204750925037093, "batch_size": 173, "loss": 0.0016978300840128212}, {"layer_params": [37, 60], "learning_rate": 0.007360952714271843, "batch_size": 303, "loss": 0.0022435580077581107}, {"layer_params": [28, 51], "learning_rate": 0.0018771742083772414, "batch_size": 214, "loss": 0.002919136844575405}, {"layer_params": [44, 26, 50, 21, 48], "learning_rate": 0.0017941836175439756, "batch_size": 20, "loss": 0.008021943063940853}, {"layer_params": [55, 33, 39, 36], "learning_rate": 0.0010345465680563536, "batch_size": 397, "loss": 0.0026629355433396996}, {"layer_params": [20, 45], "learning_rate": 0.004268835315185015, "batch_size": 281, "loss": 0.002465339624322951}, {"layer_params": [37, 31, 40, 38], "learning_rate": 0.0007293092914848661, "batch_size": 453, "loss": 0.004948449754156172}, {"layer_params": [36, 51, 53, 35, 44], "learning_rate": 0.0027606018741965885, "batch_size": 138, "loss": 0.002533625561045483}, {"layer_params": [57, 62, 16, 22], "learning_rate": 0.0042613253042251015, "batch_size": 84, "loss": 0.002154568174155429}, {"layer_params": [58, 25], "learning_rate": 0.004330198147701319, "batch_size": 395, "loss": 0.003013701813761145}, {"layer_params": [30, 39, 32, 38, 37], "learning_rate": 0.0007015573327358403, "batch_size": 48, "loss": 0.0077759269368834795}, {"layer_params": [42, 17], "learning_rate": 0.00948922066173051, "batch_size": 495, "loss": 0.002378572967136279}, {"layer_params": [39, 25, 64, 28, 50], "learning_rate": 0.0007954288879387334, "batch_size": 257, "loss": 0.004276452411431819}, {"layer_params": [62, 27, 43, 20], "learning_rate": 0.0014606748970962906, "batch_size": 159, "loss": 0.004473635540343821}, {"layer_params": [17, 64], "learning_rate": 0.005550742156627936, "batch_size": 431, "loss": 0.0030755312135443092}, {"layer_params": [43, 38, 41], "learning_rate": 0.0002417078778662399, "batch_size": 501, "loss": 0.0061137469299137595}, {"layer_params": [62, 45, 42], "learning_rate": 0.002140313956326531, "batch_size": 98, "loss": 0.002283115528989583}, {"layer_params": [54, 26, 45], "learning_rate": 0.006669217116598404, "batch_size": 385, "loss": 0.0014737498527392745}, {"layer_params": [52, 47, 26], "learning_rate": 0.002712003120899118, "batch_size": 444, "loss": 0.0017414603952784092}, {"layer_params": [46, 38], "learning_rate": 0.005644053199598453, "batch_size": 218, "loss": 0.002130696178646758}, {"layer_params": [16, 42, 42, 20, 48], "learning_rate": 0.009922664126466075, "batch_size": 512, "loss": 0.0028819416114129128}, {"layer_params": [23, 51], "learning_rate": 0.0058490472981582355, "batch_size": 54, "loss": 0.0064911592286080125}, {"layer_params": [31, 32, 56], "learning_rate": 0.001946243689727719, "batch_size": 130, "loss": 0.003714025621302426}, {"layer_params": [33, 44], "learning_rate": 0.004354223118481302, "batch_size": 242, "loss": 0.00236993653816171}, {"layer_params": [26, 52, 60], "learning_rate": 0.0022101382276553594, "batch_size": 362, "loss": 0.0011335198202868924}, {"layer_params": [52, 57], "learning_rate": 0.005918334369309967, "batch_size": 289, "loss": 0.0017105249641463161}, {"layer_params": [48, 34, 37], "learning_rate": 0.005549541132686179, "batch_size": 259, "loss": 0.0018943889392539859}, {"layer_params": [46, 39, 41, 33, 58], "learning_rate": 0.008698233249547186, "batch_size": 82, "loss": 0.002918162466958165}, {"layer_params": [45, 52, 54], "learning_rate": 0.009700777469662088, "batch_size": 429, "loss": 0.001727622572798282}, {"layer_params": [62, 20, 55, 30], "learning_rate": 0.007383364971281491, "batch_size": 122, "loss": 0.0017744277825113386}, {"layer_params": [50, 27, 56], "learning_rate": 0.00748920575942789, "batch_size": 306, "loss": 0.002365926232887432}, {"layer_params": [55, 41, 58, 37], "learning_rate": 0.0036600630262288323, "batch_size": 360, "loss": 0.0011556838476099074}, {"layer_params": [17, 63, 49, 46, 19], "learning_rate": 0.000576015901236772, "batch_size": 343, "loss": 0.004756541906390339}, {"layer_params": [44, 56, 43, 46], "learning_rate": 0.00033275978050536007, "batch_size": 230, "loss": 0.005534310950897634}, {"layer_params": [44, 26, 21], "learning_rate": 0.00871657943472617, "batch_size": 18, "loss": 0.008976301564835011}, {"layer_params": [19, 31], "learning_rate": 0.005656189563975038, "batch_size": 435, "loss": 0.0037249096692539754}, {"layer_params": [32, 47, 30, 50, 37], "learning_rate": 0.0047202722857281245, "batch_size": 438, "loss": 0.001252332617295906}, {"layer_params": [17, 33, 57], "learning_rate": 0.006773242143762871, "batch_size": 128, "loss": 0.003478108202107251}, {"layer_params": [55, 46, 32], "learning_rate": 0.00348413398694098, "batch_size": 101, "loss": 0.00260903580696322}, {"layer_params": [39, 46, 64, 55], "learning_rate": 0.006368111838877726, "batch_size": 303, "loss": 0.0011317628814140335}, {"layer_params": [48, 44, 29, 53, 36], "learning_rate": 0.006931376005661571, "batch_size": 172, "loss": 0.0018393525516148656}, {"layer_params": [25, 51, 53, 43, 53], "learning_rate": 0.004596673378038434, "batch_size": 291, "loss": 0.0010684199677780271}, {"layer_params": [34, 45], "learning_rate": 0.0058784133445562185, "batch_size": 370, "loss": 0.001524119992973283}, {"layer_params": [25, 64, 38, 28, 20], "learning_rate": 0.007686549636198121, "batch_size": 504, "loss": 0.0015187777567189187}, {"layer_params": [31, 36], "learning_rate": 0.008827076035720038, "batch_size": 266, "loss": 0.0026839511026628318}, {"layer_params": [59, 60, 38, 38, 37], "learning_rate": 0.007193384504125869, "batch_size": 196, "loss": 0.0014641406561713667}, {"layer_params": [34, 47, 32], "learning_rate": 0.008678440852493037, "batch_size": 144, "loss": 0.0013239572534803302}, {"layer_params": [39, 41], "learning_rate": 0.0017954076652203096, "batch_size": 25, "loss": 0.006559616927988827}, {"layer_params": [55, 58, 16, 56, 52], "learning_rate": 0.002351066818665495, "batch_size": 509, "loss": 0.0016709299897775054}, {"layer_params": [53, 53, 54, 57, 44], "learning_rate": 0.0022851722263974397, "batch_size": 57, "loss": 0.003846130173187703}, {"layer_params": [40, 22, 20], "learning_rate": 0.004239453415957718, "batch_size": 274, "loss": 0.0038983735418878494}, {"layer_params": [63, 25, 30], "learning_rate": 0.003920051633880417, "batch_size": 417, "loss": 0.0016768930095713585}, {"layer_params": [36, 24, 61, 56], "learning_rate": 0.008182577628185911, "batch_size": 287, "loss": 0.0021510251553263516}, {"layer_params": [44, 59, 17], "learning_rate": 0.0025904620335496504, "batch_size": 476, "loss": 0.002884813412092626}, {"layer_params": [46, 22, 37, 55], "learning_rate": 0.002167094585899002, "batch_size": 420, "loss": 0.0019418532261624931}, {"layer_params": [35, 17, 26, 50, 45], "learning_rate": 0.007587545077263056, "batch_size": 203, "loss": 0.003997048728633672}, {"layer_params": [48, 26, 38, 39], "learning_rate": 0.003363299040381936, "batch_size": 238, "loss": 0.0017335815145634115}, {"layer_params": [30, 40, 44, 18, 44], "learning_rate": 0.007376602956700912, "batch_size": 315, "loss": 0.0019631229958031325}, {"layer_params": [61, 46], "learning_rate": 0.0034952444774841176, "batch_size": 352, "loss": 0.0021343597071245314}, {"layer_params": [36, 19], "learning_rate": 0.0022377571394935317, "batch_size": 57, "loss": 0.0063375307223759595}, {"layer_params": [47, 43, 22], "learning_rate": 0.00852464005361393, "batch_size": 415, "loss": 0.0022058648173697293}, {"layer_params": [56, 57], "learning_rate": 0.004429593416968359, "batch_size": 355, "loss": 0.0017380630283150822}, {"layer_params": [63, 46], "learning_rate": 0.008894986708745004, "batch_size": 306, "loss": 0.001879003852372989}, {"layer_params": [52, 23, 27, 23], "learning_rate": 0.009714290519681262, "batch_size": 410, "loss": 0.0027048620674759148}, {"layer_params": [64, 63, 56, 42], "learning_rate": 0.005627884410935947, "batch_size": 332, "loss": 0.0008744429692160338}, {"layer_params": [59, 56, 55], "learning_rate": 0.006263209241567256, "batch_size": 480, "loss": 0.0010433124704286457}, {"layer_params": [45, 35], "learning_rate": 0.0006674653079301633, "batch_size": 248, "loss": 0.007444433099590242}, {"layer_params": [32, 28, 39, 59, 17], "learning_rate": 0.0036171803815173765, "batch_size": 423, "loss": 0.002617927792016417}, {"layer_params": [16, 23], "learning_rate": 0.005664326385968755, "batch_size": 376, "loss": 0.0057442380394786595}, {"layer_params": [46, 28, 31, 28, 43], "learning_rate": 0.007226858828489589, "batch_size": 474, "loss": 0.0017868665477726608}, {"layer_params": [47, 57, 41, 37], "learning_rate": 0.001304623903447148, "batch_size": 479, "loss": 0.001465643383562565}, {"layer_params": [57, 28], "learning_rate": 0.007719740831207011, "batch_size": 356, "loss": 0.001492221374064684}, {"layer_params": [31, 17], "learning_rate": 0.004168726205932746, "batch_size": 431, "loss": 0.0028808497684076426}, {"layer_params": [25, 26], "learning_rate": 0.00046288089915142084, "batch_size": 217, "loss": 0.009875049265101552}, {"layer_params": [32, 58, 22], "learning_rate": 0.009730289270730165, "batch_size": 429, "loss": 0.0015571049554273487}, {"layer_params": [24, 59, 62], "learning_rate": 0.0026608417130981293, "batch_size": 454, "loss": 0.0011472688434878363}, {"layer_params": [47, 26, 42], "learning_rate": 0.007104336853909789, "batch_size": 479, "loss": 0.002125307929236442}, {"layer_params": [36, 42, 48], "learning_rate": 0.005751904426768069, "batch_size": 143, "loss": 0.0015449397685006261}, {"layer_params": [24, 53, 28, 21, 62], "learning_rate": 0.005824272277420968, "batch_size": 165, "loss": 0.002316664312966168}, {"layer_params": [46, 43, 40, 41, 54], "learning_rate": 0.0013996602683901851, "batch_size": 444, "loss": 0.001834416901692748}, {"layer_params": [32, 28, 54], "learning_rate": 0.004457298186014545, "batch_size": 496, "loss": 0.002126528831431642}, {"layer_params": [50, 61], "learning_rate": 0.0007296484266969807, "batch_size": 86, "loss": 0.006556925610639155}, {"layer_params": [42, 53, 18], "learning_rate": 0.0024789653914501267, "batch_size": 72, "loss": 0.0040659071179106835}, {"layer_params": [18, 56], "learning_rate": 0.00893420963433812, "batch_size": 107, "loss": 0.0032809759373776614}, {"layer_params": [35, 57, 22, 38, 32], "learning_rate": 0.005866926340452441, "batch_size": 366, "loss": 0.0009608518244931475}, {"layer_params": [21, 57, 62], "learning_rate": 0.00879609100105649, "batch_size": 479, "loss": 0.0013139764487277716}, {"layer_params": [33, 57, 57, 60, 58], "learning_rate": 0.008523780136656691, "batch_size": 428, "loss": 0.0013874795695301145}, {"layer_params": [39, 58, 54], "learning_rate": 0.0017378994902797018, "batch_size": 367, "loss": 0.0016693306027445942}, {"layer_params": [35, 33, 35], "learning_rate": 0.004149793933132578, "batch_size": 16, "loss": 0.006375097380951047}, {"layer_params": [31, 48, 43, 56], "learning_rate": 0.0088373770764804, "batch_size": 87, "loss": 0.003259483468718827}, {"layer_params": [37, 20, 39], "learning_rate": 0.009121147854772941, "batch_size": 292, "loss": 0.002723107973579317}, {"layer_params": [25, 54, 47, 40], "learning_rate": 0.004201155494826541, "batch_size": 115, "loss": 0.002444547928171232}, {"layer_params": [54, 57], "learning_rate": 0.0028416551419154046, "batch_size": 276, "loss": 0.0013740114658139645}, {"layer_params": [33, 54, 17], "learning_rate": 0.003230066592040291, "batch_size": 141, "loss": 0.0030905227619223295}, {"layer_params": [63, 22, 28], "learning_rate": 0.008137875619770571, "batch_size": 101, "loss": 0.003093570820055902}, {"layer_params": [16, 46, 47, 28, 44], "learning_rate": 0.007425305585452362, "batch_size": 491, "loss": 0.0018028708279598505}, {"layer_params": [62, 44, 61, 41], "learning_rate": 0.001659774762700748, "batch_size": 396, "loss": 0.001512274054111913}, {"layer_params": [57, 48, 45, 38], "learning_rate": 0.004038514129259361, "batch_size": 499, "loss": 0.0010401437361724675}, {"layer_params": [19, 47, 57, 48], "learning_rate": 0.005928041860538302, "batch_size": 120, "loss": 0.003844087177421898}, {"layer_params": [44, 41, 62, 58, 18], "learning_rate": 0.00416467092727658, "batch_size": 444, "loss": 0.0011092722229659557}, {"layer_params": [30, 58, 33, 56], "learning_rate": 0.005982545637728769, "batch_size": 22, "loss": 0.005787505032494664}, {"layer_params": [20, 51, 49, 20], "learning_rate": 0.0021436723607261587, "batch_size": 224, "loss": 0.0026009726873598995}, {"layer_params": [36, 19, 40, 43, 44], "learning_rate": 0.0043790882584647485, "batch_size": 340, "loss": 0.0023576412396505474}, {"layer_params": [52, 33, 43, 59, 61], "learning_rate": 0.00601541301246839, "batch_size": 173, "loss": 0.0014977175614330918}, {"layer_params": [20, 16, 25, 40, 34], "learning_rate": 0.0027600801049410986, "batch_size": 262, "loss": 0.003645319563802332}, {"layer_params": [41, 38, 57, 45], "learning_rate": 0.0026241004216381474, "batch_size": 163, "loss": 0.0017462237854488194}, {"layer_params": [58, 42, 61, 30, 45], "learning_rate": 0.000832350093868627, "batch_size": 182, "loss": 0.002769547984935343}, {"layer_params": [47, 46, 27], "learning_rate": 0.007275208062851205, "batch_size": 247, "loss": 0.0013974085153313353}, {"layer_params": [62, 33], "learning_rate": 0.001408611496853493, "batch_size": 65, "loss": 0.005726824295707047}, {"layer_params": [26, 53, 49, 32], "learning_rate": 0.00021245377198527633, "batch_size": 298, "loss": 0.0069655161630362275}, {"layer_params": [47, 35], "learning_rate": 0.002392589743102497, "batch_size": 272, "loss": 0.002429375562351197}, {"layer_params": [55, 29], "learning_rate": 0.008851611842045906, "batch_size": 380, "loss": 0.003227326404303312}, {"layer_params": [26, 57, 53, 59], "learning_rate": 0.007430280816653546, "batch_size": 249, "loss": 0.0021104078111238776}, {"layer_params": [34, 21, 16, 52, 23], "learning_rate": 0.009037283713007653, "batch_size": 413, "loss": 0.002223996705142781}, {"layer_params": [19, 17, 35, 17], "learning_rate": 0.004740567510107629, "batch_size": 483, "loss": 0.004037829751614481}, {"layer_params": [31, 59, 54, 19], "learning_rate": 0.002718489516479609, "batch_size": 225, "loss": 0.002212324603460729}, {"layer_params": [51, 41, 22, 41, 53], "learning_rate": 0.009898966232820825, "batch_size": 418, "loss": 0.0018577590747736394}, {"layer_params": [21, 43, 61, 23], "learning_rate": 0.0028882470669798804, "batch_size": 111, "loss": 0.002970426413230598}, {"layer_params": [38, 58, 62, 21, 44], "learning_rate": 0.009072514424093603, "batch_size": 501, "loss": 0.0013522771489806473}, {"layer_params": [33, 24, 59, 64, 57], "learning_rate": 0.0012680355808719309, "batch_size": 377, "loss": 0.002326363433385268}, {"layer_params": [28, 54, 39, 55, 27], "learning_rate": 0.00931862745823946, "batch_size": 268, "loss": 0.002115018604090437}, {"layer_params": [21, 41, 16], "learning_rate": 0.005877912109043411, "batch_size": 179, "loss": 0.0022609304124489426}, {"layer_params": [27, 63, 63, 33, 48], "learning_rate": 0.0007680832869931402, "batch_size": 333, "loss": 0.0023645350080914794}, {"layer_params": [47, 37], "learning_rate": 0.007879242321215433, "batch_size": 235, "loss": 0.0019585628947243095}, {"layer_params": [30, 57, 19, 54], "learning_rate": 0.0016735803697660774, "batch_size": 477, "loss": 0.0027095242077484726}, {"layer_params": [38, 39, 26], "learning_rate": 0.001828994979020293, "batch_size": 69, "loss": 0.005687657122034579}, {"layer_params": [42, 51, 28, 40], "learning_rate": 0.009818723971271587, "batch_size": 119, "loss": 0.003047949131578207}, {"layer_params": [22, 34, 63, 53, 59], "learning_rate": 0.0033663986334322793, "batch_size": 484, "loss": 0.0020851828285958617}, {"layer_params": [35, 40, 16], "learning_rate": 0.001518953517107965, "batch_size": 364, "loss": 0.0043308336287736894}, {"layer_params": [40, 64, 39], "learning_rate": 0.00017638895943794343, "batch_size": 505, "loss": 0.0082596343010664}, {"layer_params": [32, 63], "learning_rate": 0.005361508490488271, "batch_size": 397, "loss": 0.0020371449971571566}, {"layer_params": [42, 42], "learning_rate": 0.000831612282596249, "batch_size": 328, "loss": 0.0061871010670438405}, {"layer_params": [32, 52, 25, 55, 59], "learning_rate": 0.008544118979090107, "batch_size": 300, "loss": 0.0024621684290468695}, {"layer_params": [41, 36, 34], "learning_rate": 0.008849932991636075, "batch_size": 448, "loss": 0.0016392879630438984}, {"layer_params": [16, 27], "learning_rate": 0.006869669225767463, "batch_size": 108, "loss": 0.005855592954903841}, {"layer_params": [53, 16, 44, 32], "learning_rate": 0.00875249183180085, "batch_size": 148, "loss": 0.0027029390772804617}, {"layer_params": [27, 41], "learning_rate": 0.0037677707941539576, "batch_size": 391, "loss": 0.003334405883215368}, {"layer_params": [35, 40], "learning_rate": 0.008581851157466708, "batch_size": 477, "loss": 0.0017302226368337869}, {"layer_params": [22, 44, 62, 32], "learning_rate": 0.009181619039984932, "batch_size": 317, "loss": 0.0019445684482343494}, {"layer_params": [28, 55], "learning_rate": 0.008986158254393, "batch_size": 232, "loss": 0.002189495814964175}, {"layer_params": [60, 59, 39, 33], "learning_rate": 0.007334284967556177, "batch_size": 283, "loss": 0.0012299915903713555}, {"layer_params": [33, 31], "learning_rate": 0.00889170771999731, "batch_size": 18, "loss": 0.00792171087116003}, {"layer_params": [48, 30, 50], "learning_rate": 0.009348945211271605, "batch_size": 138, "loss": 0.0027132480591535568}, {"layer_params": [36, 36, 27], "learning_rate": 0.0010563128855033514, "batch_size": 512, "loss": 0.0029324736376293}, {"layer_params": [63, 26, 64], "learning_rate": 0.006863454060515728, "batch_size": 115, "loss": 0.0018257513036951422}, {"layer_params": [57, 38], "learning_rate": 0.006605741774646887, "batch_size": 421, "loss": 0.0019200193625874818}, {"layer_params": [47, 58], "learning_rate": 0.007644830995450539, "batch_size": 78, "loss": 0.002184989482630044}, {"layer_params": [46, 56, 62, 45], "learning_rate": 0.008434656625046267, "batch_size": 360, "loss": 0.0008450354140950366}, {"layer_params": [24, 64, 63, 52, 58], "learning_rate": 0.000841928724233136, "batch_size": 72, "loss": 0.0049660403234884146}, {"layer_params": [31, 25], "learning_rate": 0.009429158692204728, "batch_size": 131, "loss": 0.0050724966474808755}, {"layer_params": [37, 23, 29, 35], "learning_rate": 0.0017768953415610294, "batch_size": 445, "loss": 0.0027024976862594485}, {"layer_params": [53, 58], "learning_rate": 0.00875005956202575, "batch_size": 263, "loss": 0.0022846085869241504}, {"layer_params": [56, 48, 57], "learning_rate": 0.006653805147580639, "batch_size": 480, "loss": 0.0010734594718087465}, {"layer_params": [30, 38, 31, 32], "learning_rate": 0.004443070982646684, "batch_size": 387, "loss": 0.0021685142617207023}, {"layer_params": [35, 56, 29, 40], "learning_rate": 0.005306722881949118, "batch_size": 115, "loss": 0.0015548369567841291}, {"layer_params": [41, 56, 26, 43, 43], "learning_rate": 0.007680143995879221, "batch_size": 142, "loss": 0.0017699134303256869}, {"layer_params": [50, 34, 60], "learning_rate": 0.0048699122448991146, "batch_size": 392, "loss": 0.0011807341309031472}, {"layer_params": [43, 58, 45, 40], "learning_rate": 0.0022618838096745268, "batch_size": 276, "loss": 0.0016037529730238021}, {"layer_params": [26, 49, 44], "learning_rate": 0.006178172965997218, "batch_size": 283, "loss": 0.003193209026940167}, {"layer_params": [29, 37], "learning_rate": 0.004508772337695927, "batch_size": 160, "loss": 0.0021242459525819867}, {"layer_params": [35, 39], "learning_rate": 0.006422486256560486, "batch_size": 94, "loss": 0.0024228399735875426}, {"layer_params": [41, 21, 21, 51, 54], "learning_rate": 0.002597283225601353, "batch_size": 398, "loss": 0.002048707513604313}, {"layer_params": [42, 57], "learning_rate": 0.0019934832614177224, "batch_size": 304, "loss": 0.0021828446700237693}, {"layer_params": [41, 53], "learning_rate": 0.0033653344028580713, "batch_size": 201, "loss": 0.0025594486424233764}, {"layer_params": [16, 24], "learning_rate": 0.008300716123260945, "batch_size": 285, "loss": 0.007047291821800172}, {"layer_params": [33, 27, 58, 62], "learning_rate": 0.008494282812036255, "batch_size": 259, "loss": 0.002321283281780779}, {"layer_params": [59, 29, 63, 26, 35], "learning_rate": 0.006156151231419811, "batch_size": 40, "loss": 0.004546114075928927}, {"layer_params": [16, 58, 38, 21], "learning_rate": 0.0015632870436900108, "batch_size": 446, "loss": 0.0035061305738054217}, {"layer_params": [54, 16, 24], "learning_rate": 0.006616455799259521, "batch_size": 226, "loss": 0.003002032877411693}, {"layer_params": [21, 56, 47, 43, 30], "learning_rate": 0.001304032521909867, "batch_size": 162, "loss": 0.004043092308565974}, {"layer_params": [64, 33, 33, 64], "learning_rate": 0.003985291587230702, "batch_size": 149, "loss": 0.0020808869297616185}, {"layer_params": [39, 37, 63], "learning_rate": 0.00539232920467958, "batch_size": 421, "loss": 0.0015994524373672903}, {"layer_params": [26, 20, 36], "learning_rate": 0.004335557686988987, "batch_size": 264, "loss": 0.004067883267998696}, {"layer_params": [34, 53, 29, 22, 35], "learning_rate": 0.007238796859582412, "batch_size": 185, "loss": 0.0018961475265678019}, {"layer_params": [28, 49], "learning_rate": 0.0024520409602691545, "batch_size": 168, "loss": 0.0029118853248655797}, {"layer_params": [44, 25, 26, 42], "learning_rate": 0.0032408408770694336, "batch_size": 263, "loss": 0.0025961241754703223}, {"layer_params": [51, 16, 52, 55], "learning_rate": 0.0064756171650799076, "batch_size": 121, "loss": 0.0031755053752567618}, {"layer_params": [51, 28, 21], "learning_rate": 0.004047581826958364, "batch_size": 256, "loss": 0.0016064610495232045}, {"layer_params": [57, 55], "learning_rate": 0.004128332635769631, "batch_size": 323, "loss": 0.001811432648682967}, {"layer_params": [58, 44, 57, 61, 42], "learning_rate": 0.007876533777095908, "batch_size": 453, "loss": 0.0012466391979251057}, {"layer_params": [32, 32, 22, 47, 25], "learning_rate": 0.0068163471828686555, "batch_size": 394, "loss": 0.0013274969719350338}, {"layer_params": [50, 51], "learning_rate": 0.001216343209689039, "batch_size": 187, "loss": 0.0036701015196740627}, {"layer_params": [58, 61, 49, 30, 27], "learning_rate": 0.008421197103526208, "batch_size": 289, "loss": 0.0009084837429691106}, {"layer_params": [24, 42, 50], "learning_rate": 0.00818425356827838, "batch_size": 151, "loss": 0.0025869940989650788}, {"layer_params": [37, 47], "learning_rate": 0.00534879504739738, "batch_size": 308, "loss": 0.002310534343123436}, {"layer_params": [62, 52, 57], "learning_rate": 0.004566023456954567, "batch_size": 450, "loss": 0.0008237322862260044}, {"layer_params": [20, 28, 53, 61], "learning_rate": 0.004896479420091806, "batch_size": 473, "loss": 0.0021405410673469307}, {"layer_params": [26, 38], "learning_rate": 0.007524034018026381, "batch_size": 314, "loss": 0.00354863912332803}, {"layer_params": [53, 55, 61], "learning_rate": 0.0014963294138323673, "batch_size": 127, "loss": 0.003130726907402277}, {"layer_params": [44, 45, 21], "learning_rate": 0.004523510731062049, "batch_size": 171, "loss": 0.0017481907410547136}, {"layer_params": [52, 34, 51, 19], "learning_rate": 0.006019161921284627, "batch_size": 128, "loss": 0.002034323624102399}, {"layer_params": [23, 44, 38, 63, 38], "learning_rate": 0.0017127271832488903, "batch_size": 229, "loss": 0.003495622386690229}, {"layer_params": [16, 37, 44, 45, 17], "learning_rate": 0.0049838372073943826, "batch_size": 287, "loss": 0.002360574349295348}, {"layer_params": [55, 49], "learning_rate": 0.005781991700958614, "batch_size": 403, "loss": 0.001300391461700201}, {"layer_params": [21, 43], "learning_rate": 0.0037480876311155467, "batch_size": 25, "loss": 0.006424073572270572}, {"layer_params": [21, 51, 22, 51, 38], "learning_rate": 0.008421031583635684, "batch_size": 502, "loss": 0.0012935829366324469}, {"layer_params": [49, 34, 39, 61, 22], "learning_rate": 0.0005360709548140006, "batch_size": 45, "loss": 0.006830313105601817}, {"layer_params": [57, 59, 47, 62, 40], "learning_rate": 0.007262854748448254, "batch_size": 150, "loss": 0.0014343951584305614}, {"layer_params": [64, 29, 36], "learning_rate": 0.00025337385357897274, "batch_size": 120, "loss": 0.008600716451182962}, {"layer_params": [28, 19, 38, 18], "learning_rate": 0.0021414547197583546, "batch_size": 283, "loss": 0.002597070861374959}, {"layer_params": [59, 39, 17], "learning_rate": 0.001663095835184497, "batch_size": 56, "loss": 0.004258487632032484}, {"layer_params": [27, 29], "learning_rate": 0.002004927871598607, "batch_size": 370, "loss": 0.0038123068399727343}, {"layer_params": [41, 45, 45], "learning_rate": 0.003097831372411549, "batch_size": 107, "loss": 0.0022635575069580227}, {"layer_params": [38, 48, 47], "learning_rate": 0.007332355339740618, "batch_size": 472, "loss": 0.0013772116065956651}, {"layer_params": [60, 49, 47, 18], "learning_rate": 0.008051362767823677, "batch_size": 411, "loss": 0.00107994272664655}, {"layer_params": [16, 47], "learning_rate": 0.00788507060010985, "batch_size": 151, "loss": 0.004203646020032465}, {"layer_params": [55, 33], "learning_rate": 0.008088877997748623, "batch_size": 303, "loss": 0.0016965712571982295}, {"layer_params": [51, 38, 61, 54, 50], "learning_rate": 0.0077137582922693045, "batch_size": 455, "loss": 0.001598510347539559}, {"layer_params": [48, 43, 47, 58, 44], "learning_rate": 0.008139239452239135, "batch_size": 23, "loss": 0.006887125836219639}, {"layer_params": [26, 53, 21, 59, 63], "learning_rate": 0.004908376798309102, "batch_size": 169, "loss": 0.0020395389769691974}, {"layer_params": [48, 51, 56, 39, 43], "learning_rate": 0.005206035747978105, "batch_size": 65, "loss": 0.0029377403983380647}, {"layer_params": [39, 59, 26], "learning_rate": 0.008262510031168815, "batch_size": 305, "loss": 0.0012414661387447267}, {"layer_params": [47, 44], "learning_rate": 0.0074704538943415714, "batch_size": 429, "loss": 0.0012768942618276923}, {"layer_params": [23, 25, 23, 51], "learning_rate": 0.005991776723636083, "batch_size": 58, "loss": 0.005302968889009207}, {"layer_params": [36, 60, 31], "learning_rate": 0.0019478980490294216, "batch_size": 399, "loss": 0.0020482712937518956}, {"layer_params": [36, 56], "learning_rate": 0.004843048659495353, "batch_size": 106, "loss": 0.0029155487474054097}, {"layer_params": [17, 37], "learning_rate": 0.0038382248960167685, "batch_size": 58, "loss": 0.005110031862277538}, {"layer_params": [63, 48, 51, 29], "learning_rate": 0.002712521873745128, "batch_size": 496, "loss": 0.0010110620822524651}, {"layer_params": [41, 27], "learning_rate": 0.008358847332426055, "batch_size": 327, "loss": 0.0011112965969368816}, {"layer_params": [30, 25, 16, 58], "learning_rate": 0.008271465150499074, "batch_size": 36, "loss": 0.03820529090240598}, {"layer_params": [45, 53, 38, 41], "learning_rate": 0.003433398386195056, "batch_size": 349, "loss": 0.0009711756289470941}, {"layer_params": [46, 46, 53], "learning_rate": 0.005164668343460688, "batch_size": 464, "loss": 0.0013669083942659198}, {"layer_params": [43, 62, 55, 48, 45], "learning_rate": 0.009921507016119628, "batch_size": 303, "loss": 0.0014588778093457223}, {"layer_params": [64, 37, 54, 30, 47], "learning_rate": 0.0023054395591497845, "batch_size": 285, "loss": 0.0010384657909162343}, {"layer_params": [62, 31, 16], "learning_rate": 0.009093546698315679, "batch_size": 402, "loss": 0.002197169769788161}, {"layer_params": [22, 27], "learning_rate": 0.00017970237930716384, "batch_size": 81, "loss": 0.032271176278591156}, {"layer_params": [29, 33], "learning_rate": 0.003035657795050007, "batch_size": 460, "loss": 0.002905070446431637}, {"layer_params": [55, 30, 47], "learning_rate": 0.007912897129453663, "batch_size": 143, "loss": 0.001228405741858296}, {"layer_params": [52, 45, 35, 18], "learning_rate": 0.00920942790457341, "batch_size": 192, "loss": 0.0016904608893673868}, {"layer_params": [34, 56, 25, 41, 19], "learning_rate": 0.0012148904693663697, "batch_size": 387, "loss": 0.002688592951744795}, {"layer_params": [57, 39, 27], "learning_rate": 0.007730450645287733, "batch_size": 317, "loss": 0.001081627556704916}, {"layer_params": [63, 29, 39], "learning_rate": 0.00012893262451116878, "batch_size": 309, "loss": 0.008445114879868924}, {"layer_params": [40, 56], "learning_rate": 0.003910893491747025, "batch_size": 398, "loss": 0.0012828771909698844}, {"layer_params": [35, 43, 27, 55], "learning_rate": 0.008132290192107417, "batch_size": 45, "loss": 0.0054479709081351755}, {"layer_params": [64, 48, 32, 62], "learning_rate": 0.003457866961332963, "batch_size": 344, "loss": 0.0010164611105574295}, {"layer_params": [47, 37, 48, 64, 53], "learning_rate": 0.007025273890214384, "batch_size": 387, "loss": 0.0013595010770950466}, {"layer_params": [53, 37], "learning_rate": 0.0031841628138669646, "batch_size": 92, "loss": 0.0032358535029925408}, {"layer_params": [54, 17, 46, 31], "learning_rate": 0.005012259953674278, "batch_size": 371, "loss": 0.0027849956252612175}, {"layer_params": [62, 19, 52, 29], "learning_rate": 0.005261084743373655, "batch_size": 373, "loss": 0.001912208287976682}, {"layer_params": [49, 18, 60, 55], "learning_rate": 0.008833662203890511, "batch_size": 21, "loss": 0.009761236172635109}, {"layer_params": [51, 29, 17, 22, 24], "learning_rate": 0.0013941194483968638, "batch_size": 102, "loss": 0.005386537413578481}, {"layer_params": [28, 27, 39, 62, 22], "learning_rate": 0.009845807946533629, "batch_size": 22, "loss": 0.008780600016470998}, {"layer_params": [61, 19, 17, 38], "learning_rate": 0.0074021733822533745, "batch_size": 208, "loss": 0.001683311351807788}, {"layer_params": [24, 17, 47, 38, 42], "learning_rate": 0.00697707083257308, "batch_size": 475, "loss": 0.003116984327789396}, {"layer_params": [43, 55, 36, 17, 54], "learning_rate": 0.004735575071317738, "batch_size": 416, "loss": 0.0012069573299959301}, {"layer_params": [23, 22], "learning_rate": 0.008637070427469326, "batch_size": 270, "loss": 0.005571068678982556}, {"layer_params": [52, 27, 22, 16], "learning_rate": 0.009598380615652848, "batch_size": 236, "loss": 0.0023949381068814547}, {"layer_params": [40, 24, 33, 42, 28], "learning_rate": 0.006202951719896187, "batch_size": 219, "loss": 0.0034436905849725007}, {"layer_params": [33, 44], "learning_rate": 0.00899170600936912, "batch_size": 385, "loss": 0.0019383307790849357}, {"layer_params": [26, 18, 34, 28, 47], "learning_rate": 0.003360931011669895, "batch_size": 278, "loss": 0.004248052253387868}, {"layer_params": [25, 50, 32, 24], "learning_rate": 0.0025370339838562623, "batch_size": 407, "loss": 0.001949639826780185}, {"layer_params": [49, 38], "learning_rate": 0.004515602950891213, "batch_size": 138, "loss": 0.00157354234426748}, {"layer_params": [59, 30, 62, 34], "learning_rate": 0.005111277641270982, "batch_size": 381, "loss": 0.001793093371670693}, {"layer_params": [28, 49, 16, 43, 60], "learning_rate": 0.008318468860357715, "batch_size": 50, "loss": 0.006192726334556937}, {"layer_params": [19, 46], "learning_rate": 0.00964891704038254, "batch_size": 148, "loss": 0.003721804094966501}, {"layer_params": [40, 43, 51, 37], "learning_rate": 0.008995910625885499, "batch_size": 180, "loss": 0.001913427186664194}, {"layer_params": [34, 41, 49, 62], "learning_rate": 0.00012465321744833312, "batch_size": 224, "loss": 0.014933024095371365}, {"layer_params": [38, 46, 29], "learning_rate": 0.0036285713583939522, "batch_size": 399, "loss": 0.0027529654861427845}, {"layer_params": [17, 63, 60, 34, 22], "learning_rate": 0.0038604484394143125, "batch_size": 336, "loss": 0.002728058323264122}, {"layer_params": [54, 34, 19], "learning_rate": 0.0063674129871423004, "batch_size": 409, "loss": 0.0018869065504986792}, {"layer_params": [26, 21], "learning_rate": 0.00010559109017639203, "batch_size": 119, "loss": 0.03653310121968389}, {"layer_params": [58, 24, 51], "learning_rate": 0.0013912694825333686, "batch_size": 488, "loss": 0.003342116966377944}, {"layer_params": [47, 29], "learning_rate": 0.0033836033911933167, "batch_size": 125, "loss": 0.004202657137066126}, {"layer_params": [23, 27, 29, 24], "learning_rate": 0.00262139569987818, "batch_size": 192, "loss": 0.003207400068640709}, {"layer_params": [26, 54], "learning_rate": 0.009235935523923792, "batch_size": 16, "loss": 0.008663523201830685}, {"layer_params": [24, 52], "learning_rate": 0.006544696413586636, "batch_size": 164, "loss": 0.0023017632111441344}, {"layer_params": [64, 16], "learning_rate": 0.0020580391084292536, "batch_size": 35, "loss": 0.007052337941713631}, {"layer_params": [60, 17, 56], "learning_rate": 0.009426415455164209, "batch_size": 18, "loss": 0.006610659689176828}, {"layer_params": [63, 46, 47, 48], "learning_rate": 0.008780427885286424, "batch_size": 374, "loss": 0.0011012169340392575}, {"layer_params": [22, 54, 56], "learning_rate": 0.008391548574767566, "batch_size": 479, "loss": 0.001181513579795137}, {"layer_params": [32, 26, 56, 40, 49], "learning_rate": 0.005493367559233796, "batch_size": 474, "loss": 0.0018712261214386672}, {"layer_params": [55, 61, 35, 60], "learning_rate": 0.0026206829508673263, "batch_size": 448, "loss": 0.0013889803434722126}, {"layer_params": [23, 21, 59, 55, 30], "learning_rate": 0.0013994160900748418, "batch_size": 95, "loss": 0.006536449920386076}, {"layer_params": [55, 43, 25, 46], "learning_rate": 0.007372434727644612, "batch_size": 389, "loss": 0.001976486931089312}, {"layer_params": [19, 42, 44, 29, 23], "learning_rate": 0.0023807393540740043, "batch_size": 254, "loss": 0.003721089598257095}, {"layer_params": [18, 49, 25, 55, 42], "learning_rate": 0.0055275692070966016, "batch_size": 410, "loss": 0.002000611132243648}, {"layer_params": [40, 43, 49, 56], "learning_rate": 0.0037719403904117885, "batch_size": 288, "loss": 0.0012932757067028434}, {"layer_params": [52, 33], "learning_rate": 0.00754954489190563, "batch_size": 296, "loss": 0.00129727489373181}, {"layer_params": [19, 29, 36, 18], "learning_rate": 0.006643691285255096, "batch_size": 311, "loss": 0.0033409823011606933}, {"layer_params": [26, 49], "learning_rate": 0.0030885832484736564, "batch_size": 261, "loss": 0.0024358639970887453}, {"layer_params": [32, 35, 64], "learning_rate": 0.007271781570403275, "batch_size": 493, "loss": 0.0010779839247697964}, {"layer_params": [26, 34, 36], "learning_rate": 0.009851985276175208, "batch_size": 339, "loss": 0.001963315479224548}, {"layer_params": [48, 22, 63], "learning_rate": 0.0010905884749368958, "batch_size": 391, "loss": 0.002268704503076151}, {"layer_params": [25, 20, 54, 31, 17], "learning_rate": 0.008068264088108682, "batch_size": 384, "loss": 0.0020235694106668233}, {"layer_params": [62, 33], "learning_rate": 0.004332618223604777, "batch_size": 384, "loss": 0.0030484868958592414}, {"layer_params": [27, 62, 48, 61, 60], "learning_rate": 0.0068620969309677714, "batch_size": 31, "loss": 0.005565635962411762}, {"layer_params": [50, 54, 63, 48], "learning_rate": 0.005769344042087215, "batch_size": 475, "loss": 0.0006524904305115342}, {"layer_params": [35, 33, 58, 25, 21], "learning_rate": 0.003704286187096688, "batch_size": 135, "loss": 0.0022457555506844072}, {"layer_params": [19, 19], "learning_rate": 0.006767897344410497, "batch_size": 140, "loss": 0.004547396574635059}, {"layer_params": [22, 40, 42], "learning_rate": 0.00391906559724345, "batch_size": 144, "loss": 0.002294879255350679}, {"layer_params": [61, 16], "learning_rate": 0.009314739130177808, "batch_size": 502, "loss": 0.002320891536073759}, {"layer_params": [31, 53, 35, 39, 18], "learning_rate": 0.009139132800691353, "batch_size": 280, "loss": 0.0023807052697520704}, {"layer_params": [24, 46, 47, 19, 53], "learning_rate": 0.00825892461786925, "batch_size": 56, "loss": 0.0049624657910317185}, {"layer_params": [63, 55, 45, 51, 34], "learning_rate": 0.0025191201786026653, "batch_size": 118, "loss": 0.0018500582640990615}, {"layer_params": [43, 58, 31, 44], "learning_rate": 0.0016701460401423993, "batch_size": 457, "loss": 0.0013272535998839884}, {"layer_params": [48, 22, 56], "learning_rate": 0.004220878775699038, "batch_size": 348, "loss": 0.0014900959702208638}, {"layer_params": [22, 40, 54], "learning_rate": 0.006950670604949269, "batch_size": 142, "loss": 0.002164358237059787}, {"layer_params": [60, 48, 38, 41, 49], "learning_rate": 0.0034894772973118955, "batch_size": 365, "loss": 0.0014904217154253275}, {"layer_params": [47, 44, 43, 56, 33], "learning_rate": 0.0032675548832686975, "batch_size": 439, "loss": 0.001421442668652162}, {"layer_params": [43, 24, 25, 17, 25], "learning_rate": 0.004946884833504173, "batch_size": 176, "loss": 0.0023769695369992407}, {"layer_params": [57, 51, 19, 44, 56], "learning_rate": 0.0006457990837742997, "batch_size": 247, "loss": 0.004363713331986219}, {"layer_params": [61, 21, 48, 36, 28], "learning_rate": 0.006302087170681461, "batch_size": 44, "loss": 0.0031713548384141176}, {"layer_params": [57, 28, 27], "learning_rate": 0.0019075709561764962, "batch_size": 504, "loss": 0.002268185883294791}, {"layer_params": [58, 18, 43], "learning_rate": 0.009640115175820417, "batch_size": 345, "loss": 0.001424841770203784}, {"layer_params": [52, 56], "learning_rate": 0.00032508711717005946, "batch_size": 99, "loss": 0.006878202622756362}, {"layer_params": [19, 18, 39, 20], "learning_rate": 0.003118638132025044, "batch_size": 178, "loss": 0.004986996056977659}, {"layer_params": [59, 41], "learning_rate": 0.007382320056357931, "batch_size": 271, "loss": 0.0009772395150503144}, {"layer_params": [49, 22], "learning_rate": 0.0019136582118764152, "batch_size": 196, "loss": 0.004348307689651847}, {"layer_params": [20, 19, 52], "learning_rate": 0.004623156075889091, "batch_size": 169, "loss": 0.005751537329051644}, {"layer_params": [16, 17, 32], "learning_rate": 0.0051563597895895675, "batch_size": 163, "loss": 0.004304361857939512}, {"layer_params": [33, 33], "learning_rate": 0.005633238775169839, "batch_size": 245, "loss": 0.0034085738798603415}, {"layer_params": [50, 29], "learning_rate": 0.002057948195229807, "batch_size": 98, "loss": 0.004724807788152248}, {"layer_params": [33, 46, 44, 44, 16], "learning_rate": 0.002533618366044368, "batch_size": 40, "loss": 0.005868148524314165}, {"layer_params": [57, 42, 41, 45], "learning_rate": 0.0071293687342455486, "batch_size": 229, "loss": 0.0013576369197107851}, {"layer_params": [36, 40, 45], "learning_rate": 0.001649123771883645, "batch_size": 28, "loss": 0.006290904711931944}, {"layer_params": [47, 62, 42, 59, 61], "learning_rate": 0.0058556966167660094, "batch_size": 46, "loss": 0.002963711676420644}, {"layer_params": [47, 20, 63, 50], "learning_rate": 0.0009355808799777469, "batch_size": 242, "loss": 0.003364258410874754}, {"layer_params": [32, 35, 30], "learning_rate": 0.002226851021855519, "batch_size": 258, "loss": 0.0028665093053132297}, {"layer_params": [63, 61], "learning_rate": 0.00944792293188304, "batch_size": 360, "loss": 0.0014125044626416639}, {"layer_params": [38, 37], "learning_rate": 0.00028691926203810254, "batch_size": 413, "loss": 0.007131022973917425}, {"layer_params": [23, 58], "learning_rate": 0.005799775217348435, "batch_size": 364, "loss": 0.0026224261010065674}, {"layer_params": [20, 41, 49], "learning_rate": 0.00887891695302366, "batch_size": 303, "loss": 0.002279487893683836}, {"layer_params": [16, 51], "learning_rate": 0.009816228479016401, "batch_size": 94, "loss": 0.0037425280292518437}, {"layer_params": [54, 49], "learning_rate": 0.00534545368681849, "batch_size": 168, "loss": 0.002009580071317032}, {"layer_params": [40, 44, 23], "learning_rate": 0.0025138864072061814, "batch_size": 393, "loss": 0.0021702770970296113}, {"layer_params": [47, 43, 61, 32, 64], "learning_rate": 0.00848918850060841, "batch_size": 343, "loss": 0.0014685546839609742}, {"layer_params": [39, 61, 17, 62], "learning_rate": 0.0031133727074920212, "batch_size": 165, "loss": 0.0014848424994852393}, {"layer_params": [31, 54], "learning_rate": 0.0026523854655272354, "batch_size": 509, "loss": 0.0023091837600804866}, {"layer_params": [41, 30, 32, 21], "learning_rate": 0.007581050325870051, "batch_size": 101, "loss": 0.0027993447636254134}, {"layer_params": [31, 54], "learning_rate": 0.004288004863472502, "batch_size": 466, "loss": 0.0023437625903170558}, {"layer_params": [25, 39, 52, 40], "learning_rate": 0.001230553743067502, "batch_size": 114, "loss": 0.005052045814227313}, {"layer_params": [27, 24], "learning_rate": 0.008365781067460696, "batch_size": 171, "loss": 0.005788062412757426}, {"layer_params": [33, 33, 53], "learning_rate": 0.00029735024487422224, "batch_size": 28, "loss": 0.013593910606577992}, {"layer_params": [17, 45, 27, 52], "learning_rate": 0.004595591597530938, "batch_size": 438, "loss": 0.0033614605944603682}, {"layer_params": [52, 34, 35, 32, 25], "learning_rate": 0.005942284009468867, "batch_size": 108, "loss": 0.002382774369325489}, {"layer_params": [22, 64], "learning_rate": 0.004127436153414044, "batch_size": 476, "loss": 0.0022208533703815194}, {"layer_params": [22, 18, 29, 61], "learning_rate": 0.003930864155421933, "batch_size": 497, "loss": 0.0023855343798641114}, {"layer_params": [52, 30], "learning_rate": 0.006345540112654362, "batch_size": 260, "loss": 0.0013243406754918396}, {"layer_params": [54, 22, 48, 60, 56], "learning_rate": 0.0012629788210646376, "batch_size": 424, "loss": 0.002144378487719223}, {"layer_params": [20, 40, 45, 37, 26], "learning_rate": 0.006769066055383181, "batch_size": 191, "loss": 0.002590884352102876}, {"layer_params": [24, 30, 17], "learning_rate": 0.0026293264217158168, "batch_size": 147, "loss": 0.0030509297084063292}, {"layer_params": [60, 45, 27, 20, 50], "learning_rate": 0.008919868601469736, "batch_size": 378, "loss": 0.0016010046482551844}, {"layer_params": [33, 36], "learning_rate": 0.002866740274510578, "batch_size": 219, "loss": 0.0038692836370319127}, {"layer_params": [26, 41, 18, 26, 38], "learning_rate": 0.0019338699628990569, "batch_size": 205, "loss": 0.0039085486810654406}, {"layer_params": [23, 52, 58], "learning_rate": 0.005182067159020519, "batch_size": 453, "loss": 0.0020545213378500194}, {"layer_params": [22, 56, 19, 25], "learning_rate": 0.008484099369849037, "batch_size": 359, "loss": 0.0015062250208575279}, {"layer_params": [46, 21, 37, 62, 32], "learning_rate": 0.0030666600780345286, "batch_size": 151, "loss": 0.0028801812219899146}, {"layer_params": [54, 26, 51, 18], "learning_rate": 0.003147582203643449, "batch_size": 200, "loss": 0.0024848603026475756}, {"layer_params": [48, 28, 59], "learning_rate": 0.00871067280889377, "batch_size": 402, "loss": 0.0012537706026341767}, {"layer_params": [49, 18, 26], "learning_rate": 0.00735164592191625, "batch_size": 436, "loss": 0.0026150215114466844}, {"layer_params": [32, 25, 28], "learning_rate": 0.0032216696640989455, "batch_size": 366, "loss": 0.0019041991420090199}, {"layer_params": [19, 64], "learning_rate": 0.0015541496089846855, "batch_size": 141, "loss": 0.005098863255698234}, {"layer_params": [23, 54], "learning_rate": 0.008865685370577617, "batch_size": 270, "loss": 0.0026311432966031134}, {"layer_params": [19, 56], "learning_rate": 0.009450997497319157, "batch_size": 437, "loss": 0.002977427402511239}, {"layer_params": [48, 36, 28, 22, 46], "learning_rate": 0.0033129928595149374, "batch_size": 20, "loss": 0.007114459691802039}, {"layer_params": [54, 22, 41, 42, 59], "learning_rate": 0.0057435825957537585, "batch_size": 481, "loss": 0.0016645428945776075}, {"layer_params": [28, 36], "learning_rate": 0.005985461176086062, "batch_size": 366, "loss": 0.002704842248931527}, {"layer_params": [55, 31, 24], "learning_rate": 0.009132406674712493, "batch_size": 358, "loss": 0.002016453202813864}, {"layer_params": [36, 53, 48, 64, 32], "learning_rate": 0.007779690243259925, "batch_size": 79, "loss": 0.0026302778290119024}, {"layer_params": [46, 53, 32], "learning_rate": 0.008693480450182381, "batch_size": 231, "loss": 0.0017628131294623018}, {"layer_params": [36, 56], "learning_rate": 0.00711050908052679, "batch_size": 493, "loss": 0.0016929655789863318}, {"layer_params": [49, 49, 40, 44], "learning_rate": 0.0032177071390655514, "batch_size": 189, "loss": 0.001877691289409995}, {"layer_params": [51, 16, 40, 52], "learning_rate": 0.002315265089950213, "batch_size": 473, "loss": 0.002095359615050256}, {"layer_params": [56, 36, 25, 44, 54], "learning_rate": 0.007566032670619587, "batch_size": 93, "loss": 0.0022681974072474988}, {"layer_params": [53, 20, 20], "learning_rate": 0.004193100996123419, "batch_size": 219, "loss": 0.002376372362487018}, {"layer_params": [61, 52, 56], "learning_rate": 0.006330966364234388, "batch_size": 140, "loss": 0.0016533962765242903}, {"layer_params": [18, 28, 45], "learning_rate": 0.002203368809928548, "batch_size": 106, "loss": 0.004525224997196347}, {"layer_params": [43, 22, 53, 59], "learning_rate": 0.005401219111545297, "batch_size": 290, "loss": 0.0017836819915100933}, {"layer_params": [26, 41, 64], "learning_rate": 0.00037536929852485915, "batch_size": 70, "loss": 0.00821212325245142}, {"layer_params": [62, 27], "learning_rate": 0.004989867590904273, "batch_size": 240, "loss": 0.002294243681244552}, {"layer_params": [41, 46, 28, 62, 60], "learning_rate": 0.007248156162897175, "batch_size": 250, "loss": 0.002777159558609128}, {"layer_params": [63, 54, 43, 37], "learning_rate": 0.0059541608085835205, "batch_size": 112, "loss": 0.0016815001878421755}, {"layer_params": [56, 50, 43], "learning_rate": 0.006529628363181336, "batch_size": 53, "loss": 0.003408918023342267}, {"layer_params": [23, 44, 37], "learning_rate": 0.008832451667763334, "batch_size": 278, "loss": 0.002504563071997836}, {"layer_params": [23, 16, 29], "learning_rate": 0.007885870297347905, "batch_size": 69, "loss": 0.0056021132739260794}, {"layer_params": [52, 32, 58], "learning_rate": 0.001898223921472111, "batch_size": 136, "loss": 0.002117176167666912}, {"layer_params": [42, 61], "learning_rate": 0.008252816631338556, "batch_size": 354, "loss": 0.0010759857861557976}, {"layer_params": [22, 19], "learning_rate": 0.006812805558004534, "batch_size": 144, "loss": 0.004588630814105273}, {"layer_params": [38, 56, 63, 49], "learning_rate": 0.0030634294350084658, "batch_size": 344, "loss": 0.001429028700804338}, {"layer_params": [58, 51], "learning_rate": 0.005647230476317162, "batch_size": 85, "loss": 0.002181848285254091}, {"layer_params": [42, 37, 33, 44, 30], "learning_rate": 0.003137938637671737, "batch_size": 119, "loss": 0.002503849196946248}, {"layer_params": [22, 42, 37, 42], "learning_rate": 0.006828937208600209, "batch_size": 418, "loss": 0.002098297830671072}, {"layer_params": [39, 19, 57], "learning_rate": 0.00604100260940065, "batch_size": 186, "loss": 0.0026724629779346287}, {"layer_params": [20, 17], "learning_rate": 0.0037211283113835454, "batch_size": 473, "loss": 0.004359192478004843}, {"layer_params": [34, 62, 16, 48, 45], "learning_rate": 0.0060777664891324065, "batch_size": 449, "loss": 0.0017689770029392093}, {"layer_params": [42, 48, 47], "learning_rate": 0.001969789006560496, "batch_size": 351, "loss": 0.0016648361110128463}, {"layer_params": [45, 18], "learning_rate": 0.007868304504048946, "batch_size": 129, "loss": 0.0036039529321715237}, {"layer_params": [40, 51, 49, 26, 24], "learning_rate": 0.005857518153114419, "batch_size": 228, "loss": 0.0017652292689308525}, {"layer_params": [61, 49, 20, 19], "learning_rate": 0.008048721362305966, "batch_size": 416, "loss": 0.0007410627481294796}, {"layer_params": [18, 17, 37, 41], "learning_rate": 0.008957816446452705, "batch_size": 107, "loss": 0.005680324351415038}, {"layer_params": [30, 64, 46], "learning_rate": 0.006211847861382244, "batch_size": 481, "loss": 0.0010497670859331266}, {"layer_params": [21, 32, 21, 60, 31], "learning_rate": 0.00568512958041102, "batch_size": 85, "loss": 0.004029562994837761}, {"layer_params": [49, 61], "learning_rate": 0.0018178476286489376, "batch_size": 449, "loss": 0.0021699663740582763}, {"layer_params": [62, 27], "learning_rate": 0.009293390544950656, "batch_size": 232, "loss": 0.001603017415618524}, {"layer_params": [61, 52, 55], "learning_rate": 0.0019326128909263043, "batch_size": 79, "loss": 0.0031374453473836184}, {"layer_params": [21, 42, 46, 32], "learning_rate": 0.0036028460407678945, "batch_size": 399, "loss": 0.0023076121311169117}, {"layer_params": [23, 63, 50, 38], "learning_rate": 0.0024901397482814643, "batch_size": 363, "loss": 0.002856874370481819}, {"layer_params": [54, 45], "learning_rate": 0.009510322794600881, "batch_size": 98, "loss": 0.002533554098336026}, {"layer_params": [16, 36, 25, 38, 20], "learning_rate": 0.002134557429693252, "batch_size": 495, "loss": 0.002979911328293383}, {"layer_params": [49, 54], "learning_rate": 0.006007958306842233, "batch_size": 423, "loss": 0.0010652464313898235}, {"layer_params": [46, 29, 31], "learning_rate": 0.009371990581838976, "batch_size": 264, "loss": 0.0017993757571093739}, {"layer_params": [25, 20, 17, 19], "learning_rate": 0.0046650544625360685, "batch_size": 325, "loss": 0.0024568442441523074}, {"layer_params": [42, 22, 52], "learning_rate": 0.005473617273804658, "batch_size": 501, "loss": 0.0019523439463227988}, {"layer_params": [16, 32, 59, 59, 20], "learning_rate": 0.009589601268071905, "batch_size": 222, "loss": 0.0027349531929939984}, {"layer_params": [60, 49], "learning_rate": 0.001490691385543608, "batch_size": 53, "loss": 0.0052428508410230275}, {"layer_params": [35, 20], "learning_rate": 0.009706096227413991, "batch_size": 508, "loss": 0.0028329634945839645}, {"layer_params": [45, 17, 33, 16], "learning_rate": 0.001091770178545868, "batch_size": 93, "loss": 0.004801585520617664}, {"layer_params": [32, 52, 60, 55, 49], "learning_rate": 0.0044349490245716465, "batch_size": 392, "loss": 0.001084232060238719}, {"layer_params": [20, 27, 60, 34, 51], "learning_rate": 0.008357022248119923, "batch_size": 229, "loss": 0.00440495973220095}, {"layer_params": [62, 35], "learning_rate": 0.008889442681161644, "batch_size": 405, "loss": 0.0018191973539069294}, {"layer_params": [57, 42, 26, 56], "learning_rate": 0.001088033320321669, "batch_size": 25, "loss": 0.007254875246435404}, {"layer_params": [59, 34, 52, 40], "learning_rate": 0.0077136404381744714, "batch_size": 97, "loss": 0.0019501749926712365}, {"layer_params": [62, 63, 36], "learning_rate": 0.007534665213999287, "batch_size": 393, "loss": 0.0013701547787059098}, {"layer_params": [55, 41, 46], "learning_rate": 0.007599157398291924, "batch_size": 481, "loss": 0.0007599575322819874}, {"layer_params": [45, 38, 20, 39, 43], "learning_rate": 0.0044860517490036955, "batch_size": 138, "loss": 0.001946425250498578}, {"layer_params": [35, 53, 42, 44], "learning_rate": 0.006897905383840077, "batch_size": 219, "loss": 0.0015800016786670311}, {"layer_params": [37, 39, 60, 45, 58], "learning_rate": 0.004598114024344982, "batch_size": 114, "loss": 0.0029285885114222767}, {"layer_params": [17, 33, 19, 38], "learning_rate": 0.001965722499903994, "batch_size": 116, "loss": 0.007252979087643325}, {"layer_params": [25, 64, 50, 25, 21], "learning_rate": 0.0044915588550750885, "batch_size": 182, "loss": 0.001662397077307105}, {"layer_params": [35, 30, 41, 51, 22], "learning_rate": 0.001127878843182195, "batch_size": 312, "loss": 0.0029995939694344997}, {"layer_params": [61, 23, 31], "learning_rate": 0.0018801840542619142, "batch_size": 67, "loss": 0.004027075681369752}, {"layer_params": [59, 41, 57, 41, 52], "learning_rate": 0.002916152222914999, "batch_size": 281, "loss": 0.0014365901157725603}, {"layer_params": [54, 49, 59, 46, 20], "learning_rate": 0.0012075621382775373, "batch_size": 381, "loss": 0.0016229186649434268}, {"layer_params": [21, 28, 39], "learning_rate": 0.009375983158239112, "batch_size": 353, "loss": 0.0031417401996441186}, {"layer_params": [41, 16, 26, 38], "learning_rate": 0.0022533048841793485, "batch_size": 502, "loss": 0.002671040582936257}, {"layer_params": [42, 49, 31], "learning_rate": 0.0077868587250046195, "batch_size": 126, "loss": 0.0013797939877258614}, {"layer_params": [46, 64, 34], "learning_rate": 0.00700930674314564, "batch_size": 84, "loss": 0.0029925293871201574}, {"layer_params": [17, 62, 16, 42], "learning_rate": 0.009463207711505254, "batch_size": 400, "loss": 0.0014698136143852026}, {"layer_params": [60, 35, 41, 54, 51], "learning_rate": 0.0017468364764021943, "batch_size": 38, "loss": 0.005668382216244936}, {"layer_params": [33, 50], "learning_rate": 0.006354947818146039, "batch_size": 207, "loss": 0.0019141621119342744}, {"layer_params": [54, 29, 22, 51], "learning_rate": 0.0007664345204876331, "batch_size": 149, "loss": 0.006449302537366748}, {"layer_params": [64, 63, 46], "learning_rate": 0.0068745457033353745, "batch_size": 319, "loss": 0.0010251996229635552}, {"layer_params": [63, 37, 25], "learning_rate": 0.0010298345790215656, "batch_size": 18, "loss": 0.007545766518451274}, {"layer_params": [48, 42, 43, 49], "learning_rate": 0.007524017452978168, "batch_size": 50, "loss": 0.004912193138152361}, {"layer_params": [57, 51, 43, 34], "learning_rate": 0.008761749931407567, "batch_size": 174, "loss": 0.0014503288851119578}, {"layer_params": [17, 53, 56, 59], "learning_rate": 0.0010271590181175842, "batch_size": 405, "loss": 0.003976057763211429}, {"layer_params": [57, 40], "learning_rate": 0.007645209309621468, "batch_size": 198, "loss": 0.0020967350713908674}, {"layer_params": [43, 22, 39, 43, 24], "learning_rate": 0.006667422355032458, "batch_size": 258, "loss": 0.0021654336480423806}, {"layer_params": [18, 63, 16], "learning_rate": 0.006857695965685378, "batch_size": 473, "loss": 0.0016686550981830806}, {"layer_params": [47, 27, 56], "learning_rate": 0.009048976656601822, "batch_size": 458, "loss": 0.0020951069868169725}, {"layer_params": [22, 28, 33], "learning_rate": 0.0035546032272575604, "batch_size": 109, "loss": 0.0037287954264320433}, {"layer_params": [28, 50], "learning_rate": 0.00745909621394799, "batch_size": 36, "loss": 0.005674161673523486}, {"layer_params": [29, 42, 25, 61, 38], "learning_rate": 0.009497393821986982, "batch_size": 159, "loss": 0.0018304240761790424}, {"layer_params": [61, 24, 38, 40], "learning_rate": 0.004730713686743058, "batch_size": 495, "loss": 0.0022392976679839194}, {"layer_params": [34, 45, 21, 37, 23], "learning_rate": 0.0036696229628363736, "batch_size": 170, "loss": 0.0018282821273896844}, {"layer_params": [31, 26, 50, 27], "learning_rate": 0.005790899677100599, "batch_size": 469, "loss": 0.0021398876898456364}, {"layer_params": [29, 21, 51, 19], "learning_rate": 0.008908525700756119, "batch_size": 325, "loss": 0.0022403540078084917}, {"layer_params": [60, 42, 19], "learning_rate": 0.008957828563249738, "batch_size": 432, "loss": 0.0023427606490440665}, {"layer_params": [16, 24, 56, 53], "learning_rate": 0.008308808722758486, "batch_size": 398, "loss": 0.003218685716856271}, {"layer_params": [48, 51, 27, 58, 55], "learning_rate": 0.0013372745391574837, "batch_size": 385, "loss": 0.002036549203330651}, {"layer_params": [41, 17], "learning_rate": 0.006903431713664159, "batch_size": 221, "loss": 0.0024869751953519883}, {"layer_params": [37, 49, 63, 48, 30], "learning_rate": 0.005865345458111163, "batch_size": 457, "loss": 0.001041721972869709}, {"layer_params": [35, 39], "learning_rate": 0.009157243361151758, "batch_size": 378, "loss": 0.0014607008919119834}, {"layer_params": [47, 47], "learning_rate": 0.007051573955035072, "batch_size": 241, "loss": 0.002003461066633463}, {"layer_params": [19, 50, 52], "learning_rate": 0.002621130961443211, "batch_size": 368, "loss": 0.002698542766738683}, {"layer_params": [28, 35, 18, 33, 16], "learning_rate": 0.004845154421444241, "batch_size": 289, "loss": 0.0033930152584798635}, {"layer_params": [18, 58, 58, 39, 61], "learning_rate": 0.001002931792180021, "batch_size": 132, "loss": 0.005275814323686063}, {"layer_params": [59, 37], "learning_rate": 0.009831785105613338, "batch_size": 51, "loss": 0.004214335405267775}, {"layer_params": [37, 17, 33, 45, 47], "learning_rate": 0.00033623097085470156, "batch_size": 87, "loss": 0.007829427709802985}, {"layer_params": [49, 60, 27, 41], "learning_rate": 0.00506772767282961, "batch_size": 91, "loss": 0.00206517354818061}, {"layer_params": [23, 39], "learning_rate": 0.004644158034377496, "batch_size": 392, "loss": 0.002562373492401093}, {"layer_params": [44, 42, 57, 59], "learning_rate": 0.0054892037312637195, "batch_size": 234, "loss": 0.0012062150659039616}, {"layer_params": [26, 41], "learning_rate": 0.004463385055305266, "batch_size": 75, "loss": 0.0041731517482548955}, {"layer_params": [22, 28, 31], "learning_rate": 0.009705040253147584, "batch_size": 337, "loss": 0.002490348557475954}, {"layer_params": [20, 32, 54, 34, 35], "learning_rate": 0.002926235422978327, "batch_size": 231, "loss": 0.0026582256332039833}, {"layer_params": [33, 22, 45, 28, 48], "learning_rate": 0.007319434662014049, "batch_size": 240, "loss": 0.0037253584875725208}, {"layer_params": [17, 56, 42], "learning_rate": 0.0087704483211239, "batch_size": 111, "loss": 0.0023588270996697247}, {"layer_params": [26, 53, 31, 64, 38], "learning_rate": 0.008566471996836151, "batch_size": 162, "loss": 0.0028333742369432004}, {"layer_params": [55, 31], "learning_rate": 0.00948995213964826, "batch_size": 399, "loss": 0.0017317193932831288}, {"layer_params": [55, 40, 22, 26, 17], "learning_rate": 0.0019337715334804108, "batch_size": 295, "loss": 0.0024600487982388585}, {"layer_params": [61, 38, 43, 24], "learning_rate": 0.0057825071338902904, "batch_size": 55, "loss": 0.003911708602681756}, {"layer_params": [32, 32, 36, 22, 60], "learning_rate": 0.004416564773833984, "batch_size": 369, "loss": 0.001588661908172071}, {"layer_params": [63, 33, 20, 51, 27], "learning_rate": 0.00324941532504785, "batch_size": 277, "loss": 0.0019814524496905507}, {"layer_params": [64, 34, 47, 40, 62], "learning_rate": 0.0005221330336306788, "batch_size": 489, "loss": 0.002380899058189243}, {"layer_params": [56, 63, 49], "learning_rate": 0.00022892415179947363, "batch_size": 119, "loss": 0.00745040628593415}, {"layer_params": [36, 20, 50], "learning_rate": 0.009922045619811975, "batch_size": 485, "loss": 0.0011802292510401458}, {"layer_params": [63, 39, 62, 45, 16], "learning_rate": 0.003322174731517911, "batch_size": 496, "loss": 0.0013521144224796443}, {"layer_params": [60, 43], "learning_rate": 0.006192731873815247, "batch_size": 439, "loss": 0.0009255560807650909}, {"layer_params": [62, 16, 52], "learning_rate": 0.0011024428613930542, "batch_size": 109, "loss": 0.0066728988988325}, {"layer_params": [34, 24, 55, 46], "learning_rate": 0.009380397064744264, "batch_size": 208, "loss": 0.002124030460836366}, {"layer_params": [53, 28, 19], "learning_rate": 0.001407292792752599, "batch_size": 51, "loss": 0.00518954117782414}, {"layer_params": [23, 49, 46, 32, 56], "learning_rate": 0.004517725912100243, "batch_size": 375, "loss": 0.0021854860452003777}, {"layer_params": [31, 30, 32, 23], "learning_rate": 0.0058340296065564215, "batch_size": 259, "loss": 0.001994239353807643}, {"layer_params": [44, 53], "learning_rate": 0.0013502614154288842, "batch_size": 137, "loss": 0.004338365830481052}, {"layer_params": [49, 43, 51], "learning_rate": 0.0027743881592104747, "batch_size": 106, "loss": 0.0025780815072357654}, {"layer_params": [28, 28, 51], "learning_rate": 0.0031011821906920234, "batch_size": 33, "loss": 0.005309063820168376}, {"layer_params": [63, 25], "learning_rate": 0.0005736188887471833, "batch_size": 458, "loss": 0.005372536112554371}, {"layer_params": [38, 37, 18], "learning_rate": 0.0072917273266705504, "batch_size": 480, "loss": 0.0016315558296628296}, {"layer_params": [62, 42], "learning_rate": 0.0034840488282759387, "batch_size": 43, "loss": 0.004951440126169473}, {"layer_params": [55, 62], "learning_rate": 0.0008719317933242269, "batch_size": 428, "loss": 0.0028933395724743604}, {"layer_params": [46, 49, 17, 64, 59], "learning_rate": 0.002874483487907606, "batch_size": 389, "loss": 0.0016509111400227995}, {"layer_params": [31, 53, 46], "learning_rate": 0.0028450193486352954, "batch_size": 75, "loss": 0.004273050629999489}, {"layer_params": [58, 55, 19, 58], "learning_rate": 0.007472038664980227, "batch_size": 355, "loss": 0.0014126813958864658}, {"layer_params": [39, 52], "learning_rate": 0.0010129871435525016, "batch_size": 327, "loss": 0.003916390449739992}, {"layer_params": [20, 25, 39, 57], "learning_rate": 0.0034703663341357103, "batch_size": 22, "loss": 0.00839925478445366}, {"layer_params": [30, 33], "learning_rate": 0.0054268939599217605, "batch_size": 232, "loss": 0.0036148018715903164}, {"layer_params": [60, 42, 18], "learning_rate": 0.008825814782938146, "batch_size": 410, "loss": 0.0015469930623658002}, {"layer_params": [41, 16, 24, 36], "learning_rate": 0.008017788096207628, "batch_size": 205, "loss": 0.0035187901044264436}, {"layer_params": [58, 26, 44, 31], "learning_rate": 0.005728908451848569, "batch_size": 400, "loss": 0.0009950593824032694}, {"layer_params": [31, 60, 26, 43, 34], "learning_rate": 0.005715167556259569, "batch_size": 431, "loss": 0.0013813638081774115}, {"layer_params": [55, 16, 29, 20, 53], "learning_rate": 0.0060725244084239485, "batch_size": 255, "loss": 0.0034707495267502966}, {"layer_params": [51, 21, 62, 35], "learning_rate": 0.0043831581109521674, "batch_size": 49, "loss": 0.0037733786716125906}, {"layer_params": [60, 45, 24], "learning_rate": 0.004065966455552221, "batch_size": 189, "loss": 0.0013214163127122447}, {"layer_params": [42, 46, 39, 64], "learning_rate": 0.006451662897695826, "batch_size": 397, "loss": 0.0009939003019826488}, {"layer_params": [39, 48], "learning_rate": 0.0011386176176124462, "batch_size": 498, "loss": 0.003312740430701524}, {"layer_params": [63, 24, 25, 43], "learning_rate": 0.004536891106192263, "batch_size": 39, "loss": 0.0029326235700864343}, {"layer_params": [64, 62], "learning_rate": 0.003925557202875307, "batch_size": 182, "loss": 0.0017783101717941464}, {"layer_params": [24, 30, 32, 37, 51], "learning_rate": 0.00036186855749447105, "batch_size": 194, "loss": 0.007727422919124365}, {"layer_params": [30, 21], "learning_rate": 0.0025820009851111624, "batch_size": 338, "loss": 0.0031214522290974856}, {"layer_params": [39, 62, 37], "learning_rate": 0.003869593332609162, "batch_size": 492, "loss": 0.001419638548977673}, {"layer_params": [38, 59, 19, 36, 25], "learning_rate": 0.009400620799612656, "batch_size": 232, "loss": 0.0015426287788432092}, {"layer_params": [61, 40, 55, 29, 35], "learning_rate": 0.00568559644814113, "batch_size": 434, "loss": 0.0013318296428769826}, {"layer_params": [55, 52, 38, 25, 48], "learning_rate": 0.002755351339527088, "batch_size": 123, "loss": 0.0018633594177663326}, {"layer_params": [17, 46, 27, 21, 64], "learning_rate": 0.0036566858164689877, "batch_size": 204, "loss": 0.003276506601832807}, {"layer_params": [51, 26, 24, 24, 26], "learning_rate": 0.0011816803314281716, "batch_size": 163, "loss": 0.004339646552689373}, {"layer_params": [54, 55, 43, 24, 39], "learning_rate": 0.006398522841640342, "batch_size": 51, "loss": 0.0030774770793505013}, {"layer_params": [47, 28, 58, 48], "learning_rate": 0.00045438782127453346, "batch_size": 292, "loss": 0.005195301864296198}, {"layer_params": [22, 51, 57, 43, 27], "learning_rate": 0.00018332402836826318, "batch_size": 294, "loss": 0.007587038851343095}, {"layer_params": [63, 30], "learning_rate": 0.002561014295595825, "batch_size": 333, "loss": 0.0025489108730107546}, {"layer_params": [51, 26, 25, 59], "learning_rate": 0.0019159340307355033, "batch_size": 92, "loss": 0.003509923382662237}, {"layer_params": [56, 17, 28, 59, 49], "learning_rate": 0.0024630721851238704, "batch_size": 190, "loss": 0.0026700315368361773}, {"layer_params": [35, 59, 45, 47, 28], "learning_rate": 0.0020448177673186786, "batch_size": 435, "loss": 0.0013465296139474959}, {"layer_params": [29, 20, 55], "learning_rate": 0.002621005807530458, "batch_size": 301, "loss": 0.002666771193034947}, {"layer_params": [31, 53, 54, 34], "learning_rate": 0.0007267340658005696, "batch_size": 150, "loss": 0.0043694349052384495}, {"layer_params": [63, 50, 20, 31], "learning_rate": 0.003707395703714503, "batch_size": 353, "loss": 0.0010031186271226033}, {"layer_params": [47, 27], "learning_rate": 0.0010125637636710432, "batch_size": 266, "loss": 0.006481790090911091}, {"layer_params": [59, 33, 48], "learning_rate": 0.005918145382515246, "batch_size": 439, "loss": 0.0012509651499567553}, {"layer_params": [34, 31], "learning_rate": 0.00609582561464233, "batch_size": 422, "loss": 0.0020756650459952653}, {"layer_params": [37, 23], "learning_rate": 0.006313982051421718, "batch_size": 256, "loss": 0.0017156163952313363}, {"layer_params": [35, 39, 26], "learning_rate": 0.005586201921051242, "batch_size": 305, "loss": 0.0012880355364177376}, {"layer_params": [49, 37, 41, 64, 41], "learning_rate": 0.004912456515607807, "batch_size": 373, "loss": 0.0017764151562005281}, {"layer_params": [43, 22, 52], "learning_rate": 0.006463291312709346, "batch_size": 434, "loss": 0.002195266953203827}, {"layer_params": [16, 32, 26], "learning_rate": 0.009645233737380958, "batch_size": 60, "loss": 0.00439836984500289}, {"layer_params": [37, 23, 25], "learning_rate": 0.004391614738980134, "batch_size": 154, "loss": 0.0028913878509774804}, {"layer_params": [18, 27, 55, 56], "learning_rate": 0.007506240571987036, "batch_size": 373, "loss": 0.0017436266329605133}, {"layer_params": [53, 19], "learning_rate": 0.007774033386079274, "batch_size": 468, "loss": 0.0025439683627337217}, {"layer_params": [61, 64, 21, 58], "learning_rate": 0.0073890096796828475, "batch_size": 46, "loss": 0.0029940808692481367}, {"layer_params": [28, 27, 57, 32], "learning_rate": 0.005335142648903964, "batch_size": 287, "loss": 0.0017602090176660568}, {"layer_params": [38, 31], "learning_rate": 0.006741053862455317, "batch_size": 318, "loss": 0.0028132344922050835}, {"layer_params": [57, 33, 33, 48], "learning_rate": 0.002992718334529279, "batch_size": 431, "loss": 0.0014836413983721286}, {"layer_params": [17, 38, 62, 37], "learning_rate": 0.007472304843156518, "batch_size": 108, "loss": 0.004395159122068435}, {"layer_params": [46, 44, 27], "learning_rate": 0.005694007835269405, "batch_size": 68, "loss": 0.0032404822891112417}, {"layer_params": [39, 64, 59, 23], "learning_rate": 0.007177395352868144, "batch_size": 453, "loss": 0.0008980483282357455}, {"layer_params": [18, 20, 17, 45], "learning_rate": 0.0034269502566557906, "batch_size": 131, "loss": 0.004072990182321518}, {"layer_params": [39, 26, 26], "learning_rate": 0.008122479226475344, "batch_size": 41, "loss": 0.005563515017274767}, {"layer_params": [56, 36], "learning_rate": 0.005481261102662673, "batch_size": 59, "loss": 0.003328877077437937}, {"layer_params": [28, 40], "learning_rate": 0.0009561379085485291, "batch_size": 248, "loss": 0.006291933204047382}, {"layer_params": [33, 47, 18], "learning_rate": 0.0075284153389007895, "batch_size": 404, "loss": 0.0016549108014442026}, {"layer_params": [19, 56, 18], "learning_rate": 0.004449236325861881, "batch_size": 132, "loss": 0.002606540151173249}, {"layer_params": [50, 54], "learning_rate": 0.004285576611483031, "batch_size": 172, "loss": 0.002427943698130548}, {"layer_params": [60, 38, 42, 19, 45], "learning_rate": 0.0056667912445141164, "batch_size": 84, "loss": 0.002052345259580761}, {"layer_params": [25, 49, 34, 27], "learning_rate": 0.0029472835958715064, "batch_size": 466, "loss": 0.0014127676619682462}, {"layer_params": [36, 59, 44, 18, 63], "learning_rate": 0.003983126102737259, "batch_size": 465, "loss": 0.0020375004631932826}, {"layer_params": [33, 32, 34, 48], "learning_rate": 0.0003142573415456962, "batch_size": 91, "loss": 0.008040427607484161}, {"layer_params": [57, 52, 58, 41, 33], "learning_rate": 0.0006936292799984876, "batch_size": 367, "loss": 0.0019214187620673329}, {"layer_params": [30, 49, 63, 28], "learning_rate": 0.0044166580070876295, "batch_size": 500, "loss": 0.0008115639945026487}, {"layer_params": [40, 20, 22, 58], "learning_rate": 0.004240115449536556, "batch_size": 502, "loss": 0.001892131386557594}, {"layer_params": [50, 26, 64, 27], "learning_rate": 0.00950471676840744, "batch_size": 367, "loss": 0.0011671565397409723}, {"layer_params": [55, 27, 17, 59, 36], "learning_rate": 0.0020786436550049993, "batch_size": 195, "loss": 0.0032810333045199514}, {"layer_params": [23, 60], "learning_rate": 0.009089511408230035, "batch_size": 96, "loss": 0.00278310606488958}, {"layer_params": [19, 64, 56], "learning_rate": 0.006240503092067218, "batch_size": 466, "loss": 0.0026679225731641052}, {"layer_params": [17, 22, 60, 59], "learning_rate": 0.008704496869344942, "batch_size": 64, "loss": 0.005602057240903378}, {"layer_params": [54, 57, 38], "learning_rate": 0.006199410698934269, "batch_size": 278, "loss": 0.0009939574066083878}, {"layer_params": [52, 21, 57], "learning_rate": 0.0036040005779775855, "batch_size": 512, "loss": 0.002515197756001726}, {"layer_params": [50, 37], "learning_rate": 0.008284624408067594, "batch_size": 185, "loss": 0.0013223328575259076}, {"layer_params": [49, 38, 45, 56, 46], "learning_rate": 0.009095878588727848, "batch_size": 504, "loss": 0.0013853732869029045}, {"layer_params": [64, 17, 34, 42], "learning_rate": 0.0032835106289864613, "batch_size": 375, "loss": 0.002195960214594379}, {"layer_params": [27, 32, 20, 19], "learning_rate": 0.005914932842539097, "batch_size": 228, "loss": 0.002731906500412151}, {"layer_params": [40, 62, 24, 44], "learning_rate": 0.007383169691192706, "batch_size": 272, "loss": 0.0011424582521431148}, {"layer_params": [49, 39], "learning_rate": 0.009746295233305809, "batch_size": 349, "loss": 0.0019038144743535668}, {"layer_params": [62, 60, 62], "learning_rate": 0.004445471163247142, "batch_size": 298, "loss": 0.0009974561107810587}, {"layer_params": [29, 18, 47, 20], "learning_rate": 0.0016075843909760862, "batch_size": 204, "loss": 0.006932150451466441}, {"layer_params": [27, 42, 53, 33], "learning_rate": 0.008643844743808398, "batch_size": 131, "loss": 0.0021645530534442512}, {"layer_params": [22, 40, 56, 55, 46], "learning_rate": 0.0029711577041632996, "batch_size": 160, "loss": 0.0019375754857901483}, {"layer_params": [58, 22, 58, 17], "learning_rate": 0.007311005437117523, "batch_size": 188, "loss": 0.0030692684976384044}, {"layer_params": [27, 21], "learning_rate": 0.008898181720195414, "batch_size": 499, "loss": 0.0024275500234216454}, {"layer_params": [62, 17, 47], "learning_rate": 0.0006596191940574229, "batch_size": 289, "loss": 0.005674623753875494}, {"layer_params": [59, 62, 16, 19], "learning_rate": 0.003108825589596771, "batch_size": 368, "loss": 0.001964346076129004}, {"layer_params": [38, 58, 42, 51], "learning_rate": 0.0003931888376303444, "batch_size": 177, "loss": 0.00597465019673109}, {"layer_params": [47, 56, 51], "learning_rate": 0.008892958939829432, "batch_size": 174, "loss": 0.0016279772133566438}, {"layer_params": [45, 40, 27], "learning_rate": 0.006477330158313947, "batch_size": 198, "loss": 0.002049974409164861}, {"layer_params": [23, 22, 32], "learning_rate": 0.0076943708251844475, "batch_size": 205, "loss": 0.0042968591954559085}, {"layer_params": [25, 37, 62], "learning_rate": 0.008234792081689403, "batch_size": 171, "loss": 0.00278331165201962}, {"layer_params": [57, 50, 21, 25], "learning_rate": 0.0015571519178537918, "batch_size": 364, "loss": 0.001801053355447948}, {"layer_params": [31, 44], "learning_rate": 0.006070371780131372, "batch_size": 147, "loss": 0.002626650013262406}, {"layer_params": [30, 55, 28], "learning_rate": 0.0038700094574457052, "batch_size": 144, "loss": 0.0027343824610579757}, {"layer_params": [57, 37, 23, 40, 32], "learning_rate": 0.00462229043465125, "batch_size": 135, "loss": 0.0019706925586797297}, {"layer_params": [49, 57, 18, 28, 61], "learning_rate": 0.009310630914489039, "batch_size": 243, "loss": 0.001537601436721161}, {"layer_params": [39, 25, 32], "learning_rate": 4.689147714480346e-05, "batch_size": 237, "loss": 0.0362585635855794}, {"layer_params": [28, 51, 46, 21], "learning_rate": 0.004970969567494544, "batch_size": 265, "loss": 0.0022005211480427534}, {"layer_params": [48, 25, 60, 57], "learning_rate": 0.0008260995776291755, "batch_size": 411, "loss": 0.0026813942170701923}, {"layer_params": [28, 53, 42, 27], "learning_rate": 0.004992215052471863, "batch_size": 42, "loss": 0.003677413125988096}, {"layer_params": [57, 51, 59, 54], "learning_rate": 0.002047561309033656, "batch_size": 115, "loss": 0.002080509377410635}, {"layer_params": [48, 21, 32, 26], "learning_rate": 0.0016312490576346238, "batch_size": 369, "loss": 0.002472257970366627}, {"layer_params": [62, 32, 35, 50, 48], "learning_rate": 0.0025281251724630694, "batch_size": 352, "loss": 0.0022503009985666723}, {"layer_params": [55, 48, 30], "learning_rate": 0.008634372812582275, "batch_size": 237, "loss": 0.0017393758636899293}, {"layer_params": [21, 40, 35, 62], "learning_rate": 0.006855626809040547, "batch_size": 173, "loss": 0.002425832332810387}, {"layer_params": [30, 24, 18, 24, 33], "learning_rate": 0.0007717501236063158, "batch_size": 487, "loss": 0.0058242384158074855}, {"layer_params": [43, 38, 22, 59, 36], "learning_rate": 0.006662744374454804, "batch_size": 376, "loss": 0.0011787708889460192}, {"layer_params": [52, 61, 59], "learning_rate": 0.008914632578772393, "batch_size": 413, "loss": 0.0020813044544775038}, {"layer_params": [53, 42, 20, 16], "learning_rate": 0.009951723358991402, "batch_size": 445, "loss": 0.0010097537317778915}, {"layer_params": [59, 52, 56, 49], "learning_rate": 0.002349842736532636, "batch_size": 32, "loss": 0.00486350215272978}, {"layer_params": [17, 48, 31, 58, 43], "learning_rate": 0.003765287703127026, "batch_size": 354, "loss": 0.0033661993290297685}, {"layer_params": [49, 57, 53, 45, 40], "learning_rate": 0.0028165889975185917, "batch_size": 174, "loss": 0.002207558046793565}, {"layer_params": [48, 24, 28], "learning_rate": 0.0021824005463228027, "batch_size": 85, "loss": 0.002948336125118658}, {"layer_params": [55, 56], "learning_rate": 0.003001219201953332, "batch_size": 40, "loss": 0.004429852589964867}, {"layer_params": [17, 36], "learning_rate": 0.007836785773433675, "batch_size": 159, "loss": 0.00402017297456041}, {"layer_params": [46, 53], "learning_rate": 0.003982743444814749, "batch_size": 296, "loss": 0.002617331676883623}, {"layer_params": [17, 52, 34, 52, 50], "learning_rate": 0.007591642417748088, "batch_size": 467, "loss": 0.0020633883273694664}, {"layer_params": [43, 54, 30, 18], "learning_rate": 0.0013332056047107841, "batch_size": 158, "loss": 0.004010097894351929}, {"layer_params": [58, 23, 28], "learning_rate": 0.0026135732204420996, "batch_size": 113, "loss": 0.0025546199479140343}, {"layer_params": [64, 34], "learning_rate": 0.00974545257947378, "batch_size": 237, "loss": 0.0014313357719220221}, {"layer_params": [55, 16], "learning_rate": 0.009878226346028238, "batch_size": 158, "loss": 0.0028878722083754836}, {"layer_params": [24, 61], "learning_rate": 0.006427391043877075, "batch_size": 302, "loss": 0.003069198844023049}, {"layer_params": [27, 16, 26, 49], "learning_rate": 0.004394227531252571, "batch_size": 84, "loss": 0.005608228421770036}, {"layer_params": [24, 64, 25], "learning_rate": 0.00423554950206273, "batch_size": 421, "loss": 0.0016602114611305296}, {"layer_params": [48, 39, 63, 36, 33], "learning_rate": 0.006368584852075605, "batch_size": 174, "loss": 0.0011850862466963009}, {"layer_params": [28, 50, 19, 59, 18], "learning_rate": 0.0053735138575851105, "batch_size": 239, "loss": 0.0021947185462340714}, {"layer_params": [26, 33, 49, 55], "learning_rate": 0.0025898184875214683, "batch_size": 117, "loss": 0.0038022064440883696}, {"layer_params": [54, 58], "learning_rate": 0.0019910418126267847, "batch_size": 451, "loss": 0.0014997673709876834}, {"layer_params": [28, 64], "learning_rate": 0.0006926520139329193, "batch_size": 396, "loss": 0.00521403128048405}, {"layer_params": [24, 60], "learning_rate": 0.003458561948391349, "batch_size": 137, "loss": 0.005195630807429552}, {"layer_params": [52, 18], "learning_rate": 0.00010139590623249679, "batch_size": 236, "loss": 0.02384998643770814}, {"layer_params": [64, 44, 21, 35], "learning_rate": 0.0015740818662896186, "batch_size": 371, "loss": 0.0022520956362131984}, {"layer_params": [20, 30, 38, 55, 42], "learning_rate": 0.006438389315613157, "batch_size": 169, "loss": 0.0028122422262094916}, {"layer_params": [19, 28], "learning_rate": 0.0008499414774610274, "batch_size": 436, "loss": 0.007786764879710972}, {"layer_params": [60, 40, 34, 58], "learning_rate": 0.0010684705565586732, "batch_size": 394, "loss": 0.0025011837179772555}, {"layer_params": [54, 49, 31, 63], "learning_rate": 0.006812752859459624, "batch_size": 460, "loss": 0.0010107271326705814}, {"layer_params": [41, 47, 30, 42, 20], "learning_rate": 0.004037871702929567, "batch_size": 467, "loss": 0.0010021442343713717}, {"layer_params": [59, 47, 43], "learning_rate": 0.001681218737066496, "batch_size": 290, "loss": 0.0015751180576626211}, {"layer_params": [51, 40, 21], "learning_rate": 0.0006371096989000555, "batch_size": 193, "loss": 0.005966358873993158}, {"layer_params": [40, 30, 53, 58, 60], "learning_rate": 0.009569909918375303, "batch_size": 452, "loss": 0.0008838329429272562}, {"layer_params": [57, 42, 24, 36], "learning_rate": 0.0014650862781251778, "batch_size": 83, "loss": 0.0029005683690775186}, {"layer_params": [24, 32, 26, 62, 18], "learning_rate": 0.005421287516291786, "batch_size": 97, "loss": 0.0030442163615953177}, {"layer_params": [38, 31], "learning_rate": 0.0017865704019162812, "batch_size": 228, "loss": 0.004546071966178716}, {"layer_params": [20, 24, 23], "learning_rate": 0.005830701739649827, "batch_size": 487, "loss": 0.0020800124621018767}, {"layer_params": [62, 29, 53], "learning_rate": 0.006620404329562928, "batch_size": 331, "loss": 0.001463685667840764}, {"layer_params": [48, 51, 36, 59, 17], "learning_rate": 0.005704894442334989, "batch_size": 475, "loss": 0.0017750292213167995}, {"layer_params": [63, 43], "learning_rate": 0.006396993415284653, "batch_size": 163, "loss": 0.0014114341896492987}, {"layer_params": [37, 50, 40, 59], "learning_rate": 0.0029194368377279674, "batch_size": 215, "loss": 0.0022034217149484903}, {"layer_params": [54, 32, 30], "learning_rate": 0.0014123069219748236, "batch_size": 37, "loss": 0.006265888235066086}, {"layer_params": [49, 56, 50], "learning_rate": 0.006353621795080501, "batch_size": 103, "loss": 0.002334022942231968}, {"layer_params": [19, 57, 16, 27, 41], "learning_rate": 0.009212967075277622, "batch_size": 156, "loss": 0.0035066707199439408}, {"layer_params": [46, 62, 35, 54], "learning_rate": 0.009183630177293144, "batch_size": 241, "loss": 0.0009039454307639971}, {"layer_params": [25, 63, 45], "learning_rate": 0.009431123738898086, "batch_size": 86, "loss": 0.002521018766565248}, {"layer_params": [49, 59, 56, 58], "learning_rate": 0.00651811725486303, "batch_size": 50, "loss": 0.002779719301033765}, {"layer_params": [50, 57], "learning_rate": 0.006134687972038127, "batch_size": 404, "loss": 0.00083483531314414}, {"layer_params": [27, 39], "learning_rate": 0.008331736511929443, "batch_size": 390, "loss": 0.0025861942628398536}, {"layer_params": [52, 25, 38, 43, 58], "learning_rate": 0.0017481421313751521, "batch_size": 91, "loss": 0.0033874261076562106}, {"layer_params": [52, 61, 59, 53], "learning_rate": 0.006320632795738113, "batch_size": 162, "loss": 0.0014440092991571873}, {"layer_params": [29, 63, 37, 37], "learning_rate": 0.002196659379320204, "batch_size": 472, "loss": 0.0015510723006445914}, {"layer_params": [49, 40, 35, 54], "learning_rate": 0.009658347570437062, "batch_size": 152, "loss": 0.0018656391219701617}, {"layer_params": [50, 33, 26], "learning_rate": 0.0002565052090990797, "batch_size": 380, "loss": 0.0075745935831218955}, {"layer_params": [60, 46, 52, 55, 40], "learning_rate": 0.006451360837148797, "batch_size": 245, "loss": 0.001291115420171991}, {"layer_params": [20, 59, 55, 18, 39], "learning_rate": 0.0030620813517520194, "batch_size": 401, "loss": 0.0013925154006574304}, {"layer_params": [54, 31, 56], "learning_rate": 0.004405371028080758, "batch_size": 69, "loss": 0.0030459414469078184}, {"layer_params": [28, 61, 25, 46], "learning_rate": 0.005312891200111066, "batch_size": 446, "loss": 0.0011366749048465864}, {"layer_params": [41, 40, 28, 22], "learning_rate": 0.007267370783267717, "batch_size": 339, "loss": 0.0009896028792718426}, {"layer_params": [33, 33, 25, 64], "learning_rate": 0.001804165867808404, "batch_size": 484, "loss": 0.0022817924758419396}, {"layer_params": [24, 36], "learning_rate": 0.008053095379575262, "batch_size": 190, "loss": 0.004584258000832051}, {"layer_params": [32, 19], "learning_rate": 0.0060477594132717265, "batch_size": 465, "loss": 0.0037163096759468316}, {"layer_params": [64, 30, 37, 39, 28], "learning_rate": 0.003925666775439766, "batch_size": 145, "loss": 0.001901028285501525}, {"layer_params": [39, 29], "learning_rate": 0.007836661781910495, "batch_size": 360, "loss": 0.002936084996908903}, {"layer_params": [19, 40], "learning_rate": 0.0036311352223587614, "batch_size": 191, "loss": 0.0035169010376557707}, {"layer_params": [20, 63], "learning_rate": 0.009612044204663932, "batch_size": 393, "loss": 0.002345088055590168}, {"layer_params": [55, 52, 49, 34, 58], "learning_rate": 0.004563843680751556, "batch_size": 89, "loss": 0.00218953370465897}, {"layer_params": [23, 21, 51, 21, 32], "learning_rate": 0.0013638328915673392, "batch_size": 454, "loss": 0.004053711933083832}, {"layer_params": [34, 27, 50], "learning_rate": 0.0067780571534897995, "batch_size": 177, "loss": 0.002295269179157913}, {"layer_params": [16, 30, 49], "learning_rate": 0.0005263471142832477, "batch_size": 439, "loss": 0.007363859950564802}, {"layer_params": [51, 21], "learning_rate": 0.003217508657333225, "batch_size": 122, "loss": 0.0024900427903048693}, {"layer_params": [51, 54], "learning_rate": 0.0029742442806911075, "batch_size": 434, "loss": 0.0019375147204846145}, {"layer_params": [22, 48, 24, 29], "learning_rate": 0.0033869696716198236, "batch_size": 224, "loss": 0.0019219514238648116}, {"layer_params": [29, 49, 29, 22, 54], "learning_rate": 0.002657281187322425, "batch_size": 202, "loss": 0.002692290965933353}, {"layer_params": [30, 54, 63, 29], "learning_rate": 0.0037207210474500814, "batch_size": 127, "loss": 0.0025410829938482494}, {"layer_params": [46, 45, 45, 35, 22], "learning_rate": 0.001010633983093897, "batch_size": 111, "loss": 0.004744614178780466}, {"layer_params": [27, 64], "learning_rate": 0.0017811661511922346, "batch_size": 262, "loss": 0.0035526038822717965}, {"layer_params": [57, 51], "learning_rate": 0.0064757809523812325, "batch_size": 419, "loss": 0.001888980889925733}, {"layer_params": [59, 32], "learning_rate": 0.00039678936580058897, "batch_size": 293, "loss": 0.0067645509075373415}, {"layer_params": [36, 22, 50, 43, 63], "learning_rate": 0.0026534640700883383, "batch_size": 179, "loss": 0.002363810028182343}, {"layer_params": [48, 24, 55], "learning_rate": 0.006574849675327035, "batch_size": 271, "loss": 0.002070531081408262}, {"layer_params": [54, 52], "learning_rate": 0.001878398753939404, "batch_size": 472, "loss": 0.0019338551780674607}, {"layer_params": [47, 61, 47], "learning_rate": 0.00709339800694655, "batch_size": 269, "loss": 0.0011365628254134208}, {"layer_params": [60, 34, 50, 45, 20], "learning_rate": 0.002981380240064859, "batch_size": 491, "loss": 0.001997034589294344}, {"layer_params": [25, 48, 48, 18], "learning_rate": 0.009500467331326812, "batch_size": 126, "loss": 0.0023041134607046845}, {"layer_params": [60, 18], "learning_rate": 0.005772534681552385, "batch_size": 414, "loss": 0.0036102249706164}, {"layer_params": [20, 46, 43, 38], "learning_rate": 0.00922005848388035, "batch_size": 346, "loss": 0.002357562220422551}, {"layer_params": [47, 26, 21], "learning_rate": 0.005973562699465974, "batch_size": 269, "loss": 0.004674270888790489}, {"layer_params": [51, 31, 55], "learning_rate": 0.005751034080538458, "batch_size": 212, "loss": 0.0017961799527984113}, {"layer_params": [60, 36, 27], "learning_rate": 0.008207325207857118, "batch_size": 297, "loss": 0.0013025380525505171}, {"layer_params": [52, 17], "learning_rate": 0.007017131887770359, "batch_size": 47, "loss": 0.004361465484835208}, {"layer_params": [34, 23, 55, 31], "learning_rate": 0.004861459278350204, "batch_size": 141, "loss": 0.0028276145621202887}, {"layer_params": [39, 36], "learning_rate": 0.009289645086689249, "batch_size": 329, "loss": 0.0014943618536926806}, {"layer_params": [26, 59, 33, 27], "learning_rate": 0.002498550637995049, "batch_size": 451, "loss": 0.0024585452442988753}, {"layer_params": [29, 51, 55, 63], "learning_rate": 0.00514177800829181, "batch_size": 168, "loss": 0.0015362373471725732}, {"layer_params": [27, 17, 34], "learning_rate": 0.008220297514888036, "batch_size": 421, "loss": 0.00433578385040164}, {"layer_params": [29, 59], "learning_rate": 0.008448833358537577, "batch_size": 324, "loss": 0.0033239416079595685}, {"layer_params": [63, 43], "learning_rate": 0.003048384158407201, "batch_size": 173, "loss": 0.002379166993778199}, {"layer_params": [58, 27], "learning_rate": 0.006616592275707852, "batch_size": 17, "loss": 0.007318770261481405}, {"layer_params": [43, 38, 49, 56], "learning_rate": 0.002853130636933809, "batch_size": 512, "loss": 0.0015523210854735225}, {"layer_params": [18, 20, 47, 37, 35], "learning_rate": 0.0020730985023630763, "batch_size": 43, "loss": 0.00836740663042292}, {"layer_params": [19, 51, 21, 18, 23], "learning_rate": 0.00943263909443133, "batch_size": 435, "loss": 0.0022031847515609116}, {"layer_params": [38, 45, 28], "learning_rate": 0.00410273346395993, "batch_size": 183, "loss": 0.0018252183217555285}, {"layer_params": [31, 22, 59], "learning_rate": 2.8034262512739295e-05, "batch_size": 439, "loss": 0.03634209332987666}, {"layer_params": [58, 39, 29, 23, 26], "learning_rate": 0.004999883305824748, "batch_size": 447, "loss": 0.0012499279231997207}, {"layer_params": [54, 56, 18], "learning_rate": 0.0086108004109106, "batch_size": 168, "loss": 0.0018860031943768263}, {"layer_params": [39, 45], "learning_rate": 0.005014739184860307, "batch_size": 372, "loss": 0.0015343571652192622}, {"layer_params": [20, 21, 36, 59], "learning_rate": 0.007856629222374052, "batch_size": 166, "loss": 0.0032711674249731003}, {"layer_params": [46, 26, 45, 61], "learning_rate": 0.005918568392343098, "batch_size": 47, "loss": 0.004151963093318045}, {"layer_params": [46, 36], "learning_rate": 0.009101065817395055, "batch_size": 362, "loss": 0.002565356872510165}, {"layer_params": [29, 30, 61, 56], "learning_rate": 0.00690164044353197, "batch_size": 234, "loss": 0.0017841019539628178}, {"layer_params": [51, 47, 19, 16], "learning_rate": 0.005162722725179763, "batch_size": 417, "loss": 0.0014350179745815693}, {"layer_params": [63, 30, 59, 45], "learning_rate": 0.007694477925634971, "batch_size": 409, "loss": 0.0009652522957185283}, {"layer_params": [55, 47, 33], "learning_rate": 0.0037938429367480016, "batch_size": 103, "loss": 0.0027236556680873035}, {"layer_params": [39, 56, 19], "learning_rate": 0.009185020422401602, "batch_size": 468, "loss": 0.0012464749964419752}, {"layer_params": [18, 18, 25, 61], "learning_rate": 0.007266932604264657, "batch_size": 464, "loss": 0.002216249156044796}, {"layer_params": [63, 23], "learning_rate": 0.00551674976890366, "batch_size": 273, "loss": 0.003208274038042873}, {"layer_params": [23, 29, 56, 28, 58], "learning_rate": 0.005439791713542557, "batch_size": 42, "loss": 0.005675920501817018}, {"layer_params": [48, 35, 51], "learning_rate": 0.007804157091155048, "batch_size": 452, "loss": 0.0014027316239662469}, {"layer_params": [50, 26, 60], "learning_rate": 0.00561122108443523, "batch_size": 142, "loss": 0.0020552741468418388}, {"layer_params": [30, 24, 43, 44], "learning_rate": 0.0037635995669636864, "batch_size": 56, "loss": 0.0048433603532612324}, {"layer_params": [27, 33, 33, 55], "learning_rate": 0.00830860251794381, "batch_size": 148, "loss": 0.0026297998742666096}, {"layer_params": [37, 44, 45], "learning_rate": 0.0040305531533008036, "batch_size": 258, "loss": 0.0016798866738099605}, {"layer_params": [29, 36, 53], "learning_rate": 0.006474250653305382, "batch_size": 341, "loss": 0.0018715542391873896}, {"layer_params": [25, 36], "learning_rate": 0.0028015159626408933, "batch_size": 298, "loss": 0.0031787717365659774}, {"layer_params": [57, 42, 27], "learning_rate": 0.008112340943128892, "batch_size": 287, "loss": 0.0009046622988535091}, {"layer_params": [37, 61, 63, 59, 39], "learning_rate": 0.0028148402792149575, "batch_size": 259, "loss": 0.001476176866563037}, {"layer_params": [50, 27, 29], "learning_rate": 0.006317135937553919, "batch_size": 312, "loss": 0.0012287435441976414}, {"layer_params": [27, 33], "learning_rate": 0.00549399534839457, "batch_size": 375, "loss": 0.00308447593357414}, {"layer_params": [25, 44], "learning_rate": 0.0012137340874999493, "batch_size": 136, "loss": 0.0048008653428405525}, {"layer_params": [46, 34, 40], "learning_rate": 0.002136811463744106, "batch_size": 270, "loss": 0.001634661799762398}, {"layer_params": [35, 48], "learning_rate": 0.0039223933730177666, "batch_size": 56, "loss": 0.003873081086203456}, {"layer_params": [59, 42, 26, 49], "learning_rate": 0.0021043432445478675, "batch_size": 368, "loss": 0.0022277673264034094}, {"layer_params": [50, 53, 25, 48], "learning_rate": 0.006681482263587441, "batch_size": 261, "loss": 0.0022866028489079327}, {"layer_params": [64, 37, 31, 53], "learning_rate": 0.0022260217349473225, "batch_size": 492, "loss": 0.0010326011752476915}, {"layer_params": [52, 63, 46, 22, 53], "learning_rate": 0.008211436880807449, "batch_size": 296, "loss": 0.0009689748386153952}, {"layer_params": [54, 39], "learning_rate": 0.008367821039869876, "batch_size": 360, "loss": 0.001515673550311476}, {"layer_params": [25, 59, 48], "learning_rate": 0.005228877072870044, "batch_size": 186, "loss": 0.002189100512769073}, {"layer_params": [33, 28, 27, 32], "learning_rate": 0.005606253157519531, "batch_size": 482, "loss": 0.0014137893205042927}, {"layer_params": [37, 21, 33, 38, 61], "learning_rate": 0.0029015019300892616, "batch_size": 484, "loss": 0.0020339145022444426}, {"layer_params": [56, 40, 48], "learning_rate": 0.0052195869549515475, "batch_size": 272, "loss": 0.0018582355335820466}, {"layer_params": [29, 22, 63, 57], "learning_rate": 0.0002356176441110528, "batch_size": 351, "loss": 0.007793549923226237}, {"layer_params": [40, 17, 63], "learning_rate": 0.005614222652108506, "batch_size": 365, "loss": 0.002313409590860829}, {"layer_params": [23, 62, 47, 43], "learning_rate": 0.007311866017445347, "batch_size": 49, "loss": 0.004108162501361221}, {"layer_params": [55, 34, 60], "learning_rate": 0.00793281796589425, "batch_size": 192, "loss": 0.002409208588069305}, {"layer_params": [60, 32, 23], "learning_rate": 0.004851189693069182, "batch_size": 217, "loss": 0.0016431870660744607}, {"layer_params": [16, 48, 20, 25, 33], "learning_rate": 0.00826821974544782, "batch_size": 199, "loss": 0.0024998383212368937}, {"layer_params": [49, 18, 16], "learning_rate": 0.002312718654949118, "batch_size": 78, "loss": 0.005042609611991793}, {"layer_params": [35, 56], "learning_rate": 0.0033557415981460364, "batch_size": 272, "loss": 0.002613789166789502}, {"layer_params": [59, 23, 57], "learning_rate": 0.002342790110091328, "batch_size": 481, "loss": 0.0017582750832661987}, {"layer_params": [57, 41, 56, 19, 51], "learning_rate": 0.0011740438611031888, "batch_size": 39, "loss": 0.00624083147617057}, {"layer_params": [34, 23, 36], "learning_rate": 0.00596856253034957, "batch_size": 321, "loss": 0.0017703541787341237}, {"layer_params": [39, 62], "learning_rate": 0.007842617100793495, "batch_size": 291, "loss": 0.0018446974945254624}, {"layer_params": [54, 58, 48, 31, 56], "learning_rate": 0.0033767817333332294, "batch_size": 376, "loss": 0.0012390719540417193}, {"layer_params": [56, 48, 43], "learning_rate": 0.0018897043777071113, "batch_size": 69, "loss": 0.00438545300392434}, {"layer_params": [62, 42, 61], "learning_rate": 0.00908785271673359, "batch_size": 65, "loss": 0.0024483824195340276}, {"layer_params": [62, 27, 16, 38, 57], "learning_rate": 0.008216788428605347, "batch_size": 143, "loss": 0.002425727425143123}, {"layer_params": [38, 46, 47], "learning_rate": 0.0002664855842697113, "batch_size": 65, "loss": 0.008666425533592701}, {"layer_params": [46, 54, 35], "learning_rate": 0.004447825418086737, "batch_size": 298, "loss": 0.0011281471158144996}, {"layer_params": [44, 23, 62, 37, 17], "learning_rate": 0.0077513623299089816, "batch_size": 55, "loss": 0.005561492859851569}, {"layer_params": [38, 45, 30], "learning_rate": 0.009446597553539998, "batch_size": 291, "loss": 0.0014622203877661377}, {"layer_params": [45, 32, 52], "learning_rate": 0.00504723573937816, "batch_size": 306, "loss": 0.0013768278225325047}, {"layer_params": [40, 64, 29], "learning_rate": 0.009292578089040658, "batch_size": 202, "loss": 0.0017468716867733746}, {"layer_params": [34, 64, 19, 50, 64], "learning_rate": 0.003505488628416293, "batch_size": 281, "loss": 0.0021155449154321103}, {"layer_params": [23, 31], "learning_rate": 0.006994669373427945, "batch_size": 497, "loss": 0.002187947559868917}, {"layer_params": [30, 22, 33, 41, 22], "learning_rate": 0.0071100108819578765, "batch_size": 471, "loss": 0.002250872545409948}, {"layer_params": [26, 21, 59, 35, 43], "learning_rate": 0.001597330860727055, "batch_size": 491, "loss": 0.002911098103504628}, {"layer_params": [51, 51, 50], "learning_rate": 0.007010895934907769, "batch_size": 502, "loss": 0.0009178496891399845}, {"layer_params": [32, 36, 25, 25], "learning_rate": 0.0011975992109815202, "batch_size": 486, "loss": 0.004517893081065268}, {"layer_params": [46, 36], "learning_rate": 0.004833679004548366, "batch_size": 253, "loss": 0.001950655549298972}, {"layer_params": [30, 34, 47, 50], "learning_rate": 0.0007551957306351721, "batch_size": 31, "loss": 0.0074750320566818115}, {"layer_params": [27, 52, 18, 33, 31], "learning_rate": 0.005825883110788151, "batch_size": 240, "loss": 0.0023815915687009693}, {"layer_params": [64, 50, 54, 51], "learning_rate": 0.009561571210222585, "batch_size": 190, "loss": 0.001174151985323988}, {"layer_params": [21, 56, 64, 20, 31], "learning_rate": 0.00016203665813008342, "batch_size": 32, "loss": 0.012692546234466135}, {"layer_params": [19, 39, 57], "learning_rate": 0.0012285295967688638, "batch_size": 252, "loss": 0.006156774624250829}, {"layer_params": [18, 57, 22, 42], "learning_rate": 0.009579654318682549, "batch_size": 152, "loss": 0.002225214515347034}, {"layer_params": [38, 57, 50], "learning_rate": 0.009179348159969028, "batch_size": 464, "loss": 0.001143718220992014}, {"layer_params": [23, 56, 32], "learning_rate": 0.007289571962448776, "batch_size": 309, "loss": 0.0022679241304285826}, {"layer_params": [52, 41, 31, 28], "learning_rate": 0.0005614486890356984, "batch_size": 239, "loss": 0.005292547740973532}, {"layer_params": [62, 50, 39, 44, 47], "learning_rate": 0.008547019030711395, "batch_size": 428, "loss": 0.0012067802197998389}, {"layer_params": [54, 44, 26, 40], "learning_rate": 0.0056771587744682914, "batch_size": 390, "loss": 0.0009019684791564942}, {"layer_params": [37, 58, 35], "learning_rate": 0.005500286904586316, "batch_size": 452, "loss": 0.0009650230093393475}, {"layer_params": [52, 23], "learning_rate": 0.008231205298074341, "batch_size": 478, "loss": 0.0030096554034389554}, {"layer_params": [45, 51, 29], "learning_rate": 0.0006578441644090803, "batch_size": 357, "loss": 0.004964820612221956}, {"layer_params": [30, 45, 39], "learning_rate": 0.007489172933016248, "batch_size": 186, "loss": 0.0027734153368510306}, {"layer_params": [49, 60, 17, 20], "learning_rate": 0.001232507624758603, "batch_size": 374, "loss": 0.00181099311565049}, {"layer_params": [42, 33, 62, 39], "learning_rate": 0.009240725855670345, "batch_size": 51, "loss": 0.003471527660731226}, {"layer_params": [49, 59], "learning_rate": 0.009164603695902239, "batch_size": 134, "loss": 0.0027623779023997486}, {"layer_params": [61, 60, 52], "learning_rate": 0.0020062720456742902, "batch_size": 349, "loss": 0.0008955374982906506}, {"layer_params": [19, 43, 44], "learning_rate": 0.007417088488989034, "batch_size": 337, "loss": 0.0016073022491764277}, {"layer_params": [31, 27, 20, 41], "learning_rate": 0.00820032979383731, "batch_size": 115, "loss": 0.00307828911812976}, {"layer_params": [29, 55, 53, 40], "learning_rate": 0.002329825337541839, "batch_size": 244, "loss": 0.0018831231363583356}, {"layer_params": [40, 35], "learning_rate": 0.008613151475030742, "batch_size": 257, "loss": 0.0027895846054889263}, {"layer_params": [35, 32, 45, 32, 21], "learning_rate": 0.0036930930630959297, "batch_size": 459, "loss": 0.00298337705200538}, {"layer_params": [45, 58], "learning_rate": 0.004150782833882208, "batch_size": 339, "loss": 0.0026428101607598366}, {"layer_params": [30, 32, 39], "learning_rate": 0.0019447117448895444, "batch_size": 28, "loss": 0.00714308423222974}, {"layer_params": [16, 27, 29], "learning_rate": 0.0033396318697557995, "batch_size": 240, "loss": 0.003142703336197883}, {"layer_params": [28, 52, 36, 61], "learning_rate": 0.009354718663678605, "batch_size": 27, "loss": 0.007328229940030724}, {"layer_params": [42, 62, 27, 29], "learning_rate": 0.006503635466645435, "batch_size": 223, "loss": 0.0017061023623682558}, {"layer_params": [35, 40, 39, 40, 40], "learning_rate": 0.0032922665179052455, "batch_size": 95, "loss": 0.002874225601553917}, {"layer_params": [23, 30, 19, 37, 45], "learning_rate": 0.00673943960506239, "batch_size": 50, "loss": 0.004844895782880485}, {"layer_params": [43, 53, 48, 23], "learning_rate": 0.008224523073285729, "batch_size": 450, "loss": 0.000859719553263858}, {"layer_params": [27, 17, 33, 16, 20], "learning_rate": 0.0024285487950567895, "batch_size": 194, "loss": 0.004368447670713067}, {"layer_params": [57, 35, 63], "learning_rate": 0.008576346818584475, "batch_size": 64, "loss": 0.003174438202986494}, {"layer_params": [33, 18], "learning_rate": 0.007480377498796797, "batch_size": 294, "loss": 0.0020061953517142685}, {"layer_params": [23, 31, 36, 61], "learning_rate": 0.005211843369401056, "batch_size": 321, "loss": 0.002984777248930186}, {"layer_params": [58, 24, 35, 19, 58], "learning_rate": 0.005959816725083464, "batch_size": 313, "loss": 0.0015413707855623216}, {"layer_params": [43, 61, 53, 40, 31], "learning_rate": 0.004950446029241519, "batch_size": 60, "loss": 0.0028979550884105265}, {"layer_params": [16, 48, 17], "learning_rate": 0.00964657390649301, "batch_size": 352, "loss": 0.0032182899909093976}, {"layer_params": [50, 34, 44, 57], "learning_rate": 0.0072838669682406135, "batch_size": 78, "loss": 0.004135384769178927}, {"layer_params": [35, 28, 24, 51], "learning_rate": 0.006962495249782227, "batch_size": 145, "loss": 0.002187964568147436}, {"layer_params": [31, 60, 23, 51, 19], "learning_rate": 0.001327300111862461, "batch_size": 223, "loss": 0.0025068186887074262}, {"layer_params": [49, 62], "learning_rate": 0.0010982097140090604, "batch_size": 468, "loss": 0.0035685056541115046}, {"layer_params": [62, 59, 16, 56, 18], "learning_rate": 0.00866529208891547, "batch_size": 511, "loss": 0.0007030158565612509}, {"layer_params": [25, 46, 62, 33], "learning_rate": 0.0012843137556700652, "batch_size": 237, "loss": 0.0031097412295639517}, {"layer_params": [28, 63, 36, 25, 31], "learning_rate": 0.004031817295067042, "batch_size": 177, "loss": 0.0022461289656348525}, {"layer_params": [34, 49], "learning_rate": 0.008692299101013625, "batch_size": 414, "loss": 0.0027498282119631768}, {"layer_params": [47, 47, 34, 25, 43], "learning_rate": 0.009104267144512134, "batch_size": 253, "loss": 0.0014901735004968942}, {"layer_params": [38, 54, 48, 47, 22], "learning_rate": 0.0041184029049046, "batch_size": 31, "loss": 0.005748433069093153}, {"layer_params": [59, 19, 30, 34, 29], "learning_rate": 0.002216483498080413, "batch_size": 403, "loss": 0.0031507883383892475}, {"layer_params": [21, 48, 62, 56, 48], "learning_rate": 0.006557177467594929, "batch_size": 455, "loss": 0.0011315708950860425}, {"layer_params": [22, 56, 33, 16, 35], "learning_rate": 0.008782053493741004, "batch_size": 86, "loss": 0.0036513526435010134}, {"layer_params": [38, 24, 19, 32, 54], "learning_rate": 0.005223929004766785, "batch_size": 405, "loss": 0.0032414184045046566}, {"layer_params": [46, 50, 29, 26, 36], "learning_rate": 0.0017933460433478328, "batch_size": 75, "loss": 0.0033960062824189663}, {"layer_params": [27, 34], "learning_rate": 0.003165540249170762, "batch_size": 256, "loss": 0.0021606410678941756}, {"layer_params": [45, 23], "learning_rate": 0.0014519970827086375, "batch_size": 181, "loss": 0.005054818110074848}, {"layer_params": [38, 47, 27, 58], "learning_rate": 0.0006912874717547184, "batch_size": 262, "loss": 0.004404518220108003}, {"layer_params": [55, 16], "learning_rate": 0.0047273111334485045, "batch_size": 462, "loss": 0.0022936620377004145}, {"layer_params": [32, 53, 27, 30, 51], "learning_rate": 0.004004947323454473, "batch_size": 171, "loss": 0.0017697907914407552}, {"layer_params": [29, 30, 52, 41, 56], "learning_rate": 0.006063151237934034, "batch_size": 114, "loss": 0.0020945792854763566}, {"layer_params": [34, 57], "learning_rate": 0.006221632709939743, "batch_size": 31, "loss": 0.0044880134484265}, {"layer_params": [44, 57, 38, 23], "learning_rate": 0.002387562947040278, "batch_size": 262, "loss": 0.0023927737248595803}, {"layer_params": [63, 40, 18, 58], "learning_rate": 0.006280814066553442, "batch_size": 448, "loss": 0.0017343415261711925}, {"layer_params": [64, 49], "learning_rate": 0.003291849624796589, "batch_size": 89, "loss": 0.003091461565345526}, {"layer_params": [49, 60, 20, 58], "learning_rate": 0.0035858939298821207, "batch_size": 464, "loss": 0.0009537579998141155}, {"layer_params": [59, 57], "learning_rate": 0.000714347590424369, "batch_size": 178, "loss": 0.004933646104764194}, {"layer_params": [35, 18], "learning_rate": 0.00655663533761313, "batch_size": 274, "loss": 0.0015044673474039882}, {"layer_params": [51, 45, 22, 57, 60], "learning_rate": 0.0071848085906689434, "batch_size": 33, "loss": 0.004382762068416923}, {"layer_params": [35, 40], "learning_rate": 0.009873002805226391, "batch_size": 306, "loss": 0.00198116397485137}, {"layer_params": [52, 32], "learning_rate": 0.00040847263465862925, "batch_size": 162, "loss": 0.007308852048590779}, {"layer_params": [53, 43, 46, 21, 38], "learning_rate": 0.0007090532805025064, "batch_size": 289, "loss": 0.0037670192052610216}, {"layer_params": [48, 16, 34, 53], "learning_rate": 0.0005186693745728159, "batch_size": 107, "loss": 0.006488684150390327}, {"layer_params": [52, 63], "learning_rate": 0.002850598469101528, "batch_size": 277, "loss": 0.0020400677737779913}, {"layer_params": [43, 22, 37, 52], "learning_rate": 0.0012169884513298073, "batch_size": 71, "loss": 0.006806817415636033}, {"layer_params": [54, 39, 21, 44, 44], "learning_rate": 0.002806890266364824, "batch_size": 165, "loss": 0.0017942216154187918}, {"layer_params": [58, 64, 62, 49], "learning_rate": 0.00523163739455923, "batch_size": 341, "loss": 0.0009083039278630167}, {"layer_params": [16, 16, 23], "learning_rate": 0.000527549717806233, "batch_size": 191, "loss": 0.008438407378271222}, {"layer_params": [22, 25, 47, 55], "learning_rate": 0.004318480629452827, "batch_size": 47, "loss": 0.006264996761456132}, {"layer_params": [56, 39, 25, 53, 64], "learning_rate": 0.0004907091506736721, "batch_size": 215, "loss": 0.005484495505224913}, {"layer_params": [56, 47, 41, 36], "learning_rate": 0.0004660590493299046, "batch_size": 339, "loss": 0.005456378906965256}, {"layer_params": [26, 55], "learning_rate": 0.006733130906407351, "batch_size": 265, "loss": 0.0021022333309520034}, {"layer_params": [34, 49], "learning_rate": 0.007111766562602367, "batch_size": 255, "loss": 0.0031032102880999444}, {"layer_params": [39, 47], "learning_rate": 0.009882376635565116, "batch_size": 92, "loss": 0.0025385396310593934}, {"layer_params": [21, 61, 63], "learning_rate": 0.00877217859686141, "batch_size": 159, "loss": 0.0022643862036056815}, {"layer_params": [63, 48], "learning_rate": 0.00617736886731252, "batch_size": 209, "loss": 0.0025473987951409073}, {"layer_params": [34, 53, 23, 31], "learning_rate": 0.0066633998248412105, "batch_size": 252, "loss": 0.00253719630651176}, {"layer_params": [61, 23, 31], "learning_rate": 0.0009203835244638763, "batch_size": 493, "loss": 0.005062241000123322}, {"layer_params": [50, 26, 55], "learning_rate": 0.002912295534386376, "batch_size": 443, "loss": 0.001673524563666433}, {"layer_params": [46, 32], "learning_rate": 0.00594614407644212, "batch_size": 402, "loss": 0.0030584216164425016}, {"layer_params": [21, 41, 42, 34], "learning_rate": 0.005028984132498155, "batch_size": 144, "loss": 0.00301124301739037}, {"layer_params": [43, 54, 54], "learning_rate": 0.003743857035682209, "batch_size": 355, "loss": 0.0015849917044397444}, {"layer_params": [16, 45, 24], "learning_rate": 0.0073924252658663595, "batch_size": 388, "loss": 0.0030857130326330663}, {"layer_params": [29, 24, 34, 38], "learning_rate": 0.007587614523072655, "batch_size": 486, "loss": 0.0013301756139844655}, {"layer_params": [48, 35], "learning_rate": 0.007409816093002271, "batch_size": 370, "loss": 0.0009067436761688441}, {"layer_params": [34, 23, 55], "learning_rate": 0.006460532288887882, "batch_size": 290, "loss": 0.002102002657484263}, {"layer_params": [46, 58, 17, 20, 64], "learning_rate": 0.006515792545628368, "batch_size": 70, "loss": 0.002934602970490232}, {"layer_params": [51, 64, 33, 34, 48], "learning_rate": 0.005048058022367665, "batch_size": 319, "loss": 0.0010672200069529935}, {"layer_params": [42, 44], "learning_rate": 0.0007802495942579243, "batch_size": 482, "loss": 0.004648018397856504}, {"layer_params": [40, 34, 45], "learning_rate": 0.00895162913356833, "batch_size": 399, "loss": 0.0016135321429464966}, {"layer_params": [33, 46], "learning_rate": 0.005796200393848864, "batch_size": 232, "loss": 0.0019521229772362857}, {"layer_params": [36, 62, 61, 45], "learning_rate": 0.005224990214562299, "batch_size": 380, "loss": 0.001045241592801176}, {"layer_params": [42, 25, 45, 21, 37], "learning_rate": 0.0022989441097273585, "batch_size": 338, "loss": 0.002500725770369172}, {"layer_params": [34, 55, 20, 39, 63], "learning_rate": 0.002377152236223311, "batch_size": 458, "loss": 0.0017330509307794274}, {"layer_params": [58, 58], "learning_rate": 0.003715326864761664, "batch_size": 75, "loss": 0.0023179234261624516}, {"layer_params": [57, 26, 62, 30, 58], "learning_rate": 0.009823542280844278, "batch_size": 351, "loss": 0.0018326230254024267}, {"layer_params": [40, 38, 37], "learning_rate": 0.007035677005849477, "batch_size": 16, "loss": 0.008824913913849741}, {"layer_params": [61, 52], "learning_rate": 0.00976033995364453, "batch_size": 177, "loss": 0.0014210849243681879}, {"layer_params": [17, 21, 63, 62, 59], "learning_rate": 0.00039518462126449463, "batch_size": 147, "loss": 0.007969191879965365}, {"layer_params": [45, 28, 17], "learning_rate": 0.00825109674683699, "batch_size": 79, "loss": 0.0032590251322835682}, {"layer_params": [62, 16, 39, 64, 21], "learning_rate": 0.00032855289211331824, "batch_size": 18, "loss": 0.009019547943025827}, {"layer_params": [52, 53, 33, 28, 33], "learning_rate": 0.006242172924491677, "batch_size": 25, "loss": 0.006589572913944721}, {"layer_params": [42, 32, 27], "learning_rate": 0.0068697673857751876, "batch_size": 360, "loss": 0.0022576234198641034}, {"layer_params": [18, 30, 60, 60], "learning_rate": 0.0017871414441661389, "batch_size": 312, "loss": 0.002541891431901604}, {"layer_params": [50, 55, 41, 43], "learning_rate": 0.005273469295046122, "batch_size": 502, "loss": 0.0007445688539883122}, {"layer_params": [37, 39], "learning_rate": 0.0007269491383672199, "batch_size": 64, "loss": 0.0075020099524408575}, {"layer_params": [37, 56, 50, 61], "learning_rate": 0.007408545435516041, "batch_size": 69, "loss": 0.0019746733980719}, {"layer_params": [63, 19], "learning_rate": 0.0042310648480107455, "batch_size": 223, "loss": 0.0042707767593674366}, {"layer_params": [44, 55, 42, 44], "learning_rate": 0.0057988391455435035, "batch_size": 410, "loss": 0.0008987132064066827}, {"layer_params": [32, 30, 31, 47], "learning_rate": 0.001233347743973504, "batch_size": 355, "loss": 0.002389877123059705}, {"layer_params": [45, 63], "learning_rate": 0.009254050484326487, "batch_size": 117, "loss": 0.0019618990237358956}, {"layer_params": [45, 27], "learning_rate": 0.00668745452331669, "batch_size": 386, "loss": 0.0030984104704111816}, {"layer_params": [42, 45, 51], "learning_rate": 0.004305334808930111, "batch_size": 357, "loss": 0.001605351282050833}, {"layer_params": [34, 16], "learning_rate": 0.0063463591034394915, "batch_size": 171, "loss": 0.0036639220477081833}, {"layer_params": [64, 43], "learning_rate": 0.009517565423124853, "batch_size": 156, "loss": 0.002132919323630631}, {"layer_params": [64, 35, 63, 44, 23], "learning_rate": 0.004226057134194951, "batch_size": 268, "loss": 0.0022838334017433225}, {"layer_params": [22, 36, 49], "learning_rate": 0.0012087064493308242, "batch_size": 175, "loss": 0.0057374252611771225}, {"layer_params": [40, 22], "learning_rate": 0.004627998678883159, "batch_size": 498, "loss": 0.004229310704395175}, {"layer_params": [29, 59], "learning_rate": 0.0006801619600007596, "batch_size": 356, "loss": 0.005254929235670716}, {"layer_params": [53, 22, 18, 59, 44], "learning_rate": 0.007978157802456238, "batch_size": 177, "loss": 0.03885371597483754}, {"layer_params": [50, 39], "learning_rate": 0.00290549454524069, "batch_size": 300, "loss": 0.0017752141889650374}, {"layer_params": [55, 56, 29, 41], "learning_rate": 0.005381376308795969, "batch_size": 276, "loss": 0.0012019693991169333}, {"layer_params": [55, 62, 59, 48, 54], "learning_rate": 0.00837924578189156, "batch_size": 283, "loss": 0.0007668003544677049}, {"layer_params": [62, 57], "learning_rate": 0.009984599074500859, "batch_size": 45, "loss": 0.0031298607343342153}, {"layer_params": [41, 61], "learning_rate": 0.0020266557519627694, "batch_size": 149, "loss": 0.003844606645870954}, {"layer_params": [34, 30], "learning_rate": 0.0072948741578899665, "batch_size": 152, "loss": 0.003962527583353221}, {"layer_params": [20, 41], "learning_rate": 0.0038505030965413525, "batch_size": 498, "loss": 0.003929797480814159}, {"layer_params": [32, 45, 17], "learning_rate": 0.009817206440879009, "batch_size": 192, "loss": 0.0027716163825243713}, {"layer_params": [31, 24, 26, 19, 53], "learning_rate": 0.0015626688418642763, "batch_size": 120, "loss": 0.004667288768105209}, {"layer_params": [39, 63, 40, 17, 38], "learning_rate": 0.007596270862529753, "batch_size": 128, "loss": 0.0024416118627414106}, {"layer_params": [31, 30], "learning_rate": 0.008344636594502386, "batch_size": 346, "loss": 0.003030632317531854}, {"layer_params": [50, 59, 61, 46, 31], "learning_rate": 0.008179053265885233, "batch_size": 40, "loss": 0.004109897487796843}, {"layer_params": [64, 38, 64, 38, 52], "learning_rate": 0.009743822746006315, "batch_size": 229, "loss": 0.0007289076148299501}, {"layer_params": [57, 19, 47, 16, 23], "learning_rate": 0.0016129922120162478, "batch_size": 402, "loss": 0.004159207029733807}, {"layer_params": [43, 42, 41], "learning_rate": 0.006641604565860158, "batch_size": 415, "loss": 0.0013133232854306697}, {"layer_params": [25, 58], "learning_rate": 0.004710959752270109, "batch_size": 194, "loss": 0.0017454811057541519}, {"layer_params": [17, 33, 20, 40, 17], "learning_rate": 0.0032855639041269144, "batch_size": 305, "loss": 0.0038035105913877486}, {"layer_params": [50, 51, 34, 40, 33], "learning_rate": 0.007321853189682722, "batch_size": 34, "loss": 0.005051759220659733}, {"layer_params": [64, 56, 44, 29, 18], "learning_rate": 0.008428760390894772, "batch_size": 40, "loss": 0.004501415560953319}, {"layer_params": [64, 58], "learning_rate": 0.008322617599267177, "batch_size": 184, "loss": 0.0019901322107762098}, {"layer_params": [39, 55, 27, 25], "learning_rate": 0.004454201884764985, "batch_size": 102, "loss": 0.003217945131473243}, {"layer_params": [36, 60, 30, 39], "learning_rate": 0.007039844517546663, "batch_size": 234, "loss": 0.0011419522593496367}, {"layer_params": [41, 59, 44, 26, 16], "learning_rate": 0.007381883408453088, "batch_size": 83, "loss": 0.002612488828599453}, {"layer_params": [63, 31, 17, 25], "learning_rate": 0.0031364717350352823, "batch_size": 57, "loss": 0.0037714141979813577}, {"layer_params": [40, 30], "learning_rate": 5.499717631040005e-05, "batch_size": 368, "loss": 0.043949763625860214}, {"layer_params": [54, 51, 64, 35, 34], "learning_rate": 0.0004955840456925053, "batch_size": 228, "loss": 0.0055158914113417265}, {"layer_params": [58, 17, 22, 43, 60], "learning_rate": 0.004373419348863599, "batch_size": 237, "loss": 0.0016729920788202434}, {"layer_params": [17, 64, 24, 19, 22], "learning_rate": 0.0058033430235533735, "batch_size": 263, "loss": 0.0024340392532758415}, {"layer_params": [61, 39], "learning_rate": 0.005325358846813115, "batch_size": 472, "loss": 0.000993898761807941}, {"layer_params": [20, 47], "learning_rate": 0.00625850558098812, "batch_size": 32, "loss": 0.005616393589880317}, {"layer_params": [45, 31, 50, 62, 28], "learning_rate": 0.005427990421589038, "batch_size": 283, "loss": 0.0017064866505097599}, {"layer_params": [54, 38], "learning_rate": 0.005392895658231186, "batch_size": 335, "loss": 0.0014202285825740547}, {"layer_params": [64, 63, 62], "learning_rate": 0.000390701650045631, "batch_size": 373, "loss": 0.003640099517069757}, {"layer_params": [58, 43], "learning_rate": 0.007423847183742715, "batch_size": 180, "loss": 0.002117953433189541}, {"layer_params": [34, 59, 20], "learning_rate": 0.0006451265640042861, "batch_size": 303, "loss": 0.004484814389143139}, {"layer_params": [19, 32, 64, 19], "learning_rate": 0.008377988677811832, "batch_size": 298, "loss": 0.0030502222711220385}, {"layer_params": [62, 17, 44, 39, 28], "learning_rate": 0.006954532200396657, "batch_size": 156, "loss": 0.0023357655701693146}, {"layer_params": [48, 34, 43], "learning_rate": 0.0014534641379465542, "batch_size": 475, "loss": 0.0017201447556726634}, {"layer_params": [41, 35], "learning_rate": 0.0014661443018074531, "batch_size": 290, "loss": 0.0032962444238364697}, {"layer_params": [53, 29, 57, 40], "learning_rate": 0.008514769581290268, "batch_size": 374, "loss": 0.0018851540167815982}, {"layer_params": [37, 19, 61, 57], "learning_rate": 0.0078223581021816, "batch_size": 228, "loss": 0.0020396530034486205}, {"layer_params": [56, 21, 48, 57, 21], "learning_rate": 0.007406259851026868, "batch_size": 385, "loss": 0.0011098396312445402}, {"layer_params": [57, 33, 53], "learning_rate": 0.0001959237297053996, "batch_size": 47, "loss": 0.012669365727342665}, {"layer_params": [24, 41, 28, 52], "learning_rate": 0.004405935430727101, "batch_size": 221, "loss": 0.0022496231482364236}, {"layer_params": [18, 61], "learning_rate": 0.003687786391724478, "batch_size": 244, "loss": 0.0034940274455584584}, {"layer_params": [19, 53, 59, 21, 47], "learning_rate": 0.00015146294147315589, "batch_size": 292, "loss": 0.009768541138619184}, {"layer_params": [16, 61, 55, 47], "learning_rate": 0.002947436523154605, "batch_size": 165, "loss": 0.0036010770336724817}, {"layer_params": [46, 47, 27, 27, 52], "learning_rate": 0.0030077532792245954, "batch_size": 32, "loss": 0.005254081084858626}, {"layer_params": [47, 26], "learning_rate": 0.006432241702918384, "batch_size": 286, "loss": 0.0026511068758554757}, {"layer_params": [37, 34], "learning_rate": 0.0023276819833960463, "batch_size": 411, "loss": 0.0026120140426792206}, {"layer_params": [53, 41, 54], "learning_rate": 0.009866348263771273, "batch_size": 391, "loss": 0.0017793336405884474}, {"layer_params": [42, 23, 51], "learning_rate": 0.005953703926124132, "batch_size": 60, "loss": 0.0036376016214489937}, {"layer_params": [19, 49], "learning_rate": 0.005987101134476855, "batch_size": 96, "loss": 0.0065802093734964725}, {"layer_params": [56, 35, 54, 54, 42], "learning_rate": 0.00781339118319191, "batch_size": 477, "loss": 0.0014771628449670971}, {"layer_params": [23, 28, 30, 30], "learning_rate": 0.004118369471922732, "batch_size": 366, "loss": 0.0022583065193612127}, {"layer_params": [36, 51, 16, 48], "learning_rate": 0.007586037238050531, "batch_size": 69, "loss": 0.003281297691864893}, {"layer_params": [18, 16, 31], "learning_rate": 0.0069165208975790525, "batch_size": 105, "loss": 0.006215098719112575}, {"layer_params": [30, 31, 20], "learning_rate": 0.005739046312866887, "batch_size": 360, "loss": 0.0022274570434819905}, {"layer_params": [50, 25, 42, 35], "learning_rate": 0.00035405786459845925, "batch_size": 371, "loss": 0.005580095648765564}, {"layer_params": [23, 62, 26, 34, 26], "learning_rate": 0.003990029724249791, "batch_size": 101, "loss": 0.0052571978536434475}, {"layer_params": [45, 16], "learning_rate": 0.0018819498072058486, "batch_size": 164, "loss": 0.0033990143472328784}, {"layer_params": [59, 22, 37, 38], "learning_rate": 0.003412189354460596, "batch_size": 92, "loss": 0.0032542089058551936}, {"layer_params": [48, 37, 45, 22], "learning_rate": 0.0028580575749006408, "batch_size": 158, "loss": 0.002564491966040805}, {"layer_params": [20, 62, 55], "learning_rate": 0.008352651593144644, "batch_size": 153, "loss": 0.001742525730514899}, {"layer_params": [55, 35, 44], "learning_rate": 0.009360345717732558, "batch_size": 24, "loss": 0.006289510156493634}, {"layer_params": [26, 51, 29, 20, 34], "learning_rate": 0.0004969763586570385, "batch_size": 267, "loss": 0.006720215347595513}, {"layer_params": [27, 48, 23], "learning_rate": 0.008477487773302731, "batch_size": 458, "loss": 0.0017256509338039905}, {"layer_params": [16, 35, 16], "learning_rate": 0.006350378612917593, "batch_size": 175, "loss": 0.00563041624147445}, {"layer_params": [44, 41, 50, 31], "learning_rate": 0.008365263142246655, "batch_size": 30, "loss": 0.005664588643703609}, {"layer_params": [40, 51], "learning_rate": 0.009027676801229784, "batch_size": 199, "loss": 0.0021715611696708948}, {"layer_params": [64, 51, 42], "learning_rate": 0.0042578296543076466, "batch_size": 242, "loss": 0.0023796113848220555}, {"layer_params": [60, 42], "learning_rate": 0.0029103608653107712, "batch_size": 48, "loss": 0.005697130186017602}, {"layer_params": [35, 39, 50, 47, 18], "learning_rate": 0.00047128245410113696, "batch_size": 412, "loss": 0.004582651760429144}, {"layer_params": [49, 37, 38, 44, 24], "learning_rate": 0.00420615445576239, "batch_size": 441, "loss": 0.0011570885381661355}, {"layer_params": [33, 48], "learning_rate": 0.007693754987055457, "batch_size": 279, "loss": 0.0014414303563535214}, {"layer_params": [25, 31, 26], "learning_rate": 0.004246166908760847, "batch_size": 105, "loss": 0.004808356112334877}, {"layer_params": [42, 26, 19, 52], "learning_rate": 0.002510427837181255, "batch_size": 392, "loss": 0.0030909719364717605}, {"layer_params": [38, 21], "learning_rate": 0.0036437565136273366, "batch_size": 404, "loss": 0.001861994171049446}, {"layer_params": [47, 41], "learning_rate": 0.008457940340155515, "batch_size": 323, "loss": 0.0022938880673609675}, {"layer_params": [55, 28], "learning_rate": 0.006189980179245494, "batch_size": 62, "loss": 0.003554040442686528}, {"layer_params": [46, 59, 27, 21, 55], "learning_rate": 0.00930426938875184, "batch_size": 147, "loss": 0.0014098414126783609}, {"layer_params": [20, 63, 53, 16], "learning_rate": 0.009900401678170299, "batch_size": 154, "loss": 0.002931797159835696}, {"layer_params": [53, 26, 53, 59, 27], "learning_rate": 0.0033026942491204054, "batch_size": 19, "loss": 0.006837121378630399}, {"layer_params": [43, 19, 18, 46], "learning_rate": 0.008752977796132606, "batch_size": 242, "loss": 0.0030411142017692325}, {"layer_params": [21, 28], "learning_rate": 0.004582548449231907, "batch_size": 222, "loss": 0.007277863100171089}, {"layer_params": [62, 38, 50, 48, 18], "learning_rate": 0.004863106572148184, "batch_size": 429, "loss": 0.0011230662278831004}, {"layer_params": [29, 60, 61, 45, 57], "learning_rate": 0.008444363407906613, "batch_size": 303, "loss": 0.0009856790758203714}, {"layer_params": [60, 52], "learning_rate": 0.002749102403501727, "batch_size": 458, "loss": 0.0014099538675509393}, {"layer_params": [24, 57], "learning_rate": 0.005773677488351405, "batch_size": 496, "loss": 0.001785150106297806}, {"layer_params": [48, 63, 30], "learning_rate": 0.009208939696218398, "batch_size": 271, "loss": 0.0013398056675214321}, {"layer_params": [50, 37], "learning_rate": 0.00614713128677562, "batch_size": 186, "loss": 0.0038885582401417197}, {"layer_params": [23, 19, 52, 54, 54], "learning_rate": 0.005921910952277053, "batch_size": 342, "loss": 0.002539517907425761}, {"layer_params": [57, 55, 24, 51, 59], "learning_rate": 0.000597609798701749, "batch_size": 292, "loss": 0.0029828236903995274}, {"layer_params": [31, 38], "learning_rate": 0.00798035210203046, "batch_size": 439, "loss": 0.0015097377146594227}, {"layer_params": [47, 39, 51, 28], "learning_rate": 0.004029691005789026, "batch_size": 471, "loss": 0.0012727897556032985}, {"layer_params": [40, 55, 27, 64, 26], "learning_rate": 0.004572527864459788, "batch_size": 277, "loss": 0.0019381315598729998}, {"layer_params": [27, 63, 48], "learning_rate": 0.005966405510560071, "batch_size": 266, "loss": 0.001608443857403472}, {"layer_params": [38, 26, 51, 64, 32], "learning_rate": 0.004644565263861573, "batch_size": 446, "loss": 0.0018977737345267087}, {"layer_params": [23, 59, 36], "learning_rate": 0.002387692391888226, "batch_size": 262, "loss": 0.0027413220377638936}]